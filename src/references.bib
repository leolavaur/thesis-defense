% LTEX: enabled=false

@online{_1998DARPAIntrusion_,
  title = {1998 {{DARPA Intrusion Detection Evaluation Dataset}} \textbar{} {{MIT Lincoln Laboratory}}},
  url = {https://www.ll.mit.edu/r-d/datasets/1998-darpa-intrusion-detection-evaluation-dataset},
  urldate = {2024-06-19}
}

@online{_NetworkAnomalyDetection_,
  title = {Network {{Anomaly Detection Using Federated Deep Autoencoding Gaussian Mixture Model}} \textbar{} {{Machine Learning}} for {{Networking}}},
  url = {https://dlnext.acm.org/doi/10.1007/978-3-030-45778-5_1},
  urldate = {2024-04-12},
  langid = {english},
  organization = {Guide Proceedings}
}

@online{_TechnicalSupportClarivate_,
  title = {Technical {{Support}} - {{Clarivate Analytics}}},
  url = {https://support.clarivate.com/ScientificandAcademicResearch/s/Product-or-technical-question?language=en_US},
  urldate = {2023-05-05}
}

@online{_TrafficFlowPrediction_,
  title = {Traffic {{Flow Prediction Based}} on {{Federated Learning}} with {{Joint PCA Compression}} and {{Bayesian Optimization}} \textbar{} {{IEEE Conference Publication}} \textbar{} {{IEEE Xplore}}},
  url = {https://ieeexplore.ieee.org/document/9945217},
  urldate = {2024-04-02}
}

@inproceedings{abbasi_FLITCNovelFederated_2022,
  title = {{{FLITC}}: {{A Novel Federated Learning-Based Method}} for {{IoT Traffic Classification}}},
  shorttitle = {{{FLITC}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Smart Computing}} ({{SMARTCOMP}})},
  author = {Abbasi, Mahmoud and Taherkordi, Amir and Shahraki, Amin},
  date = {2022-06},
  pages = {206--212},
  issn = {2693-8340},
  doi = {10.1109/SMARTCOMP55677.2022.00055},
  abstract = {Internet of Things (IoT) systems are rightly receiving considerable interest for many real-world applications, from in-body networks to satellite networks. Such a massive-scale system generates a considerable amount of traffic data, making IoT systems a distributed data source generator. For many reasons, such as the functionality of IoT applications and Quality of Service (QoS) provisioning, classifying these traffic data is of high importance. In the last few years, widespread interest has been expressed in applying Machine Learning (ML)-based techniques for Network Traffic Classification (NTC) tasks. However, the traditional centralized learning-based traffic classifiers pose serious challenges, especially in IoT networks. The centralized ML techniques call for collecting a large amount of data from various IoT devices, which in turn introduces data governance and privacy challenges. Furthermore, in the centralized ML, training data need to be transferred to the Cloud, which increases communication cost and latency. To address these problems, we propose Federated Learning (FL) Internet of Things (IoT) Traffic Classifier (FLITC)-a Federated Learning (FL)-based IoT traffic classification method which is based on the Multi-Layer Perception (MLP) neural network and holds the local data unimpaired on IoT devices by sending only the learned parameters to the aggregation server. Our experimental results show that the FLITC beats centralized learning in preserving the privacy of sensitive data and offers a better degree of accuracy at the cost of a longer training time.},
  eventtitle = {2022 {{IEEE International Conference}} on {{Smart Computing}} ({{SMARTCOMP}})},
  keywords = {Costs,Data privacy,Federated Learning,Internet of Things,Network Traffic Analysis,Privacy,Quality of service,Soft sensors,Telecommunication traffic,Traffic Classification,Training,Training data}
}

@article{abdel-basset_PrivacyPreservedCyberattackDetection_2022,
  title = {Privacy-{{Preserved Cyberattack Detection}} in {{Industrial Edge}} of {{Things}} ({{IEoT}}): {{A Blockchain-Orchestrated Federated Learning Approach}}},
  shorttitle = {Privacy-{{Preserved Cyberattack Detection}} in {{Industrial Edge}} of {{Things}} ({{IEoT}})},
  author = {Abdel-Basset, Mohamed and Moustafa, Nour and Hawash, Hossam},
  date = {2022-11},
  journaltitle = {IEEE Transactions on Industrial Informatics},
  volume = {18},
  number = {11},
  pages = {7920--7934},
  issn = {1941-0050},
  doi = {10.1109/TII.2022.3167663},
  url = {https://ieeexplore.ieee.org/abstract/document/9760107},
  urldate = {2024-04-12},
  abstract = {The Industrial Internet ofThings (IIoT) plays an essential role in the digital renovation of conventional industries to Industry 4.0. With the connectivity of sensors, actuators, appliances, and other industrial objects, IIoT enables data availability, improved analytics, and automatic control. Thanks to the complex distributed nature, a wide range of stealthy and evolving cyberattacks become a major threat to the trustworthiness and security of IIoT systems. This makes the standard security procedures unable to assure the trustworthiness of IIoT that protect against cyberattacks. As a remedy, this article presents a blockchain-orchestrated edge intelligence (BoEI) framework that integrates an innovative decentralized federated learning (called Fed-Trust) for cyberattack detection in IIoT. In the Fed-Trust, a temporal convolutional generative network is introduced to enable semi-supervised learning from semi-labeled data. BoEI includes reputation-based blockchain to enable decentralized recording and verification of the transactions for guaranteeing the security and privacy of data and gradients. Fog computing is exploited to offload the block mining operation from the edge side thereby improving the overall computation and communication performance of Fed-Trust. Proof of concept simulations using two public datasets validate the robustness and efficiency of the Fed-Trust over the cutting-edge cyberattack detection approaches.},
  eventtitle = {{{IEEE Transactions}} on {{Industrial Informatics}}},
  keywords = {Blockchains,Cyberattack detection,Data models,federated learning (FL),Industrial Internet of Things,industrial Internet of Things (IIoT),privacy,Privacy,security,Security,semi-supervised generative adversarial network (GAN),Servers,Training,trustworthiness}
}

@article{abdelbasset_EfficientLightweightConvolutional_2022,
  title = {Efficient and {{Lightweight Convolutional Networks}} for {{IoT Malware Detection}}: {{A Federated Learning Approach}}},
  shorttitle = {Efficient and {{Lightweight Convolutional Networks}} for {{IoT Malware Detection}}},
  author = {Abdelbasset, Mohamed and Hawash, Hossam and Sallam, Karam M. and Elgendi, Ibrahim and Munasinghe, Kumudu and Jamalipour, Abbas},
  date = {2022},
  journaltitle = {IEEE Internet of Things Journal},
  pages = {1--1},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2022.3229005},
  abstract = {Over the past few years, billions of unsecured Internet of Things (IoT) devices have been produced and released, and that number will only grow as wireless technology advances. As a result of their susceptibility to malware, effective methods have become necessary for identifying IoT malware. However, the low generalizability and the non-independently and identically distributed data (non-IID) still pose a major challenge to achieving this goal. In this work, a new federated malware detection paradigm, termed FED-MAL, is introduced to collaboratively train multiple distributed edge devices to detect malware. In FED-MAL, the malware binaries are transformed into image format to lessen the impact on non-IID, and then a compact convolutional model, named AM-NET, is proposed to learn the malware patterns as an image recognition task. The compact nature of AM-NET makes it an appropriate choice for deployment on resource-constrained IoT devices. Following, a refined edge-based adversarial training is given in FED-MAL to empower generalizability and resistibility by generating adversarial samples from various participating clients. Experimental evaluation on publicly available malware datasets shows that the FED-MAL is efficacious, reliable, expandable, generalizable, and communication efficient.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {adversarial attacks,Deep Learning,Detectors,Edge/Fog Computing,Feature extraction,Federated Learning,Image edge detection,Internet of Things,Malware,Malware Detection,Security,Training}
}

@online{abdelmoniem_ImpactDeviceBehavioral_2021,
  title = {On the {{Impact}} of {{Device}} and {{Behavioral Heterogeneity}} in {{Federated Learning}}},
  author = {Abdelmoniem, Ahmed M. and Ho, Chen-Yu and Papageorgiou, Pantelis and Bilal, Muhammad and Canini, Marco},
  date = {2021-02-15},
  eprint = {2102.07500},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2102.07500},
  urldate = {2023-11-02},
  abstract = {Federated learning (FL) is becoming a popular paradigm for collaborative learning over distributed, private datasets owned by non-trusting entities. FL has seen successful deployment in production environments, and it has been adopted in services such as virtual keyboards, autocompletion, item recommendation, and several IoT applications. However, FL comes with the challenge of performing training over largely heterogeneous datasets, devices, and networks that are out of the control of the centralized FL server. Motivated by this inherent setting, we make a first step towards characterizing the impact of device and behavioral heterogeneity on the trained model. We conduct an extensive empirical study spanning close to 1.5K unique configurations on five popular FL benchmarks. Our analysis shows that these sources of heterogeneity have a major impact on both model performance and fairness, thus sheds light on the importance of considering heterogeneity in FL system design.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Machine Learning,Computer Science - Performance}
}

@report{abdulwahab_IntrusionDetectionIoT_2022,
  type = {preprint},
  title = {Intrusion {{Detection}} in the {{IoT}} under {{Data}} and {{Concept Drifts}}: {{Online Deep Learning Approach}}},
  shorttitle = {Intrusion {{Detection}} in the {{IoT}} under {{Data}} and {{Concept Drifts}}},
  author = {Abdul Wahab, Omar},
  date = {2022-02-23},
  doi = {10.36227/techrxiv.19210197.v1},
  url = {https://www.techrxiv.org/articles/preprint/Intrusion_Detection_in_the_IoT_under_Data_and_Concept_Drifts_Online_Deep_Learning_Approach/19210197/1},
  urldate = {2022-03-04},
  abstract = {Although the existing machine learning-based intrusion detection systems in the Internet of Things (IoT) usually perform well in static environments, they struggle to preserve their performance over time, in dynamic environments. Yet, the IoT is a highly dynamic and heterogeneous environment, leading to what is known as data drift and concept drift. Data drift is a phenomenon which embodies the change that happens in the relationships among the independent features, which is mainly due to changes in the data quality over time. Concept drift is a phenomenon which depicts the change in the relationships between input and output data in the machine learning model over time. To detect data and concept drifts, we first propose a drift detection technique that capitalizes on the Principal Component Analysis (PCA) method to study the change in the variance of the features across the intrusion detection data streams. We also discuss an online outlier detection technique that identifies the outliers that diverge both from historical and temporally close data points. To counter these drifts, we discuss an online deep neural network that dynamically adjusts the sizes of the hidden layers based on the Hedge weighting mechanism, thus enabling the model to steadily learn and adapt as new intrusion data come. Experiments conducted on an IoT-based intrusion detection dataset suggest that our solution stabilizes the performance of the intrusion detection on both the training and testing data compared to the static deep neural network model, which is widely used for intrusion detection.},
  langid = {english},
  keywords = {obsidian}
}

@article{abosata_CustomisedIntrusionDetection_2023,
  title = {Customised {{Intrusion Detection}} for an {{Industrial IoT Heterogeneous Network Based}} on {{Machine Learning Algorithms Called FTL-CID}}},
  author = {Abosata, Nasr and Al-Rubaye, Saba and Inalhan, Gokhan},
  date = {2023-01},
  journaltitle = {Sensors},
  volume = {23},
  number = {1},
  pages = {321},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s23010321},
  url = {https://www.mdpi.com/1424-8220/23/1/321},
  urldate = {2023-01-09},
  abstract = {Technological breakthroughs in the Internet of Things (IoT) easily promote smart lives for humans by connecting everything through the Internet. The de facto standardised IoT routing strategy is the routing protocol for low-power and lossy networks (RPL), which is applied in various heterogeneous IoT applications. Hence, the increase in reliance on the IoT requires focus on the security of the RPL protocol. The top defence layer is an intrusion detection system (IDS), and the heterogeneous characteristics of the IoT and variety of novel intrusions make the design of the RPL IDS significantly complex. Most existing IDS solutions are unified models and cannot detect novel RPL intrusions. Therefore, the RPL requires a customised global attack knowledge-based IDS model to identify both existing and novel intrusions in order to enhance its security. Federated transfer learning (FTL) is a trending topic that paves the way to designing a customised RPL-IoT IDS security model in a heterogeneous IoT environment. In this paper, we propose a federated-transfer-learning-assisted customised distributed IDS (FT-CID) model to detect RPL intrusion in a heterogeneous IoT. The design process of FT-CID includes three steps: dataset collection, FTL-assisted edge IDS learning, and intrusion detection. Initially, the central server initialises the FT-CID with a predefined learning model and observes the unique features of different RPL-IoTs to construct a local model. The experimental model generates an RPL-IIoT dataset with normal and abnormal traffic through simulation on the Contiki-NG OS. Secondly, the edge IDSs are trained using the local parameters and the globally shared parameters generated by the central server through federation and aggregation of different local parameters of various edges. Hence, transfer learning is exploited to update the server's and edges' local and global parameters based on relational knowledge. It also builds and customised IDS model with partial retraining through local learning based on globally shared server knowledge. Finally, the customised IDS in the FT-CID model enforces the detection of intrusions in heterogeneous IoT networks. Moreover, the FT-CID model accomplishes high RPL security by implicitly utilising the local and global parameters of different IoTs with the assistance of FTL. The FT-CID detects RPL intrusions with an accuracy of 85.52\% in tests on a heterogeneous IoT network.},
  issue = {1},
  langid = {english},
  keywords = {AMI,application,attacks,distributed sensors,Internet of Things (IoT),intrusion detection,machine learning,security}
}

@inproceedings{abouzahra_EffectCommunityType_2014,
  title = {The {{Effect}} of {{Community Type}} on {{Knowledge Sharing Incentives}} in {{Online Communities}}: {{A Meta-analysis}}},
  booktitle = {2014 47th {{Hawaii International Conference}} on {{System Sciences}}},
  author = {Abouzahra, Mohamed and Tan, Joseph},
  date = {2014-01},
  pages = {1765--1773},
  publisher = {IEEE},
  issn = {15301605},
  doi = {10.1109/HICSS.2014.224},
  url = {http://ieeexplore.ieee.org/document/6758821/},
  abstract = {Online communities are computer mediated, self-organizing, open networks where people voluntarily communicate and share knowledge. Knowledge sharing in online communities requires exerting time and effort and hence community members need motivation to contribute in these communities. Prior research identified numerous incentives that can motivate knowledge sharing in online communities such as self-efficacy and trust. However, research did not consider the effects of community types on the effectiveness of these incentives. In this paper we use meta-analysis to examine the effects of community type on knowledge sharing incentives in communities of interest and communities of practice. We examined 24 papers focusing on knowledge sharing incentives and we found that the type of online community moderates the effects of trust, commitment, task enjoyment and reciprocity on knowledge sharing. The outcome of this research demonstrates that future research should consider community types in knowledge sharing models. \copyright{} 2014 IEEE.},
  isbn = {978-1-4799-2504-9}
}

@article{abubaker_Blockchainedserviceprovisioning_2022,
  title = {Blockchained Service Provisioning and Malicious Node Detection via Federated Learning in Scalable {{Internet}} of {{Sensor Things}} Networks},
  author = {Abubaker, Zain and Javaid, Nadeem and Almogren, Ahmad and Akbar, Mariam and Zuair, Mansour and Ben-Othman, Jalel},
  date = {2022-02-26},
  journaltitle = {Computer Networks},
  shortjournal = {Computer Networks},
  volume = {204},
  pages = {108691},
  issn = {1389-1286},
  doi = {10.1016/j.comnet.2021.108691},
  url = {https://www.sciencedirect.com/science/article/pii/S1389128621005570},
  urldate = {2024-04-12},
  abstract = {In this paper, a blockchained Beyond Fifth Generation (B5G) enabled malicious node detection model is proposed for the Internet of Sensor Things (IoSTs). Moreover, a secure service provisioning scheme using cascading encryption and feature evaluation process is also proposed for the IoSTs. The presence of malicious nodes causes severe issues in the localization and service provisioning, which discourages new entities to join the network. Therefore, it is very important to establish trust between all entities by detecting and removing such nodes. The proposed B5G enabled malicious node detection model uses federated learning for the detection of malicious nodes. The federated learning uses Support Vector Machine (SVM) and Random Forest (RF) classifiers to detect the malicious nodes. The malicious nodes are classified on the bases of their honesty and end-to-end delay. Moreover, the service provider nodes provide services to each other and get the reward. However, the service provisioning in the IoSTs has many issues like a repudiation of service providers as well as the clients. The feature evaluation and cascading encryption mechanisms are used to solve these issues. The digital signature in cascading encryption ensures the non-repudiation of the service provider. On the other hand, feature evaluation of service ensures that the client cannot repudiate about actually demanded services. Moreover, the conformance of services is also ensured by the feature evaluation process. The simulation results show the effectiveness of our proposed non-repudiation model. The SVM and RF classifiers are compared in terms of accuracy, precision, F1 score and recall. The accuracy, precision, F1 score and recall of SVM are 79\%, 1, 0.8795 and 0.78, respectively. On the other hand, the accuracy, precision, F1 score and recall of RF classifier are 95\%, 0.92, 0.96 and 1, respectively. The results show that RF has better accuracy than RF in malicious nodes detection.},
  keywords = {Beyond Fifth Generation,Blockchain,Cascading encryption,Internet of Sensor Things,Localization,Non-repudiation,Random Forest algorithm,Service provisioning,Support Vector Machine}
}

@online{ACM_artifacts,
  title = {Artifact {{Review}} and {{Badging}} v1.1},
  author = {{ACM}},
  date = {2020-08-24},
  url = {https://www.acm.org/publications/policies/artifact-review-and-badging-current},
  urldate = {2022-08-17},
  abstract = {Result and Artifact Review documentation and badges - V.1.1},
  langid = {english},
  keywords = {pinned}
}

@article{afzaliseresht_MAISIDSdistributedintrusion_2014,
  title = {{{MAIS-IDS}}: {{A}} Distributed Intrusion Detection System Using Multi-Agent {{AIS}} Approach},
  shorttitle = {{{MAIS-IDS}}},
  author = {Afzali Seresht, Neda and Azmi, Reza},
  date = {2014-10},
  journaltitle = {Engineering Applications of Artificial Intelligence},
  shortjournal = {Engineering Applications of Artificial Intelligence},
  volume = {35},
  pages = {286--298},
  issn = {09521976},
  doi = {10.1016/j.engappai.2014.06.022},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0952197614001444},
  urldate = {2021-07-21},
  abstract = {This paper proposes an agent-based approach using artificial immune system (AIS) paradigms as a successful mechanism for a distributed intrusion detection system (IDS). The AIS paradigms are negative selection, clonal selection, danger theory, and immune network. These paradigms are very successful for anomaly IDS. The AIS paradigms are inspired by the powerful human immune system (HIS) and are promising candidate for design of an IDS. The proposed AIS-based agents are capable of learning, selfadaption, platform mobility, autonomy and collaboration. The proposed system (MAIS-IDS) was designed using these powerful and collaborative agents. This system has mobile and static agents with detector agents as the main actors in MAIS-IDS. The life cycles of agents are determined using the proposed immune algorithms in specific phases. Essential characteristics of MAIS-IDS are cloning, mutation, migration, collaboration, and randomness. MAIS-IDS was evaluated using a network of virtualized hosts, a kernel-based virtual machine (KVM) hypervisor and management Orchestra.},
  langid = {english},
  keywords = {\_read}
}

@article{agrawal_FederatedLearningintrusion_2022,
  title = {Federated {{Learning}} for Intrusion Detection System: {{Concepts}}, Challenges and Future Directions},
  shorttitle = {Federated {{Learning}} for Intrusion Detection System},
  author = {Agrawal, Shaashwat and Sarkar, Sagnik and Aouedi, Ons and Yenduri, Gokul and Piamrat, Kandaraj and Alazab, Mamoun and Bhattacharya, Sweta and Maddikunta, Praveen Kumar Reddy and Gadekallu, Thippa Reddy},
  date = {2022-11-01},
  journaltitle = {Computer Communications},
  shortjournal = {Computer Communications},
  volume = {195},
  pages = {346--361},
  issn = {0140-3664},
  doi = {10.1016/j.comcom.2022.09.012},
  url = {https://www.sciencedirect.com/science/article/pii/S0140366422003516},
  urldate = {2024-06-09},
  abstract = {The rapid development of the Internet and smart devices trigger surge in network traffic making its infrastructure more complex and heterogeneous. The predominated usage of mobile phones, wearable devices and autonomous vehicles are examples of distributed networks which generate huge amount of data each and every day. The computational power of these devices have also seen steady progression which has created the need to transmit information, store data locally and drive network computations towards edge devices. Intrusion detection systems (IDS) play a significant role in ensuring security and privacy of such devices. Machine Learning (ML) and Deep Learning (DL) with Intrusion Detection Systems have gained great momentum due to their achievement of high classification accuracy. However the privacy and security aspects potentially gets jeopardized due to the need of storing and communicating data to centralized server. On the contrary, Federated Learning (FL) fits in appropriately as a privacy-preserving decentralized learning technique that does not transfer data but trains models locally and transfers the parameters to the centralized server. The present paper aims to present an extensive and exhaustive review on the use of FL in intrusion detection system. In order to establish the need for FL, various types of IDS, relevant ML approaches and its associated issues are discussed. The paper presents detailed overview of the implementation of FL in various aspects of anomaly detection. The allied challenges of FL implementations are also identified which provides idea on the scope of future direction of research. The paper finally presents the plausible solutions associated with the identified challenges in FL based intrusion detection system implementation acting as a baseline for prospective research.},
  keywords = {\_processed,+survey,â›” No DOI found,Anomaly detection,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Deep Learning,Federated Learning,Intrusion detection system,Machine Learning}
}

@incollection{ahmed_NetworkTrafficPattern_2015,
  title = {Network {{Traffic Pattern Analysis Using Improved Information Theoretic Co-clustering Based Collective Anomaly Detection}}},
  booktitle = {International {{Conference}} on {{Security}} and {{Privacy}} in {{Communication Networks}}},
  author = {Ahmed, Mohiuddin and Mahmood, Abdun Naser},
  editor = {Tian, Jin and Jing, Jiwu and Srivatsa, Mudhakar},
  date = {2015},
  volume = {153},
  pages = {204--219},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-23802-9_17},
  url = {http://link.springer.com/10.1007/978-3-319-23802-9_17},
  urldate = {2022-08-12},
  abstract = {Collective anomaly is a pattern in the data when a group of similar data instances behave anomalously with respect to the entire dataset. Clustering is a useful unsupervised technique to identify the underlying pattern in the data as well as anomaly detection. However, existing clustering based techniques have high false alarm rates and consider individual data instance behaviour for anomaly detection. In this paper, we formulate the problem of detecting DoS (Denial of Service) attacks as collective anomaly detection and propose a mathematically logical criteria for selecting the important traffic attributes for detecting collective anomaly. Information theoretic co-clustering algorithm is advantageous over regular clustering for creating more fine-grained representation of the data, however lacks the ability to handle mixed attribute data. We extend the co-clustering algorithm by incorporating the ability to handle categorical attributes which augments the detection accuracy of DoS attacks in benchmark KDD cup 1999 network traffic dataset than the existing techniques.},
  isbn = {978-3-319-23801-2 978-3-319-23802-9},
  langid = {english}
}

@article{aissaoui_Surveyingcryptographicmethods_[review],
  title = {Surveying Cryptographic Methods for {{UAV}} Communications},
  author = {Aissaoui, Ridwane},
  year = {[review]},
  volume = {7},
  number = {7},
  pages = {85},
  abstract = {This article presents our survey work on Unmanned Aerial Vehicle (UAV) communication security for UAV Traffic Management (UTM) safety [1]. A majority of UAV missions require flying through public airspace. Airspace management is a sector with very high safety standards, as can be seen with commercial civil aviation. Reliable communication links between aircraft, their pilots and UTM systems are necessary to safely carry out these missions. Several security properties have to be provided in order to ensure a safe traffic. Current cryptographic standards used over the internet are not suitable to Unmanned Aerial System (UAS), mainly due to their computational complexity. The survey discusses every communication link and assesses the security needs in order to enable a safe traffic management. We then present and discuss several research works providing the required properties using cryptographic primitives. In particular, authenticated key exchange protocols specifically developed for constrained systems are compared and evaluated as solutions for UAS security. We also discuss symmetric encryption alternatives to the AES algorithm as well as works to secure current UTM protocols such as ADS-B and RemoteID. The analysis reveals a lack of signature solutions, the need for the development of a complete secure architecture able to provide authentication and integrity and a need for post-quantum lightweight solutions. We then present our current work which focuses on implementing a post-quantum signature standard to evaluate its pertinence for UAS.},
  langid = {english},
  keywords = {\_done,\_unpublished}
}

@incollection{akhlaq_ImplementationEvaluationNetwork_2011,
  title = {Implementation and {{Evaluation}} of {{Network Intrusion Detection Systems}}},
  booktitle = {Network {{Performance Engineering}}},
  author = {Akhlaq, Monis and Alserhani, Faeiz and Awan, Irfan and Mellor, John and Cullen, Andrea J. and Al-Dhelaan, Abdullah},
  editor = {Kouvatsos, Demetres D.},
  date = {2011},
  volume = {5233},
  pages = {988--1016},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-02742-0_42},
  url = {http://link.springer.com/10.1007/978-3-642-02742-0_42},
  urldate = {2022-01-12},
  abstract = {Performance evaluation of Network Intrusion Detection Systems (NIDS) has been carried out to identify its limitations in high speed environment. This has been done by employing evasive and avoidance strategies simulating real-life normal and attack traffic flows on a sophisticated Test-Bench. Snort, an open source Intrusion Detection System, has been selected as an evaluation platform. In this paper, Snort has been evaluated on host and virtual configurations using different operating systems and hardware implementations. Evaluation methodology is based on the concept of stressing the system by injecting various traffic loads (packet sizes, bandwidth and attack signatures) and analyzing its packet handling and detection capacity. We have observed few performance issues with Snort which has resulted into packet drop and low detection rate. Finally, we have analyzed the factors responsible for it and have recommended techniques to improve systems packet handling and detection capability.},
  isbn = {978-3-642-02741-3 978-3-642-02742-0},
  langid = {english}
}

@article{al-ameer_Federatedlearningsecurity_2023,
  title = {Federated Learning Security Mechanisms for Protecting Sensitive Data},
  author = {Al-Ameer, Asraa A. Abd and Bhaya, Wesam Sameer},
  date = {2023-08-01},
  journaltitle = {Bulletin of Electrical Engineering and Informatics},
  shortjournal = {Bulletin EEI},
  volume = {12},
  number = {4},
  pages = {2421--2427},
  issn = {2302-9285, 2089-3191},
  doi = {10.11591/eei.v12i4.4751},
  url = {https://beei.org/index.php/EEI/article/view/4751},
  urldate = {2024-04-12},
  abstract = {One of the new trends in the field of artificial intelligence is federated learning (FL), which will have promising roles in many real-world applications due to the work characteristics of its architecture. The learning mechanism for this technique is based on making training in a distributed manner on the local data for each client using decentralized data, then collecting parameters for each local training and uploading it to the server, which in turn will send model updates to all clients to give the final learning result. To provide a broad study on FL from security and privacy aspects, this research paper introduces a general view of FL and its categories, most attacks that can befall it, the safety mechanisms used by existing works in attacks defense, enhancing the safety and privacy of FL whether in the transmission or collecting of data. Then, the usage of FL in network security by many research papers has been presented, and how good results were achieved, and finally a comparison has been made between these papers.},
  langid = {english}
}

@inproceedings{al-athbaal-marri_FederatedMimicLearning_2020,
  title = {Federated {{Mimic Learning}} for {{Privacy Preserving Intrusion Detection}}},
  booktitle = {2020 {{IEEE International Black Sea Conference}} on {{Communications}} and {{Networking}} ({{BlackSeaCom}})},
  author = {Al-Athba Al-Marri, Noor Ali and Ciftler, Bekir S. and Abdallah, Mohamed M.},
  date = {2020-05},
  pages = {1--6},
  doi = {10.1109/BlackSeaCom48709.2020.9234959},
  url = {https://ieeexplore.ieee.org/document/9234959},
  urldate = {2024-04-12},
  abstract = {Internet of things (IoT) devices are prone to attacks due to the limitation of their privacy and security components. These attacks vary from exploiting backdoors to disrupting the communication network of the devices. Intrusion Detection Systems (IDS) play an essential role in ensuring information privacy and security of IoT devices against these attacks. Recently, deep learning-based IDS techniques are becoming more prominent due to their high classification accuracy. However, conventional deep learning techniques jeopardize user privacy due to the transfer of user data to a centralized server. Federated learning (FL) is a popular privacy-preserving decentralized learning method. FL enables training models locally at the edge devices and transferring local models to a centralized server instead of transferring sensitive data. Nevertheless, FL can suffer from reverse engineering ML attacks that can learn information about the user's data from model. To overcome the problem of reverse engineering, mimic learning is another way to preserve the privacy of ML-based IDS. In mimic learning, a student model is trained with the public dataset, which is labeled with the teacher model that is trained by sensitive user data. In this work, we propose a novel approach that combines the advantages of FL and mimic learning, namely federated mimic learning to create a distributed IDS while minimizing the risk of jeopardizing users' privacy, and benchmark its performance compared to other ML-based IDS techniques using NSL-KDD dataset. Our results show that we can achieve 98.11\% detection accuracy with federated mimic learning.},
  eventtitle = {2020 {{IEEE International Black Sea Conference}} on {{Communications}} and {{Networking}} ({{BlackSeaCom}})},
  keywords = {Benchmark testing,Data models,Data privacy,Feature extraction,Federated Learning,Internet of Things,Intrusion detection,Intrusion Detection Systems,Mimic Learning,Privacy-Preserving,Servers,survey-fids,Training}
}

@article{al-hawawreh_FederatedLearningassistedDistributed_2023,
  title = {Federated {{Learning-assisted Distributed Intrusion Detection Using Mesh Satellite Nets}} for {{Autonomous Vehicle Protection}}},
  author = {Al-Hawawreh, Muna and Hossain, M. Shamim},
  date = {2023},
  journaltitle = {IEEE Transactions on Consumer Electronics},
  pages = {1--1},
  issn = {1558-4127},
  doi = {10.1109/TCE.2023.3318727},
  url = {https://ieeexplore.ieee.org/abstract/document/10261489},
  urldate = {2024-04-12},
  abstract = {The widespread use of intelligent consumer electronics, specifically autonomous vehicles, has exponentially increased. The key enablers of this pervasive are the Internet of Things (IoT), Artificial Intelligence (AI), and Satellite communications, which provide consumers with highly precise and reliable self-driving vehicles. However, autonomous vehicles come also with significant cybersecurity concerns. Attackers can easily use satellite links to launch cyberattacks against autonomous vehicles. An Intrusion Detection System (IDS) is one of the most effective mechanisms for providing secure autonomous vehicles. However, existing IDSs based on machine and deep learning train their models in a centralized server, which uploads data or parameters to the central server for training. This structure of IDS has challenges with vehicle mobility, brings processing delays, and increases privacy and security risks, affecting vehicles' performance. Therefore, for the first time, this paper proposes a new federated learning-assisted distributed IDS using a mesh satellite net to protect autonomous vehicles. We construct a local model using a deep neural network. Then, we provide a mesh federated learning approach that keeps model training local and lets satellites exchange their parameters in a privacy-preserving way. The simulation results show that our proposed model works well while keeping the computation cost reasonable.},
  eventtitle = {{{IEEE Transactions}} on {{Consumer Electronics}}},
  keywords = {Autonomous vehicles,Consumer electronics,federated learning,intrusion detection,Intrusion detection,LEO satellite,Low earth orbit satellites,Peer-to-peer computing,Satellites,Servers,Training}
}

@article{al-naday_FederateddeepQlearning_2023,
  title = {Federated Deep {{Q-learning}} Networks for Service-Based Anomaly Detection and Classification in Edge-to-Cloud Ecosystems},
  author = {AL-Naday, Mays and Dobre, Vlad and Reed, Martin and Toor, Salman and Volckaert, Bruno and De Turck, Filip},
  date = {2023-08-31},
  journaltitle = {Annals of Telecommunications},
  shortjournal = {Ann. Telecommun.},
  issn = {1958-9395},
  doi = {10.1007/s12243-023-00977-4},
  url = {https://doi.org/10.1007/s12243-023-00977-4},
  urldate = {2024-04-12},
  abstract = {The diversity of services and infrastructure in metropolitan edge-to-cloud network(s) is rising to unprecedented levels. This is causing a rising threat of a wider range of cyber attacks coupled with a growing integration of a constrained range of infrastructure, particularly seen at the network edge. Deep reinforcement-based learning is an attractive approach to detecting attacks, as it allows less dependency on labeled data with better ability to classify different attacks. However, current approaches to learning are known to be computationally expensive (cost), and the learning experience can be negatively impacted by the presence of outliers and noise (quality). This work tackles both the cost and quality challenges with a novel service-based federated deep reinforcement learning solution, enabling anomaly detection and attack classification at a reduced data cost and with better quality. The federated settings in the proposed approach enable multiple edge units to create clusters that follow a bottom-up learning approach. The proposed solution adapts a deep Q-learning network (DQN) for service-tunable flow classification and introduces a novel federated DQN (FDQN) for federated learning. Through such targeted training and validation, variation in data patterns and noise is reduced. This leads to improved performance per service with lower training cost. Performance and cost of the solution, along with sensitivity to exploration parameters, are evaluated using examples of publicly available datasets (UNSW-NB15 and CIC-IDS2018). Evaluation results show the proposed solution to maintain detection accuracy in the range of {$\approx$}75--85\% with lower data supply while improving the classification rate by a factor of {$\approx$}2.},
  langid = {english},
  keywords = {Anomaly detection,Cloud-to-edge continuum,Cyber security,Deep Q-learning,Federated deep reinforcement learning,Fog computing}
}

@inproceedings{al-naday_ServicebasedFederatedDeep_2023,
  title = {Service-Based {{Federated Deep Reinforcement Learning}} for {{Anomaly Detection}} in {{Fog Ecosystems}}},
  booktitle = {2023 26th {{Conference}} on {{Innovation}} in {{Clouds}}, {{Internet}} and {{Networks}} and {{Workshops}} ({{ICIN}})},
  author = {Al-Naday, Mays and Reed, Martin and Dobre, Vlad and Toor, Salman and Volckaert, Bruno and De Turck, Filip},
  date = {2023-03},
  pages = {121--128},
  issn = {2472-8144},
  doi = {10.1109/ICIN56760.2023.10073495},
  url = {https://ieeexplore.ieee.org/document/10073495},
  urldate = {2024-04-12},
  abstract = {With Digital transformation, the diversity of services and infrastructure in backhaul fog network(s) is rising to unprecedented levels. This is causing a rising threat of a wider range of cyber attacks coupled with a growing integration of constrained range of infrastructure, particularly seen at the network edge. Deep reinforcement-based learning is an attractive approach to detecting attacks, as it allows less dependency on labeled data with better ability to classify different attacks. However, current approaches to learning are known to be computationally expensive (cost) and the learning experience can be negatively impacted by the presence of outliers and noise (quality). This work tackles both the cost and quality challenges with a novel service-based federated deep reinforcement learning solution, enabling anomaly detection and attack classification at a reduced data cost and with better quality. The federated settings in the proposed approach enable multiple edge units to create clusters that follow a bottom-up learning approach. The proposed solution adapts deep Q-learning Network (DQN) for service-tunable flow classification, and introduces a novel federated DQN (FDQN) for federated learning. Through such targeted training and validation, variation in data patterns and noise is reduced. This leads to improved performance per service with lower training cost. Performance and cost of the solution, along with sensitivity to exploration parameters are evaluated using an example publicly available dataset (UNSW-NB15). Evaluation results show the proposed solution to maintain detection accuracy with lower data supply, while improving the classification rate by a factor of {$\approx$} 2.},
  eventtitle = {2023 26th {{Conference}} on {{Innovation}} in {{Clouds}}, {{Internet}} and {{Networks}} and {{Workshops}} ({{ICIN}})},
  keywords = {anomaly detection,Cloud computing,cloud-to-edge continuum,Costs,cyber security,Deep learning,Deep Q-Learning,federated deep reinforcement learning,fog computing,Q-learning,Sensitivity,Technological innovation,Training}
}

@article{al-wesabi_PelicanOptimizationAlgorithm_2023,
  title = {Pelican {{Optimization Algorithm}} with {{Federated Learning Driven Attack Detection}} Model in {{Internet}} of {{Things}} Environment},
  author = {Al-Wesabi, Fahd N. and Mengash, Hanan Abdullah and Marzouk, Radwa and Alruwais, Nuha and Allafi, Randa and Alabdan, Rana and Alharbi, Meshal and Gupta, Deepak},
  date = {2023-11-01},
  journaltitle = {Future Generation Computer Systems},
  shortjournal = {Future Generation Computer Systems},
  volume = {148},
  pages = {118--127},
  issn = {0167-739X},
  doi = {10.1016/j.future.2023.05.029},
  url = {https://www.sciencedirect.com/science/article/pii/S0167739X23002121},
  urldate = {2024-04-12},
  abstract = {The Internet of Things (IoT) is comprised of millions of physical devices interconnected with the Internet through network that performs a task independently with less human interference. Despite the benefits of IoT, it is vulnerable to malicious attacks. Therefore, machine learning (ML) inspired decision-making is hardly preferred due to drawbacks (the requirement that every training dataset is stored on the central database), computation cost related to the training of massive amounts of information on the unified server, and security issues related to transferring attained statistics from IoT sensor to the server. The Federated Learning (FL) algorithm is the adaptable and most prominent way to resolve the shortcoming of ML-based techniques. The study proposes a Pelican Optimization Algorithm with Federated Learning Driven Attack Detection and classification (POAFL-DDC) technique in the IoT. The POAFL-DDC technique operates on decentralized on-device data for attack detection in the IoT. By substituting update weight with the central FL server, the data is placed on the local IoT device whereas federating training cycles on the DL model. For attack detection process, deep belief network (DBN) model is used in this work. In this study, the POA is utilized to optimize the DBN hyperparameters. The experimental validation of the POAFL-DDC algorithm is tested on TON\_IOT dataset and the results are examined in terms of different measures. The experimental outcomes demonstrated that the POAFL-DDC technique reaches superior results over other models.},
  keywords = {Attack detection,Deep learning,Federated Learning,Internet of Things,Pelican Optimization Algorithm}
}

@article{al-yaseen_Realtimemultiagentsystem_2017,
  title = {Real-Time Multi-Agent System for an Adaptive Intrusion Detection System},
  author = {Al-Yaseen, Wathiq Laftah and Othman, Zulaiha Ali and Nazri, Mohd Zakree Ahmad},
  date = {2017-01},
  journaltitle = {Pattern Recognition Letters},
  shortjournal = {Pattern Recognition Letters},
  volume = {85},
  pages = {56--64},
  issn = {01678655},
  doi = {10.1016/j.patrec.2016.11.018},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167865516303415},
  urldate = {2021-07-21},
  langid = {english},
  keywords = {\_read}
}

@article{alam_FedSepsisFederatedMultiModal_2023,
  title = {{{FedSepsis}}: {{A Federated Multi-Modal Deep Learning-Based Internet}} of {{Medical Things Application}} for {{Early Detection}} of {{Sepsis}} from {{Electronic Health Records Using Raspberry Pi}} and {{Jetson Nano Devices}}},
  shorttitle = {{{FedSepsis}}},
  author = {Alam, Mahbub Ul and Rahmani, Rahim},
  date = {2023-01-14},
  journaltitle = {Sensors},
  shortjournal = {Sensors},
  volume = {23},
  number = {2},
  pages = {970},
  issn = {1424-8220},
  doi = {10.3390/s23020970},
  url = {https://www.mdpi.com/1424-8220/23/2/970},
  urldate = {2024-04-12},
  abstract = {The concept of the Internet of Medical Things brings a promising option to utilize various electronic health records stored in different medical devices and servers to create practical but secure clinical decision support systems. To achieve such a system, we need to focus on several aspects, most notably the usability aspect of deploying it using low-end devices. This study introduces one such application, namely FedSepsis, for the early detection of sepsis using electronic health records. We incorporate several cutting-edge deep learning techniques for the prediction and natural-language processing tasks. We also explore the multimodality aspect for the better use of electronic health records. A secure distributed machine learning mechanism is essential to building such a practical internet of medical things application. To address this, we analyze two federated learning techniques. Moreover, we use two different kinds of low-computational edge devices, namely Raspberry Pi and Jetson Nano, to address the challenges of using such a system in a practical setting and report the comparisons. We report several critical system-level information about the devices, namely CPU utilization, disk utilization, process CPU threads in use, process memory in use (non-swap), process memory available (non-swap), system memory utilization, temperature, and network traffic. We publish the prediction results with the evaluation metrics area under the receiver operating characteristic curve, the area under the precision--recall curve, and the earliness to predict sepsis in hours. Our results show that the performance is satisfactory, and with a moderate amount of devices, the federated learning setting results are similar to the single server-centric setting. Multimodality provides the best results compared to any single modality in the input features obtained from the electronic health records. Generative adversarial neural networks provide a clear superiority in handling the sparsity of electronic health records. Multimodality with the generative adversarial neural networks provides the best result: the area under the precision--recall curve is 96.55\%, the area under the receiver operating characteristic curve is 99.35\%, and earliness is 4.56 h. FedSepsis suggests that incorporating such a concept together with low-end computational devices could be beneficial for all the medical sector stakeholders and should be explored further.},
  langid = {english}
}

@article{alamleh_FederatedLearningIoMT_2023,
  title = {Federated {{Learning}} for {{IoMT Applications}}: {{A Standardization}} and {{Benchmarking Framework}} of {{Intrusion Detection Systems}}},
  shorttitle = {Federated {{Learning}} for {{IoMT Applications}}},
  author = {Alamleh, Amneh and Albahri, O. S. and Zaidan, A. A. and Albahri, A. S. and Alamoodi, A. H. and Zaidan, B. B. and Qahtan, Sarah and Alsatar, H. A. and Al-Samarraay, Mohammed S. and Jasim, Ali Najm},
  date = {2023-02},
  journaltitle = {IEEE Journal of Biomedical and Health Informatics},
  volume = {27},
  number = {2},
  pages = {878--887},
  issn = {2168-2208},
  doi = {10.1109/JBHI.2022.3167256},
  url = {https://ieeexplore.ieee.org/abstract/document/9756888},
  urldate = {2024-04-12},
  abstract = {Efficient evaluation for machine learning (ML)-based intrusion detection systems (IDSs) for federated learning (FL) in the Internet of Medical Things (IoMTs) environment falls under the standardisation and multicriteria decision-making (MCDM) problems. Thus, this study is developing an MCDM framework for standardising and benchmarking the ML-based IDSs used in the FL architecture of IoMT applications. In the methodology, firstly, the evaluation criteria of ML-based IDSs are standardised using the fuzzy Delphi method (FDM). Secondly, the evaluation decision matrix (DM) is formulated based on the intersection of standardised evaluation criteria and a list of ML-based IDSs. Such formulation is achieved using a dataset with 125,973 records, and each record comprises 41 features. Thirdly, the integration of MCDM methods is formulated to determine the importance weights of the main and sub standardised security and performance criteria, followed by benchmarking and selecting the optimal ML-based IDSs. In this phase, the Borda voting method is used to unify the different ranks and perform a group benchmarking context. The following results are confirmed. (1) Using FDM, 17 out of 20 evaluation criteria (14 for security and 3 for performance) reach the consensus of experts. (2) The area under curve criterion has the lowest set of weights, whilst the CPU time criterion has the highest one. (3) VIKOR group ranking shows that the BayesNet is a best classifier, whilst SVM is the last choice. For evaluation, three assessments, namely, systematic ranking, computational cost and comparative analysis, are used.},
  eventtitle = {{{IEEE Journal}} of {{Biomedical}} and {{Health Informatics}}},
  keywords = {Benchmark testing,Computational modeling,Data models,Data privacy,federate learning,internet of medical things,Intrusion detection systems,machine learning,multicriteria decision making,Security,Servers,Training}
}

@article{alazab_EnhancingPrivacyPreservingIntrusion_2023,
  title = {Enhancing {{Privacy-Preserving Intrusion Detection}} through {{Federated Learning}}},
  author = {Alazab, Ammar and Khraisat, Ansam and Singh, Sarabjot and Jan, Tony},
  date = {2023-01},
  journaltitle = {Electronics},
  volume = {12},
  number = {16},
  pages = {3382},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics12163382},
  url = {https://www.mdpi.com/2079-9292/12/16/3382},
  urldate = {2024-04-12},
  abstract = {Detecting anomalies, intrusions, and security threats in the network (including Internet of Things) traffic necessitates the processing of large volumes of sensitive data, which raises concerns about privacy and security. Federated learning, a distributed machine learning approach, enables multiple parties to collaboratively train a shared model while preserving data decentralization and privacy. In a federated learning environment, instead of training and evaluating the model on a single machine, each client learns a local model with the same structure but is trained on different local datasets. These local models are then communicated to an aggregation server that employs federated averaging to aggregate them and produce an optimized global model. This approach offers significant benefits for developing efficient and effective intrusion detection system (IDS) solutions. In this research, we investigated the effectiveness of federated learning for IDSs and compared it with that of traditional deep learning models. Our findings demonstrate that federated learning, by utilizing random client selection, achieved higher accuracy and lower loss compared to deep learning, particularly in scenarios emphasizing data privacy and security. Our experiments highlight the capability of federated learning to create global models without sharing sensitive data, thereby mitigating the risks associated with data breaches or leakage. The results suggest that federated averaging in federated learning has the potential to revolutionize the development of IDS solutions, thus making them more secure, efficient, and effective.},
  issue = {16},
  langid = {english},
  keywords = {anomaly detection,communication network security,data privacy,federated learning,intrusion detection system}
}

@article{alazab_FederatedLearningCybersecurity_2021,
  title = {Federated {{Learning}} for {{Cybersecurity}}: {{Concepts}}, {{Challenges}} and {{Future Directions}}},
  shorttitle = {Federated {{Learning}} for {{Cybersecurity}}},
  author = {Alazab, Mamoun and R M, Swarna Priya and M, Parimala and Reddy, Praveen and Gadekallu, Thippa Reddy and Pham, Quoc-Viet},
  date = {2021},
  journaltitle = {IEEE Transactions on Industrial Informatics},
  shortjournal = {IEEE Trans. Ind. Inf.},
  pages = {1--1},
  issn = {1551-3203, 1941-0050},
  doi = {10/gnm4dj},
  url = {https://ieeexplore.ieee.org/document/9566732/},
  urldate = {2021-12-02},
  abstract = {Federated learning (FL) is a recent development in artificial intelligence which is typically based on the concept of decentralized data. As cyber-attacks are frequently happening in the various applications deployed in real-time, most industrialists are hesitating to move forward in adopting the technology of the Internet of Everything (IoE). This paper aims to provide an extensive study on how FL could be utilized for providing better cybersecurity and prevent various cyber-attacks in real-time. We present an extensive survey of the various FL models currently developed by researchers for providing authentication, privacy, trust management and attack detection. We also discuss few realtime use cases that have been deployed recently and how FL is adopted in them for preserving privacy of data and improving the performance of the system. Based on the study, we conclude the paper with some prominent challenges and future directions on which the researchers can focus for adopting FL in real-time scenarios.},
  langid = {english},
  keywords = {\_processed,+survey}
}

@article{alazzam_FederatedDeepLearning_2022,
  title = {Federated {{Deep Learning Approaches}} for the {{Privacy}} and {{Security}} of {{IoT Systems}}},
  author = {Alazzam, Malik Bader and Alassery, Fawaz and Almulihi, Ahmed},
  editor = {Rani, Shalli},
  date = {2022-04-01},
  journaltitle = {Wireless Communications and Mobile Computing},
  shortjournal = {Wireless Communications and Mobile Computing},
  volume = {2022},
  pages = {1--7},
  issn = {1530-8677, 1530-8669},
  doi = {10.1155/2022/1522179},
  url = {https://www.hindawi.com/journals/wcmc/2022/1522179/},
  urldate = {2022-04-06},
  abstract = {Using federated learning, which is a distributed machine learning approach, a machine learning model can train on a distributed data set without having to transfer any data between computers. Instead of using a centralised server for training, the model uses data stored locally on the device itself. After that, the server uses this model to create a jointly trained model. Federated learning asserts that privacy is preserved because no data is sent. Botnet attacks are detected using on-device decentralised traffic statistics and a deep autoencoder. This proposed federated learning approach addresses privacy and security concerns about data privacy and security rather than allowing data to be transferred or relocated off the network edge. In order to get the intended results of a previously centralised machine learning technique while also increasing data security, computation will be shifted to the edge layer. Up to 98\% accuracy is achieved in anomaly detection with our proposed model using features like MAC IP and source/destination/IP for training. Our solution outperforms a standard centrally managed system in terms of attack detection accuracy, according to our comparative performance analysis.},
  langid = {english}
}

@report{albaseer_DataDrivenParticipantSelection_2022,
  type = {preprint},
  title = {Data-{{Driven Participant Selection}} and {{Bandwidth Allocation}} for {{Heterogeneous Federated Edge Learning}}},
  author = {Albaseer, Abdullatif and Abdallah, Mohamed and Al-Fuqaha, Ala and Erbad, aiman},
  date = {2022-03-11},
  doi = {10.36227/techrxiv.19317671.v1},
  url = {https://www.techrxiv.org/articles/preprint/Data-Driven_Participant_Selection_and_Bandwidth_Allocation_for_Heterogeneous_Federated_Edge_Learning/19317671/1},
  urldate = {2022-03-23},
  abstract = {Federated edge learning (FEEL) is a fast-growing distributed learning technique for next-generation wireless edge systems. Smart systems in different application domains suffer from data heterogeneity, limited wireless resources, and device heterogeneity, necessitating the need for intelligent participants' selection schemes that accelerate the convergence rate. Hence, this paper proposes joint participants selection and bandwidth allocation schemes to address these challenges. First, we formulate an optimization problem considering communication and computation latencies and imbalanced data distribution that meets a target round deadline and bandwidth constraints. To tackle participant selection combinatorial problems, we use a relaxation method followed by a proposed priority selection algorithm to select near-optimal participants. The proposed algorithm initially prioritizes participants with more data, effective channel states, and better CPU speed. To tackle data heterogeneity, we propose a randomized deadline controlling algorithm that diversifies the updates by enabling the edge server to involve various participants with small data samples into training rounds. The proposed algorithms provide near-optimal performance compared to the brute-force method. Experiments demonstrate that our proposed scheme accelerates the convergence rate by up to 55\% under extensive non-i.i.d settings compared to benchmarks. Additionally, the controlling algorithm significantly improves the performance of the high data heterogeneity levels, resulting in faster FEEL systems.},
  langid = {english}
}

@article{aledhari_FederatedLearningSurvey_2020,
  title = {Federated {{Learning}}: {{A Survey}} on {{Enabling Technologies}}, {{Protocols}}, and {{Applications}}},
  author = {Aledhari, Mohammed and Razzak, Rehma and Parizi, Reza M. and Saeed, Fahad},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {140699--140725},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3013541},
  url = {https://ieeexplore.ieee.org/document/9153560/},
  abstract = {This paper provides a comprehensive study of Federated Learning (FL) with an emphasis on enabling software and hardware platforms, protocols, real-life applications and use-cases. FL can be applicable to multiple domains but applying it to different industries has its own set of obstacles. FL is known as collaborative learning, where algorithm(s) get trained across multiple devices or servers with decentralized data samples without having to exchange the actual data. This approach is radically different from other more established techniques such as getting the data samples uploaded to servers or having data in some form of distributed infrastructure. FL on the other hand generates more robust models without sharing data, leading to privacy-preserved solutions with higher security and access privileges to data. This paper starts by providing an overview of FL. Then, it gives an overview of technical details that pertain to FL enabling technologies, protocols, and applications. Compared to other survey papers in the field, our objective is to provide a more thorough summary of the most relevant protocols, platforms, and real-life use-cases of FL to enable data scientists to build better privacy-preserving solutions for industries in critical need of FL. We also provide an overview of key challenges presented in the recent literature and provide a summary of related research work. Moreover, we explore both the challenges and advantages of FL and present detailed service use-cases to illustrate how different architectures and protocols that use FL can fit together to deliver desired results.}
}

@article{alexander_MITREATTCK_2020,
  title = {{{MITRE ATT}}\&{{CK}} for {{Industrial Control Systems}} : {{Design}} and {{Philosophy}}},
  author = {Alexander, Otis and Belisle, Misha and Steele, Jacob},
  date = {2020},
  abstract = {This paper discusses the motivation behind the creation of MITRE ATT\&CK\textregistered{} for Industrial Control Systems (ICS), the unique components described within it, its design philosophy, how the project has progressed, and how it can be used. For individuals new to ATT\&CK, the MITRE ATT\&CK\textregistered : Design and Philosophy whitepaper [1] should be read before reading this paper. This document does not represent a comprehensive resource on MITRE ATT\&CK. For individuals already familiar with ATT\&CK, this document can be viewed as an extension to the MITRE ATT\&CK whitepaper that highlights unique, as well as some common, aspects of the design and philosophy of ATT\&CK for ICS.},
  keywords = {â›” No DOI found}
}

@inproceedings{alexopoulos_BlockchainBasedCollaborativeIntrusion_2018,
  title = {Towards {{Blockchain-Based Collaborative Intrusion Detection Systems}}},
  booktitle = {Critical {{Information Infrastructures Security}}},
  author = {Alexopoulos, Nikolaos and Vasilomanolakis, Emmanouil and Iv\'ank\'o, Nat\'alia R\'eka and M\"uhlh\"auser, Max},
  editor = {D'Agostino, Gregorio and Scala, Antonio},
  date = {2018},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {107--118},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-99843-5_10},
  abstract = {In an attempt to cope with the increased number of cyber-attacks, research in Intrusion Detection System IDSs is moving towards more collaborative mechanisms. Collaborative IDSs (CIDSs) are such an approach; they combine the knowledge of a plethora of monitors to generate a holistic picture of the monitored network. Despite the research done in this field, CIDSs still face a number of fundamental challenges, especially regarding maintaining trust among the collaborating parties. Recent advances in distributed ledger technologies, e.g. various implementations of blockchain protocols, are a good fit to the problem of enhancing trust in collaborative environments. This paper touches the intersection of CIDSs and blockchains. Particularly, it introduces the idea of utilizing blockchain technologies as a mechanism for improving CIDSs. We argue that certain properties of blockchains can be of significant benefit for CIDSs; namely for the improvement of trust between monitors, and for providing accountability and consensus. For this, we study the related work and highlight the research gaps and challenges towards such a task. Finally, we propose a generic architecture for the incorporation of blockchains into the field of CIDSs and an analysis of the design decisions that need to be made to implement such an architecture.},
  isbn = {978-3-319-99843-5},
  langid = {english}
}

@article{ali_BlockchainFederatedLearningbased_2023,
  title = {Blockchain and {{Federated Learning-based Intrusion Detection Approaches}} for {{Edge-enabled Industrial IoT Networks}}: {{A Survey}}},
  shorttitle = {Blockchain and {{Federated Learning-based Intrusion Detection Approaches}} for {{Edge-enabled Industrial IoT Networks}}},
  author = {Ali, Saqib and Li, Qianmu and Yousafzai, Abdullah},
  date = {2023-10-07},
  journaltitle = {Ad Hoc Networks},
  shortjournal = {Ad Hoc Networks},
  doi = {10.1016/j.adhoc.2023.103320},
  abstract = {The Industrial Internet of Things (IIoT) is an evolutionary extension of the traditional Internet of Things (IoT) into processes and machines for applications in the industrial sector. The IIoT systems generate a large amount of private and sensitive data i.e., stored and processed somewhere on the cloud-edge continuum. The IIoT devices, and the IIoT networks are subject to security mechanisms such as intelligent Intrusion Detection and Prevention Systems (IDS/IPS) systems, that can detect and respond unseen malicious network attacks. The adoption of centralized machine learning methods for IDS has become impractical due to the high computational cost and privacy concerns associated with storing large amounts of data on a single server along the cloud-edge continuum. The combination of federated learning and Blockchain has emerged as a promising advancement in addressing the challenge. Federated learning distributes learning to individual IIoT devices without compromising data privacy, while Blockchain enhances privacy and security. Many academic and industrial efforts outline IDS mechanisms using machine learning, deep learning, federated learning, and Blockchain technologies. The utilization of federated learning-based IDS has become increasingly popular and is now being applied to various tasks including IDS/IPS systems. However, existing intrusion detection systems (IDSs) survey are limited to the scope of classical machine learning and deep learning. To address this limitation, we analyze the IIoT literature that integrates Blockchain and federated learning to enhance IDSs and improve its threat detection capabilities. This survey explores the role of Blockchain and federated learning in addressing security and privacy issues, particularly those associated with IDS/IPS in IIoT networks. Insights on the possibilities of machine learning, federated learning, and Blockchain in supporting IDS to monitor IIoT network traffic for anomaly detection are discussed in detail through state of the art. Furthermore, we provide a set of recommendation based on our literature for the effective implementation of a Blockchain and federated learning-based network intrusion detection system. Finally, we summarize the study and highlight challenges as future research directions for Blockchain and Federated Learning-based technologies for cybersecurity and intrusion detection in IIoT.}
}

@article{ali_systematicreviewfederated_2023,
  title = {A Systematic Review of Federated Learning Incentive Mechanisms and Associated Security Challenges},
  author = {Ali, Asad and Ilahi, Inaam and Qayyum, Adnan and Mohammed, Ihab and Al-Fuqaha, Ala and Qadir, Junaid},
  date = {2023-11-01},
  journaltitle = {Computer Science Review},
  shortjournal = {Computer Science Review},
  volume = {50},
  pages = {100593},
  issn = {1574-0137},
  doi = {10.1016/j.cosrev.2023.100593},
  url = {https://www.sciencedirect.com/science/article/pii/S1574013723000606},
  urldate = {2024-04-12},
  abstract = {In response to various privacy risks, researchers and practitioners have been exploring different paradigms that can leverage the increased computational capabilities of consumer devices to train machine learning (ML) models in a distributed fashion without requiring the uploading of the training data from individual devices to central facilities. For this purpose, federated learning (FL) was proposed as a technique that can learn a global machine model at a central master node by the aggregation of models trained locally using private data. However, organizations may be reluctant to train models locally and to share these local ML models due to the required computational resources for model training at their end and due to privacy risks that may result from adversaries inverting these models to infer information about the private training data. Incentive mechanisms have been proposed to motivate end users to participate in collaborative training of ML models (using their local data) in return for certain rewards. However, the design of an optimal incentive mechanism for FL is challenging due to its distributed nature and the fact that the central server has no access to clients' hyperparameters information and the amount/quality data used for training, which makes the task of determining the reward based on the contribution of individual clients in FL environment difficult. Even though several incentive mechanisms have been proposed for FL, a thorough up-to-date systematic review is missing and this paper fills this gap. To the best of our knowledge, this paper is the first systematic review that comprehensively enlists the design principles required for implementing these incentive mechanisms and then categorizes various incentive mechanisms according to their design principles. In addition, we also provide a comprehensive overview of security challenges associated with incentive-driven FL. Finally, we highlight the limitations and pitfalls of these incentive schemes and elaborate upon open-research issues that require further research attention.},
  keywords = {Blockchain,Federated learning,Game theory,Incentive schemes,Mechanism design}
}

@inproceedings{ali-tolppa_SELFHEALINGRESILIENCEFUTURE_2018,
  title = {{{SELF-HEALING AND RESILIENCE IN FUTURE 5G COGNITIVE AUTONOMOUS NETWORKS}}},
  booktitle = {2018 {{ITU Kaleidoscope}}: {{Machine Learning}} for a {{5G Future}} ({{ITU K}})},
  author = {Ali-Tolppa, Janne and Kocsis, Szilard and Schultz, Benedek and Bodrog, Levente and Kajo, Marton},
  date = {2018-11},
  pages = {1--8},
  publisher = {IEEE},
  location = {Santa Fe},
  doi = {10.23919/ITU-WT.2018.8598115},
  url = {https://ieeexplore.ieee.org/document/8598115/},
  urldate = {2022-03-31},
  abstract = {In the Self-Organizing Networks (SON) concept, self-healing functions are used to detect, diagnose and correct degraded states in the managed network functions or other resources. Such methods are increasingly important in future network deployments, since ultra-high reliability is one of the key requirements for the future 5G mobile networks, e.g. in critical machine-type communication. In this paper, we discuss the considerations for improving the resiliency of future cognitive autonomous mobile networks. In particular, we present an automated anomaly detection and diagnosis function for SON self-healing based on multi-dimensional statistical methods, case-based reasoning and active learning techniques. Insights from both the human expert and sophisticated machine learning methods are combined in an iterative way. Additionally, we present how a more holistic view on mobile network self-healing can improve its performance.},
  eventtitle = {2018 {{ITU Kaleidoscope}}: {{Machine Learning}} for a {{5G Future}} ({{ITU K}})},
  isbn = {978-92-61-26921-0},
  langid = {english}
}

@article{alkhalidy_NewSchemeDetecting_2022,
  title = {A {{New Scheme}} for {{Detecting Malicious Nodes}} in {{Vehicular Ad Hoc Networks Based}} on {{Monitoring Node Behavior}}},
  author = {Alkhalidy, Muhsen and Al-Serhan, Atalla Fahed and Alsarhan, Ayoub and Igried, Bashar},
  date = {2022},
  journaltitle = {Future Internet},
  pages = {11},
  doi = {10.3390/fi14080223},
  abstract = {Vehicular ad hoc networks have played a key role in intelligent transportation systems that considerably improve road safety and management. This new technology allows vehicles to communicate and share road information. However, malicious users may inject false emergency alerts into vehicular ad hoc networks, preventing nodes from accessing accurate road information. In order to assure the reliability and trustworthiness of information through the networks, assessing the credibility of nodes has become a critical task in vehicular ad hoc networks. A new scheme for malicious node detection is proposed in this work. Multiple factors are fed into a fuzzy logic model for evaluating the trust for each node. Vehicles are divided into clusters in our approach, and a road side unit manages each cluster. The road side unit assesses the credibility of nodes before accessing vehicular ad hoc networks. The road side unit evicts a malicious node based on trust value. Simulations are used to validate our technique. We demonstrate that our scheme can detect and evict all malicious nodes in the vehicular ad hoc network over time, lowering the ratio of malicious nodes. Furthermore, it has a positive impact on selfish node participation. The scheme increases the success rate of delivered data to the same level as the ideal cases when no selfish node is present.},
  langid = {english}
}

@article{almanifi_Communicationcomputationefficiency_2023,
  title = {Communication and Computation Efficiency in {{Federated Learning}}: {{A}} Survey},
  shorttitle = {Communication and Computation Efficiency in {{Federated Learning}}},
  author = {Almanifi, Omair Rashed Abdulwareth and Chow, Chee-Onn and Tham, Mau-Luen and Chuah, Joon Huang and Kanesan, Jeevan},
  date = {2023-03-05},
  journaltitle = {Internet of Things},
  shortjournal = {Internet of Things},
  pages = {100742},
  issn = {2542-6605},
  doi = {10.1016/j.iot.2023.100742},
  url = {https://www.sciencedirect.com/science/article/pii/S2542660523000653},
  urldate = {2023-03-09},
  abstract = {Federated Learning is a much-needed technology in this golden era of big data and Artificial Intelligence, due to its vital role in preserving data privacy, and eliminating the need to transfer and process huge amounts of data, while maintaining the numerous benefits of Machine Learning. As opposed to the typical central training process, Federated Learning involves the collaborative training of statistical models by exchanging learned parameter updates. However, wide adoption of the technology is hindered by the communication and computation overhead forming due to the demanding computational cost of training, and the large-sized parameter updates exchanged. In popular applications such as those involving Internet of Things, the effects of the overhead are exacerbated due to the low computational prowess of edge and fog devices, limited bandwidth, and data capacity of internet connections. Over the years, many research activities that target this particular issue were conducted but a comprehensive review of the fragmented literature is still missing. This paper aims at filling this gap by providing a systematic review of recent work conducted to improve the communication and/or computation efficiency in Federated Learning. We begin by introducing the essentials of Federated Learning and its variations, followed by the literature review placed according to an encompassing, easy-to-follow taxonomy. Lastly, the work sheds light on the current challenges faced by the technology and possible directions for future work.},
  langid = {english},
  keywords = {Communication efficiency,Computation efficiency,Federated Learning,Internet of Things,Machine learning}
}

@article{almomani_WSNDSDatasetIntrusion_2016,
  title = {{{WSN-DS}}: {{A Dataset}} for {{Intrusion Detection Systems}} in {{Wireless Sensor Networks}}},
  shorttitle = {{{WSN-DS}}},
  author = {Almomani, Iman and Al-Kasasbeh, Bassam and AL-Akhras, Mousa},
  date = {2016},
  journaltitle = {Journal of Sensors},
  shortjournal = {Journal of Sensors},
  volume = {2016},
  pages = {1--16},
  issn = {1687-725X, 1687-7268},
  doi = {10.1155/2016/4731953},
  url = {https://www.hindawi.com/journals/js/2016/4731953/},
  urldate = {2021-10-25},
  abstract = {Wireless Sensor Networks (WSN) have become increasingly one of the hottest research areas in computer science due to their wide range of applications including critical military and civilian applications. Such applications have created various security threats, especially in unattended environments. To ensure the security and dependability of WSN services, an Intrusion Detection System (IDS) should be in place. This IDS has to be compatible with the characteristics of WSNs and capable of detecting the largest possible number of security threats. In this paper a specialized dataset for WSN is developed to help better detect and classify four types of Denial of Service (DoS) attacks: Blackhole, Grayhole, Flooding, and Scheduling attacks. This paper considers the use of LEACH protocol which is one of the most popular hierarchical routing protocols in WSNs. A scheme has been defined to collect data from Network Simulator 2 (NS-2) and then processed to produce 23 features. The collected dataset is called WSN-DS. Artificial Neural Network (ANN) has been trained on the dataset to detect and classify different DoS attacks. The results show that WSN-DS improved the ability of IDS to achieve higher classification accuracy rate. WEKA toolbox was used with holdout and 10-Fold Cross Validation methods. The best results were achieved with 10-Fold Cross Validation with one hidden layer. The classification accuracies of attacks were 92.8\%, 99.4\%, 92.2\%, 75.6\%, and 99.8\% for Blackhole, Flooding, Scheduling, and Grayhole attacks, in addition to the normal case (without attacks), respectively.},
  langid = {english}
}

@article{alrumaih_GENINDindustrialnetwork_2023,
  title = {{{GENIND}}: {{An}} Industrial Network Topology Generator},
  shorttitle = {{{GENIND}}},
  author = {Alrumaih, Thuraya N. I. and Alenazi, Mohammed J. F.},
  date = {2023-09-15},
  journaltitle = {Alexandria Engineering Journal},
  shortjournal = {Alexandria Engineering Journal},
  volume = {79},
  pages = {56--71},
  issn = {1110-0168},
  doi = {10.1016/j.aej.2023.07.062},
  url = {https://www.sciencedirect.com/science/article/pii/S111001682300649X},
  urldate = {2024-07-08},
  abstract = {The availability of industrial network topologies is limited, which presents a significant challenge for researchers in this field. Network generators are essential tools for generating realistic simulation outcomes in network research. Thus, it is crucial to use realistic topologies that can accurately represent the characteristics of the target network. The primary objective of this study is to address the existing research gap by developing an industrial network topology generator for novel topology datasets specific to industrial networks and the industrial Internet of Things (IIoT). In this paper, we describe the development of the graph theoretic industrial topology generator (GENIND), a topology generator that can produce realistic IIoT and industrial network topologies. The proposed GENIND network topology generator is validated through comparisons with real-world industrial network topologies. The evaluation framework assesses the performance of the proposed GENIND system using three main measures: the overall network structure, path-related factors, and resilience topological structure features. The results of the evaluation demonstrate a high degree of similarity between the graphs generated by the GENIND system and the real-world industrial networks used for comparison. This finding suggests that the generated graphs can be utilized as reliable tools to predict the behavior of industrial networks under various conditions.},
  keywords = {Dataset generator,Graph theory,Industrial Internet of Things (IIoT) network topology generator,Industrial network generator,Industrial network topology simulation,Large-scale cyber-physical system networks}
}

@inproceedings{alsaheel_ATLASSequencebasedLearning_2021,
  title = {{{ATLAS}}: {{A Sequence-based Learning Approach}} for {{Attack Investigation}}},
  shorttitle = {{{ATLAS}}},
  author = {Alsaheel, Abdulellah and Nan, Yuhong and Ma, Shiqing and Yu, Le and Walkup, Gregory and Celik, Z. Berkay and Zhang, Xiangyu and Xu, Dongyan},
  date = {2021},
  pages = {3005--3022},
  url = {https://www.usenix.org/conference/usenixsecurity21/presentation/alsaheel},
  urldate = {2022-08-30},
  eventtitle = {30th {{USENIX Security Symposium}} ({{USENIX Security}} 21)},
  isbn = {978-1-939133-24-3},
  langid = {english}
}

@article{alsamiri_FederatedLearningIntrusion_2023,
  title = {Federated {{Learning}} for {{Intrusion Detection Systems}} in {{Internet}} of {{Vehicles}}: {{A General Taxonomy}}, {{Applications}}, and {{Future Directions}}},
  shorttitle = {Federated {{Learning}} for {{Intrusion Detection Systems}} in {{Internet}} of {{Vehicles}}},
  author = {Alsamiri, Jadil and Alsubhi, Khalid},
  date = {2023-12},
  journaltitle = {Future Internet},
  volume = {15},
  number = {12},
  pages = {403},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1999-5903},
  doi = {10.3390/fi15120403},
  url = {https://www.mdpi.com/1999-5903/15/12/403},
  urldate = {2024-04-12},
  abstract = {In recent years, the Internet of Vehicles (IoV) has garnered significant attention from researchers and automotive industry professionals due to its expanding range of applications and services aimed at enhancing road safety and driver/passenger comfort. However, the massive amount of data spread across this network makes securing it challenging. The IoV network generates, collects, and processes vast amounts of valuable and sensitive data that intruders can manipulate. An intrusion detection system (IDS) is the most typical method to protect such networks. An IDS monitors activity on the road to detect any sign of a security threat and generates an alert if a security anomaly is detected. Applying machine learning methods to large datasets helps detect anomalies, which can be utilized to discover potential intrusions. However, traditional centralized learning algorithms require gathering data from end devices and centralizing it for training on a single device. Vehicle makers and owners may not readily share the sensitive data necessary for training the models. Granting a single device access to enormous volumes of personal information raises significant privacy concerns, as any system-related problems could result in massive data leaks. To alleviate these problems, more secure options, such as Federated Learning (FL), must be explored. A decentralized machine learning technique, FL allows model training on client devices while maintaining user data privacy. Although FL for IDS has made significant progress, to our knowledge, there has been no comprehensive survey specifically dedicated to exploring the applications of FL for IDS in the IoV environment, similar to successful systems research in deep learning. To address this gap, we undertake a well-organized literature review on IDSs based on FL in an IoV environment. We introduce a general taxonomy to describe the FL systems to ensure a coherent structure and guide future research. Additionally, we identify the relevant state of the art in FL-based intrusion detection within the IoV domain, covering the years from FL's inception in 2016 through 2023. Finally, we identify challenges and future research directions based on the existing literature.},
  issue = {12},
  langid = {english},
  keywords = {deep learning,Federated Learning (FL),Internet of Vehicles (IoV),intrusion detection systems (IDS),machine learning}
}

@inproceedings{althubiti_ApplyingLongShortTerm_2018,
  title = {Applying {{Long Short-Term Memory Recurrent Neural Network}} for {{Intrusion Detection}}},
  booktitle = {{{SoutheastCon}} 2018},
  author = {Althubiti, Sara and Nick, William and Mason, Janelle and Yuan, Xiaohong and Esterline, Albert},
  date = {2018-04},
  pages = {1--5},
  publisher = {IEEE},
  location = {St. Petersburg, FL},
  doi = {10.1109/SECON.2018.8478898},
  url = {https://ieeexplore.ieee.org/document/8478898/},
  urldate = {2021-10-13},
  abstract = {These days, web applications are used extensively. While organizations benefit from the new abilities they provide, the chance of being targeted is increased, which may cause massive system damage. It is thus important to detect web application attacks. Web intrusion detection systems (IDSs) are important for protecting systems from external users or internal attacks. There are however, many challenges that arise while developing a powerful IDS for unexpected and irregular attacks. Deep Learning approaches provide several methods, and they can detect known and unknown attacks. Long Short-Term Memory (LSTM) is a type of Recurrent Neural Network (RNN) and has the ability to remember values over arbitrary intervals. LSTM is a suitable method to classify and predict known and unknown intrusions. In this work, we propose a deep learning approach to construct an IDS. We apply LSTM RNNs and train the model using the CSIC 2010 HTTP dataset. An LSTM model using the Adam optimizer can construct an efficient IDS binary classifier with an accuracy rate of 0.9997.},
  eventtitle = {{{SoutheastCon}} 2018},
  isbn = {978-1-5386-6133-8},
  langid = {english}
}

@article{alves_Selectionmesuressimilarite_,
  title = {S\'election de mesures de similarit\'e pour les donn\'ees cat\'egorielles},
  author = {Alves, Guilherme and Couceiro, Miguel and Napoli, Amedeo},
  langid = {french}
}

@inproceedings{amadeo_ClientDiscoveryData_2022,
  title = {Client {{Discovery}} and {{Data Exchange}} in {{Edge-based Federated Learning}} via {{Named Data Networking}}},
  booktitle = {{{ICC}} 2022 - {{IEEE International Conference}} on {{Communications}}},
  author = {Amadeo, Marica and Campolo, Claudia and Iera, Antonio and Molinaro, Antonella and Ruggeri, Giuseppe},
  date = {2022-05},
  pages = {2990--2995},
  issn = {1938-1883},
  doi = {10.1109/ICC45855.2022.9839172},
  abstract = {Federated learning (FL) is gaining momentum as a prominent solution to perform training procedures without the need to move sensitive end-user data to a centralized third party server. In FL, models are locally trained at distributed end-devices, acting as clients, and only model updates are transferred from the clients to the aggregator, which is in charge of global model aggregation. Although FL can ensure better privacy preservation than centralized machine learning (ML), it exhibits still some concerns. First, clients need to be properly discovered and selected to ensure that highly accurate models are built. Second, huge models may still require to be exchanged from the aggregator to all the selected clients, incurring a not negligible network footprint. To tackle such issues, in this paper, we propose a framework built upon in-network caching, multicast and name based data delivery, natively provided by the Named Data Networking (NDN) paradigm, in order to support client discovery and aggregator-clients data exchange. Benefits of the proposal are showcased when compared to a conventional application-layer solution.},
  eventtitle = {{{ICC}} 2022 - {{IEEE International Conference}} on {{Communications}}},
  keywords = {Collaborative work,Edge Artificial Intelligence,Federated Learning,In-network caching,Information Centric Networking,Machine learning,Multicast communication,Named Data Networking,Packet loss,Privacy,Proposals,Training}
}

@article{amadeo_NDNeEnhancingNamed_2016,
  title = {{{NDNe}}: {{Enhancing Named Data Networking}} to {{Support Cloudification}} at the {{Edge}}},
  shorttitle = {{{NDNe}}},
  author = {Amadeo, Marica and Campolo, Claudia and Molinaro, Antonella},
  date = {2016-11},
  journaltitle = {IEEE Communications Letters},
  volume = {20},
  number = {11},
  pages = {2264--2267},
  issn = {1558-2558},
  doi = {10.1109/LCOMM.2016.2597850},
  abstract = {The technological advances in mobile devices are pushing cloud computing to the network edge, where services such as data storage and processing can be offered by mobile devices locally with improved quality. In this letter, we identify named data networking (NDN) as a key enabler to support ``by design'' the peculiarities of decentralized edge clouds at the network layer. We extend NDN beyond its original scope of content retrieval facilitator, by letting names to address, not only ``contents'' but also ``cloud services,'' and enhancing the semantics of NDN primitives to efficiently and reliably support both the provider discovery and the service provisioning phases. An early evaluation is performed to showcase the benefits of the proposal, and also when compared with a traditional TCP/IP-based approach.},
  eventtitle = {{{IEEE Communications Letters}}},
  keywords = {Cloud computing,Delays,Memory,mobile cloud computing,Mobile communication,mobile edge computing,Mobile handsets,Named data networking,Semantics,Wireless communication}
}

@article{amiri-zarandi_SIDSfederatedlearning_2023,
  title = {{{SIDS}}: {{A}} Federated Learning Approach for Intrusion Detection in {{IoT}} Using {{Social Internet}} of {{Things}}},
  shorttitle = {{{SIDS}}},
  author = {Amiri-Zarandi, Mohammad and Dara, Rozita A. and Lin, Xiaodong},
  date = {2023-11-01},
  journaltitle = {Computer Networks},
  shortjournal = {Computer Networks},
  volume = {236},
  pages = {110005},
  issn = {1389-1286},
  doi = {10.1016/j.comnet.2023.110005},
  url = {https://www.sciencedirect.com/science/article/pii/S1389128623004504},
  urldate = {2024-04-12},
  abstract = {The Internet of Things (IoT) ecosystem needs Intrusion Detection Systems (IDS) to mitigate cyberattacks and exploit security vulnerabilities. Over the past years, utilizing machine learning in IDSs has gained a lot of attention. However, in many current works, the training data from different locations should be collected in a central server to be used in the learning process. This data-sharing procedure increases concerns regarding data privacy and decreases the data holders' motivation to participate in the learning process. The use of distributed learning models has been considered a solution to overcome concerns related to privacy. However, these distributed learning models are vulnerable in the presence of untrusted nodes that can participate in the learning process and deteriorate performance. In this paper, we propose SIDS (Social Intrusion Detection System), a trust-oriented federated learning approach for intrusion detection in IoT that utilizes the Social Internet of Things (SIoT). The proposed approach leverages the social relationships among the objects in a system to provide a privacy-preserving collaborative mechanism for detecting intrusions in IoT environments. The experimental results show the proposed solution outperforms the learning models on individual servers while providing a privacy-preserving and trustable environment for collaboration.},
  keywords = {Federated learning,Generative Adversarial Networks,IoT,Privacy,Security,SIoT}
}

@inproceedings{anceaume_AnKLeDetectingAttacks_2012,
  title = {{{AnKLe}}: {{Detecting Attacks}} in {{Large Scale Systems}} via {{Information Divergence}}},
  booktitle = {2012 {{Ninth European Dependable Computing Conference}}},
  author = {Anceaume, Emmanuelle and Busnel, Yann and Gambs, S\'ebastien},
  date = {2012-05},
  pages = {114--125},
  publisher = {IEEE},
  doi = {10.1109/EDCC.2012.9},
  url = {http://ieeexplore.ieee.org/document/6214766/},
  abstract = {In this paper, we consider the setting of large scale distributed systems, in which each node needs to quickly process a huge amount of data received in the form of a stream that may have been tampered with by an adversary. In this situation, a fundamental problem is how to detect and quantify the amount of work performed by the adversary. To address this issue, we propose AnKLe (for Attack-tolerant enhanced Kullback-Leibler divergence Estimator), a novel algorithm for estimating the KL divergence of an observed stream compared to the expected one. AnKLe combines sampling techniques and information-theoretic methods. It is very efficient, both in terms of space and time complexities, and requires only a single pass over the data stream. Experimental results show that the estimation provided by AnKLe remains accurate even for different adversarial settings for which the quality of other methods dramatically decreases. \copyright{} 2012 IEEE.},
  isbn = {978-1-4673-0938-7}
}

@inproceedings{anceaume_AnomalyCharacterizationLarge_2014,
  title = {Anomaly {{Characterization}} in {{Large Scale Networks}}},
  booktitle = {2014 44th {{Annual IEEE}}/{{IFIP International Conference}} on {{Dependable Systems}} and {{Networks}}},
  author = {Anceaume, Emmanuelle and Busnel, Yann and Merrer, Erwan Le and Ludinard, Romaric and Marchand, Jean Louis and Sericola, Bruno},
  date = {2014-06},
  pages = {68--79},
  publisher = {IEEE},
  doi = {10.1109/DSN.2014.23},
  url = {https://ieeexplore.ieee.org/document/6903568},
  abstract = {The context of this work is the online characterization of errors in large scale systems. In particular, we address the following question: Given two successive configurations of the system, can we distinguish massive errors from isolated ones, the former ones impacting a large number of nodes while the second ones affect solely a small number of them, or even a single one? The rationale of this question is twofold. First, from a theoretical point of view, we characterize errors with respect to their neighbourhood, and we show that there are error scenarios for which isolated and massive errors are indistinguishable from an omniscient observer point of view. We then relax the definition of this problem by introducing unresolved configurations, and exhibit necessary and sufficient conditions that allow any node to determine the type of errors it has been impacted by. These conditions only depend on the close neighbourhood of each node and thus are locally computable. We present algorithms that implement these conditions, and show through extensive simulations, their performances. Now from a practical point of view, distinguishing isolated errors from massive ones is of utmost importance for networks providers. For instance, for Internet service providers that operate millions of home gateways, it would be very interesting to have procedures that allow gateways to self distinguish whether their dysfunction is caused by network-level errors or by their own hardware or software, and to notify the service provider only in the latter case.},
  isbn = {978-1-4799-2233-8}
}

@inproceedings{androulaki_HyperledgerFabricDistributed_2018,
  title = {Hyperledger {{Fabric}}: {{A Distributed Operating System}} for {{Permissioned Blockchains}}},
  booktitle = {Proceedings of the {{Thirteenth EuroSys Conference}}},
  author = {Androulaki, Elli and Barger, Artem and Bortnikov, Vita and Cachin, Christian and Christidis, Konstantinos and De Caro, Angelo and Enyeart, David and Ferris, Christopher and Laventman, Gennady and Manevich, Yacov and Muralidharan, Srinivasan and Murthy, Chet and Nguyen, Binh and Sethi, Manish and Singh, Gari and Smith, Keith and Sorniotti, Alessandro and Stathakopoulou, Chrysoula and Vukoli\'c, Marko and Cocco, Sharon Weed and Yellick, Jason},
  date = {2018-04-23},
  pages = {1--15},
  publisher = {ACM},
  location = {New York, NY, USA},
  doi = {10.1145/3190508.3190538},
  url = {https://dl.acm.org/doi/10.1145/3190508.3190538},
  abstract = {Fabric is a modular and extensible open-source system for deploying and operating permissioned blockchains and one of the Hyperledger projects hosted by the Linux Foundation (www.hyperledger.org). Fabric is the first truly extensible blockchain system for running distributed applications. It supports modular consensus protocols, which allows the system to be tailored to particular use cases and trust models. Fabric is also the first blockchain system that runs distributed applications written in standard, general-purpose programming languages, without systemic dependency on a native cryptocurrency. This stands in sharp contrast to existing block-chain platforms that require "smart-contracts" to be written in domain-specific languages or rely on a cryptocurrency. Fabric realizes the permissioned model using a portable notion of membership, which may be integrated with industry-standard identity management. To support such flexibility, Fabric introduces an entirely novel blockchain design and revamps the way blockchains cope with non-determinism, resource exhaustion, and performance attacks. This paper describes Fabric, its architecture, the rationale behind various design decisions, its most prominent implementation aspects, as well as its distributed application programming model. We further evaluate Fabric by implementing and benchmarking a Bitcoin-inspired digital currency. We show that Fabric achieves end-to-end throughput of more than 3500 transactions per second in certain popular deployment configurations, with sub-second latency, scaling well to over 100 peers.},
  isbn = {978-1-4503-5584-1}
}

@inproceedings{anton_PuttingTogetherPieces_2019,
  title = {Putting {{Together}} the {{Pieces}}: {{A Concept}} for {{Holistic Industrial Intrusion Detection}}},
  booktitle = {Proceedings of the 2019 {{European Conference}} on {{Cyber Warfare}} and {{Security}} ({{ECCWS}})},
  author = {Ant\'on, Simon Duque and Schotten, Hans Dieter},
  date = {2019},
  pages = {11},
  eventtitle = {European {{Conference}} on {{Cyber Warfare}} and {{Security}} ({{ECCWS}})},
  langid = {english},
  keywords = {â›” No DOI found}
}

@article{aouedi_FederatedSemisupervisedLearning_2023,
  title = {Federated {{Semisupervised Learning}} for {{Attack Detection}} in {{Industrial Internet}} of {{Things}}},
  author = {Aouedi, Ons and Piamrat, Kandaraj and Muller, Guillaume and Singh, Kamal},
  date = {2023-01},
  journaltitle = {IEEE Transactions on Industrial Informatics},
  volume = {19},
  number = {1},
  pages = {286--295},
  issn = {1941-0050},
  doi = {10.1109/TII.2022.3156642},
  url = {https://ieeexplore.ieee.org/abstract/document/9729433},
  urldate = {2024-04-12},
  abstract = {Security has become a critical issue for Industry4.0 due to different emerging cyber-security threats. Recently, many deep learning (DL) approaches have focused on intrusion detection. However, such approaches often require sending data to a central entity. This in turn raises concerns related to privacy, efficiency, and latency. Despite the huge amount of data generated by the Internet of Things (IoT) devices in Industry 4.0, it is difficult to get labeled data, because data labeling is costly and time-consuming. This poses many challenges for several DL approaches, which require labeled data. In order to deal with these issues, new approaches should be adopted. This article proposes a novel federated semisupervised learning scheme that takes advantage of both unlabeled and labeled data in a federated way. First, an autoencoder (AE) is trained on each device (using unlabeled local/private data) to learn the representative and low-dimensional features. Then, a cloud server aggregates these models into a global AE using federated learning (FL). Finally, the cloud server composes a supervised neural network, by adding fully connected layers (FCN) to the global encoder (the first part of the global AE) and trains the resulting model using publicly available labeled data. Extensive case studies on two real-world industrial datasets demonstrate that our model: (a) ensures that no local private data is exchanged; (b) detects attacks with high classification performance, (c) works even when only a few amounts of labeled data are available; and (d) haslow communication overhead.},
  eventtitle = {{{IEEE Transactions}} on {{Industrial Informatics}}},
  keywords = {\_read\_urgently,Data models,Data privacy,deep learning (DL),federated learning (FL),Industrial Internet of Things,intrusion detection,Intrusion detection,machine learning,Radio frequency,semisupervised learning,Servers,Training}
}

@inproceedings{aouedi_FLUIDSFederatedLearning_2022,
  title = {{{FLUIDS}}: {{Federated Learning}} with Semi-Supervised Approach for {{Intrusion Detection System}}},
  shorttitle = {{{FLUIDS}}},
  booktitle = {2022 {{IEEE}} 19th {{Annual Consumer Communications}} \& {{Networking Conference}} ({{CCNC}})},
  author = {Aouedi, Ons and Piamrat, Kandaraj and Muller, Guillaume and Singh, Kamal},
  date = {2022-01},
  pages = {523--524},
  issn = {2331-9860},
  doi = {10.1109/CCNC49033.2022.9700632},
  abstract = {In this paper, we present FLUIDS, a Federated Learning with semi-sUpervised approach for Intrusion Detection System. FLUIDS formulates the intrusion detection into a semi-supervised learning where both supervised learning (using labeled data) and unsupervised learning (no label data) are combined in a collaborative way. The combination of federated learning and semi-supervised Learning allows the solution to: better preserve the privacy, improve training and inference efficiency, achieve better accuracy, and be cheaper to deploy.},
  eventtitle = {2022 {{IEEE}} 19th {{Annual Consumer Communications}} \& {{Networking Conference}} ({{CCNC}})},
  keywords = {Auto-Encoder (AE),Collaborative work,Deep Learning (DL),Federated Learning (FL),Fluids,Intrusion detection,Intrusion Detection System (IDS),Machine Learning (ML),Privacy,Semi-Supervised Learning,Semisupervised learning,Supervised learning,Training}
}

@inproceedings{aouedi_IntrusiondetectionSoftwarized_2022,
  title = {Intrusion Detection for {{Softwarized Networks}} with {{Semi-supervised Federated Learning}}},
  booktitle = {{{ICC}} 2022 - {{IEEE International Conference}} on {{Communications}}},
  author = {Aouedi, Ons and Piamrat, Kandaraj and Muller, Guillaume and Singh, Kamal},
  date = {2022-05},
  pages = {5244--5249},
  issn = {1938-1883},
  doi = {10.1109/ICC45855.2022.9839042},
  url = {https://ieeexplore.ieee.org/document/9839042},
  urldate = {2024-04-25},
  abstract = {With the increasing development of 5G/Beyond 5G and network softwarization techniques, we have more flexibility and agility in the network. This can be exploited by Machine Learning (ML) to integrate intelligence in the network and improve network as well as service management in edge-cloud environment. Intrusion detection systems (IDS) is one of the challenging issues for managing network. However, traditional approaches in this domain require all data (and their associated labels) to be centralized at the same location. In this context, such approaches lead to: (i) a large bandwidth overhead, as raw data needs to be transmitted to the server, (ii) low incentives for devices to send their private data, and (iii) large computing and storage resources needed on the server side to label and treat all this data. In this paper, to cope with the above limitations, we propose a semi-supervised federated learning model for IDS. Moreover, we use network softwarisation for automation and deployment. Our model combines Federated Learning and Semi-Supervised Learning where the clients train unsupervised models (using unlabeled data) to learn the representative and low-dimensional features and the server conducts a supervised model (using labeled data). We evaluate this approach on the well-known UNSW-NB15 dataset and the experimental results demonstrate that our approach can achieve accuracy and detection rates up to 84.32\% and 83.10\%, respectively while keeping the data private with limited overhead.},
  eventtitle = {{{ICC}} 2022 - {{IEEE International Conference}} on {{Communications}}},
  keywords = {\_read,â›” No DOI found,Automation,Bandwidth,Computational modeling,Deep Learning,Federated Learning,Image edge detection,Internet of Things,Intrusion detection,Intrusion Detection,Machine learning,Machine Learning,Semi-supervised learning,Semisupervised learning}
}

@inproceedings{aouedi_SemisupervisedStackedAutoencoder_2020,
  title = {A {{Semi-supervised Stacked Autoencoder Approach}} for {{Network Traffic Classification}}},
  booktitle = {2020 {{IEEE}} 28th {{International Conference}} on {{Network Protocols}} ({{ICNP}})},
  author = {Aouedi, Ons and Piamrat, Kandaraj and Bagadthey, Dhruvjyoti},
  date = {2020-10},
  pages = {1--6},
  issn = {2643-3303},
  doi = {10.1109/ICNP49622.2020.9259390},
  url = {https://ieeexplore.ieee.org/document/9259390},
  urldate = {2024-06-19},
  abstract = {Network traffic classification is an important task in modern communications. Several approaches have been proposed to improve the performance of differentiating among applications. However, most of them are based on supervised learning where only labeled data are used. In reality, a lot of datasets are partially labeled due to many reasons and unlabeled portions of the data, which can also provide informative characteristics, are ignored. To handle this issue, we propose a semi-supervised approach based on deep learning. We deployed deep learning because of its unique nature for solving problems, and its ability to take into account both labeled and unlabeled data. Moreover, it can also integrate feature extraction and classification into a single model. To achieve these goals, we propose an approach using stacked sparse autoencoder (SSAE) accompanied by de-noising and dropout techniques to improve the robustness of extracted features and prevent the over-fitting problem during the training process. The obtained results demonstrate a better performance than traditional models while keeping the whole procedure automated.},
  eventtitle = {2020 {{IEEE}} 28th {{International Conference}} on {{Network Protocols}} ({{ICNP}})},
  keywords = {Deep learning,Dropout,Feature extraction,Machine learning,Noise reduction,Semi-supervised learning,Stacked Autoencoder,Stacked De-noising Autoencoder,Standards,Task analysis,Traffic classification,Training,Unsupervised learning}
}

@article{apruzzese_AppConMitigatingEvasion_2020,
  title = {{{AppCon}}: {{Mitigating Evasion Attacks}} to {{ML Cyber Detectors}}},
  shorttitle = {{{AppCon}}},
  author = {Apruzzese, Giovanni and Andreolini, Mauro and Marchetti, Mirco and Colacino, Vincenzo Giuseppe and Russo, Giacomo},
  date = {2020-04-21},
  journaltitle = {Symmetry},
  shortjournal = {Symmetry},
  volume = {12},
  number = {4},
  pages = {653},
  issn = {2073-8994},
  doi = {10.3390/sym12040653},
  url = {https://www.mdpi.com/2073-8994/12/4/653},
  urldate = {2022-07-05},
  abstract = {Adversarial attacks represent a critical issue that prevents the reliable integration of machine learning methods into cyber defense systems. Past work has shown that even proficient detectors are highly affected just by small perturbations to malicious samples, and that existing countermeasures are immature. We address this problem by presenting AppCon, an original approach to harden intrusion detectors against adversarial evasion attacks. Our proposal leverages the integration of ensemble learning to realistic network environments, by combining layers of detectors devoted to monitor the behavior of the applications employed by the organization. Our proposal is validated through extensive experiments performed in heterogeneous network settings simulating botnet detection scenarios, and consider detectors based on distinct machine- and deep-learning algorithms. The results demonstrate the effectiveness of AppCon in mitigating the dangerous threat of adversarial attacks in over 75\% of the considered evasion attempts, while not being affected by the limitations of existing countermeasures, such as performance degradation in non-adversarial settings. For these reasons, our proposal represents a valuable contribution to the development of more secure cyber defense platforms.},
  langid = {english},
  keywords = {\_read\_urgently}
}

@article{apruzzese_CrossevaluationMachineLearningbased_2022,
  title = {The {{Cross-evaluation}} of {{Machine Learning-based Network Intrusion Detection Systems}}},
  author = {Apruzzese, Giovanni and Pajola, Luca and Conti, Mauro},
  date = {2022},
  journaltitle = {IEEE Transactions on Network and Service Management},
  shortjournal = {IEEE Trans. Netw. Serv. Manage.},
  pages = {1--1},
  issn = {1932-4537, 2373-7379},
  doi = {10.1109/TNSM.2022.3157344},
  url = {https://ieeexplore.ieee.org/document/9729769/},
  urldate = {2022-07-05},
  abstract = {Enhancing Network Intrusion Detection Systems (NIDS) with supervised Machine Learning (ML) is tough. MLNIDS must be trained and evaluated, operations requiring data where benign and malicious samples are clearly labelled. Such labels demand costly expert knowledge, resulting in a lack of real deployments, as well as on papers always relying on the same outdated data. The situation improved recently, as some efforts disclosed their labelled datasets. However, most past works used such datasets just as a `yet another' testbed, overlooking the added potential provided by such availability.},
  langid = {english},
  keywords = {Evaluation.,Intrusion Detection Systems,Labeling,Machine learning,Machine Learning,Monitoring,Network intrusion detection,Network Security,Proposals,Reliability,Training}
}

@inproceedings{arazo_UnsupervisedLabelNoise_2019,
  title = {Unsupervised {{Label Noise Modeling}} and {{Loss Correction}}},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Arazo, Eric and Ortego, Diego and Albert, Paul and O'Connor, Noel and Mcguinness, Kevin},
  date = {2019-05-24},
  pages = {312--321},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v97/arazo19a.html},
  urldate = {2024-03-28},
  abstract = {Despite being robust to small amounts of label noise, convolutional neural networks trained with stochastic gradient methods have been shown to easily fit random labels. When there are a mixture of correct and mislabelled targets, networks tend to fit the former before the latter. This suggests using a suitable two-component mixture model as an unsupervised generative model of sample loss values during training to allow online estimation of the probability that a sample is mislabelled. Specifically, we propose a beta mixture to estimate this probability and correct the loss by relying on the network prediction (the so-called bootstrapping loss). We further adapt mixup augmentation to drive our approach a step further. Experiments on CIFAR-10/100 and TinyImageNet demonstrate a robustness to label noise that substantially outperforms recent state-of-the-art. Source code is available at https://git.io/fjsvE and Appendix at https://arxiv.org/abs/1904.11238.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@article{arisdakessian_SurveyIoTIntrusion_2023,
  title = {A {{Survey}} on {{IoT Intrusion Detection}}: {{Federated Learning}}, {{Game Theory}}, {{Social Psychology}}, and {{Explainable AI}} as {{Future Directions}}},
  shorttitle = {A {{Survey}} on {{IoT Intrusion Detection}}},
  author = {Arisdakessian, Sarhad and Wahab, Omar Abdel and Mourad, Azzam and Otrok, Hadi and Guizani, Mohsen},
  date = {2023-03},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {10},
  number = {5},
  pages = {4059--4092},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2022.3203249},
  url = {https://ieeexplore.ieee.org/abstract/document/9872110},
  urldate = {2024-04-12},
  abstract = {In the past several years, the world has witnessed an acute surge in the production and usage of smart devices which are referred to as the Internet of Things (IoT). These devices interact with each other as well as with their surrounding environments to sense, gather and process data of various kinds. Such devices are now part of our everyday's life and are being actively used in several verticals, such as transportation, healthcare, and smart homes. IoT devices, which usually are resource-constrained, often need to communicate with other devices, such as fog nodes and/or cloud computing servers to accomplish certain tasks that demand large resource requirements. These communications entail unprecedented security vulnerabilities, where malicious parties find in this heterogeneous and multiparty architecture a compelling platform to launch their attacks. In this work, we conduct an in-depth survey on the existing intrusion detection solutions proposed for the IoT ecosystem which includes the IoT devices as well as the communications between the IoT, fog computing, and cloud computing layers. Although some survey articles already exist, the originality of this work stems from the three following points: 1) discuss the security issues of the IoT ecosystem not only from the perspective of IoT devices but also taking into account the communications between the IoT, fog, and cloud computing layers; 2) propose a novel two-level classification scheme that first categorizes the literature based on the approach used to detect attacks and then classify each approach into a set of subtechniques; and 3) propose a comprehensive cybersecurity framework that combines the concepts of explainable artificial intelligence (XAI), federated learning, game theory, and social psychology to offer future IoT systems a strong protection against cyberattacks.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {Cloud computing,Collaborative work,Cybersecurity,Edge computing,explainable artificial intelligence (XAI),federated learning (FL),game theory,Game theory,Internet of Things,internet of Things (IoT),Intrusion detection,intrusion detection systems (IDSs),Taxonomy}
}

@inproceedings{arp_Dosdonts_2022,
  title = {Dos and Don'ts of Machine Learning in Computer Security},
  booktitle = {31st {{USENIX}} Security Symposium ({{USENIX}} Security 22)},
  author = {Arp, Daniel and Quiring, Erwin and Pendlebury, Feargus and Warnecke, Alexander and Pierazzi, Fabio and Wressnegger, Christian and Cavallaro, Lorenzo and Rieck, Konrad},
  date = {2022-08},
  pages = {3971--3988},
  publisher = {USENIX Association},
  location = {Boston, MA},
  url = {https://www.usenix.org/conference/usenixsecurity22/presentation/arp},
  isbn = {978-1-939133-31-1},
  keywords = {\_read\_urgently}
}

@article{arya_IntruderDetectionVANET_2023,
  title = {Intruder {{Detection}} in {{VANET Data Streams Using Federated Learning}} for {{Smart City Environments}}},
  author = {Arya, Monika and Sastry, Hanumat and Dewangan, Bhupesh Kumar and Rahmani, Mohammad Khalid Imam and Bhatia, Surbhi and Muzaffar, Abdul Wahab and Bivi, Mariyam Aysha},
  date = {2023-02-09},
  journaltitle = {Electronics},
  shortjournal = {Electronics},
  volume = {12},
  number = {4},
  pages = {894},
  issn = {2079-9292},
  doi = {10.3390/electronics12040894},
  url = {https://www.mdpi.com/2079-9292/12/4/894},
  urldate = {2024-04-12},
  abstract = {Vehicular networks improve quality of life, security, and safety, making them crucial to smart city development. With the rapid advancement of intelligent vehicles, the confidentiality and security concerns surrounding vehicular ad hoc networks (VANETs) have garnered considerable attention. VANETs are intrinsically more vulnerable to attacks than wired networks due to high mobility, common network medium, and lack of centrally managed security services. Intrusion detection (ID) servers are the first protection layer against cyberattacks in this digital age. The most frequently used mechanism in a VANET is intrusion detection systems (IDSs), which rely on vehicle collaboration to identify attackers. Regrettably, existing cooperative IDSs get corrupted and cause the IDSs to operate abnormally. This article presents an approach to intrusion detection based on the distributed federated learning (FL) of heterogeneous neural networks for smart cities. It saves time and resources by using the most efficient intruder detection approach. First, vehicles use a federated learning technique to develop local, deep learning-based IDS classifiers for VANET data streams. They then share their locally learned classifiers upon request, significantly reducing communication overhead with neighboring vehicles. Then, an ensemble of federated heterogeneous neural networks is constructed for each vehicle, including locally and remotely trained classifiers. Finally, the global ensemble model is again shared with local devices for their updating. The effectiveness of the suggested method for intrusion detection in VANETs is evaluated using performance indicators such as attack detection rates, classification accuracy, precision, recall, and F1 scores over a ToN-IoT data stream. The ID model shows 0.994 training and 0.981 testing accuracy.},
  langid = {english}
}

@inproceedings{aryal_AnalysisLabelFlipPoisoning_2022,
  title = {Analysis of {{Label-Flip Poisoning Attack}} on {{Machine Learning Based Malware Detector}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  author = {Aryal, Kshitiz and Gupta, Maanak and Abdelsalam, Mahmoud},
  date = {2022-12},
  pages = {4236--4245},
  doi = {10.1109/BigData55660.2022.10020528},
  url = {https://ieeexplore.ieee.org/abstract/document/10020528},
  urldate = {2024-03-28},
  abstract = {With the increase in machine learning (ML) applications in different domains, incentives for deceiving these models have reached more than ever. As data is the core backbone of ML algorithms, attackers shifted their interest towards polluting the training data itself. Data credibility is at even higher risk with the rise of state-of-art research topics like open design principles, federated learning, and crowd-sourcing. Since the machine learning model depends on different stakeholders for obtaining data, there are no existing reliable automated mechanisms to verify the veracity of data from each source.Malware detection is arduous due to its malicious nature with the addition of metamorphic and polymorphic ability in the evolving samples. ML has proven to solve the zero-day malware detection problem, which is unresolved by traditional signature- based approaches. The poisoning of malware training data can allow the malware files to go undetected by the ML-based malware detectors, helping the attackers to fulfill their malicious goals. A feasibility analysis of the data poisoning threat in the malware detection domain is still lacking. Our work will focus on two major sections: training ML-based malware detectors and poisoning the training data using the label-poisoning approach. We will analyze the robustness of different machine learning models against data poisoning with varying volumes of poisoning data.},
  eventtitle = {2022 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  keywords = {Adversarial Malware Analysis,Big Data,Cybersecurity,Detectors,Federated learning,Machine Learning,Machine learning algorithms,Malware,Malware Detectors,Poisoning Attacks,Training,Training data}
}

@article{asgharzadeh_AnomalybasedIntrusionDetection_2023,
  title = {Anomaly-Based {{Intrusion Detection System}} in the {{Internet}} of {{Things}} Using a {{Convolutional Neural Network}} and {{Multi-Objective Enhanced Capuchin Search Algorithm}}},
  author = {Asgharzadeh, Hossein and Ghaffari, Ali and Masdari, Mohammad and Soleimanian Gharehchopogh, Farhad},
  date = {2023-01-09},
  journaltitle = {Journal of Parallel and Distributed Computing},
  shortjournal = {Journal of Parallel and Distributed Computing},
  issn = {0743-7315},
  doi = {10.1016/j.jpdc.2022.12.009},
  url = {https://www.sciencedirect.com/science/article/pii/S0743731522002611},
  urldate = {2023-01-12},
  abstract = {Nowadays, the growth and pervasiveness of Internet of Things (IoT) devices have led to increased attacks by hackers and attackers. On the other hand, using IoT infrastructure in various fields has increased the number of node security breaches, attacks, and anomalies. Therefore, detecting anomalies in IoT devices is vital to reduce attacks and strengthen security. Over the past few years, various research has been conducted in anomaly-based intrusion detection using machine learning and deep learning methods. The biggest challenge in machine learning methods is the inability to extract new features. To do this, researchers use deep learning methods to extract new features that lead to increased accuracy in intrusion detection. There are important unsolved challenges in research, including determining important features in detecting malicious attacks, extracting features from raw network traffic data using deep networks, and insufficient accuracy in detecting attacks against IoT devices. Convolutional neural networks are considered a powerful and reliable method in this field due to the ability to automatically extract features from data and perform faster calculations. This study has designed and implemented the IoT features extraction convolutional neural network called IoTFECNN with hybrid layers for better anomaly detection in the IoT. Moreover, a binary multi-objective enhanced Capuchin Search Algorithm (CSA) called BMECapSA is developed for efficient feature selection. The combination of the IoTFECNN and BMECapSA methods has led to the introduction of a new hybrid method called CNN-BMECapSA-RF. Finally, the proposed method is implemented and tested on two data sets, NSL-KDD and TON-IoT. The results of various experiments exhibit that the proposed method has better results regarding classification criteria compared to existing deep learning and machine learning-based anomaly detection systems. The proposed method has reached 99.99\% and 99.85\% accuracy by identifying 27\% and 44\% of the effective features on the TON-IoT and NSL-KDD datasets, respectively.},
  langid = {english},
  keywords = {Convolutional neural network,Internet of Things,Intrusion detection system,Multi-objective CSA}
}

@article{ashraf_FIDChainFederatedIntrusion_2022,
  title = {{{FIDChain}}: {{Federated Intrusion Detection System}} for {{Blockchain-Enabled IoT Healthcare Applications}}},
  shorttitle = {{{FIDChain}}},
  author = {Ashraf, Eman and Areed, Nihal F. F. and Salem, Hanaa and Abdelhay, Ehab H. and Farouk, Ahmed},
  date = {2022-06-15},
  journaltitle = {Healthcare},
  shortjournal = {Healthcare},
  volume = {10},
  number = {6},
  pages = {1110},
  issn = {2227-9032},
  doi = {10.3390/healthcare10061110},
  url = {https://www.mdpi.com/2227-9032/10/6/1110},
  urldate = {2022-07-05},
  abstract = {Recently, there has been considerable growth in the internet of things (IoT)-based healthcare applications; however, they suffer from a lack of intrusion detection systems (IDS). Leveraging recent technologies, such as machine learning (ML), edge computing, and blockchain, can provide suitable and strong security solutions for preserving the privacy of medical data. In this paper, FIDChain IDS is proposed using lightweight artificial neural networks (ANN) in a federated learning (FL) way to ensure healthcare data privacy preservation with the advances of blockchain technology that provides a distributed ledger for aggregating the local weights and then broadcasting the updated global weights after averaging, which prevents poisoning attacks and provides full transparency and immutability over the distributed system with negligible overhead. Applying the detection model at the edge protects the cloud if an attack happens, as it blocks the data from its gateway with smaller detection time and lesser computing and processing capacity as FL deals with smaller sets of data. The ANN and eXtreme Gradient Boosting (XGBoost) models were evaluated using the BoT-IoT dataset. The results show that ANN models have higher accuracy and better performance with the heterogeneity of data in IoT devices, such as intensive care unit (ICU) in healthcare systems. Testing the FIDChain with different datasets (CSE-CIC-IDS2018, Bot Net IoT, and KDD Cup 99) reveals that the BoT-IoT dataset has the most stable and accurate results for testing IoT applications, such as those used in healthcare systems.},
  langid = {english}
}

@inproceedings{attanayaka_PeertoPeerFederatedLearning_2023,
  title = {Peer-to-{{Peer Federated Learning Based Anomaly Detection}} for {{Open Radio Access Networks}}},
  booktitle = {{{ICC}} 2023 - {{IEEE International Conference}} on {{Communications}}},
  author = {Attanayaka, Dinaj and Porambage, Pawani and Liyanage, Madhusanka and Ylianttila, Mika},
  date = {2023-05},
  pages = {5464--5470},
  issn = {1938-1883},
  doi = {10.1109/ICC45041.2023.10278993},
  url = {https://ieeexplore.ieee.org/document/10278993},
  urldate = {2024-04-12},
  abstract = {Open radio access network (O-RAN) has been recognized as a revolutionized architecture to support the multi-class wireless services required in fifth-generation (5G) and beyond 5G networks. The openness and the distributed nature of the O-RAN architecture have created new forms of threat surfaces than the conventional RAN architecture and require complex anomaly detection mechanisms. Moreover, with the introduction of RAN intelligent controllers (RICs), it is possible to utilize advanced Artificial Intelligence (AI)/ Machine Learning (ML) algorithms based on closed control loops to detect anomalies in a data-driven manner. In this paper, we particularly investigate the use of Federated Learning (FL) for anomaly detection in the O-RAN architecture, which can further preserve data privacy. We propose a peer-to-peer (P2P) FL-based anomaly detection mechanism for the O-RAN architecture and provide a comprehensive analysis of four variants of P2P FL techniques. Moreover, we simulate the proposed models using the UNSW-NB15 dataset.},
  eventtitle = {{{ICC}} 2023 - {{IEEE International Conference}} on {{Communications}}},
  keywords = {5G,5G mobile communication,6G,Anomaly detection,Data privacy,Federated learning,Machine learning algorithms,Network automation,O-RAN,Peer-to-peer computing,Privacy,RAN Intelligent controllers,Security,Wireless communication}
}

@article{attota_EnsembleMultiViewFederated_2021,
  title = {An {{Ensemble Multi-View Federated Learning Intrusion Detection}} for {{IoT}}},
  author = {Attota, Dinesh Chowdary and Mothukuri, Viraaji and Parizi, Reza M. and Pouriyeh, Seyedamin},
  date = {2021},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {9},
  pages = {117734--117745},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2021.3107337},
  url = {https://ieeexplore.ieee.org/document/9521524/},
  urldate = {2023-10-19},
  abstract = {The rise in popularity of Internet of Things (IoT) devices has attracted hackers to develop IoT-specific attacks. The microservice architecture of IoT devices relies on the Internet to provide their intended services. An unguarded IoT network makes inter-connected devices vulnerable to attacks. It will be a tedious and ineffective process to manually detect the attacks in the network, as the attackers frequently upgrade their attack strategies. Machine learning (ML)-assisted approaches have been proposed to build intrusion detection for cybersecurity automation in IoT networks. However, most such approaches focus on training an ML model using a single view of the dataset, which often fails to build insightful knowledge and understand each feature's impact on the ML model's decision-making ability. As such, the model training with a single view may result in an incomplete understanding of patterns in large feature-set datasets. Moreover, the current approaches are mainly designed in a centralized manner in which the raw data is transferred from the edge devices to the central server for training. This, in turn, may expose the data to all kinds of attacks without adhering to the privacy-preserving of data security. Multi-view learning has gained popularity for its ability to learn from different data views and deliver efficient performance with more distinguished predictions. This paper proposes a federated learning-based intrusion detection approach, called MV-FLID, that trains on multiple views of IoT network data in a decentralized format to detect, classify, and defend against attacks. The multi-view ensemble learning aspect helps in maximizing the learning efficiency of different classes of attacks. The Federated Learning (FL) aspect, wherein the device's data is not shared to the server, performs profile aggregation efficiently with the benefit of peer learning. Our evaluation results show that our proposed approach has higher accuracy compared to the traditional non-FL centralized approach.},
  langid = {english},
  keywords = {\_read\_urgently}
}

@inproceedings{awan_CONTRADefendingPoisoning_2021,
  title = {{{CONTRA}}: {{Defending Against Poisoning Attacks}} in {{Federated Learning}}},
  shorttitle = {{{CONTRA}}},
  booktitle = {Computer {{Security}} -- {{ESORICS}} 2021},
  author = {Awan, Sana and Luo, Bo and Li, Fengjun},
  editor = {Bertino, Elisa and Shulman, Haya and Waidner, Michael},
  date = {2021},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {455--475},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-88418-5_22},
  abstract = {Federated learning (FL) is an emerging machine learning paradigm. With FL, distributed data owners aggregate their model updates to train a shared deep neural network collaboratively, while keeping the training data locally. However, FL has little control over the local data and the training process. Therefore, it is susceptible to poisoning attacks, in which malicious or compromised clients use malicious training data or local updates as the attack vector to poison the trained global model. Moreover, the performance of existing detection and defense mechanisms drops significantly in a scaled-up FL system with non-iid data distributions. In this paper, we propose a defense scheme named CONTRA~to defend against poisoning attacks, e.g., label-flipping and backdoor attacks, in FL systems. CONTRA~implements a cosine-similarity-based measure to determine the credibility of local model parameters in each round and a reputation scheme to dynamically promote or penalize individual clients based on their per-round and historical contributions to the global model. With extensive experiments, we show that CONTRA~significantly reduces the attack success rate while achieving high accuracy with the global model. Compared with a state-of-the-art (SOTA) defense, CONTRA~reduces the attack success rate by 70\% and reduces the global model performance degradation by~50\%.},
  isbn = {978-3-030-88418-5},
  langid = {english},
  keywords = {Adversarial machine learning,Backdoor attacks,Data poisoning,Federated learning,Label-flipping attacks}
}

@inproceedings{ayed_FederatedLearningAnomalyBased_2021,
  title = {Federated {{Learning}} for {{Anomaly-Based Intrusion Detection}}},
  booktitle = {2021 {{International Symposium}} on {{Networks}}, {{Computers}} and {{Communications}} ({{ISNCC}})},
  author = {Ayed, Mohamed Ali and Talhi, Chamseddine},
  date = {2021-10-31},
  pages = {1--8},
  publisher = {IEEE},
  location = {Dubai, United Arab Emirates},
  doi = {10/gpbg2j},
  url = {https://ieeexplore.ieee.org/document/9615816/},
  urldate = {2022-01-31},
  abstract = {We are attending a severe zero-day cyber attacks. Machine learning based anomaly detection is definitely the most efficient defence in depth approach. It consists to analyzing the network traffic in order to distinguish the normal behaviour from the abnormal one. This approach is usually implemented in a central server where all the network traffic is analyzed which can rise privacy issues. In fact, with the increasing adoption of Cloud infrastructures, it is important to reduce as much as possible the outsourcing of such sensitive information to the several network nodes. A better approach is to ask each node to analyze its own data and then to exchange its learning finding (model) with a coordinator. In this paper, we investigate the application of federated learning for networkbased intrusion detection. Our experiment was conducted based on the CICIDS2017 dataset. We present a f ederated learning on a deep learning algorithm CNN based on model averaging. It is a self-learning system for detecting anomalies caused by malicious adversaries without human intervention and can cope with new and unknown attacks without decreasing performance. These experimentation demonstrate that this approach is effective in detecting intrusion.},
  eventtitle = {2021 {{International Symposium}} on {{Networks}}, {{Computers}} and {{Communications}} ({{ISNCC}})},
  isbn = {978-1-66540-304-7},
  langid = {english},
  keywords = {\_read}
}

@inproceedings{ayed_FederatedLearningAnomalyBased_2021a,
  title = {Federated {{Learning}} for {{Anomaly-Based Intrusion Detection}}},
  booktitle = {2021 {{International Symposium}} on {{Networks}}, {{Computers}} and {{Communications}} ({{ISNCC}})},
  author = {Ayed, Mohamed Ali and Talhi, Chamseddine},
  date = {2021-10},
  pages = {1--8},
  doi = {10.1109/ISNCC52172.2021.9615816},
  url = {https://ieeexplore.ieee.org/abstract/document/9615816},
  urldate = {2024-04-12},
  abstract = {We are attending a severe zero-day cyber attacks. Machine learning based anomaly detection is definitely the most efficient defence in depth approach. It consists to analyzing the network traffic in order to distinguish the normal behaviour from the abnormal one. This approach is usually implemented in a central server where all the network traffic is analyzed which can rise privacy issues. In fact, with the increasing adoption of Cloud infrastructures, it is important to reduce as much as possible the outsourcing of such sensitive information to the several network nodes. A better approach is to ask each node to analyze its own data and then to exchange its learning finding (model) with a coordinator. In this paper, we investigate the application of federated learning for network-based intrusion detection. Our experiment was conducted based on the C ICIDS2017 dataset. We present a f ederated learning on a deep learning algorithm C NN based on model averaging. It is a self-learning system for detecting anomalies caused by malicious adversaries without human intervention and can cope with new and unknown attacks without decreasing performance. These experimentation demonstrate that this approach is effective in detecting intrusion.},
  eventtitle = {2021 {{International Symposium}} on {{Networks}}, {{Computers}} and {{Communications}} ({{ISNCC}})},
  keywords = {Collaborative work,Data models,Data privacy,Deep learning,Network intrusion detection,Privacy,Telecommunication traffic}
}

@incollection{ayoubi_DataDrivenEvaluationIntrusion_2023,
  title = {Data-{{Driven Evaluation}} of {{Intrusion Detectors}}: {{A Methodological Framework}}},
  shorttitle = {Data-{{Driven Evaluation}} of {{Intrusion Detectors}}},
  booktitle = {Foundations and {{Practice}} of {{Security}}},
  author = {Ayoubi, Solayman and Blanc, Gregory and Jmila, Houda and Silverston, Thomas and Tixeuil, S\'ebastien},
  editor = {Jourdan, Guy-Vincent and Mounier, Laurent and Adams, Carlisle and S\`edes, Florence and Garcia-Alfaro, Joaquin},
  date = {2023},
  volume = {13877},
  pages = {142--157},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-30122-3_9},
  url = {https://link.springer.com/10.1007/978-3-031-30122-3_9},
  urldate = {2023-05-12},
  abstract = {Intrusion detection systems are an important domain in cybersecurity research. Countless solutions have been proposed, continuously improving upon one another. Yet, and despite the introduction of distinct approaches, including machine-learning methods, the evaluation methodology has barely evolved.},
  isbn = {978-3-031-30121-6 978-3-031-30122-3},
  langid = {english},
  keywords = {\_read\_urgently}
}

@article{ayoubi_EvaluationFrameworkMLbased_[review],
  title = {Evaluation {{Framework}} for {{ML-based IDS}}},
  author = {Ayoubi, Solayman and Blanc, Gregory and Jmila, Houda and Silverston, Thomas and Tixeuil, Sebastien},
  year = {[review]},
  abstract = {Intrusion detection is an important topic in cybersecurity research, but the evaluation methodology has remained stagnant despite advancements including the use of machine learning. In this paper, we design a comprehensive evaluation framework for Machine Learning (ML)-based IDS and take into account the unique aspects of ML algorithms, their strengths, and weaknesses. The framework design is inspired by both i) traditional IDS evaluation methods and ii) recommendations for evaluating ML algorithms in diverse application areas. Data quality being the key to machine learning, we focus on datadriven evaluation by exploring data-related issues.},
  langid = {english},
  keywords = {\_done,\_unpublished,â›” No DOI found}
}

@article{babbar_FRHIDSFederatedLearning_2023,
  title = {{{FRHIDS}}: {{Federated Learning Recommender Hydrid Intrusion Detection System Model}} in {{Software Defined Networking}} for {{Consumer Devices}}},
  shorttitle = {{{FRHIDS}}},
  author = {Babbar, Himanshi and Rani, Shalli},
  date = {2023},
  journaltitle = {IEEE Transactions on Consumer Electronics},
  pages = {1--1},
  issn = {1558-4127},
  doi = {10.1109/TCE.2023.3329151},
  url = {https://ieeexplore.ieee.org/abstract/document/10304342},
  urldate = {2024-04-12},
  abstract = {In the past few years, numerous methods of attack against recommendation systems have been developed. Cellphones, smart devices, and self-driving cars are instances of distributed IoT consumer devices that generate massive amounts of data on a daily basis and pose security threats to the cloud server. Due to the higher exchange of data, the challenges in this domain lead to increased security issues. Therefore, intrusion detection systems are important for the security and privacy of IoT consumer devices and hence to the cloud server. Due to the prediction, classification of attacks and recommendation of malware devices, the accuracy of machine learning and deep learning approaches for research in security for IoT consumer devices has gained tremendous popularity. Federated learning (FL), is a privacy-preserving decentralized learning technique that does not transport data but instead trains the model locally before sending the parameters to a cloud server, which helps in ensuring the security of data. However, communication channels can still be attacked by hackers, so blocking malicious data is a major requirement for the cloud server. In this paper, a federated learning recommender hybrid intrusion detection system (FRHIDS) model has been proposed that detects the attacks on the SDN network incoming from the IoT consumer devices and recommends that the safety devices transmit the decrypted data to the federated cloud server. In this model, the preservation of the security and privacy model parameters by utilizing the process of testing and training has been implemented. Simulation shows that the proposed approach's well-designed recommender system has outperformed state-of-the-art models. The performance of the proposed technique is evaluated based on its computational complexity and validation, which have shown 12\% improvement over the already existing techniques.},
  eventtitle = {{{IEEE Transactions}} on {{Consumer Electronics}}},
  keywords = {Cloud computing,Computational modeling,Consumer Devices,Data models,Deep learning,Federated Learning,Hybrid Deep Learning Model,Intrusion detection,Intrusion Detection System,Recommender System,Security,Servers}
}

@article{badr_PrivacyPreservingCommunicationEfficientEnergy_2023,
  title = {Privacy-{{Preserving}} and {{Communication-Efficient Energy Prediction Scheme Based}} on {{Federated Learning}} for {{Smart Grids}}},
  author = {Badr, Mahmoud M. and Mahmoud, Mohamed M. E. A. and Fang, Yuguang and Abdulaal, Mohammed and Aljohani, Abdulah Jeza and Alasmary, Waleed and Ibrahem, Mohamed I.},
  date = {2023-05},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {10},
  number = {9},
  pages = {7719--7736},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2022.3230586},
  url = {https://ieeexplore.ieee.org/abstract/document/10005179},
  urldate = {2024-04-12},
  abstract = {Energy forecasting is important because it enables infrastructure planning and power dispatching while reducing power outages and equipment failures. It is well-known that federated learning (FL) can be used to build a global energy predictor for smart grids without revealing the customers' raw data to preserve privacy. However, it still reveals local models' parameters during the training process, which may still leak customers' data privacy. In addition, for the global model to converge, it requires multiple training rounds, which must be done in a communication-efficient way. Moreover, most existing works only focus on load forecasting while neglecting energy forecasting in net-metering systems. To address these limitations, in this article, we propose a privacy-preserving and communication-efficient FL-based energy predictor for net-metering systems. Based on a data set for real power consumption/generation readings, we first propose a multidata-source hybrid deep learning (DL)-based predictor to accurately predict future readings. Then, we repurpose an efficient inner-product functional encryption (IPFE) scheme for implementing secure data aggregation to preserve the customers' privacy by encrypting their models' parameters during the FL training. To address communication efficiency, we use a change and transmit (CAT) approach to update local model's parameters, where only the parameters with sufficient changes are updated. Our extensive studies demonstrate that our approach accurately predicts future readings while providing privacy protection and high communication efficiency.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {Communication efficiency,Data models,energy prediction,federated learning (FL),Forecasting,Predictive models,Privacy,privacy preservation,Servers,smart grids,Smart grids,Training}
}

@inproceedings{badsha_BloCyNfoShareBlockchainbased_2020,
  title = {{{BloCyNfo-Share}}: {{Blockchain}} Based {{Cybersecurity Information Sharing}} with {{Fine Grained Access Control}}},
  booktitle = {2020 10th {{Annual Computing}} and {{Communication Workshop}} and {{Conference}} ({{CCWC}})},
  author = {Badsha, Shahriar and Vakilinia, Iman and Sengupta, Shamik},
  date = {2020-01},
  pages = {0317--0323},
  publisher = {IEEE},
  doi = {10.1109/CCWC47524.2020.9031164},
  url = {https://ieeexplore.ieee.org/document/9031164/},
  abstract = {To build a proactive cyber defense system, sharing the cybersecurity information has been very popular by which any organization can get more information about unknown and new threats. Cybersecurity Information Exchange (CYBEX) is one of the important platforms which has been playing an important role in implementing proactive cyber defense system by allowing organizations sharing their cybersecurity information. However, they are centralized and therefore they may suffer from complete failure in case of any damage or accident. Moreover, while sharing private information it lacks the mechanism of providing rights to query organizations i.e., enabling the access control over the shared sensitive information. Finally, nonrepudiation of the system does not exist i.e., there is no way to track or keep the record what any organization is sharing and it is necessary to keep the record in case anyone denies after sharing false information. To address these issues, in this paper we propose blockchain based privacy preserving cybersecurity information sharing using proxy re-encryption and attribute-based encryption (BloCyNfo-Share) where the organization can achieve fine-grain access control by delegating which organization can have the access to its cybersecurity information leveraging the benefits of blockchain technology. We conduct privacy and experimental analysis of the proposed system and the findings show that the model is private as well as efficient.},
  isbn = {978-1-72813-783-4}
}

@inproceedings{badsha_PrivacyPreservingCyber_2019,
  title = {Privacy {{Preserving Cyber Threat Information Sharing}} and {{Learning}} for {{Cyber Defense}}},
  booktitle = {2019 {{IEEE}} 9th {{Annual Computing}} and {{Communication Workshop}} and {{Conference}} ({{CCWC}})},
  author = {Badsha, Shahriar and Vakilinia, Iman and Sengupta, Shamik},
  date = {2019-01},
  pages = {0708--0714},
  publisher = {IEEE},
  doi = {10.1109/CCWC.2019.8666477},
  url = {https://ieeexplore.ieee.org/document/8666477/},
  abstract = {To secure cyber infrastructure against intentional and potentially malicious threats, a growing collaborative effort between cybersecurity professionals and researchers from institutions, private industries, academia, and government agencies has engaged in exploiting and designing a variety of cyber defense systems. Cybersecurity researchers and designers aim to maintain the confidentiality, integrity, and availability of information and information management systems through various cyber defense systems that protect computers and networks from hackers who may want to steal financial, medical, or other identity-based information. The Cooperative Cyber-defense has been recognized as an essential strategy to fight against cyberattacks. Cyber-security information sharing among various organizations and leveraging the aggregated cyber information to build proactive cyber defense system is nontrivial for organizations. However, building such cyber defense system is challenged by two issues: (1) organizations are reluctant to share their private information to others (2) even when they agree on a solution where information can be shared in privacy preserving manner, the obfuscated cyber threat information has to be processed to build the trained model for future prediction of any new or unknown cyber incident. To address these issues, in this paper, we propose a privacy preserving protocol where organizations can share their private information as an encrypted form with others and they can learn the information for future prediction without disclosing any private information. More specifically we propose a privacy preserving decision tree algorithm, where each organization can build and learn the decision tree based on overall organizations' training spam/ham email data without disclosing any private information of any party. Once the building of a decision tree is done, the organizations can predict if any new email is spam or ham locally.},
  isbn = {978-1-72810-554-3}
}

@article{bahaa_novelhybridoptimization_2022,
  title = {A Novel Hybrid Optimization Enabled Robust {{CNN}} Algorithm for an {{IoT}} Network Intrusion Detection Approach},
  author = {Bahaa, Ahmed and Sayed, Abdalla and Elfangary, Laila and Fahmy, Hanan},
  editor = {V. E., Sathishkumar},
  date = {2022-12-01},
  journaltitle = {PLOS ONE},
  shortjournal = {PLoS ONE},
  volume = {17},
  number = {12},
  pages = {e0278493},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0278493},
  url = {https://dx.plos.org/10.1371/journal.pone.0278493},
  urldate = {2022-12-14},
  abstract = {Due to the huge number of connected Internet of Things (IoT) devices within a network, denial of service and flooding attacks on networks are on the rise. IoT devices are disrupted and denied service because of these attacks. In this study, we proposed a novel hybrid meta-heuristic adaptive particle swarm optimization--whale optimizer algorithm (APSOWOA) for optimization of the hyperparameters of a convolutional neural network (APSOWOA-CNN). The APSO--WOA optimization algorithm's fitness value is defined as the validation set's cross-entropy loss function during CNN model training. In this study, we compare our optimization algorithm with other optimization algorithms, such as the APSO algorithm, for optimization of the hyperparameters of CNN. In model training, the APSO--WOA--CNN algorithm achieved the best performance compared to the FNN algorithm, which used manual parameter settings. We evaluated the APSO--WOA--CNN algorithm against APSO--CNN, SVM, and FNN. The simulation results suggest that APSO--WOA--CNf[N is effective and can reliably detect multi-type IoT network attacks. The results show that the APSO--WOA--CNN algorithm improves accuracy by 1.25\%, average precision by 1\%, the kappa coefficient by 11\%, Hamming loss by 1.2\%, and the Jaccard similarity coefficient by 2\%, as compared to the APSO--CNN algorithm, and the APSO--CNN algorithm achieves the best performance, as compared to other algorithms.},
  langid = {english}
}

@inproceedings{bajpai_ChallengesReproducibility_2017,
  title = {Challenges with {{Reproducibility}}},
  booktitle = {Proceedings of the {{Reproducibility Workshop}}},
  author = {Bajpai, Vaibhav and K\"uhlewind, Mirja and Ott, J\"org and Sch\"onw\"alder, J\"urgen and Sperotto, Anna and Trammell, Brian},
  date = {2017-08-11},
  pages = {1--4},
  publisher = {ACM},
  location = {Los Angeles CA USA},
  doi = {10.1145/3097766.3097767},
  url = {https://dl.acm.org/doi/10.1145/3097766.3097767},
  urldate = {2022-08-12},
  abstract = {The Computer Science (CS) culture is gentle to accepting papers that are non-reproducible as long as they appear plausible. In this paper, we discuss some of the challenges with reproducibility and a set of recommendations that we as a community can undertake to initiate a cultural change.},
  eventtitle = {{{SIGCOMM}} '17: {{ACM SIGCOMM}} 2017 {{Conference}}},
  isbn = {978-1-4503-5060-0},
  langid = {english}
}

@article{bajpai_Dagstuhlbeginnersguide_2019,
  title = {The {{Dagstuhl}} Beginners Guide to Reproducibility for Experimental Networking Research},
  author = {Bajpai, Vaibhav and Brunstrom, Anna and Feldmann, Anja and Kellerer, Wolfgang and Pras, Aiko and Schulzrinne, Henning and Smaragdakis, Georgios and W\"ahlisch, Matthias and Wehrle, Klaus},
  date = {2019-02-20},
  journaltitle = {ACM SIGCOMM Computer Communication Review},
  shortjournal = {SIGCOMM Comput. Commun. Rev.},
  volume = {49},
  number = {1},
  pages = {24--30},
  issn = {0146-4833},
  doi = {10.1145/3314212.3314217},
  url = {https://dl.acm.org/doi/10.1145/3314212.3314217},
  urldate = {2022-08-12},
  abstract = {Reproducibility is one of the key characteristics of good science, but hard to achieve for experimental disciplines like Internet measurements and networked systems. This guide provides advice to researchers, particularly those new to the field, on designing experiments so that their work is more likely to be reproducible and to serve as a foundation for follow-on work by others.},
  langid = {english}
}

@article{banabilah_Federatedlearningreview_2022,
  title = {Federated Learning Review: {{Fundamentals}}, Enabling Technologies, and Future Applications},
  shorttitle = {Federated Learning Review},
  author = {Banabilah, Syreen and Aloqaily, Moayad and Alsayed, Eitaa and Malik, Nida and Jararweh, Yaser},
  date = {2022-11-01},
  journaltitle = {Information Processing \& Management},
  shortjournal = {Information Processing \& Management},
  volume = {59},
  number = {6},
  pages = {103061},
  issn = {0306-4573},
  doi = {10.1016/j.ipm.2022.103061},
  url = {https://www.sciencedirect.com/science/article/pii/S0306457322001649},
  urldate = {2022-08-30},
  abstract = {Federated Learning (FL) has been foundational in improving the performance of a wide range of applications since it was first introduced by Google. Some of the most prominent and commonly used FL-powered applications are Android's Gboard for predictive text and Google Assistant. FL can be defined as a setting that makes on-device, collaborative Machine Learning possible. A wide range of literature has studied FL technical considerations, frameworks, and limitations with several works presenting a survey of the prominent literature on FL. However, prior surveys have focused on technical considerations and challenges of FL, and there has been a limitation in more recent work that presents a comprehensive overview of the status and future trends of FL in applications and markets. In this survey, we introduce the basic fundamentals of FL, describing its underlying technologies, architectures, system challenges, and privacy-preserving methods. More importantly, the contribution of this work is in scoping a wide variety of FL current applications and future trends in technology and markets today. We present a classification and clustering of literature progress in FL in application to technologies including Artificial Intelligence, Internet of Things, blockchain, Natural Language Processing, autonomous vehicles, and resource allocation, as well as in application to market use cases in domains of Data Science, healthcare, education, and industry. We discuss future open directions and challenges in FL within recommendation engines, autonomous vehicles, IoT, battery management, privacy, fairness, personalization, and the role of FL for governments and public sectors. By presenting a comprehensive review of the status and prospects of FL, this work serves as a reference point for researchers and practitioners to explore FL applications under a wide range of domains.},
  langid = {english},
  keywords = {+survey,Data privacy,Data security,Decentralized learning,Distributed learning,Federated learning,Machine learning,Mobile edge networks}
}

@inproceedings{bano_KafkaFedTwoTierFederated_2022,
  title = {{{KafkaFed}}: {{Two-Tier Federated Learning Communication Architecture}} for {{Internet}} of {{Vehicles}}},
  shorttitle = {{{KafkaFed}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Pervasive Computing}} and {{Communications Workshops}} and Other {{Affiliated Events}} ({{PerCom Workshops}})},
  author = {Bano, Saira and Tonellotto, Nicola and Cassar\`a, Pietro and Gotta, Alberto},
  date = {2022-03},
  pages = {515--520},
  doi = {10.1109/PerComWorkshops53856.2022.9767510},
  abstract = {In the current era of the Internet of Vehicles (IoV), vehicle to vehicle data sharing can provide customized applications for Connected and Autonomous Vehicles (CAVs). The advancement of Deep Learning (DL) methodologies is one of the key driving forces for CAVs, allowing elaborating a massive amount of data by the resource-constrained onboard devices. In a traditional centralized DL approach, vehicle data are transmitted to the cloud for the training of models. This approach leads to significant communication overhead, high delays, and data privacy concerns. Conversely, Federated Learning (FL) performs the training using the local models in a distributed fashion and mitigates the data privacy risks by sharing only the model parameters with the server, optimizing the FL to be used with resources-constrained devices. In this paper, we propose the design of a scalable communication infrastructure to support the FL procedure based on Information-Centric Networking (ICN) using Apache Kafka, called KafkaFed. The ICN-based infrastructure allows to overcome the shortcomings of current client-server architectures for FL, in which routing is content-based or name-based to achieve efficient data retrieval for mobile nodes. In ICN, data are stored at intermediate nodes to provide efficient and reliable data delivery. A proof of concept of the KafkaFed communication architecture is developed and tested in an emulated environment. The performance of the proposed framework compared to the client server-based FL architecture, i.e., FLOWER showed a boost of almost 40\% with just 32 clients in addition to several other advantages of scalability, reliability, and security},
  eventtitle = {2022 {{IEEE International Conference}} on {{Pervasive Computing}} and {{Communications Workshops}} and Other {{Affiliated Events}} ({{PerCom Workshops}})},
  keywords = {Apache Kafka,Collaborative work,Computer architecture,Conferences,Connected and autonomous vehicles,Data models,Data privacy,Federated Learning,Publish/Subscribe model,Scalability,Training}
}

@article{bao_Federatedlearningcloudedge_2022,
  title = {Federated Learning in Cloud-Edge Collaborative Architecture: Key Technologies, Applications and Challenges},
  shorttitle = {Federated Learning in Cloud-Edge Collaborative Architecture},
  author = {Bao, Guanming and Guo, Ping},
  date = {2022-12-15},
  journaltitle = {Journal of Cloud Computing},
  shortjournal = {Journal of Cloud Computing},
  volume = {11},
  number = {1},
  pages = {94},
  issn = {2192-113X},
  doi = {10.1186/s13677-022-00377-4},
  url = {https://doi.org/10.1186/s13677-022-00377-4},
  urldate = {2023-01-09},
  abstract = {In recent years, with the rapid growth of edge data, the~novel cloud-edge collaborative architecture has been proposed to compensate for the lack of data processing power of traditional cloud computing. On the other hand, on account of the increasing demand of the public for data privacy, federated learning has been proposed to compensate for the lack of security of traditional centralized machine learning. Deploying federated learning in cloud-edge collaborative architecture is widely considered to be a promising cyber infrastructure in the future. Although each cloud-edge collaboration and federated learning is hot research topic respectively at present, the discussion of deploying federated learning in cloud-edge collaborative architecture is still in its infancy and little research has been conducted. This article aims to fill the gap by providing a detailed description of the critical technologies, challenges, and applications of deploying federated learning in cloud-edge collaborative architecture, and providing guidance on future research directions.},
  keywords = {Cloud-edge collaborative computing,Federated learning}
}

@online{bars_RefinedConvergenceTopology_2022,
  title = {Refined {{Convergence}} and {{Topology Learning}} for {{Decentralized Optimization}} with {{Heterogeneous Data}}},
  author = {Bars, B. Le and Bellet, A. and Tommasi, M. and Lavoie, E. and Kermarrec, A. M.},
  date = {2022-06-10},
  eprint = {2204.04452},
  eprinttype = {arXiv},
  eprintclass = {cs, math, stat},
  doi = {10.48550/arXiv.2204.04452},
  url = {http://arxiv.org/abs/2204.04452},
  urldate = {2022-07-05},
  abstract = {One of the key challenges in decentralized and federated learning is to design algorithms that efficiently deal with highly heterogeneous data distributions across agents. In this paper, we revisit the analysis of Decentralized Stochastic Gradient Descent algorithm (D-SGD) under data heterogeneity. We exhibit the key role played by a new quantity, called \textbackslash emph\{neighborhood heterogeneity\}, on the convergence rate of D-SGD. By coupling the communication topology and the heterogeneity, our analysis sheds light on the poorly understood interplay between these two concepts in decentralized learning. We then argue that neighborhood heterogeneity provides a natural criterion to learn data-dependent topologies that reduce (and can even eliminate) the otherwise detrimental effect of data heterogeneity on the convergence time of D-SGD. For the important case of classification with label skew, we formulate the problem of learning such a good topology as a tractable optimization problem that we solve with a Frank-Wolfe algorithm. As illustrated over a set of simulated and real-world experiments, our approach provides a principled way to design a sparse topology that balances the convergence speed and the per-iteration communication costs of D-SGD under data heterogeneity.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning}
}

@incollection{bayou_wIDSMultilayerIDS_2017,
  title = {{{wIDS}}: {{A Multilayer IDS}} for {{Wireless-Based SCADA Systems}}},
  shorttitle = {{{wIDS}}},
  booktitle = {Information {{Systems Security}}},
  author = {Bayou, Lyes and Espes, David and Cuppens-Boulahia, Nora and Cuppens, Fr\'ed\'eric},
  editor = {Shyamasundar, Rudrapatna K. and Singh, Virendra and Vaidya, Jaideep},
  date = {2017},
  volume = {10717},
  pages = {387--404},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-72598-7_24},
  url = {http://link.springer.com/10.1007/978-3-319-72598-7_24},
  urldate = {2022-01-31},
  abstract = {The increasing use of wireless sensors networks in Supervisory Control and Data Acquisition systems (SCADA) raises the need of enforcing the security of this promising technology. Indeed, SCADA systems are used to manage critical installations that have hard security, reliability and real-time requirements. Consequently, in order to ensure Wireless Industrial Sensor Networks (WISN) security, Intrusion Detection Systems should be used as a second line of defense, in addition to sensor's embedded security mechanisms. In this paper, we present wIDS a multilayer specification-based Intrusion Detection System specially tailored for WISN. It has a two-level detection architecture and is based on a formal description of node's normal behavior.},
  isbn = {978-3-319-72597-0 978-3-319-72598-7},
  langid = {english}
}

@article{belenguer_GowFednovelfederated_2023,
  title = {{{G\"owFed}}: {{A}} Novel Federated Network Intrusion Detection System},
  shorttitle = {{{G\"owFed}}},
  author = {Belenguer, Aitor and Pascual, Jose A. and Navaridas, Javier},
  date = {2023-04-29},
  journaltitle = {Journal of Network and Computer Applications},
  shortjournal = {Journal of Network and Computer Applications},
  pages = {103653},
  issn = {1084-8045},
  doi = {10.1016/j.jnca.2023.103653},
  url = {https://www.sciencedirect.com/science/article/pii/S1084804523000723},
  urldate = {2023-05-02},
  abstract = {Network intrusion detection systems are evolving into intelligent systems that perform data analysis while searching for anomalies in their environment. Indeed, the development of deep learning techniques paved the way to build more complex and effective threat detection models. However, training those models may be computationally infeasible in most Edge or IoT devices. Current approaches rely on powerful centralized servers that receive data from all their parties --- violating basic privacy constraints and substantially affecting response times and operational costs due to the huge communication overheads. To mitigate these issues, Federated Learning emerged as a promising approach, where different agents collaboratively train a shared model, without exposing training data to others or requiring a compute-intensive centralized infrastructure. This work presents G\"owFed, a novel network threat detection system that combines the usage of Gower Dissimilarity matrices and Federated averaging. Different approaches of G\"owFed have been developed based on state-of the-art knowledge: (1) a vanilla version --- achieving a median point of [0.888, 0.960] in the PR space and a median accuracy of 0.930; and (2) a version instrumented with an attention mechanism --- achieving comparable results when 0.8 of the best performing nodes contribute to the model. Furthermore, each variant has been tested using simulation oriented tools provided by TensorFlow Federated framework. In the same way, a centralized analogous development of the Federated systems is carried out to explore their differences in terms of scalability and performance --- the median point of the experiments is [0.987, 0.987]) and the median accuracy is 0.989. Overall, G\"owFed intends to be the first stepping stone towards the combined usage of Federated Learning and Gower Dissimilarity matrices to detect network threats in industrial-level networks.},
  langid = {english},
  keywords = {Federated Learning,Gower distance,Internet of Things,Intrusion Detection Systems}
}

@article{bellet_DCliquesCompensatingNonIIDness_2021,
  title = {D-{{Cliques}}: {{Compensating NonIIDness}} in {{Decentralized Federated Learning}} with {{Topology}}},
  shorttitle = {D-{{Cliques}}},
  author = {Bellet, A. and Kermarrec, Anne-Marie and Lavoie, Erick},
  date = {2021},
  journaltitle = {ArXiv},
  url = {https://www.semanticscholar.org/paper/D-Cliques%3A-Compensating-NonIIDness-in-Decentralized-Bellet-Kermarrec/163f98375fdc9bc3faff00dee6b8143cbe25f880},
  urldate = {2023-09-11},
  abstract = {The convergence speed of machine learning models trained with Federated Learning is significantly affected by non-independent and identically distributed (non-IID) data partitions, even more so in a fully decentralized setting without a central server. In this paper, we show that the impact of local class bias, an important type of data non-IIDness, can be significantly reduced by carefully designing the underlying communication topology. We present D-Cliques, a novel topology that reduces gradient bias by grouping nodes in interconnected cliques such that the local joint distribution in a clique is representative of the global class distribution. We also show how to adapt the updates of decentralized SGD to obtain unbiased gradients and implement an effective momentum with D-Cliques. Our empirical evaluation on MNIST and CIFAR10 demonstrates that our approach provides similar convergence speed as a fully-connected topology with a significant reduction in the number of edges and messages. In a 1000-node topology, D-Cliques requires 98\% less edges and 96\% less total messages, with further possible gains using a small-world topology across cliques.},
  keywords = {â›” No DOI found}
}

@article{beltran_DecentralizedFederatedLearning_2022,
  title = {Decentralized {{Federated Learning}}: {{Fundamentals}}, {{State}} of the {{Art}}, {{Frameworks}}, {{Trends}}, and {{Challenges}}},
  shorttitle = {Decentralized {{Federated Learning}}},
  author = {Beltr\'an, Enrique Tom\'as Mart\'inez and P\'erez, Mario Quiles and S\'anchez, Pedro Miguel S\'anchez and Bernal, Sergio L\'opez and Bovet, G\'er\^ome and P\'erez, Manuel Gil and P\'erez, Gregorio Mart\'inez and Celdr\'an, Alberto Huertas},
  date = {2022},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2211.08413},
  url = {https://arxiv.org/abs/2211.08413},
  urldate = {2023-09-11},
  abstract = {In recent years, Federated Learning (FL) has gained relevance in training collaborative models without sharing sensitive data. Since its birth, Centralized FL (CFL) has been the most common approach in the literature, where a central entity creates a global model. However, a centralized approach leads to increased latency due to bottlenecks, heightened vulnerability to system failures, and trustworthiness concerns affecting the entity responsible for the global model creation. Decentralized Federated Learning (DFL) emerged to address these concerns by promoting decentralized model aggregation and minimizing reliance on centralized architectures. However, despite the work done in DFL, the literature has not (i) studied the main aspects differentiating DFL and CFL; (ii) analyzed DFL frameworks to create and evaluate new solutions; and (iii) reviewed application scenarios using DFL. Thus, this article identifies and analyzes the main fundamentals of DFL in terms of federation architectures, topologies, communication mechanisms, security approaches, and key performance indicators. Additionally, the paper at hand explores existing mechanisms to optimize critical DFL fundamentals. Then, the most relevant features of the current DFL frameworks are reviewed and compared. After that, it analyzes the most used DFL application scenarios, identifying solutions based on the fundamentals and frameworks previously defined. Finally, the evolution of existing DFL solutions is studied to provide a list of trends, lessons learned, and open challenges.},
  version = {4},
  keywords = {{Distributed, Parallel, and Cluster Computing (cs.DC)},Cryptography and Security (cs.CR),FOS: Computer and information sciences,Machine Learning (cs.LG),Networking and Internet Architecture (cs.NI)}
}

@article{bemani_AggregationStrategyFederated_2022,
  title = {Aggregation {{Strategy}} on {{Federated Machine Learning Algorithm}} for {{Collaborative Predictive Maintenance}}},
  author = {Bemani, Ali and Bj\"orsell, Niclas},
  date = {2022-08-19},
  journaltitle = {Sensors},
  shortjournal = {Sensors},
  volume = {22},
  number = {16},
  pages = {6252},
  issn = {1424-8220},
  doi = {10.3390/s22166252},
  url = {https://www.mdpi.com/1424-8220/22/16/6252},
  urldate = {2022-08-25},
  abstract = {Industry 4.0 lets the industry build compact, precise, and connected assets and also has made modern industrial assets a massive source of data that can be used in process optimization, defining product quality, and predictive maintenance (PM). Large amounts of data are collected from machines, processed, and analyzed by different machine learning (ML) algorithms to achieve effective PM. These machines, assumed as edge devices, transmit their data readings to the cloud for processing and modeling. Transmitting massive amounts of data between edge and cloud is costly, increases latency, and causes privacy concerns. To address this issue, efforts have been made to use edge computing in PM applications., reducing data transmission costs and increasing processing speed. Federated learning (FL) has been proposed a mechanism that provides the ability to create a model from distributed data in edge, fog, and cloud layers without violating privacy and offers new opportunities for a collaborative approach to PM applications. However, FL has challenges in confronting with asset management in the industry, especially in the PM applications, which need to be considered in order to be fully compatible with these applications. This study describes distributed ML for PM applications and proposes two federated algorithms: Federated support vector machine (FedSVM) with memory for anomaly detection and federated long-short term memory (FedLSTM) for remaining useful life (RUL) estimation that enables factories at the fog level to maximize their PM models' accuracy without compromising their privacy. A global model at the cloud level has also been generated based on these algorithms. We have evaluated the approach using the Commercial Modular Aero-Propulsion System Simulation (CMAPSS) dataset to predict engines' RUL Experimental results demonstrate the advantage of FedSVM and FedLSTM in terms of model accuracy, model convergence time, and network usage resources.},
  langid = {english}
}

@article{berger_AttacksIndustrialInternet_2020,
  title = {Attacks on the {{Industrial Internet}} of {{Things}} -- {{Development}} of a Multi-Layer {{Taxonomy}}},
  author = {Berger, Stephan and B\"urger, Olga and R\"oglinger, Maximilian},
  date = {2020-06},
  journaltitle = {Computers \& Security},
  volume = {93},
  pages = {101790},
  publisher = {Elsevier Ltd},
  issn = {01674048},
  doi = {10.1016/j.cose.2020.101790},
  url = {https://doi.org/10.1016/j.cose.2020.101790},
  abstract = {The Industrial Internet of Things (IIoT) provides new opportunities to improve process and production efficiency, which enable new business models. At the same time, the high degree of cross-linking and decentralization increases the complexity of IIoT systems and creates new vulnerabilities. Hence, organizations are not only vulnerable to conventional IT threats, but also to a multitude of new, IIoT-specific attacks. Yet, a literature-based and empirically evaluated understanding of attacks on the IIoT is still lacking. Against this backdrop, we develop a multi-layer taxonomy that helps researchers and practitioners to identify similarities and differences between attacks on the IIoT. Based on the latest literature and a sample of about 50 attacks, we deductively and inductively determine attack characteristics and dimensions. We demonstrate the usefulness and practical relevance of our taxonomy by applying it to a real-world incident affecting a German steel facility. By combining IT security, IIoT, and risk management to form an interdisciplinary approach, we contribute to the descriptive knowledge in these fields. Industry experts confirm that our taxonomy enables a detailed classification of attacks, which supports the identification, documentation, and communication of incidents within organizations and their value-creation networks. With this, our taxonomy provides a profound basis for the further development of IT security management and the derivation of mitigation measures.}
}

@inproceedings{bernstein_signSGDCompressedoptimisation_2018,
  title = {{{signSGD}}: {{Compressed}} Optimisation for Non-Convex Problems},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  author = {Bernstein, Jeremy and Wang, Yu-Xiang and Azizzadenesheli, Kamyar and Anandkumar, Animashree},
  editor = {Dy, Jennifer and Krause, Andreas},
  date = {2018-07-10/2018-07-15},
  series = {Proceedings of Machine Learning Research},
  volume = {80},
  pages = {560--569},
  publisher = {PMLR},
  url = {https://proceedings.mlr.press/v80/bernstein18a.html},
  abstract = {Training large neural networks requires distributing learning across multiple workers, where the cost of communicating gradients can be a significant bottleneck. signSGD alleviates this problem by transmitting just the sign of each minibatch stochastic gradient. We prove that it can get the best of both worlds: compressed gradients and SGD-level convergence rate. The relative {$_1$}/{$_2$} geometry of gradients, noise and curvature informs whether signSGD or SGD is theoretically better suited to a particular problem. On the practical side we find that the momentum counterpart of signSGD is able to match the accuracy and convergence speed of Adam on deep Imagenet models. We extend our theory to the distributed setting, where the parameter server uses majority vote to aggregate gradient signs from each worker enabling 1-bit compression of worker-server communication in both directions. Using a theorem by Gauss we prove that majority vote can achieve the same reduction in variance as full precision distributed SGD. Thus, there is great promise for sign-based optimisation schemes to achieve fast communication and fast convergence. Code to reproduce experiments is to be found at https://github.com/jxbz/signSGD.}
}

@online{bertoli_Generalizingintrusiondetection_2022,
  title = {Generalizing Intrusion Detection for Heterogeneous Networks: {{A}} Stacked-Unsupervised Federated Learning Approach},
  shorttitle = {Generalizing Intrusion Detection for Heterogeneous Networks},
  author = {Bertoli, Gustavo de Carvalho and Junior, Louren\c co Alves Pereira and family=Santos, given=Aldri Luiz, prefix=dos, useprefix=false and Saotome, Osamu},
  date = {2022-09-07},
  eprint = {2209.00721},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2209.00721},
  urldate = {2022-09-12},
  abstract = {The constantly evolving digital transformation imposes new requirements on our society. Aspects relating to reliance on the networking domain and the difficulty of achieving security by design pose a challenge today. As a result, data-centric and machine-learning approaches arose as feasible solutions for securing large networks. Although, in the network security domain, ML-based solutions face a challenge regarding the capability to generalize between different contexts. In other words, solutions based on specific network data usually do not perform satisfactorily on other networks. This paper describes the stacked-unsupervised federated learning (FL) approach to generalize on a cross-silo configuration for a flow-based network intrusion detection system (NIDS). The proposed approach we have examined comprises a deep autoencoder in conjunction with an energy flow classifier in an ensemble learning task. Our approach performs better than traditional local learning and naive cross-evaluation (training in one context and testing on another network data). Remarkably, the proposed approach demonstrates a sound performance in the case of non-iid data silos. In conjunction with an informative feature in an ensemble architecture for unsupervised learning, we advise that the proposed FL-based NIDS results in a feasible approach for generalization between heterogeneous networks. To the best of our knowledge, our proposal is the first successful approach to applying unsupervised FL on the problem of network intrusion detection generalization using flow-based data.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {\_read\_urgently,Computer Science - Cryptography and Security}
}

@inproceedings{bethencourt_CiphertextPolicyAttributeBasedEncryption_2007,
  title = {Ciphertext-{{Policy Attribute-Based Encryption}}},
  booktitle = {2007 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}} '07)},
  author = {Bethencourt, John and Sahai, Amit and Waters, Brent},
  date = {2007-05},
  pages = {321--334},
  publisher = {IEEE},
  issn = {10816011},
  doi = {10.1109/SP.2007.11},
  url = {http://ieeexplore.ieee.org/document/4223236/},
  abstract = {In several distributed systems a user should only be able to access data if a user posses a certain set of credentials or attributes. Currently, the only method for enforcing such policies is to employ a trusted server to store the data and mediate access control. However, if any server storing the data is compromised, then the confidentiality of the data will be compromised. In this paper we present a system for realizing complex access control on encrypted data that we call Ciphertext-Policy Attribute-Based Encryption. By using our techniques encrypted data can be kept confidential even if the storage server is untrusted; moreover, our methods are secure against collusion attacks. Previous Attribute-Based Encryption systems used attributes to describe the encrypted data and built policies into user's keys; while in our system attributes are used to describe a user's credentials, and a party encrypting data determines a policy for who can decrypt. Thus, our methods are conceptually closer to traditional access control methods such as Role-Based Access Control (RBAC). In addition, we provide an implementation of our system and give performance measurements. \copyright 2007 IEEE.},
  isbn = {0-7695-2848-1}
}

@unpublished{beutel_Flowerfriendlyfederated_2020,
  title = {Flower: {{A}} Friendly Federated Learning Research Framework},
  author = {Beutel, Daniel J and Topal, Taner and Mathur, Akhil and Qiu, Xinchi and Parcollet, Titouan and Lane, Nicholas D},
  date = {2020},
  eprint = {2007.14390},
  eprinttype = {arXiv},
  keywords = {â›” No DOI found}
}

@inproceedings{bhagoji_AnalyzingFederatedLearning_2019,
  title = {Analyzing {{Federated Learning}} through an {{Adversarial Lens}}},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Bhagoji, Arjun Nitin and Chakraborty, Supriyo and Mittal, Prateek and Calo, Seraphin},
  date = {2019-05-24},
  pages = {634--643},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v97/bhagoji19a.html},
  urldate = {2023-02-23},
  abstract = {Federated learning distributes model training among a multitude of agents, who, guided by privacy concerns, perform training using their local data but share only model parameter updates, for iterative aggregation at the server to train an overall global model. In this work, we explore how the federated learning setting gives rise to a new threat, namely model poisoning, which differs from traditional data poisoning. Model poisoning is carried out by an adversary controlling a small number of malicious agents (usually 1) with the aim of causing the global model to misclassify a set of chosen inputs with high confidence. We explore a number of strategies to carry out this attack on deep neural networks, starting with targeted model poisoning using a simple boosting of the malicious agent's update to overcome the effects of other agents. We also propose two critical notions of stealth to detect malicious updates. We bypass these by including them in the adversarial objective to carry out stealthy model poisoning. We improve its stealth with the use of an alternating minimization strategy which alternately optimizes for stealth and the adversarial objective. We also empirically demonstrate that Byzantine-resilient aggregation strategies are not robust to our attacks. Our results indicate that highly constrained adversaries can carry out model poisoning attacks while maintaining stealth, thus highlighting the vulnerability of the federated learning setting and the need to develop effective defense strategies.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@inproceedings{bhatia_PrivacyRiskCybersecurity_2016,
  title = {Privacy {{Risk}} in {{Cybersecurity Data Sharing}}},
  booktitle = {Proceedings of the 2016 {{ACM}} on {{Workshop}} on {{Information Sharing}} and {{Collaborative Security}} - {{WISCS}}'16},
  author = {Bhatia, Jaspreet and Breaux, Travis D. and Friedberg, Liora and Hibshi, Hanan and Smullen, Daniel},
  date = {2016},
  pages = {57--64},
  publisher = {ACM Press},
  doi = {10.1145/2994539.2994541},
  abstract = {As information systems become increasingly interdependent, there is an increased need to share cybersecurity data across government agencies and companies, and within and across industrial sectors. This sharing includes threat, vulnerability and incident reporting data, among other data. For cyberattacks that include socio-technical vectors, such as phishing or watering hole attacks, this increased sharing could expose customer and employee personal data to increased privacy risk. In the US, privacy risk arises when the government voluntarily receives data from companies without meaningful consent from individuals, or without a lawful procedure that protects an individual's right to due process. In this paper, we describe a study to examine the trade-off between the need for potentially sensitive data, which we call incident data usage, and the perceived privacy risk of sharing that data with the government. The study is comprised of two parts: a data usage estimate built from a survey of 76 security professionals with mean eight years' experience; and a privacy risk estimate that measures privacy risk using an ordinal likelihood scale and nominal data types in factorial vignettes. The privacy risk estimate also factors in data purposes with different levels of societal benefit, including terrorism, imminent threat of death, economic harm, and loss of intellectual property. The results show which data types are high-usage, low-risk versus those that are low-usage, high-risk. We discuss the implications of these results and recommend future work to improve privacy when data must be shared despite the increased risk to privacy.}
}

@inproceedings{bhunia_Dynamicattackdetection_2017,
  title = {Dynamic Attack Detection and Mitigation in {{IoT}} Using {{SDN}}},
  booktitle = {2017 27th {{International Telecommunication Networks}} and {{Applications Conference}} ({{ITNAC}})},
  author = {Bhunia, Suman Sankar and Gurusamy, Mohan},
  date = {2017-11},
  pages = {1--6},
  publisher = {IEEE},
  location = {Melbourne, VIC},
  doi = {10.1109/ATNAC.2017.8215418},
  url = {http://ieeexplore.ieee.org/document/8215418/},
  urldate = {2022-04-09},
  abstract = {With the advent of smart devices and lowering prices of sensing devices, adoption of Internet of Things (IoT) is gaining momentum. These IoT devices come with greater threat of being attacked or compromised that could lead to Denial of Service (DoS) and Distributed Denial of Service (DDoS). The high volume of IoT devices with high level of heterogeneity, magnify the possibility of security threats. So far, there is no protocol to guarantee the security of IoT devices. But to enable resilience, continuous monitoring is required along with adaptive decision making. These challenges can be addressed with the help of Software Defined Networking (SDN) which can effectively handle the security threats to the IoT devices in dynamic and adaptive manner without any burden on the IoT devices. In this paper, we propose an SDN-based secure IoT framework called SoftThings to detect abnormal behaviors and attacks as early as possible and mitigate as appropriate. Machine Learning is used at the SDN controller to monitor and learn the behavior of IoT devices over time. We have conducted experiments on Mininet emulator. Initial results show that this framework is capable to detect attacks on IoT with around 98\% precision.},
  eventtitle = {2017 27th {{International Telecommunication Networks}} and {{Applications Conference}} ({{ITNAC}})},
  isbn = {978-1-5090-6796-1},
  langid = {english}
}

@article{bierbrauer_Transferlearningraw_2022,
  title = {Transfer Learning for Raw Network Traffic Detection},
  author = {Bierbrauer, David A. and De Lucia, Michael J. and Reddy, Krishna and Maxwell, Paul and Bastian, Nathaniel D.},
  date = {2022-08-24},
  journaltitle = {Expert Systems with Applications},
  shortjournal = {Expert Systems with Applications},
  pages = {118641},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2022.118641},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417422016840},
  urldate = {2022-08-29},
  abstract = {Traditional machine learning models used for network intrusion detection systems rely on vast amounts of network traffic data with expertly engineered features. The abundance of computational and expert resources at the enterprise level allow for the employment of such models; however, these resources quickly dwindle in edge network scenarios. As Internet of Battlefield Things (IoBT) networks become common place in tactical environments, there is a need for improved and distributed models trained without these enterprise resources. Transfer learning -- which allows us to take information learned in one domain and apply it to another -- provides one way to create and distribute these models towards the edge. Using neural networks, we demonstrate the feasibility of transfer learning for intrusion detection using only raw network traffic in computationally limited environments. Our results show that with a transferred one-dimensional convolutional neural network model combined with a retrained random forest model, we obtain over 96\% accuracy with only 5,000 training samples on edge devices with an edge training time of approximately 67~s.},
  langid = {english},
  keywords = {Deep learning,Feature engineering,Internet of Battlefield Things,Machine learning,Network intrusion detection,Transfer learning}
}

@inproceedings{biglarbeigi_effectivefeatureselection_2014,
  title = {Towards Effective Feature Selection in Machine Learning-Based Botnet Detection Approaches},
  booktitle = {2014 {{IEEE Conference}} on {{Communications}} and {{Network Security}}},
  author = {Biglar Beigi, Elaheh and Hadian Jazi, Hossein and Stakhanova, Natalia and Ghorbani, Ali A.},
  date = {2014-10},
  pages = {247--255},
  publisher = {IEEE},
  location = {San Francisco, CA, USA},
  doi = {10.1109/CNS.2014.6997492},
  url = {https://ieeexplore.ieee.org/document/6997492},
  urldate = {2021-10-25},
  abstract = {Botnets, as one of the most formidable cyber security threats, are becoming more sophisticated and resistant to detection. In spite of specific behaviors each botnet has, there exist adequate similarities inside each botnet that separate its behavior from benign traffic. Several botnet detection systems have been proposed based on these similarities. However, offering a solution for differentiating botnet traffic (even those using same protocol, e.g. IRC) from normal traffic is not trivial. Extraction of features in either host or network level to model a botnet has been one of the most popular methods in botnet detection. A subset of features, usually selected based on some intuitive understanding of botnets, is used by the machine learning algorithms to classify/ cluster botnet traffic. These approaches, tested against two or three botnet traces, have mostly showed satisfactory detection results. Even though, their effectiveness in detection of other botnets or real traffic remains in doubt. Additionally, effectiveness of different combination of features in terms of providing more detection coverage has not been fully studied. In this paper we revisit flow-based features employed in the existing botnet detection studies and evaluate their relative effectiveness. To ensure a proper evaluation we create a dataset containing a diverse set of botnet traces and background traffic.},
  eventtitle = {2014 {{IEEE Conference}} on {{Communications}} and {{Network Security}} ({{CNS}})},
  isbn = {978-1-4799-5890-0},
  langid = {english}
}

@book{bishop_Patternrecognitionmachine_2006,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, Christopher M.},
  date = {2006},
  series = {Information Science and Statistics},
  publisher = {Springer},
  location = {New York},
  isbn = {978-0-387-31073-2},
  pagetotal = {738},
  keywords = {Machine learning,Pattern perception}
}

@article{blackburn_TruthWholeTruth_2016,
  title = {The {{Truth}}, {{The Whole Truth}}, and {{Nothing But}} the {{Truth}}: {{A Pragmatic Guide}} to {{Assessing Empirical Evaluations}}},
  shorttitle = {The {{Truth}}, {{The Whole Truth}}, and {{Nothing But}} the {{Truth}}},
  author = {Blackburn, Stephen M. and Diwan, Amer and Hauswirth, Matthias and Sweeney, Peter F. and Amaral, Jos\'e Nelson and Brecht, Tim and Bulej, Lubom\'ir and Click, Cliff and Eeckhout, Lieven and Fischmeister, Sebastian and Frampton, Daniel and Hendren, Laurie J. and Hind, Michael and Hosking, Antony L. and Jones, Richard E. and Kalibera, Tomas and Keynes, Nathan and Nystrom, Nathaniel and Zeller, Andreas},
  date = {2016-10-13},
  journaltitle = {ACM Transactions on Programming Languages and Systems},
  shortjournal = {ACM Trans. Program. Lang. Syst.},
  volume = {38},
  number = {4},
  pages = {1--20},
  issn = {0164-0925, 1558-4593},
  doi = {10.1145/2983574},
  url = {https://dl.acm.org/doi/10.1145/2983574},
  urldate = {2021-09-24},
  abstract = {An unsound claim can misdirect a field, encouraging the pursuit of unworthy ideas and the abandonment of promising ideas. An inadequate description of a claim can make it difficult to reason about the claim, for example, to determine whether the claim is sound. Many practitioners will acknowledge the threat of unsound claims or inadequate descriptions of claims to their field. We believe that this situation is exacerbated, and even encouraged, by the lack of a systematic approach to exploring, exposing, and addressing the source of unsound claims and poor exposition.             This article proposes a framework that identifies three sins of reasoning that lead to unsound claims and two sins of exposition that lead to poorly described claims and evaluations. Sins of exposition obfuscate the objective of determining whether or not a claim is sound, while sins of reasoning lead directly to unsound claims.             Our framework provides practitioners with a principled way of critiquing the integrity of their own work and the work of others. We hope that this will help individuals conduct better science and encourage a cultural shift in our research community to identify and promulgate sound claims.},
  langid = {english},
  keywords = {\_read}
}

@article{blanchard_Machinelearningadversaries_2017,
  title = {Machine Learning with Adversaries: {{Byzantine}} Tolerant Gradient Descent},
  shorttitle = {Machine Learning with Adversaries},
  author = {Blanchard, Peva and El Mhamdi, El Mahdi and Guerraoui, Rachid and Stainer, Julien},
  date = {2017},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {30},
  keywords = {â›” No DOI found}
}

@inproceedings{blanchard_MachineLearningAdversaries_2017a,
  title = {Machine {{Learning}} with {{Adversaries}}: {{Byzantine Tolerant Gradient Descent}}},
  shorttitle = {Machine {{Learning}} with {{Adversaries}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Blanchard, Peva and El Mhamdi, El Mahdi and Guerraoui, Rachid and Stainer, Julien},
  date = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2017/hash/f4b9ec30ad9f68f89b29639786cb62ef-Abstract.html},
  urldate = {2024-03-06}
}

@article{bonawitz_FederatedLearningScale_2019,
  title = {Towards {{Federated Learning}} at {{Scale}}: {{System Design}}},
  author = {Bonawitz, Keith and Eichner, Hubert and Grieskamp, Wolfgang and Huba, Dzmitry and Ingerman, Alex and Ivanov, Vladimir and Kiddon, Chloe and Kone\v cn\'y, Jakub and Mazzocchi, Stefano and McMahan, H. Brendan and Van Overveldt, Timon and Petrou, David and Ramage, Daniel and Roselander, Jason},
  date = {2019-02-04},
  journaltitle = {arXiv},
  url = {http://arxiv.org/abs/1902.01046},
  abstract = {Federated Learning is a distributed machine learning approach which enables model training on a large corpus of decentralized data. We have built a scalable production system for Federated Learning in the domain of mobile devices, based on TensorFlow. In this paper, we describe the resulting high-level design, sketch some of the challenges and their solutions, and touch upon the open problems and future directions.},
  keywords = {â›” No DOI found}
}

@inproceedings{bonawitz_PracticalSecureAggregation_2017,
  title = {Practical {{Secure Aggregation}} for {{Privacy-Preserving Machine Learning}}},
  booktitle = {Proceedings of the 2017 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Bonawitz, Keith and Ivanov, Vladimir and Kreuter, Ben and Marcedone, Antonio and McMahan, H. Brendan and Patel, Sarvar and Ramage, Daniel and Segal, Aaron and Seth, Karn},
  date = {2017-10-30},
  pages = {1175--1191},
  publisher = {ACM},
  location = {New York, NY, USA},
  issn = {15437221},
  doi = {10.1145/3133956.3133982},
  url = {https://dl.acm.org/doi/10.1145/3133956.3133982},
  abstract = {We design a novel, communication-efficient, failure-robust protocol for secure aggregation of high-dimensional data. Our protocol allows a server to compute the sum of large, user-held data vectors from mobile devices in a secure manner (i.e. without learning each user's individual contribution), and can be used, for example, in a federated learning setting, to aggregate user-provided model updates for a deep neural network. We prove the security of our protocol in the honest-but-curious and active adversary settings, and show that security is maintained even if an arbitrarily chosen subset of users drop out at any time. We evaluate the efficiency of our protocol and show, by complexity analysis and a concrete implementation, that its runtime and communication overhead remain low even on large data sets and client pools. For 16-bit input values, our protocol offers 1.73\texttimes{} communication expansion for 210 users and 220-dimensional vectors, and 1.98\texttimes{} expansion for 214 users and 224-dimensional vectors over sending data in the clear.},
  isbn = {978-1-4503-4946-8}
}

@online{Bot-IoT_url,
  title = {The {{Bot-IoT Dataset}}},
  url = {https://research.unsw.edu.au/projects/bot-iot-dataset},
  urldate = {2023-03-22}
}

@thesis{boubou_Contributionauxmethodes_2007,
  title = {Contribution Aux M\'ethodes de Classification Non Supervis\'ee via Des Approches Pr\'etopologiques et d'agr\'egation d'opinions},
  author = {Boubou, Mounzer},
  date = {2007-11},
  institution = {Universit\'e Claude Bernard - Lyon I},
  url = {https://tel.archives-ouvertes.fr/tel-00195779}
}

@inproceedings{boudko_FederatedLearningCollaborative_2023,
  title = {Federated {{Learning}} for~{{Collaborative Cybersecurity}} of~{{Distributed Healthcare}}},
  booktitle = {Advances in {{Mobile Computing}} and {{Multimedia Intelligence}}},
  author = {Boudko, Svetlana},
  editor = {Delir Haghighi, Pari and Khalil, Ismail and Kotsis, Gabriele and ER, Ngurah Agus Sanjaya},
  date = {2023},
  pages = {57--62},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-48348-6_5},
  abstract = {Healthcare 4.0 is a new paradigm for providing healthcare services in highly distributed and complex settings. The distributed and heterogeneous nature of home-based medical devices, and their need to exchange data with external sources make Healthcare 4.0 solutions susceptible to cyberattacks and require decentralized solutions to protect sensitive local data. This work presents a collaborative approach to security incident detection for distributed healthcare utilizing federated learning. At this stage, the federated learning process has been facilitated and evaluated using simulation, training, and testing.},
  isbn = {978-3-031-48348-6},
  langid = {english}
}

@article{bougueroua_SurveyMultiAgentBased_2021,
  title = {A {{Survey}} on {{Multi-Agent Based Collaborative Intrusion Detection Systems}}},
  author = {Bougueroua, Nassima and Mazouzi, Smaine and Belaoued, Mohamed and Seddari, Noureddine and Derhab, Abdelouahid and Bouras, Abdelghani},
  date = {2021-04-01},
  journaltitle = {Journal of Artificial Intelligence and Soft Computing Research},
  shortjournal = {Journal of Artificial Intelligence and Soft Computing Research},
  volume = {11},
  pages = {111--142},
  doi = {10.2478/jaiscr-2021-0008},
  abstract = {Multi-Agent Systems (MAS) have been widely used in many areas like modeling and simulation of complex phenomena, and distributed problem solving. Likewise, MAS have been used in cyber-security, to build more efficient Intrusion Detection Systems (IDS), namely Collaborative Intrusion Detection Systems (CIDS). This work presents a taxonomy for classifying the methods used to design intrusion detection systems, and how such methods were used alongside with MAS in order to build IDS that are deployed in distributed environments, resulting in the emergence of CIDS. The proposed taxonomy, consists of three parts: 1) general architecture of CIDS, 2) the used agent technology, and 3) decision techniques, in which used technologies are presented. The proposed taxonomy reviews and classifies the most relevant works in this topic and highlights open research issues in view of recent and emerging threats. Thus, this work provides a good insight regarding past, current, and future solutions for CIDS, and helps both researchers and professionals design more effective solutions.}
}

@inproceedings{bourtoule_MachineUnlearning_2021,
  title = {Machine {{Unlearning}}},
  booktitle = {2021 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  author = {Bourtoule, Lucas and Chandrasekaran, Varun and Choquette-Choo, Christopher A. and Jia, Hengrui and Travers, Adelin and Zhang, Baiwu and Lie, David and Papernot, Nicolas},
  date = {2021-05},
  pages = {141--159},
  issn = {2375-1207},
  doi = {10.1109/SP40001.2021.00019},
  abstract = {Once users have shared their data online, it is generally difficult for them to revoke access and ask for the data to be deleted. Machine learning (ML) exacerbates this problem because any model trained with said data may have memorized it, putting users at risk of a successful privacy attack exposing their information. Yet, having models unlearn is notoriously difficult.We introduce SISA training, a framework that expedites the unlearning process by strategically limiting the influence of a data point in the training procedure. While our framework is applicable to any learning algorithm, it is designed to achieve the largest improvements for stateful algorithms like stochastic gradient descent for deep neural networks. SISA training reduces the computational overhead associated with unlearning, even in the worst-case setting where unlearning requests are made uniformly across the training set. In some cases, the service provider may have a prior on the distribution of unlearning requests that will be issued by users. We may take this prior into account to partition and order data accordingly, and further decrease overhead from unlearning.Our evaluation spans several datasets from different domains, with corresponding motivations for unlearning. Under no distributional assumptions, for simple learning tasks, we observe that SISA training improves time to unlearn points from the Purchase dataset by 4.63\texttimes, and 2.45\texttimes{} for the SVHN dataset, over retraining from scratch. SISA training also provides a speed-up of 1.36\texttimes{} in retraining for complex learning tasks such as ImageNet classification; aided by transfer learning, this results in a small degradation in accuracy. Our work contributes to practical data governance in machine unlearning.},
  eventtitle = {2021 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  keywords = {Data privacy,Limiting,Privacy,Stochastic processes,Training,Training data,Transfer learning}
}

@inproceedings{briggs_Federatedlearninghierarchical_2020,
  title = {Federated Learning with Hierarchical Clustering of Local Updates to Improve Training on Non-{{IID}} Data},
  booktitle = {2020 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Briggs, Christopher and Fan, Zhong and Andras, Peter},
  date = {2020-07},
  pages = {1--9},
  issn = {2161-4407},
  doi = {10.1109/IJCNN48605.2020.9207469},
  abstract = {Federated learning (FL) is a well established method for performing machine learning tasks over massively distributed data. However in settings where data is distributed in a non-iid (not independent and identically distributed) fashion - as is typical in real world situations - the joint model produced by FL suffers in terms of test set accuracy and/or communication costs compared to training on iid data. We show that learning a single joint model is often not optimal in the presence of certain types of non-iid data. In this work we present a modification to FL by introducing a hierarchical clustering step (FL+HC) to separate clusters of clients by the similarity of their local updates to the global joint model. Once separated, the clusters are trained independently and in parallel on specialised models. We present a robust empirical analysis of the hyperparameters for FL+HC for several iid and non-iid settings. We show how FL+HC allows model training to converge in fewer communication rounds (significantly so under some non-iid settings) compared to FL without clustering. Additionally, FL+HC allows for a greater percentage of clients to reach a target accuracy compared to standard FL. Finally we make suggestions for good default hyperparameters to promote superior performing specialised models without modifying the the underlying federated learning communication protocol.},
  eventtitle = {2020 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  keywords = {Cats,Clustering algorithms,clustering applications,Data models,Distributed databases,distributed machine learning,federated learning,Merging,Task analysis,Training}
}

@article{buczak_SurveyDataMining_2016,
  title = {A {{Survey}} of {{Data Mining}} and {{Machine Learning Methods}} for {{Cyber Security Intrusion Detection}}},
  author = {Buczak, Anna L. and Guven, Erhan},
  date = {2016},
  journaltitle = {IEEE Communications Surveys Tutorials},
  volume = {18},
  number = {2},
  pages = {1153--1176},
  issn = {1553-877X},
  doi = {10.1109/COMST.2015.2494502},
  abstract = {This survey paper describes a focused literature survey of machine learning (ML) and data mining (DM) methods for cyber analytics in support of intrusion detection. Short tutorial descriptions of each ML/DM method are provided. Based on the number of citations or the relevance of an emerging method, papers representing each method were identified, read, and summarized. Because data are so important in ML/DM approaches, some well-known cyber data sets used in ML/DM are described. The complexity of ML/DM algorithms is addressed, discussion of challenges for using ML/DM for cyber security is presented, and some recommendations on when to use a given method are provided.},
  eventtitle = {{{IEEE Communications Surveys Tutorials}}},
  keywords = {\_read,+survey,Computer security,Cyber analytics,Cyber Analytics,data mining,Data mining,Data Mining,Data models,IP networks,machine learning,Machine Learning,Measurement,Ports (Computers),Protocols}
}

@inproceedings{bukhtoyarov_EnsembleDistributedApproachClassification_2014,
  title = {Ensemble-{{Distributed Approach}} in {{Classification Problem Solution}} for {{Intrusion Detection Systems}}},
  booktitle = {Intelligent {{Data Engineering}} and {{Automated Learning}} -- {{IDEAL}} 2014},
  author = {Bukhtoyarov, Vladimir and Zhukov, Vadim},
  editor = {Corchado, Emilio and Lozano, Jos\'e A. and Quinti\'an, H\'ector and Yin, Hujun},
  date = {2014},
  pages = {255--265},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-10840-7_32},
  abstract = {Network activity has become an essential part of daily life of almost any individual or company. At the same time the number of various network threats and attacks in private and corporate networks is constantly increasing. Therefore, the development of effective methods of intrusion detection is an urgent problem nowadays. In the paper the basic scheme and main steps of the novel ensemble-distributed approach are proposed. This approach can be used to solve a wide range of classification problems. Its scheme is well suited for the problem of intrusion detection in computer networks. Unlike traditional ensemble approaches the proposed approach provides partial obtaining of adaptive solutions by individual classifiers without an ensemble classifier. The proposed approach has been used to solve some test problems. The results are presented in the article. The approach was also tested on a data set KDD~Cup~'99 and the results confirm the high efficiency of the proposed scheme of ensemble-distributed classification. In comparison with the traditional approaches for distributed intrusion detection systems there is a significant reduction (about 10\%) of information flows between distributed individual classifiers and a centralized ensemble classifier. Possible ways of approach improving and possible applications of the proposed collective-distributed scheme are presented in the final part of the article.},
  isbn = {978-3-319-10840-7},
  langid = {english},
  keywords = {classification,ensemble approach,information security,intrusion detection}
}

@book{bureauinternationaldespoidsetmesures_Internationalvocabularymetrology_2012,
  title = {International Vocabulary of Metrology: {{Basic}} and General Concepts and Associated Terms ({{VIM}})},
  author = {Bureau International des Poids et Mesures},
  date = {2012},
  url = {https://www.bipm.org/en/committees/jc/jcgm/publications}
}

@thesis{busnel_Systemesinformationcollaboratifs_2008,
  title = {Syst\`emes d'information Collaboratifs et Auto-Organisants Pour R\'eseaux de Capteurs Large-\'Echelle : "{{De}} La Th\'eorie \`a La Pratique"},
  author = {Busnel, Yann},
  date = {2008-11},
  institution = {Universit\'e Rennes 1},
  url = {https://tel.archives-ouvertes.fr/tel-00365659},
  abstract = {Les syst\`emes informatiques ont connu r\'ecemment de grandes avanc\'ees dans leur conception. D'une part, la d\'emocratisation des r\'eseaux via la croissance exponentielle de l'Internet a permis d'envisager des syst\`emes \`a l'\'echelle mondiale, visant de mettre en commun une multitude de ressources \`a travers la plan\`ete enti\`ere. D'autre part, la r\'eduction continue de la taille des \'equipements informatiques a permis l'apparition de mat\'eriels miniatures. Le jumelage de ces deux \'evolutions est \`a l'origine de l'apparition des r\'eseaux de capteurs sans fil. Le spectre des applications potentielles de ces r\'eseaux est extr\^emement large, que cela soit dans le contexte d'une infrastructure fixe autant que dans l'informatique embarqu\'ee. Cette th\`ese propose un ensemble de contributions pour la gestion de l'information \`a la fois dans le contexte mobile et statique. \'Edifi\'ees autour des m\^emes propri\'et\'es de collaboration et d'auto-organisation, ces propositions sont con\c cues selon une m\'ethodologie de la th\'eorie vers la pratique. Cette th\`ese vise ainsi, en premier lieu, une analyse th\'eorique a priori d'une application classique des r\'eseaux de capteurs statiques, \`a savoir le suivi de trajectoires d'objets mobiles non identifi\'es. Par la suite, nous \'etendons le spectre des applications vis\'ees en proposant une structure g\'en\'erique \`a toute mise en oeuvre r\'eelle de r\'eseaux de capteurs statiques. En second lieu, nous consid\'erons une mod\'elisation de la mobilit\'e permettant d'analyser fondamentalement les impacts de celle-ci sur la convergence des protocoles dits de population. Enfin, nous \'etablissons un parall\`ele entre les travaux men\'es th\'eoriquement sur les r\'eseaux de capteurs mobiles avec ceux plus pratiques et empiriques propos\'es dans le cadre des protocoles \'epid\'emiques sur r\'eseaux filaires. En d\'emontrant que ces deux domaines portent en r\'ealit\'e sur la m\^eme classe de protocoles -- et donc de probl\`emes -- nous ouvrons ainsi une voie captivante pour de futures recherches dans chacun de ces deux domaines, par l'utilisation de l'un dans l'autre.}
}

@inproceedings{caglayan_ClusteringBasedScoringMechanism_2022,
  title = {A {{Clustering-Based Scoring Mechanism}} for {{Malicious Model Detection}} in {{Federated Learning}}},
  booktitle = {2022 25th {{Euromicro Conference}} on {{Digital System Design}} ({{DSD}})},
  author = {Caglayan, Cem and Yurdakul, Arda},
  date = {2022-08},
  pages = {224--231},
  publisher = {IEEE},
  location = {Maspalomas, Spain},
  doi = {10.1109/DSD57027.2022.00038},
  url = {https://ieeexplore.ieee.org/document/9996731/},
  urldate = {2024-04-12},
  abstract = {Federated learning is a distributed machine learning technique that aggregates every client model on a server to obtain a global model. However, some clients may harm the system by poisoning their model or data to make the global model irrelevant to its objective. This paper introduces an approach for the server to detect adversarial models by coordinate-based statistical comparison and eliminate them from the system when their participation rate is at most 40\%. Realistic experiments that use non-independent and identically distributed (non-iid) datasets with different batch sizes have been carried out to show that the proposed method can still identify the malicious nodes successfully even if some of the clients learn slower than others or send quantized model weights due to energy limitations.},
  eventtitle = {2022 25th {{Euromicro Conference}} on {{Digital System Design}} ({{DSD}})},
  isbn = {978-1-66547-404-7},
  langid = {english}
}

@inproceedings{cai_ClusterbasedFederatedLearning_2022,
  title = {Cluster-Based {{Federated Learning Framework}} for {{Intrusion Detection}}},
  booktitle = {2022 {{IEEE}} 13th {{International Symposium}} on {{Parallel Architectures}}, {{Algorithms}} and {{Programming}} ({{PAAP}})},
  author = {Cai, Luxin and Chen, Naiyue and Wei, Yuanmeng and Chen, Huaping and Li, Yidong},
  date = {2022-11},
  pages = {1--6},
  doi = {10.1109/PAAP56126.2022.10010553},
  url = {https://ieeexplore.ieee.org/abstract/document/10010553},
  urldate = {2024-04-12},
  abstract = {With the rapid development of Industrial Internet, the network intrusion detection has become particularly important. In the Industrial Internet, large-scale data is distributed in the edge nodes caused the joint analysis of network intrusion detection at each edge node has become necessary. Federated learning structure can avoid data out of local nodes to protect user privacy data. However, the data distribution is different for each edge nodes, which limits the effectiveness of federated learning models. We focus on the non-IID data features and propose a new cluster-based federated learning framework for network intrusion detection. In this method, we cluster clients into different communities by data labels, which the clients contain the similar proportion of data labels in the same community. Based on the clustering results, we decompose federated learning model aggregation into cluster aggregation and global aggregation by leveraging similarities both within and between clusters. We conduct extensive experiments based on UNSW\_NB15 dataset. The results show that our method has better performance than FedAvg and FedProx. It can work well in scenarios with different distributions of data samples while ensuring data security and privacy protection.},
  eventtitle = {2022 {{IEEE}} 13th {{International Symposium}} on {{Parallel Architectures}}, {{Algorithms}} and {{Programming}} ({{PAAP}})},
  keywords = {\_read\_urgently,cluster,Data privacy,Data security,Distributed databases,federated learning,Federated learning,Image edge detection,Intrusion detection,Network intrusion detection,non-IID,Programming,similarity}
}

@article{cai_Hybridparalleldeep_2022,
  title = {A {{Hybrid}} Parallel Deep Learning Model for Efficient Intrusion Detection Based on Metric Learning},
  author = {Cai, Shaokang and Han, Dezhi and Yin, Xinming and Li, Dun and Chang, Chin-Chen},
  date = {2022-01-16},
  journaltitle = {Connection Science},
  shortjournal = {Connection Science},
  pages = {1--27},
  issn = {0954-0091, 1360-0494},
  doi = {10/gpbg4f},
  url = {https://www.tandfonline.com/doi/full/10.1080/09540091.2021.2024509},
  urldate = {2022-01-31},
  abstract = {With the rapid development of network technology, a variety of new malicious attacks appear while attack methods are constantly updated. As the attackers exploit the vulnerabilities of popular thirdparty components to invade target websites, further improving the classification accuracy of malicious network traffic is the key to improving the performance of abnormal traffic detection. Existing intrusion detection systems may suffer from incomplete feature extraction and low classification accuracy. Thus, this paper proposes an efficient hybrid parallel deep learning model (HPM) for intrusion detection based on margin learning. First, HPM constructs two parallel CNN architectures and fuses the spatial features obtained through full convolution. Secondly, the temporal information of the fused features is parsed separately using two parallel LSTMs. Finally, the extracted spatial-temporal features are fed into the CosMargin classifier for classification detection after global convolution and global pooling. Besides, this paper proposes an improved traffic feature extraction method, which not only reduces redundant features but also speeds up the convergence speed of the network. In the experiment, our HPM has achieved 99\% detection accuracy of each malicious class, ranging from 5\%--10\% improvement with other models, which demonstrates the superiority of our proposed model.},
  langid = {english}
}

@unpublished{caldas_LEAFBenchmarkFederated_2019,
  title = {{{LEAF}}: {{A Benchmark}} for {{Federated Settings}}},
  shorttitle = {{{LEAF}}},
  author = {Caldas, Sebastian and Duddu, Sai Meher Karthik and Wu, Peter and Li, Tian and Kone\v cn\'y, Jakub and McMahan, H. Brendan and Smith, Virginia and Talwalkar, Ameet},
  date = {2019-12-09},
  eprint = {1812.01097},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1812.01097},
  urldate = {2021-10-18},
  abstract = {Modern federated networks, such as those comprised of wearable devices, mobile phones, or autonomous vehicles, generate massive amounts of data each day. This wealth of data can help to learn models that can improve the user experience on each device. However, the scale and heterogeneity of federated data presents new challenges in research areas such as federated learning, meta-learning, and multi-task learning. As the machine learning community begins to tackle these challenges, we are at a critical time to ensure that developments made in these areas are grounded with realistic benchmarks. To this end, we propose LEAF, a modular benchmarking framework for learning in federated settings. LEAF includes a suite of open-source federated datasets, a rigorous evaluation framework, and a set of reference implementations, all geared towards capturing the obstacles and intricacies of practical federated environments.},
  langid = {english},
  keywords = {â›” No DOI found,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{calvert_ModelingInternettopology_1997,
  title = {Modeling {{Internet}} Topology},
  author = {Calvert, K.L. and Doar, M.B. and Zegura, E.W.},
  date = {1997-06},
  journaltitle = {IEEE Communications Magazine},
  volume = {35},
  number = {6},
  pages = {160--163},
  issn = {1558-1896},
  doi = {10.1109/35.587723},
  url = {https://ieeexplore.ieee.org/document/587723},
  urldate = {2024-07-07},
  abstract = {The topology of a network, or a group of networks such as the Internet, has a strong bearing on many management and performance issues. Good models of the topological structure of a network are essential for developing and analyzing internetworking technology. This article discusses how graph-based models can be used to represent the topology of large networks, particularly aspects of locality and hierarchy present in the Internet. Two implementations that generate networks whose topology resembles that of typical internetworks are described, together with publicly available source code.},
  eventtitle = {{{IEEE Communications Magazine}}},
  keywords = {Analytical models,Explosives,FDDI,Internet,IP networks,LAN interconnection,Network topology,Routing,Spine,Switches}
}

@inproceedings{camacho_DatasetQualityAssessment_2022,
  title = {Dataset {{Quality Assessment}} in {{Autonomous Networks}} with {{Permutation Testing}}},
  booktitle = {{{NOMS}} 2022-2022 {{IEEE}}/{{IFIP Network Operations}} and {{Management Symposium}}},
  author = {Camacho, Jos\'e and Wasielewska, Katarzyna},
  date = {2022-04},
  pages = {1--4},
  issn = {2374-9709},
  doi = {10.1109/NOMS54207.2022.9789767},
  abstract = {The development of autonomous or self-driving networks is one of the main challenges faced by the telecommunication industry. Future networks are expected to realise a number of tasks, including network optimization and failure recovery, with minimal human supervision. In this context, the network community (manufacturers, operators, researchers, etc.) is looking at Machine Learning (ML) methods with high expectations. However, ML models can only be as good as the data they are trained on, which means that autonomous networks also require a sound autonomous procedure to assess, and if possible improve, data quality. Although the application of ML techniques in communication networks is ample in the literature, analyzing the quality of the network data seems an ignored problem. This paper presents work in progress on the application of permutation testing to assess the quality of network datasets. We illustrate our approach on a number of simple synthetic datasets with pre-established quality and then we demonstrate its application in a publicly available network dataset.},
  eventtitle = {{{NOMS}} 2022-2022 {{IEEE}}/{{IFIP Network Operations}} and {{Management Symposium}}},
  keywords = {anomaly detection,autonomous networks,classification,Communication networks,Communications technology,Data integrity,Data models,data quality assessment,Industries,Machine learning,network data,permutation testing,Quality assessment,self-driving networks}
}

@incollection{campolo_NamedAINetworking_2020,
  title = {Towards {{Named AI Networking}}: {{Unveiling}} the {{Potential}} of {{NDN}} for {{Edge AI}}},
  shorttitle = {Towards {{Named AI Networking}}},
  booktitle = {Ad-{{Hoc}}, {{Mobile}}, and {{Wireless Networks}}},
  author = {Campolo, Claudia and Lia, Gianmarco and Amadeo, Marica and Ruggeri, Giuseppe and Iera, Antonio and Molinaro, Antonella},
  editor = {Grieco, Luigi Alfredo and Boggia, Gennaro and Piro, Giuseppe and Jararweh, Yaser and Campolo, Claudia},
  date = {2020},
  volume = {12338},
  pages = {16--22},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-61746-2_2},
  url = {https://link.springer.com/10.1007/978-3-030-61746-2_2},
  urldate = {2022-09-29},
  abstract = {Thanks to recent advancements in edge computing, the traditional centralized cloud-based approach to deploy Artificial Intelligence (AI) techniques will be soon replaced or complemented by the so-called edge AI approach. By pushing AI at the network edge, close to the large amount of raw input data, the traffic traversing the core network as well as the inference latency can be reduced. Despite such neat benefits, the actual deployment of edge AI across distributed nodes raises novel challenges to be addressed, such as the need to enforce proper addressing and discovery procedures, to identify AI components, and to chain them in an interoperable manner. Named Data Networking (NDN) has been recently argued as one of the main enablers of network and computing convergence, which edge AI should build upon. However, the peculiarities of such a new paradigm entails to go a step further. In this paper we disclose the potential of NDN to support the orchestration of edge AI. Several motivations are discussed, as well as the challenges which serve as guidelines for progress beyond the state of the art in this topic.},
  isbn = {978-3-030-61745-5 978-3-030-61746-2},
  langid = {english}
}

@article{campos_EvaluatingFederatedLearning_2022,
  title = {Evaluating {{Federated Learning}} for Intrusion Detection in {{Internet}} of {{Things}}: {{Review}} and Challenges},
  shorttitle = {Evaluating {{Federated Learning}} for Intrusion Detection in {{Internet}} of {{Things}}},
  author = {Campos, Enrique M\'armol and Saura, Pablo Fern\'andez and Gonz\'alez-Vidal, Aurora and Hern\'andez-Ramos, Jos\'e L. and Bernab\'e, Jorge Bernal and Baldini, Gianmarco and Skarmeta, Antonio},
  date = {2022-02-11},
  journaltitle = {Computer Networks},
  shortjournal = {Computer Networks},
  volume = {203},
  pages = {108661},
  issn = {1389-1286},
  doi = {10.1016/j.comnet.2021.108661},
  url = {https://www.sciencedirect.com/science/article/pii/S1389128621005405},
  urldate = {2024-04-25},
  abstract = {The application of Machine Learning (ML) techniques to the well-known intrusion detection systems (IDS) is key to cope with increasingly sophisticated cybersecurity attacks through an effective and efficient detection process. In the context of the Internet of Things (IoT), most ML-enabled IDS approaches use centralized approaches where IoT devices share their data with data centers for further analysis. To mitigate privacy concerns associated with centralized approaches, in recent years the use of Federated Learning (FL) has attracted a significant interest in different sectors, including healthcare and transport systems. However, the development of FL-enabled IDS for IoT is in its infancy, and still requires research efforts from various areas, in order to identify the main challenges for the deployment in real-world scenarios. In this direction, our work evaluates a FL-enabled IDS approach based on a multiclass classifier considering different data distributions for the detection of different attacks in an IoT scenario. In particular, we use three different settings that are obtained by partitioning the recent ToN\_IoT dataset according to IoT devices' IP address and types of attack. Furthermore, we evaluate the impact of different aggregation functions according to such setting by using the recent IBMFL framework as FL implementation. Additionally, we identify a set of challenges and future directions based on the existing literature and the analysis of our evaluation results.},
  keywords = {\_processed,+survey,â›” No DOI found,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Computer Science - Networking and Internet Architecture,Federated Learning,Internet of Things,Intrusion detection systems}
}

@unpublished{cao_CoFEDCrosssiloHeterogeneous_2022,
  title = {{{CoFED}}: {{Cross-silo Heterogeneous Federated Multi-task Learning}} via {{Co-training}}},
  shorttitle = {{{CoFED}}},
  author = {Cao, Xingjian and Li, Zonghang and Yu, Hongfang and Sun, Gang},
  date = {2022-02-17},
  eprint = {2202.08603},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2202.08603},
  urldate = {2022-02-25},
  abstract = {Federated Learning (FL) is a machine learning technique that enables participants to train highquality models collaboratively without exchanging their private data. Participants in cross-silo FL settings are independent organizations with different task needs, and they are concerned not only with data privacy, but also with training independently their unique models due to intellectual property. Most existing FL schemes are incapability for the above scenarios. In this paper, we propose a communication-efficient FL scheme, CoFED, based on pseudo-labeling unlabeled data like co-training. To the best of our knowledge, it is the first FL scheme compatible with heterogeneous tasks, heterogeneous models, and heterogeneous training algorithms simultaneously. Experimental results show that CoFED achieves better performance with a lower communication cost. Especially for the non-IID settings and heterogeneous models, the proposed method improves the performance by 35\%.},
  langid = {english},
  keywords = {â›” No DOI found,Computer Science - Machine Learning}
}

@online{cao_FLTrustByzantinerobustFederated_2022,
  title = {{{FLTrust}}: {{Byzantine-robust Federated Learning}} via {{Trust Bootstrapping}}},
  shorttitle = {{{FLTrust}}},
  author = {Cao, Xiaoyu and Fang, Minghong and Liu, Jia and Gong, Neil Zhenqiang},
  date = {2022-04-11},
  eprint = {2012.13995},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2012.13995},
  url = {http://arxiv.org/abs/2012.13995},
  urldate = {2022-08-09},
  abstract = {Byzantine-robust federated learning aims to enable a service provider to learn an accurate global model when a bounded number of clients are malicious. The key idea of existing Byzantine-robust federated learning methods is that the service provider performs statistical analysis among the clients' local model updates and removes suspicious ones, before aggregating them to update the global model. However, malicious clients can still corrupt the global models in these methods via sending carefully crafted local model updates to the service provider. The fundamental reason is that there is no root of trust in existing federated learning methods. In this work, we bridge the gap via proposing FLTrust, a new federated learning method in which the service provider itself bootstraps trust. In particular, the service provider itself collects a clean small training dataset (called root dataset) for the learning task and the service provider maintains a model (called server model) based on it to bootstrap trust. In each iteration, the service provider first assigns a trust score to each local model update from the clients, where a local model update has a lower trust score if its direction deviates more from the direction of the server model update. Then, the service provider normalizes the magnitudes of the local model updates such that they lie in the same hyper-sphere as the server model update in the vector space. Our normalization limits the impact of malicious local model updates with large magnitudes. Finally, the service provider computes the average of the normalized local model updates weighted by their trust scores as a global model update, which is used to update the global model. Our extensive evaluations on six datasets from different domains show that our FLTrust is secure against both existing attacks and strong adaptive attacks.},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security}
}

@inproceedings{cao_UnderstandingDistributedPoisoning_2019,
  title = {Understanding {{Distributed Poisoning Attack}} in {{Federated Learning}}},
  booktitle = {2019 {{IEEE}} 25th {{International Conference}} on {{Parallel}} and {{Distributed Systems}} ({{ICPADS}})},
  author = {Cao, Di and Chang, Shan and Lin, Zhijian and Liu, Guohua and Sun, Donghong},
  date = {2019-12},
  pages = {233--239},
  issn = {1521-9097},
  doi = {10.1109/ICPADS47876.2019.00042},
  abstract = {Federated learning is inherently vulnerable to poisoning attacks, since no training samples will be released to and checked by trustworthy authority. Poisoning attacks are widely investigated in centralized learning paradigm, however distributed poisoning attacks, in which more than one attacker colludes with each other, and injects malicious training samples into local models of their own, may result in a greater catastrophe in federated learning intuitively. In this paper, through real implementation of a federated learning system and distributed poisoning attacks, we obtain several observations about the relations between the number of poisoned training samples, attackers, and attack success rate. Moreover, we propose a scheme, Sniper, to eliminate poisoned local models from malicious participants during training. Sniper identifies benign local models by solving a maximum clique problem, and suspected (poisoned) local models will be ignored during global model updating. Experimental results demonstrate the efficacy of Sniper. The attack success rates are reduced to around 2\% even a third of participants are attackers.},
  eventtitle = {2019 {{IEEE}} 25th {{International Conference}} on {{Parallel}} and {{Distributed Systems}} ({{ICPADS}})},
  keywords = {{federated learning, distributed poisoning attack, defense, attack success rate, label-flipping}}
}

@article{cao_WhenInternetThings_2019,
  title = {When {{Internet}} of {{Things Meets Blockchain}}: {{Challenges}} in {{Distributed Consensus}}},
  author = {Cao, Bin and Li, Yixin and Zhang, Lei and Zhang, Long and Mumtaz, Shahid and Zhou, Zhenyu and Peng, Mugen},
  date = {2019-11-15},
  journaltitle = {IEEE Network},
  volume = {33},
  number = {6},
  pages = {133--139},
  issn = {0890-8044},
  doi = {10.1109/MNET.2019.1900002},
  url = {http://arxiv.org/abs/1905.06022},
  abstract = {Blockchain has been regarded as a promising technology for Internet of Things (IoT), since it provides significant solutions for decentralized network which can address trust and security concerns, high maintenance cost problem, etc. The decentralization provided by blockchain can be largely attributed to the use of consensus mechanism, which enables peer-to-peer trading in a distributed manner without the involvement of any third party. This article starts from introducing the basic concept of blockchain and illustrating why consensus mechanism plays an indispensable role in a blockchain enabled IoT system. Then, we discuss the main ideas of two famous consensus mechanisms including Proof of Work (PoW) and Proof of Stake (PoS), and list their limitations in IoT. Next, two mainstream Direct Acyclic Graph (DAG) based consensus mechanisms, i.e., the Tangle and Hashgraph, are reviewed to show why DAG consensus is more suitable for IoT system than PoW and PoS. Potential issues and challenges of DAG based consensus mechanism to be addressed in the future are discussed in the last.}
}

@article{castrucci_Designimplementationmediation_2012,
  title = {Design and Implementation of a Mediation System Enabling Secure Communication among {{Critical Infrastructures}}},
  author = {Castrucci, Marco and Neri, Alessandro and Caldeira, Filipe and Aubert, Jocelyn and Khadraoui, Djamel and Aubigny, Matthieu and Harpes, Carlo and Sim\~oes, Paulo and Suraci, Vincenzo and Capodieci, Paolo},
  date = {2012-07},
  journaltitle = {International Journal of Critical Infrastructure Protection},
  shortjournal = {International Journal of Critical Infrastructure Protection},
  volume = {5},
  number = {2},
  pages = {86--97},
  issn = {18745482},
  doi = {10.1016/j.ijcip.2012.04.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1874548212000194},
  urldate = {2021-05-19},
  abstract = {Nowadays, the increase of interdependencies among different Critical Infrastructures (CI) makes it more and more difficult to protect without using a systemic approach that considers a single infrastructure as part of a complex system of infrastructures. A strong collaboration among CI owners is required to avoid, or at least to limit the propagation of failures from one infrastructure to another and to put CI in safety mode. The key element enabling this required cooperation is the possibility for them to exchange relevant information related to the status of their infrastructures and to the services provided. In this paper, we present a middleware solution that allows CIs sharing real-time information, enabling the design and implementation of fault mitigation strategies and mechanisms to prevent the cascading phenomena generated by the failure propagation from one infrastructure to another.},
  langid = {english}
}

@incollection{catillo_CritiqueUseMachine_2021,
  title = {A {{Critique}} on the {{Use}} of {{Machine Learning}} on {{Public Datasets}} for {{Intrusion Detection}}},
  booktitle = {Quality of {{Information}} and {{Communications Technology}}},
  author = {Catillo, Marta and Del Vecchio, Andrea and Pecchia, Antonio and Villano, Umberto},
  editor = {Paiva, Ana C. R. and Cavalli, Ana Rosa and Ventura Martins, Paula and P\'erez-Castillo, Ricardo},
  date = {2021},
  volume = {1439},
  pages = {253--266},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-85347-1_19},
  url = {https://link.springer.com/10.1007/978-3-030-85347-1_19},
  urldate = {2022-05-23},
  abstract = {Intrusion detection has become an open challenge in any modern ICT system due to the ever-growing urge towards assuring security of present day networks. Various machine learning methods have been proposed for finding an effective solution to detect and prevent network intrusions. Many approaches, tuned and tested by means of public datasets, capitalize on well-known classifiers, which often reach detection accuracy close to 1. However, these results strongly depend on the training data, which may not be representative of real production environments and ever-evolving attacks. This paper is an initial exploration around this problem. After having learned a detector on the top of a public intrusion detection dataset, we test it against held-out data not used for learning and additional data gathered by attack emulation in a controlled network. The experiments presented are focused on Denial of Service attacks and based on the CICIDS2017 dataset. Overall, the figures gathered confirm that results obtained in the context of synthetic datasets may not generalize in practice.},
  isbn = {978-3-030-85346-4 978-3-030-85347-1},
  langid = {english}
}

@article{catillo_Successfulintrusiondetection_2023,
  title = {Successful Intrusion Detection with a Single Deep Autoencoder: Theory and Practice},
  shorttitle = {Successful Intrusion Detection with a Single Deep Autoencoder},
  author = {Catillo, Marta and Pecchia, Antonio and Villano, Umberto},
  date = {2023-05-25},
  journaltitle = {Software Quality Journal},
  shortjournal = {Software Qual J},
  issn = {1573-1367},
  doi = {10.1007/s11219-023-09636-2},
  url = {https://doi.org/10.1007/s11219-023-09636-2},
  urldate = {2023-06-08},
  abstract = {Intrusion detection is a key topic in computer security. Due to the ever-increasing number of network attacks, several accurate anomaly-based techniques have been proposed for intrusion detection, wherein pattern recognition through machine learning techniques is typically used. Many proposals rely on the use of autoencoders, due to their capability to analyze complex, high-dimensional, and large-scale data. They capitalize on composite architectures and accurate learning approaches, possibly in combination with sophisticated feature selection techniques. However, due to their high complexity and lack of transferability of the impressive intrusion detection results, they are hardly ever used in production environments. This paper is developed around the intuition that complexity is not necessarily justified because a single autoencoder is enough to obtain similar, if not better, intrusion detection results compared to related proposals. The wide study presented here addresses the effect of the seed, a deep investigation on the training loss, and feature selection across the use of different hardware platforms. The best practices presented, regarding set-up and training, threshold setting, and possible use of feature selection techniques for performance improvement, can be valuable for any future work on the use of autoencoders for successful intrusion detection purposes.},
  langid = {english},
  keywords = {Autoencoders,Deep learning,Denial of service,Intrusion detection}
}

@unpublished{celdran_CyberSpecIntelligentBehavioral_2022,
  title = {{{CyberSpec}}: {{Intelligent Behavioral Fingerprinting}} to {{Detect Attacks}} on {{Crowdsensing Spectrum Sensors}}},
  shorttitle = {{{CyberSpec}}},
  author = {Celdr\'an, Alberto Huertas and S\'anchez, Pedro Miguel S\'anchez and Bovet, G\'er\^ome and P\'erez, Gregorio Mart\'inez and Stiller, Burkhard},
  date = {2022-01-14},
  eprint = {2201.05410},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2201.05410},
  urldate = {2022-01-31},
  abstract = {Integrated sensing and communication (ISAC) is a novel paradigm using crowdsensing spectrum sensors to help with the management of spectrum scarcity. However, well-known vulnerabilities of resource-constrained spectrum sensors and the possibility of being manipulated by users with physical access complicate their protection against spectrum sensing data falsification (SSDF) attacks. Most recent literature suggests using behavioral fingerprinting and Machine/Deep Learning (ML/DL) for improving similar cybersecurity issues. Nevertheless, the applicability of these techniques in resource-constrained devices, the impact of attacks affecting spectrum data integrity, and the performance and scalability of models suitable for heterogeneous sensors types are still open challenges. To improve limitations, this work presents seven SSDF attacks affecting spectrum sensors and introduces CyberSpec, an ML/DL-oriented framework using device behavioral fingerprinting to detect anomalies produced by SSDF attacks affecting resource-constrained spectrum sensors. CyberSpec has been implemented and validated in ElectroSense, a real crowdsensing RF monitoring platform where several configurations of the proposed SSDF attacks have been executed in different sensors. A pool of experiments with different unsupervised ML/DL-based models has demonstrated the suitability of CyberSpec detecting the previous attacks within an acceptable timeframe.},
  langid = {english},
  keywords = {â›” No DOI found,Computer Science - Cryptography and Security}
}

@inproceedings{cetin_FederatedWirelessNetwork_2019,
  title = {Federated {{Wireless Network Intrusion Detection}}},
  booktitle = {2019 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  author = {Cetin, Burak and Lazar, Alina and Kim, Jinoh and Sim, Alex and Wu, Kesheng},
  date = {2019-12},
  pages = {6004--6006},
  publisher = {IEEE},
  location = {Los Angeles, CA, USA},
  doi = {10.1109/BigData47090.2019.9005507},
  url = {https://ieeexplore.ieee.org/document/9005507/},
  urldate = {2021-10-25},
  abstract = {Wi-Fi has become the wireless networking standard that allows short- to medium-range device to connect without wires. For the last 20 year, the Wi-Fi technology has so pervasive that most devices in use today are mobile and connect to the internet through Wi-Fi. Unlike wired network, a wireless network lacks a clear boundary, which leads to significant Wi-Fi network security concerns, especially because the current security measures are prone to several types of intrusion. To address this problem, machine learning and deep learning methods have been successfully developed to identify network attacks. However, collecting data to develop models is expensive and raises privacy concerns. The goal of this paper is to evaluate a federated learning approach that would alleviate such privacy concerns. This initial work on intrusion detection is performed in a simulated environment. Once proven feasible, this process would allow edge devices to collaboratively update global anomaly detection models, without sharing sensitive training data. On a set of tests with the AWID intrusion detection data set, we show that our federated approach is effective in terms of classification accuracy, computation cost, as well as communication cost.},
  eventtitle = {2019 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  isbn = {978-1-72810-858-2},
  langid = {english},
  keywords = {survey-fids}
}

@article{cha_BlockchainBasedCyberThreat_2020,
  title = {Blockchain-{{Based Cyber Threat Intelligence System Architecture}} for {{Sustainable Computing}}},
  author = {Cha, Jeonghun and Singh, Sushil Kumar and Pan, Yi and Park, Jong Hyuk},
  date = {2020},
  journaltitle = {Sustainability},
  volume = {12},
  number = {16},
  pages = {6401},
  issn = {2071-1050},
  doi = {10.3390/su12166401},
  abstract = {Nowadays, the designing of cyber-physical systems has a significant role and plays a substantial part in developing a sustainable computing ecosystem for secure and scalable network architecture. The introduction of Cyber Threat Intelligence (CTI) has emerged as a new security system to mitigate existing cyber terrorism for advanced applications. CTI demands a lot of requirements at every step. In particular, data collection is a critical source of information for analysis and sharing; it is highly dependent on the reliability of the data. Although many feeds provide information on threats recently, it is essential to collect reliable data, as the data may be of unknown origin and provide information on unverified threats. Additionally, effective resource management needs to be put in place due to the large volume and diversity of the data. In this paper, we propose a blockchain-based cyber threat intelligence system architecture for sustainable computing in order to address issues such as reliability, privacy, scalability, and sustainability. The proposed system model can cooperate with multiple feeds that collect CTI data, create a reliable dataset, reduce network load, and measure organizations' contributions to motivate participation. To assess the proposed model's effectiveness, we perform the experimental analysis, taking into account various measures, including reliability, privacy, scalability, and sustainability. Experimental results of evaluation using the IP of 10 open source intelligence (OSINT) CTI feeds show that the proposed model saves about 15\% of storage space compared to total network resources in a limited test environment.}
}

@article{chaabouni_NetworkIntrusionDetection_2019,
  title = {Network {{Intrusion Detection}} for {{IoT Security Based}} on {{Learning Techniques}}},
  author = {Chaabouni, Nadia and Mosbah, Mohamed and Zemmari, Akka and Sauvignac, Cyrille and Faruki, Parvez},
  date = {2019},
  journaltitle = {IEEE Communications Surveys \& Tutorials},
  volume = {21},
  number = {3},
  pages = {2671--2701},
  publisher = {IEEE},
  issn = {1553-877X},
  doi = {10.1109/COMST.2019.2896380},
  url = {https://ieeexplore.ieee.org/document/8629941/},
  abstract = {Pervasive growth of Internet of Things (IoT) is visible across the globe. The 2016 Dyn cyberattack exposed the critical fault-lines among smart networks. Security of IoT has become a critical concern. The danger exposed by infested Internet-connected Things not only affects the security of IoT but also threatens the complete Internet eco-system which can possibly exploit the vulnerable Things (smart devices) deployed as botnets. Mirai malware compromised the video surveillance devices and paralyzed Internet via distributed denial of service attacks. In the recent past, security attack vectors have evolved bothways, in terms of complexity and diversity. Hence, to identify and prevent or detect novel attacks, it is important to analyze techniques in IoT context. This survey classifies the IoT security threats and challenges for IoT networks by evaluating existing defense techniques. Our main focus is on network intrusion detection systems (NIDSs); hence, this paper reviews existing NIDS implementation tools and datasets as well as free and open-source network sniffing software. Then, it surveys, analyzes, and compares state-of-the-art NIDS proposals in the IoT context in terms of architecture, detection methodologies, validation strategies, treated threats, and algorithm deployments. The review deals with both traditional and machine learning (ML) NIDS techniques and discusses future directions. In this survey, our focus is on IoT NIDS deployed via ML since learning algorithms have a good success rate in security and privacy. The survey provides a comprehensive review of NIDSs deploying different aspects of learning techniques for IoT, unlike other top surveys targeting the traditional systems. We believe that, this paper will be useful for academia and industry research, first, to identify IoT threats and challenges, second, to implement their own NIDS and finally to propose new smart techniques in IoT context considering IoT limitations. Moreover, the survey will enable security individuals differentiate IoT NIDS from traditional ones.},
  keywords = {+survey}
}

@article{Chaabouni2019,
  title = {Network {{Intrusion Detection}} for {{IoT Security Based}} on {{Learning Techniques}}},
  author = {Chaabouni, Nadia and Mosbah, Mohamed and Zemmari, Akka and Sauvignac, Cyrille and Faruki, Parvez},
  date = {2019},
  journaltitle = {IEEE Communications Surveys \& Tutorials},
  volume = {21},
  number = {3},
  pages = {2671--2701},
  publisher = {IEEE},
  issn = {1553-877X},
  doi = {10.1109/COMST.2019.2896380},
  url = {https://ieeexplore.ieee.org/document/8629941/},
  abstract = {Pervasive growth of Internet of Things (IoT) is visible across the globe. The 2016 Dyn cyberattack exposed the critical fault-lines among smart networks. Security of IoT has become a critical concern. The danger exposed by infested Internet-connected Things not only affects the security of IoT but also threatens the complete Internet eco-system which can possibly exploit the vulnerable Things (smart devices) deployed as botnets. Mirai malware compromised the video surveillance devices and paralyzed Internet via distributed denial of service attacks. In the recent past, security attack vectors have evolved bothways, in terms of complexity and diversity. Hence, to identify and prevent or detect novel attacks, it is important to analyze techniques in IoT context. This survey classifies the IoT security threats and challenges for IoT networks by evaluating existing defense techniques. Our main focus is on network intrusion detection systems (NIDSs); hence, this paper reviews existing NIDS implementation tools and datasets as well as free and open-source network sniffing software. Then, it surveys, analyzes, and compares state-of-the-art NIDS proposals in the IoT context in terms of architecture, detection methodologies, validation strategies, treated threats, and algorithm deployments. The review deals with both traditional and machine learning (ML) NIDS techniques and discusses future directions. In this survey, our focus is on IoT NIDS deployed via ML since learning algorithms have a good success rate in security and privacy. The survey provides a comprehensive review of NIDSs deploying different aspects of learning techniques for IoT, unlike other top surveys targeting the traditional systems. We believe that, this paper will be useful for academia and industry research, first, to identify IoT threats and challenges, second, to implement their own NIDS and finally to propose new smart techniques in IoT context considering IoT limitations. Moreover, the survey will enable security individuals differentiate IoT NIDS from traditional ones.}
}

@inproceedings{chaarifourati_FederatedLearningData_2021,
  title = {Federated {{Learning}} toward {{Data Preprocessing}}: {{COVID-19 Context}}},
  shorttitle = {Federated {{Learning}} toward {{Data Preprocessing}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Communications Workshops}} ({{ICC Workshops}})},
  author = {Chaari Fourati, Lamia and Ayed, Samiha},
  date = {2021-06},
  pages = {1--6},
  publisher = {IEEE},
  location = {Montreal, QC, Canada},
  doi = {10/gpbg44},
  url = {https://ieeexplore.ieee.org/document/9473590/},
  urldate = {2022-01-31},
  abstract = {During this last decade, in the digital era, online and real-time data management becomes essential and primordial in several scenarios. In the health domain, and especially for remote healthcare monitoring systems, the management of data in real time becomes a requirement. Indeed, care providers need to access the vital information and sometimes the processed data in order to take timely the adequate decision. However, many issues arise in the data processing regarding real-time aspect, computational complexity and patient mobility. Therefore, Federated Learning (FL) engages promising technologies such as the fog and the cloud computing as well as machine learning (ML) and deep learning (DL) to address the aforementioned issues. Fog computing enables data preprocessing in proximity of medical users, exploiting patients mobile phones or personal digital assistant (PDA) or small-scale distributed servers. In this paper, we pinpoint the important role of the FL-based system within Internet of Medical Things (IoMT) to combat COVID19 pandemic. Specifically, we first introduce the architecture highlighting the fog layer within the smart healthcare system. We then discuss the preprocesing tasks that could be implemented at the fog layer with a particular focus on ML and DL tasks. After that, an investigation related to the FL against several COVID19 contexts is provided. Finally, this paper explores open issues and future directions regarding the FL potentialities in pandemic situation.},
  eventtitle = {2021 {{IEEE International Conference}} on {{Communications Workshops}} ({{ICC Workshops}})},
  isbn = {978-1-72819-441-7},
  langid = {english}
}

@article{chadwick_cloudedgebaseddata_2020,
  title = {A Cloud-Edge Based Data Security Architecture for Sharing and Analysing Cyber Threat Information},
  author = {Chadwick, David W and Fan, Wenjun and Costantino, Gianpiero and family=Lemos, given=Rogerio, prefix=de, useprefix=true and Di Cerbo, Francesco and Herwono, Ian and Manea, Mirko and Mori, Paolo and Sajjad, Ali and Wang, Xiao-Si},
  date = {2020-01},
  journaltitle = {Future Generation Computer Systems},
  shortjournal = {Future Generation Computer Systems},
  volume = {102},
  pages = {710--722},
  issn = {0167739X},
  doi = {10.1016/j.future.2019.06.026},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X19300895},
  urldate = {2021-06-01},
  abstract = {Cyber-attacks affect every aspect of our lives. These attacks have serious consequences, not only for cyber-security, but also for safety, as the cyber and physical worlds are increasingly linked. Providing effective cyber-security requires cooperation and collaboration among all the entities involved. Increasing the amount of cyber threat information (CTI) available for analysis allows better prediction, prevention and mitigation of cyber-attacks. However, organizations are deterred from sharing their CTI over concerns that sensitive and confidential information may be revealed to others. We address this concern by providing a flexible framework that allows the confidential sharing of CTI for analysis between collaborators. We propose a five-level trust model for a cloud-edge based data sharing infrastructure. The data owner can choose an appropriate trust level and CTI data sanitization approach, ranging from plain text, through anonymization/pseudonymization to homomorphic encryption, in order to manipulate the CTI data prior to sharing it for analysis. Furthermore, this sanitization can be performed by either an edge device or by the cloud service provider, depending upon the level of trust the organization has in the latter. We describe our trust model, our cloud-edge infrastructure, and its deployment model, which are designed to satisfy the broadest range of requirements for confidential CTI data sharing. Finally we briefly describe our implementation and the testing that has been carried out so far by four pilot projects that are validating our infrastructure.},
  langid = {english}
}

@article{chandola_Anomalydetectionsurvey_2009,
  title = {Anomaly Detection: {{A}} Survey},
  shorttitle = {Anomaly Detection},
  author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
  date = {2009-07},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {41},
  number = {3},
  pages = {1--58},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/1541880.1541882},
  url = {https://dl.acm.org/doi/10.1145/1541880.1541882},
  urldate = {2022-03-20},
  abstract = {Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.},
  langid = {english},
  keywords = {+survey}
}

@article{chandraumakantham_EnhancingIntrusionDetection_2024,
  title = {Enhancing {{Intrusion Detection Through Federated Learning With Enhanced Ghost}}\_{{BiNet}} and {{Homomorphic Encryption}}},
  author = {ChandraUmakantham, Om Kumar and Gajendran, Sudhakaran and Marappan, Suguna},
  date = {2024},
  journaltitle = {IEEE Access},
  volume = {12},
  pages = {24879--24893},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3362347},
  url = {https://ieeexplore.ieee.org/document/10422789},
  urldate = {2024-04-12},
  abstract = {Intrusion detection is essential for safeguarding computer systems and networks against unauthorized access, malicious activities, and security breaches. Its application domains include network security, information security, and cybersecurity across various sectors such as finance, healthcare, government, and industry. Federated learning-based intrusion detection offers improved performance compared to conventional mechanisms by leveraging decentralized data sources, preserving data privacy, and enhancing model generalization through collaboration among multiple organizations. However, challenges faced by existing federated learning-based intrusion detection mechanisms include ensuring data privacy and security, mitigating communication overhead, and enhancing detection accuracy. In order to overcome these issues, this research article proposes a federated learning-based intrusion detection methodology that leverages Enhanced Ghost\_BiNet, a novel deep learning model, to enhance the security of information sharing and detection accuracy. Federated learning, a privacy-preserving machine learning technique, is utilized to enable multiple entities to collaboratively train a global intrusion detection model without sharing sensitive data. The proposed system first trains local models using Enhanced Ghost\_BiNet, which integrates GhostNet and Bidirectional Gated Recurrent Unit (BiGRU). To optimize the model's performance, the Chaotic Chebyshev Artificial Humming Bird (CAh) algorithm is employed. Homomorphic encryption is applied to encrypt the local model updates, enhancing data privacy and security. Server-side aggregation of updates and collaborative optimization are introduced to minimize communication rounds during data aggregation. The results demonstrate that the Enhanced Ghost\_BiNet outperforms traditional models like GhostNet, BiGRU, RNN, Auto Encoder, and CNN in terms of accuracy, precision, recall, F-Score, and mean square error (MSE). For instance, the Enhanced Ghost\_BiNet achieves an accuracy of 99.24\% on the KDD CUP 99 dataset, surpassing the other models by a significant margin. The proposed methodology provides a robust and secure approach to intrusion detection, ensuring the confidentiality of sensitive data while improving detection accuracy.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Data models,Data privacy,Deep learning,enhanced Ghost\_BiNet,Federated learning,homomorphic encryption,Homomorphic encryption,hybrid deep learning,intrusion detection,Intrusion detection,Machine learning,privacy,Security,Training}
}

@inproceedings{chantzios_QuestAppropriateCyberthreat_2019,
  title = {The {{Quest}} for the {{Appropriate Cyber-threat Intelligence Sharing Platform}}},
  booktitle = {Proceedings of the 8th {{International Conference}} on {{Data Science}}, {{Technology}} and {{Applications}}},
  author = {Chantzios, Thanasis and Koloveas, Paris and Skiadopoulos, Spiros and Kolokotronis, Nikos and Tryfonopoulos, Christos and Bilali, Vasiliki-Georgia and Kavallieros, Dimitris},
  date = {2019},
  number = {786698},
  pages = {369--376},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  doi = {10.5220/0007978103690376},
  url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0007978103690376},
  abstract = {Cyber-threat intelligence (CTI) is any information that can help an organization identify, assess, monitor, and respond to cyber-threats. It relates to all cyber components of an organization such as networks, computers, and other types of information technology. In the recent years, due to the major increase of cyber-threats, CTI sharing is becoming increasingly important both as a subject of research and as a concept of providing additional security to organizations. However, selecting the proper tools and platforms for CTI sharing, is a challenging task, that pertains to a variety of aspects. In this paper, we start by overviewing the CTI procedure (threat types, categories, sources and the general CTI life-cycle). Then, we present a set of seven high-level CTI plaftorm recommendations that can be used to evaluate a platform and subsequently we survey six state-of-the-art cyber-threat intelligence platforms. Finally, we compare and evaluate the six aforementioned platforms by means of the earlier proposed recommendations.},
  isbn = {978-989-758-377-3}
}

@inproceedings{charikar_Similarityestimationtechniques_2002,
  title = {Similarity Estimation Techniques from Rounding Algorithms},
  booktitle = {Proceedings of the Thiry-Fourth Annual {{ACM}} Symposium on {{Theory}} of Computing},
  author = {Charikar, Moses S.},
  date = {2002-05-19},
  series = {{{STOC}} '02},
  pages = {380--388},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/509907.509965},
  url = {https://doi.org/10.1145/509907.509965},
  urldate = {2024-07-03},
  abstract = {(MATH) A locality sensitive hashing scheme is a distribution on a family \$\textbackslash F\$ of hash functions operating on a collection of objects, such that for two objects x,y, Prh{$\varepsilon$}F[h(x) = h(y)] = sim(x,y), where sim(x,y) {$\varepsilon$} [0,1] is some similarity function defined on the collection of objects. Such a scheme leads to a compact representation of objects so that similarity of objects can be estimated from their compact sketches, and also leads to efficient algorithms for approximate nearest neighbor search and clustering. Min-wise independent permutations provide an elegant construction of such a locality sensitive hashing scheme for a collection of subsets with the set similarity measure sim(A,B) = \textbackslash frac\{\textbar A {$\cap$} B\textbar\}\{\textbar A {$\cup$} B\textbar\}.(MATH) We show that rounding algorithms for LPs and SDPs used in the context of approximation algorithms can be viewed as locality sensitive hashing schemes for several interesting collections of objects. Based on this insight, we construct new locality sensitive hashing schemes for:A collection of vectors with the distance between {$\rightarrow$} \textbackslash over u and {$\rightarrow$} \textbackslash over v measured by \O ({$\rightarrow$} \textbackslash over u, {$\rightarrow$} \textbackslash over v)/{$\pi$}, where \O ({$\rightarrow$} \textbackslash over u, {$\rightarrow$} \textbackslash over v) is the angle between {$\rightarrow$} \textbackslash over u) and {$\rightarrow$} \textbackslash over v). This yields a sketching scheme for estimating the cosine similarity measure between two vectors, as well as a simple alternative to minwise independent permutations for estimating set similarity.A collection of distributions on n points in a metric space, with distance between distributions measured by the Earth Mover Distance (EMD), (a popular distance measure in graphics and vision). Our hash functions map distributions to points in the metric space such that, for distributions P and Q, EMD(P,Q) {$\leq$} Eh{$\varepsilon\backslash$}F [d(h(P),h(Q))] {$\leq$} O(log n log log n). EMD(P, Q).},
  isbn = {978-1-58113-495-7}
}

@article{charles_ConvergenceAccuracyTradeOffs_2021,
  title = {Convergence and {{Accuracy Trade-Offs}} in {{Federated Learning}} and {{Meta-Learning}}},
  author = {Charles, Zachary and Konecny, Jakub},
  date = {2021},
  pages = {11},
  abstract = {We study a family of algorithms, which we refer to as local update methods, generalizing many federated and meta-learning algorithms. We prove that for quadratic models, local update methods are equivalent to first-order optimization on a surrogate loss we exactly characterize. Moreover, fundamental algorithmic choices (such as learning rates) explicitly govern a trade-off between the condition number of the surrogate loss and its alignment with the true loss. We derive novel convergence rates showcasing these trade-offs and highlight their importance in communication-limited settings. Using these insights, we are able to compare local update methods based on their convergence/accuracy trade-off, not just their convergence to critical points of the empirical loss. Our results shed new light on a broad range of phenomena, including the efficacy of server momentum in federated learning and the impact of proximal client updates.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@inproceedings{charyyev_IoTTrafficFlow_2020,
  title = {{{IoT Traffic Flow Identification}} Using {{Locality Sensitive Hashes}}},
  booktitle = {{{ICC}} 2020 - 2020 {{IEEE International Conference}} on {{Communications}} ({{ICC}})},
  author = {Charyyev, Batyr and Gunes, Mehmet Hadi},
  date = {2020-06},
  volume = {2020-June},
  pages = {1--6},
  publisher = {IEEE},
  issn = {15503607},
  doi = {10.1109/ICC40277.2020.9148743},
  url = {https://ieeexplore.ieee.org/document/9148743/},
  abstract = {Systems get smarter with computing capabilities, especially in the form of Internet of Things (IoT) devices. IoT devices are often resource-limited as they are optimized for a certain task. Hence, they are prone to be compromised and have become a target of malicious activities. Since IoT devices lack computing power for security software, network administrators need to isolate such devices and limit traffic to the device based on their communication needs. To this end, network administrators need to identify IoT devices when they join a network and detect anomalous traffic when they are compromised. In this paper, we introduce a novel approach to identify the IoT device based on the Nilsimsa hash of its traffic flow. Different from previous studies, the proposed approach does not require feature extraction from the data. In our evaluations, our approach has an average precision and recall of 93\% and 90\%, respectively.},
  isbn = {978-1-72815-089-5}
}

@article{chen_ADSimNetworkAnomaly_2021,
  title = {{{ADSim}}: {{Network Anomaly Detection}} via {{Similarity-aware Heterogeneous Ensemble Learning}}},
  author = {Chen, Wenqi and Wang, Zhiliang and Zhong, Ying and Han, Dongqi and Duan, Chenxin and Yin, Xia and Yang, Jiahai and Shi, Xingang},
  date = {2021},
  pages = {5},
  abstract = {The last decade has seen increasing application of machine learning to various tasks, including network anomaly detection. But anomaly detection methods using a single machine learning algorithm often fail to perform well, since network traffic can have complex and changeable patterns. Therefore, many solutions based on ensemble learning have been proposed to address this problem. However, previous studies have a essential drawback that they overlook the similarity between the weak classifiers, which may degrade the detection ability of the model. What's more, prior work use offline and supervised algorithms, which means a large amount of memory and reliable labels are necessary during the training period.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@online{chen_DapFLFederatedLearning_2022,
  title = {Dap-{{FL}}: {{Federated Learning}} Flourishes by Adaptive Tuning and Secure Aggregation},
  shorttitle = {Dap-{{FL}}},
  author = {Chen, Qian and Wang, Zilong and Chen, Jiawei and Yan, Haonan and Lin, Xiaodong},
  date = {2022-06-07},
  eprint = {2206.03623},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2206.03623},
  urldate = {2022-07-05},
  abstract = {Federated learning (FL), an attractive and promising distributed machine learning paradigm, has sparked extensive interest in exploiting tremendous data stored on ubiquitous mobile devices. However, conventional FL suffers severely from resource heterogeneity, as clients with weak computational and communication capability may be unable to complete local training using the same local training hyper-parameters. In this paper, we propose Dap-FL, a deep deterministic policy gradient (DDPG)-assisted adaptive FL system, in which local learning rates and local training epochs are adaptively adjusted by all resource-heterogeneous clients through locally deployed DDPGassisted adaptive hyper-parameter selection schemes. Particularly, the rationality of the proposed hyper-parameter selection scheme is confirmed through rigorous mathematical proof. Besides, due to the thoughtlessness of security consideration of adaptive FL systems in previous studies, we introduce the Paillier cryptosystem to aggregate local models in a secure and privacypreserving manner. Rigorous analyses show that the proposed Dap-FL system could guarantee the security of clients' private local models against chosen-plaintext attacks and chosen-message attacks in a widely used honest-but-curious participants and active adversaries security model. In addition, through ingenious and extensive experiments, the proposed Dap-FL achieves higher global model prediction accuracy and faster convergence rates than conventional FL, and the comprehensiveness of the adjusted local training hyper-parameters is validated. More importantly, experimental results also show that the proposed Dap-FL achieves higher model prediction accuracy than two state-of-the-art RLassisted FL methods, i.e., 6.03\% higher than DDPG-based FL and 7.85\% higher than DQN-based FL.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security}
}

@article{chen_EVFLexplainablevertical_2022,
  title = {{{EVFL}}: {{An}} Explainable Vertical Federated Learning for Data-Oriented {{Artificial Intelligence}} Systems},
  shorttitle = {{{EVFL}}},
  author = {Chen, Peng and Du, Xin and Lu, Zhihui and Wu, Jie and Hung, Patrick C.K.},
  date = {2022-03},
  journaltitle = {Journal of Systems Architecture},
  shortjournal = {Journal of Systems Architecture},
  pages = {102474},
  issn = {13837621},
  doi = {10.1016/j.sysarc.2022.102474},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1383762122000583},
  urldate = {2022-04-01},
  abstract = {Vertical federated learning (VFL), as one of the latest advances of security in the data-oriented Artificial Intelligence (AI) systems, facilitates better keeping the AI systems converge faster with higher performance and security. Since a large amount of data from these systems is often of low quality, the training data needs to be interpreted and evaluated. While there have been some research efforts, they still have significant shortcomings, such as high computational complexity and impracticality. Considering the characteristics of the data, the interpretation of machine learning models allows for data cleansing, which can improve data quality and help regulators understand the decision-making process. In this paper, we propose an explainable vertical federated learning (EVFL) framework, including the credibility assessment strategy, the federated counterfactual explanation and the importance rate (IR) metric. Furthermore, we initialize the knowledge-based counterfactual instance based on prior knowledge and retrain the federated counterfactual method for feasible counterfactual features. We report experimental results obtained on the Lending Club and Zhongyuan datasets for implementing our framework to show that our approach is significantly effective. Notably, on the Lending Club dataset, our method can have a +4.9\% improvement over other selections.},
  langid = {english}
}

@article{chen_FedDualPairWiseGossip_2023,
  title = {{{FedDual}}: {{Pair-Wise Gossip Helps Federated Learning}} in {{Large Decentralized Networks}}},
  shorttitle = {{{FedDual}}},
  author = {Chen, Qian and Wang, Zilong and Wang, Hongbo and Lin, Xiaodong},
  date = {2023},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  volume = {18},
  pages = {335--350},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2022.3222935},
  abstract = {There is a significant recent interest in collaboratively training a machine learning (ML) model without collecting data to a central server. Federated learning (FL) emerges as an efficient solution mitigating systemic privacy risks and communication costs. However, conventional FL inherited from parameter server designs relies too much on a central server, which may lead to privacy risks, communication bottlenecks, or a single point of failure. In this paper, we propose an asynchronous and hierarchical local gradient aggregation and global model update algorithm, FedDual, under three different security considerations for FL in large decentralized networks. Particularly, FedDual preserves privacy by introducing local differential privacy (LDP) and aggregates local gradients asynchronously and hierarchically via a pair-wise gossip algorithm, which is more competitive than previous gossip-based decentralized FL methods in terms of privacy preservation and communication efficiency, and offers more computational efficiency compared to existing blockchain-assisted decentralized FL methods. Further, we devise a noise cutting trick based on Private Set Intersection (PSI) to mitigate the prediction performance loss of the global model caused by the leveraged LDP. Rigorous analyses show that FedDual helps decentralized FL achieve the same convergence rate of \$\textbackslash mathcal O\textbackslash left(\textbackslash frac 1T\textbackslash right) \$ as centralized ML theoretically. Ingenious experiments on MNIST, CIFAR-10, and FEMNIST confirm that the model prediction performance gained from FedDual is close to centralized ML. More importantly, the proposed noise cutting trick helps FedDual to train better global models than LDP-based FL methods in terms of prediction performance and convergence rate.},
  eventtitle = {{{IEEE Transactions}} on {{Information Forensics}} and {{Security}}},
  keywords = {Computational modeling,Convergence,Data models,decentralized networks,efficiency,Federated learning,Privacy,privacy-preserving,security,Security,Servers,Training}
}

@inproceedings{chen_FedEqualDefendingModel_2021,
  title = {{{FedEqual}}: {{Defending Model Poisoning Attacks}} in {{Heterogeneous Federated Learning}}},
  shorttitle = {{{FedEqual}}},
  booktitle = {2021 {{IEEE Global Communications Conference}} ({{GLOBECOM}})},
  author = {Chen, Ling-Yuan and Chiu, Te-Chuan and Pang, Ai-Chun and Cheng, Li-Chen},
  date = {2021-12},
  pages = {1--6},
  doi = {10.1109/GLOBECOM46510.2021.9685082},
  abstract = {With the upcoming edge AI, federated learning (FL) is a privacy-preserving framework to meet the General Data Protection Regulation (GDPR). Unfortunately, FL is vulnerable to an up-to-date security threat, model poisoning attacks. By successfully replacing the global model with the targeted poisoned model, malicious end devices can trigger backdoor attacks and manipulate the whole learning process. The traditional researches under a homogeneous environment can ideally exclude the outliers with scarce side-effects on model performance. However, in privacy-preserving FL, each end device possibly owns a few data classes and different amounts of data, forming into a substantial heterogeneous environment where outliers could be malicious or benign. To achieve the system performance and robustness of FL's framework, we should not assertively remove any local model from the global model updating procedure. Therefore, in this paper, we propose a defending strategy called FedEqual to mitigate model poisoning attacks while preserving the learning task's performance without excluding any benign models. The results show that FedEqual outperforms other state-of-the-art baselines under different heterogeneous environments based on reproduced up-to-date model poisoning attacks.},
  eventtitle = {2021 {{IEEE Global Communications Conference}} ({{GLOBECOM}})},
  keywords = {Collaborative work,Conferences,Edge AI,Federated Learning,Global communication,Model Poisoning Attacks,Model Security,Performance evaluation,Robustness,Security,System performance,System Robustness}
}

@article{chen_FedHealthFederatedTransfer_2020,
  title = {{{FedHealth}}: {{A Federated Transfer Learning Framework}} for {{Wearable Healthcare}}},
  shorttitle = {{{FedHealth}}},
  author = {Chen, Yiqiang and Qin, Xin and Wang, Jindong and Yu, Chaohui and Gao, Wen},
  date = {2020-07},
  journaltitle = {IEEE Intelligent Systems},
  volume = {35},
  number = {4},
  pages = {83--93},
  issn = {1941-1294},
  doi = {10.1109/MIS.2020.2988604},
  abstract = {With the rapid development of computing technology, wearable devices make it easy to get access to people's health information. Smart healthcare achieves great success by training machine learning models on a large quantity of user personal data. However, there are two critical challenges. First, user data often exist in the form of isolated islands, making it difficult to perform aggregation without compromising privacy security. Second, the models trained on the cloud fail on personalization. In this article, we propose FedHealth, the first federated transfer learning framework for wearable healthcare to tackle these challenges. FedHealth performs data aggregation through federated learning, and then builds relatively personalized models by transfer learning. Wearable activity recognition experiments and real Parkinson's disease auxiliary diagnosis application have evaluated that FedHealth is able to achieve accurate and personalized healthcare without compromising privacy and security. FedHealth is general and extensible in many healthcare applications.},
  eventtitle = {{{IEEE Intelligent Systems}}},
  keywords = {Biomedical monitoring,Collaborative work,Data models,Data privacy,Federated learning,Intelligent systems,Medical services,Servers,Training,Transfer learning,Wearable computing,Wearable healthcare}
}

@article{chen_IntrusionDetectionWireless_2020,
  title = {Intrusion {{Detection}} for {{Wireless Edge Networks Based}} on {{Federated Learning}}},
  author = {Chen, Zhuo and Lv, Na and Liu, Pengfei and Fang, Yu and Chen, Kun and Pan, Wu},
  date = {2020},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {8},
  pages = {217463--217472},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3041793},
  url = {https://ieeexplore.ieee.org/document/9274294/},
  urldate = {2021-10-25},
  abstract = {Edge computing provides off-load computing and application services close to end-users, greatly reducing cloud pressure and communication overhead. However, wireless edge networks still face the risk of network attacks. To ensure the security of wireless edge networks, we present Federated Learning-based Attention Gated Recurrent Unit (FedAGRU), an intrusion detection algorithm for wireless edge networks. FedAGRU differs from current centralized learning methods by updating universal learning models rather than directly sharing raw data among edge devices and a central server. We also apply the attention mechanism to increase the weight of important devices, by avoiding the upload of unimportant updates to the server, FedAGRU can greatly reduce communication overhead while ensuring learning convergence. Our experimental results show that, compared with other centralized learning algorithms, FedAGRU improves detection accuracy by approximately 8\%. In addition, FedAGRU's communication cost is 70\% less than other federated learning algorithms, and it exhibits strong robustness against poisoning attacks.},
  langid = {english},
  keywords = {survey-fids}
}

@article{chen_MachineLearningEnabledIoT_2022,
  title = {Machine {{Learning-Enabled IoT Security}}: {{Open Issues}} and {{Challenges Under Advanced Persistent Threats}}},
  author = {Chen, Zhiyan and Liu, Jinxin and Shen, Yu and Simsek, Murat and Kantarci, Burak and Mouftah, Hussein T and Djukic, Petar},
  date = {2022},
  pages = {35},
  langid = {english},
  keywords = {+survey,â›” No DOI found}
}

@inproceedings{chen_Networkanomalydetection_2020,
  title = {Network Anomaly Detection Using Federated Deep Autoencoding Gaussian Mixture Model},
  booktitle = {Machine Learning for Networking},
  author = {Chen, Yang and Zhang, Junzhe and Yeo, Chai Kiat},
  editor = {Boumerdassi, Selma and Renault, \'Eric and M\"uhlethaler, Paul},
  date = {2020},
  pages = {1--14},
  publisher = {Springer International Publishing},
  location = {Cham},
  abstract = {Deep autoencoding Gaussian mixture model (DAGMM) employs dimensionality reduction and density estimation and jointly optimizes them for unsupervised anomaly detection tasks. However, the absence of large amount of training data greatly compromises DAGMM's performance. Due to rising concerns for privacy, a worse situation can be expected. By aggregating only parameters from local training on clients for obtaining knowledge from more private data, federated learning is proposed to enhance model performance. Meanwhile, privacy is properly protected. Inspired by the aforementioned, this paper presents a federated deep autoencoding Gaussian mixture model (FDAGMM) to improve the disappointing performance of DAGMM caused by limited data amount. The superiority of our proposed FDAGMM is empirically demonstrated with extensive experiments.},
  isbn = {978-3-030-45778-5},
  keywords = {survey-fids}
}

@inproceedings{chen_NetworkAnomalyDetection_2020a,
  title = {Network {{Anomaly Detection Using Federated Deep Autoencoding Gaussian Mixture Model}}},
  booktitle = {Machine {{Learning}} for {{Networking}}},
  author = {Chen, Yang and Zhang, Junzhe and Yeo, Chai Kiat},
  editor = {Boumerdassi, Selma and Renault, \'Eric and M\"uhlethaler, Paul},
  date = {2020},
  pages = {1--14},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-45778-5_1},
  abstract = {Deep autoencoding Gaussian mixture model (DAGMM) employs dimensionality reduction and density estimation and jointly optimizes them for unsupervised anomaly detection tasks. However, the absence of large amount of training data greatly compromises DAGMM's performance. Due to rising concerns for privacy, a worse situation can be expected. By aggregating only parameters from local training on clients for obtaining knowledge from more private data, federated learning is proposed to enhance model performance. Meanwhile, privacy is properly protected. Inspired by the aforementioned, this paper presents a federated deep autoencoding Gaussian mixture model (FDAGMM) to improve the disappointing performance of DAGMM caused by limited data amount. The superiority of our proposed FDAGMM is empirically demonstrated with extensive experiments.},
  isbn = {978-3-030-45778-5},
  langid = {english},
  keywords = {survey-fids}
}

@article{chen_Nontrustdetection_2023,
  title = {Non Trust Detection of Decentralized Federated Learning Based on Historical Gradient},
  author = {Chen, Yikuan and Liang, Li and Gao, Wei},
  date = {2023-04-01},
  journaltitle = {Engineering Applications of Artificial Intelligence},
  shortjournal = {Engineering Applications of Artificial Intelligence},
  volume = {120},
  pages = {105888},
  issn = {0952-1976},
  doi = {10.1016/j.engappai.2023.105888},
  url = {https://www.sciencedirect.com/science/article/pii/S0952197623000726},
  urldate = {2024-04-12},
  abstract = {As a paradigm of distributed machine learning, federated learning is widely used in various real scenarios due to its excellent privacy protection performance on preventing local data from being disclosed. However, the traditional federated learning has the defect that a third-party server aggregates the models of various users since it's difficult to guarantee the reliability of the third party, and multicentre phenomena frequently appeared in various applications, such as social networks, banking and finance, medical health, etc. Users can't be reassured in decentralization setting due to the mixture of malicious and untrustworthy ones among them. Although untrustworthy users are benign, they may be classified as the saboteurs because of poor efficiency performance in decentralized federated learning which is caused by missing or ambiguity of data. In this paper, we propose Decentralized Federated Learning Historical Gradient (DFedHG) approach to distinguish normal users, untrustworthy users and malicious users in the decentralized federated learning setting. Simultaneously, by means of DFedHG, malicious users are sub-divided into targetless attacks and targeted attacks, which is verified by adopting two types of data sets for confirmation. The experimental results show that the proposed approach achieves better performance compared with the conventional decentralized federated learning without untrustworthy users, and further present excellent differentiation of malicious users.},
  keywords = {Decentralized federated learning,Historical gradient,Malicious detection}
}

@article{chen_Privacypreservingknowledgetransfer_2022,
  title = {Privacy-Preserving Knowledge Transfer for Intrusion Detection with Federated Deep Autoencoding Gaussian Mixture Model},
  author = {Chen, Yang and Zhang, Junzhe and Yeo, Chai Kiat},
  date = {2022-09-01},
  journaltitle = {Information Sciences},
  shortjournal = {Information Sciences},
  volume = {609},
  pages = {1204--1220},
  issn = {0020-0255},
  doi = {10.1016/j.ins.2022.07.104},
  url = {https://www.sciencedirect.com/science/article/pii/S0020025522007939},
  urldate = {2022-08-11},
  abstract = {Knowledge transfer is critical in making use of data from multi-source domains, but most existing techniques are not privacy-preserving. Nowadays, data leakage, together with the advancement of big-data-driven Artificial Intelligence, has raised huge concerns over data security. The neglect of privacy makes such approaches impractical. For addressing intrusion detection tasks, the Deep Autoencoding Gaussian Mixture Model (DAGMM) concatenates and jointly optimizes a compression and an estimation network in an unsupervised manner. However, DAGMM still suffers from the lack of diversely distributed intrusion samples in real-life scenarios where organizations are neither willing nor legally allowed to engage in data sharing. Given the increasing public concern over data privacy and scandals, federated learning which only allows model parameter sharing is thus proposed to enhance model performance while preserving data privacy. Moreover, it also addresses the competitive concerns on the part of organizations when sharing data with their rivals. This study proposes a Federated Deep Autoencoding Gaussian Mixture Model (F-DAGMM) to build up privacy-preserving knowledge transfer, to further support inter-organizational cooperation and high-level decision making. A two-phase federated optimization strategy is proposed to address the performance degradation caused by the significant differences in the individual clients' data distributions. Extensive experiments demonstrate the superiority of the proposed F-DAGMM.},
  langid = {english},
  keywords = {Anomaly detection,Deep autoencoding gaussian mixture model,Federated learning,Intrusion detection,Knowledge transfer,Privacy preserving}
}

@article{chen_trainingintegrityprivacypreservingfederated_2020,
  title = {A Training-Integrity Privacy-Preserving Federated Learning Scheme with Trusted Execution Environment},
  author = {Chen, Yu and Luo, Fang and Li, Tong and Xiang, Tao and Liu, Zheli and Li, Jin},
  date = {2020-06},
  journaltitle = {Information Sciences},
  shortjournal = {Information Sciences},
  volume = {522},
  pages = {69--79},
  issn = {00200255},
  doi = {10.1016/j.ins.2020.02.037},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0020025520301201},
  urldate = {2023-04-03},
  langid = {english}
}

@article{chen_TRMIoTtrustmanagement_2011,
  title = {{{TRM-IoT}}: {{A}} Trust Management Model Based on Fuzzy Reputation for Internet of Things},
  shorttitle = {{{TRM-IoT}}},
  author = {Chen, Dong and Chang, Guiran and Sun, Dawei and Li, Jiajia and Jia, Jie and Wang, Xingwei},
  date = {2011},
  journaltitle = {Computer Science and Information Systems},
  shortjournal = {ComSIS},
  volume = {8},
  number = {4},
  pages = {1207--1228},
  issn = {1820-0214, 2406-1018},
  doi = {10.2298/CSIS110303056C},
  url = {https://doiserbia.nb.rs/Article.aspx?ID=1820-02141100056C},
  urldate = {2024-07-03},
  abstract = {Since a large scale Wireless Sensor Network (WSN) is to be completely integrated into Internet as a core part of Internet of Things (IoT) or Cyber Physical System (CPS), it is necessary to consider various security challenges that come with IoT/CPS, such as the detection of malicious attacks. Sensors or sensor embedded things may establish direct communication between each other using 6LoWPAN protocol. A trust and reputation model is recognized as an important approach to defend a large distributed sensor networks in IoT/CPS against malicious node attacks, since trust establishment mechanisms can stimulate collaboration among distributed computing and communication entities, facilitate the detection of untrustworthy entities, and assist decision-making process of various protocols. In this paper, based on in-depth understanding of trust establishment process and quantitative comparison among trust establishment methods, we present a trust and reputation model TRM-IoT to enforce the cooperation between things in a network of IoT/CPS based on their behaviors. The accuracy, robustness and lightness of the proposed model is validated through a wide set of simulations.},
  langid = {english}
}

@article{chen_ZeroKnowledgeClustering_2021,
  title = {Zero {{Knowledge Clustering Based Adversarial Mitigation}} in {{Heterogeneous Federated Learning}}},
  author = {Chen, Zheyi and Tian, Pu and Liao, Weixian and Yu, Wei},
  date = {2021-04},
  journaltitle = {IEEE Transactions on Network Science and Engineering},
  volume = {8},
  number = {2},
  pages = {1070--1083},
  issn = {2327-4697},
  doi = {10.1109/TNSE.2020.3002796},
  abstract = {The simultaneous development of deep learning techniques and Internet of Things (IoT)/Cyber-physical Systems (CPS) technologies has afforded untold possibilities for improving distributed computing, sensing, and data analysis. Among these technologies, federated learning has received increased attention as a privacy-preserving collaborative learning paradigm, and has shown significant potential in IoT/CPS-driven large-scale smart-world systems. At the same time, the vulnerabilities of deep neural networks, especially to adversarial attacks, cannot be overstated and should not be minimized. Moreover, the distributed nature of federated learning makes defense against such adversarial attacks a more challenging problem due to the unavailability of local data and resource heterogeneity. To tackle these challenges, in this paper, we propose ZeKoC, a Zero Knowledge Clustering approach to mitigating adversarial attacks. Particularly, we first formulate the problem of resource-constrained adversarial mitigation. Specifically, noting that a global server has no access to training samples, we reformulate the unsupervised weight clustering problem. Our proposed ZeKoC approach allows the server to automatically split and merge weight clusters for weight selection and aggregation. Theoretical analysis demonstrates that convergence is guaranteed. Further, our experimental results illustrate that, in a non-i.i.d. (i.e., independent and identically distributed) data setting, the proposed ZeKoC approach successfully mitigates general attacks while outperforming state-of-art schemes.},
  eventtitle = {{{IEEE Transactions}} on {{Network Science}} and {{Engineering}}},
  keywords = {adversarial mitigation,Data models,Distributed databases,federated learning,Machine learning,Non-i.i.d. data,Peer-to-peer computing,Security,Servers,Training}
}

@article{chen_ZeroKnowledgeClustering_2021a,
  title = {Zero {{Knowledge Clustering Based Adversarial Mitigation}} in {{Heterogeneous Federated Learning}}},
  author = {Chen, Zheyi and Tian, Pu and Liao, Weixian and Yu, Wei},
  date = {2021-04},
  journaltitle = {IEEE Transactions on Network Science and Engineering},
  volume = {8},
  number = {2},
  pages = {1070--1083},
  issn = {2327-4697},
  doi = {10.1109/TNSE.2020.3002796},
  abstract = {The simultaneous development of deep learning techniques and Internet of Things (IoT)/Cyber-physical Systems (CPS) technologies has afforded untold possibilities for improving distributed computing, sensing, and data analysis. Among these technologies, federated learning has received increased attention as a privacy-preserving collaborative learning paradigm, and has shown significant potential in IoT/CPS-driven large-scale smart-world systems. At the same time, the vulnerabilities of deep neural networks, especially to adversarial attacks, cannot be overstated and should not be minimized. Moreover, the distributed nature of federated learning makes defense against such adversarial attacks a more challenging problem due to the unavailability of local data and resource heterogeneity. To tackle these challenges, in this paper, we propose ZeKoC, a Zero Knowledge Clustering approach to mitigating adversarial attacks. Particularly, we first formulate the problem of resource-constrained adversarial mitigation. Specifically, noting that a global server has no access to training samples, we reformulate the unsupervised weight clustering problem. Our proposed ZeKoC approach allows the server to automatically split and merge weight clusters for weight selection and aggregation. Theoretical analysis demonstrates that convergence is guaranteed. Further, our experimental results illustrate that, in a non-i.i.d. (i.e., independent and identically distributed) data setting, the proposed ZeKoC approach successfully mitigates general attacks while outperforming state-of-art schemes.},
  eventtitle = {{{IEEE Transactions}} on {{Network Science}} and {{Engineering}}},
  keywords = {adversarial mitigation,Data models,Distributed databases,federated learning,Machine learning,Non-i.i.d. data,Peer-to-peer computing,Security,Servers,Training}
}

@article{cheng_FederatedTransferLearning_2022,
  title = {Federated {{Transfer Learning With Client Selection}} for {{Intrusion Detection}} in {{Mobile Edge Computing}}},
  author = {Cheng, Yanyu and Lu, Jianyuan and Niyato, Dusit and Lyu, Biao and Kang, Jiawen and Zhu, Shunmin},
  date = {2022-03},
  journaltitle = {IEEE Communications Letters},
  volume = {26},
  number = {3},
  pages = {552--556},
  issn = {1558-2558},
  doi = {10.1109/LCOMM.2022.3140273},
  url = {https://ieeexplore.ieee.org/abstract/document/9668958},
  urldate = {2024-04-12},
  abstract = {In this letter, we propose an efficient federated transfer learning (FTL) framework with client selection for intrusion detection (ID) in mobile edge computing (MEC). Specifically, we leverage federated learning (FL) to preserve privacy by training model locally, and utilize transfer learning (TL) to improve training efficiency by knowledge transfer. For FL, unreliable and low-quality clients should not be selected to participate in the training. Therefore, we integrate FTL with a reinforcement learning (RL)-based client selection scheme to achieve the highest ID accuracy within a budget limit on the number of participating clients. Experimental results show that the FTL significantly improves ID accuracy and communication efficiency as compared with the FL. Furthermore, the FTL framework with RL-based client selection can achieve the highest accuracy within budget, which improves performance while saving cost.},
  eventtitle = {{{IEEE Communications Letters}}},
  keywords = {\_read\_urgently,Client selection,Computational modeling,Data models,federated transfer learning,intrusion detection,mobile edge computing,Multi-access edge computing,reinforcement learning,Servers,Training,Training data,Transfer learning}
}

@article{chhikara_Adaptivefederatedlearning_2023,
  title = {Adaptive Federated Learning Scheme for Recognition of Malicious Attacks in an {{IoT}} Network},
  author = {Chhikara, Prateek and Tekchandani, Rajkumar and Kumar, Neeraj},
  date = {2023-01-07},
  journaltitle = {Computing},
  shortjournal = {Computing},
  issn = {1436-5057},
  doi = {10.1007/s00607-022-01146-6},
  url = {https://doi.org/10.1007/s00607-022-01146-6},
  urldate = {2023-01-12},
  abstract = {The Internet of Things (IoT) is crucial for deploying a novel Artificial Intelligence (AI) model for both network and application management. However, using classical centralized learning algorithms in the IoT environment is challenging, given massively distributed private datasets. Advancements in AI have helped us solve various use cases, but it operates under two significant challenges. Firstly, the data exists in separate clusters, and secondly, the current AI has limited data privacy and security. Federated learning (FL) aims to preserve data privacy through distributed learning methods that keep the data in storage silos. Likewise, differential privacy improves data privacy by measuring the privacy loss in communication among the elements of FL. The paper proposes two adaptive approaches for making model training differentially private in a vertical federated environment. The first one uses random feature selection to train different machine learning models, and performance improvement is also proposed. The second approach uses a tree structure, i.e., Classification and Regression Trees, using some defined constraints. Further, we created a scheme to help identify malicious users/devices in a federated network cluster using parity checks for every FL iteration.},
  langid = {english},
  keywords = {68,Differential privacy,Federated learning,Internet of Things,Machine learning}
}

@article{chicco_advantagesMatthewscorrelation_2020,
  title = {The Advantages of the {{Matthews}} Correlation Coefficient ({{MCC}}) over {{F1}} Score and Accuracy in Binary Classification Evaluation},
  author = {Chicco, Davide and Jurman, Giuseppe},
  date = {2020-12},
  journaltitle = {BMC Genomics},
  shortjournal = {BMC Genomics},
  volume = {21},
  number = {1},
  pages = {6},
  issn = {1471-2164},
  doi = {10.1186/s12864-019-6413-7},
  url = {https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6413-7},
  urldate = {2022-03-11},
  abstract = {Background: To evaluate binary classifications and their confusion matrices, scientific researchers can employ several statistical rates, accordingly to the goal of the experiment they are investigating. Despite being a crucial issue in machine learning, no widespread consensus has been reached on a unified elective chosen measure yet. Accuracy and F1 score computed on confusion matrices have been (and still are) among the most popular adopted metrics in binary classification tasks. However, these statistical measures can dangerously show overoptimistic inflated results, especially on imbalanced datasets. Results: The Matthews correlation coefficient (MCC), instead, is a more reliable statistical rate which produces a high score only if the prediction obtained good results in all of the four confusion matrix categories (true positives, false negatives, true negatives, and false positives), proportionally both to the size of positive elements and the size of negative elements in the dataset. Conclusions: In this article, we show how MCC produces a more informative and truthful score in evaluating binary classifications than accuracy and F1 score, by first explaining the mathematical properties, and then the asset of MCC in six synthetic use cases and in a real genomics scenario. We believe that the Matthews correlation coefficient should be preferred to accuracy and F1 score in evaluating binary classification tasks by all scientific communities.},
  langid = {english}
}

@inproceedings{chilukuri_AchievingOptimalCache_2020,
  title = {Achieving {{Optimal Cache Utility}} in {{Constrained Wireless Networks}} through {{Federated Learning}}},
  booktitle = {2020 {{IEEE}} 21st {{International Symposium}} on "{{A World}} of {{Wireless}}, {{Mobile}} and {{Multimedia Networks}}" ({{WoWMoM}})},
  author = {Chilukuri, Shanti and Pesch, Dirk},
  date = {2020-08},
  pages = {254--263},
  doi = {10.1109/WoWMoM49955.2020.00053},
  abstract = {Edge computing allows constrained end devices in wireless networks to offioad heavy computing tasks or data storage when local resources are insufficient. Edge nodes can provide resources such as the bandwidth, storage and innetwork compute power. For example, edge nodes can provide data caches to which constrained end devices can off-load their data and from where user can access data more effectively. However, fair allocation of these resources to competing end devices and data classes while providing good Quality of Service is a challenging task, due to frequently changing network topology and/or traffic conditions. In this paper, we present Federated learning-based dynamic Cache allocation (FedCache) for edge caches in dynamic, constrained networks. FedCache uses federated learning to learn the benefit of a particular cache allocation with low communication overhead. Edge nodes learn locally to adapt to different network conditions and collaboratively share this knowledge so as to avoid having to transmit all data to a single location. Through this federated learning approach, nodes can find resource allocations that result in maximum fairness or efficiency in terms of the cache hit ratio for a given network state. Simulation results show that cache resource allocation using FedCache results in optimal fairness or efficiency of utility for different classes of data when compared to proportional allocation, while incurring low communication overhead.},
  eventtitle = {2020 {{IEEE}} 21st {{International Symposium}} on "{{A World}} of {{Wireless}}, {{Mobile}} and {{Multimedia Networks}}" ({{WoWMoM}})},
  keywords = {Bandwidth,Data models,Dynamic scheduling,edge computing,fairness,federated learning,Quality of experience,Quality of service,resource allocation,Resource management,Silicon}
}

@article{chismon_ThreatIntelligenceCollecting_2015,
  title = {Threat {{Intelligence}}: {{Collecting}}, {{Analysing}}, {{Evaluating}}},
  author = {Chismon, David and Ruks, Martyn},
  date = {2015},
  journaltitle = {Cert-Uk},
  pages = {36},
  abstract = {Threat intelligence is rapidly becoming an ever-higher business priority. There is a general awareness of the need to `do' threat intelligence, and vendors are falling over themselves to offer a confusingly diverse array of threat intelligence products. Figure},
  keywords = {â›” No DOI found}
}

@article{Chismon2015,
  title = {Threat {{Intelligence}}: {{Collecting}}, {{Analysing}}, {{Evaluating}}},
  author = {Chismon, David and Ruks, Martyn},
  date = {2015},
  journaltitle = {Cert-Uk},
  pages = {36},
  abstract = {Threat intelligence is rapidly becoming an ever-higher business priority. There is a general awareness of the need to `do' threat intelligence, and vendors are falling over themselves to offer a confusingly diverse array of threat intelligence products. Figure},
  keywords = {â›” No DOI found}
}

@article{cho_CommunicationEfficientModelHeterogeneousPersonalized_2023,
  title = {Communication-{{Efficient}} and {{Model-Heterogeneous Personalized Federated Learning}} via {{Clustered Knowledge Transfer}}},
  author = {Cho, Yae Jee and Wang, Jianyu and Chirvolu, Tarun and Joshi, Gauri},
  date = {2023},
  journaltitle = {IEEE Journal of Selected Topics in Signal Processing},
  pages = {1--14},
  issn = {1941-0484},
  doi = {10.1109/JSTSP.2022.3231527},
  abstract = {Personalized federated learning (PFL) aims to train model(s) that can perform well on the individual edge-devices' data where the edge-devices (clients) are usually IoT devices like our mobile phones. The participating clients for cross-device settings, in general, have heterogeneous system capabilities and limited communication bandwidth. Such practical properties of the edge-devices, however, are overlooked by many recent work in PFL, which use the same model architecture across all clients and incur high communication cost by directly communicating the model parameters. In our work, we propose a novel and practical PFL framework named COMET where clients can use heterogeneous models of their own choice and do not directly communicate their model parameters to other parties. Instead, COMET uses clustered codistillation, where clients use knowledge distillation to transfer their knowledge to other clients with similar data distributions. This presents a practical PFL framework for the edge-devices to train through IoT networks by lifting the heavy communication burden of communicating large models. We theoretically show the convergence and generalization properties of COMET and empirically show that COMET achieves high test accuracy with several orders of magnitude lower communication cost while allowing client model heterogeneity compared to the other state-of-the-art PFL methods.},
  eventtitle = {{{IEEE Journal}} of {{Selected Topics}} in {{Signal Processing}}},
  keywords = {clustering,Clustering,Comets,communication efficiency,Communication Efficiency,Correlation,Costs,Data models,Federated learning,Federated Learning,knowledge transfer,Knowledge Transfer,model heterogeneity,Model Heterogeneity,Servers,Task analysis,Training}
}

@article{cholakoska_FederatedLearningNetwork_2023,
  title = {Federated {{Learning}} for {{Network Intrusion Detection}} in {{Ambient Assisted Living Environments}}},
  author = {Cholakoska, Ana and Gjoreski, Hristijan and Rakovic, Valentin and Denkovski, Daniel and Kalendar, Marija and Pfitzner, Bjarne and Arnrich, Bert},
  date = {2023-07-01},
  journaltitle = {IEEE Internet Computing},
  shortjournal = {IEEE Internet Computing},
  volume = {PP},
  pages = {1--9},
  doi = {10.1109/MIC.2023.3264700},
  abstract = {Given the Internet of Things rapid expansion and widespread adoption, it is of great concern to establish secure interaction between devices without worsening the quality of their performance. Using machine learning techniques has been shown to improve detecting anomalous behavior in these types of networks, but their implementation leads to poor performance and compromised privacy. To better address these shortcomings, federated learning is being introduced. It enables devices to collaboratively train and evaluate a shared model while keeping personal data on-site (e.g., smart homes, intensive care units, hospitals, etc.), thus minimizing the possibility of an attack and fostering real-time distribution of models and learning. The paper investigates the performance of federated learning in comparison to deep learning, with respect to network intrusion detection in ambient assisted living environments. The results demonstrate comparable performances of federated learning with deep learning, while achieving improved data privacy and security.}
}

@incollection{choras_NetworkEventCorrelation_2011,
  title = {Network {{Event Correlation}} and {{Semantic Reasoning}} for {{Federated Networks Protection System}}},
  booktitle = {Computer {{Information Systems}} -- {{Analysis}} and {{Technologies}}},
  author = {Chora\'s, Micha\l{} and Kozik, Rafa\l},
  editor = {Chaki, Nabendu and Cortesi, Agostino},
  date = {2011},
  volume = {245},
  pages = {48--54},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-27245-5_8},
  url = {http://link.springer.com/10.1007/978-3-642-27245-5_8},
  urldate = {2021-10-12},
  abstract = {In this paper we present semantic approach to network event correlation for large-scale federated intrusion detection system. The major contributions of this paper are: network event correlation mechanism and semantic reasoning based on the ontology. Our propositions and deployments are used in Federated Networks Protection System as a part of the Decision Module.},
  isbn = {978-3-642-27244-8 978-3-642-27245-5},
  langid = {english}
}

@article{chu_SecuringFederatedSensitive_,
  title = {Securing {{Federated Sensitive Topic Classification}} against {{Poisoning Attacks}}},
  author = {Chu, Tianyue and Garcia-Recuero, Alvaro and Iordanou, Costas and Smaragdakis, Georgios and family=Delft, given=TU, given-i=TU and Laoutaris, Nikolaos},
  abstract = {We present a Federated Learning (FL) based solution for building a distributed classifier capable of detecting URLs containing sensitive content, i.e., content related to categories such as health, political beliefs, sexual orientation, etc. Although such a classifier addresses the limitations of previous offline/centralised classifiers, it is still vulnerable to poisoning attacks from malicious users that may attempt to reduce the accuracy for benign users by disseminating faulty model updates. To guard against this, we develop a robust aggregation scheme based on subjective logic and residual-based attack detection. Employing a combination of theoretical analysis, trace-driven simulation, as well as experimental validation with a prototype and real users, we show that our classifier can detect sensitive content with high accuracy, learn new labels fast, and remain robust in view of poisoning attacks from malicious users, as well as imperfect input from non-malicious ones.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@online{chu_SecuringFederatedSensitive_2022,
  title = {Securing {{Federated Sensitive Topic Classification}} against {{Poisoning Attacks}}},
  author = {Chu, Tianyue and Garcia-Recuero, Alvaro and Iordanou, Costas and Smaragdakis, Georgios and Laoutaris, Nikolaos},
  date = {2022-01-31},
  eprint = {2201.13086},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2201.13086},
  url = {http://arxiv.org/abs/2201.13086},
  urldate = {2022-10-20},
  abstract = {We present a Federated Learning (FL) based solution for building a distributed classifier capable of detecting URLs containing GDPR-sensitive content related to categories such as health, sexual preference, political beliefs, etc. Although such a classifier addresses the limitations of previous offline/centralised classifiers,it is still vulnerable to poisoning attacks from malicious users that may attempt to reduce the accuracy for benign users by disseminating faulty model updates. To guard against this, we develop a robust aggregation scheme based on subjective logic and residual-based attack detection. Employing a combination of theoretical analysis, trace-driven simulation, as well as experimental validation with a prototype and real users, we show that our classifier can detect sensitive content with high accuracy, learn new labels fast, and remain robust in view of poisoning attacks from malicious users, as well as imperfect input from non-malicious ones.},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},68M25,Computer Science - Cryptography and Security,I.2.11,K.4.1}
}

@incollection{clark_hardwareplatformnetwork_2005,
  title = {A Hardware Platform for Network Intrusion Detection and Prevention},
  booktitle = {Network {{Processor Design}}},
  author = {Clark, Chris and Lee, Wenke and Schimmel, David and Contis, Didier and Kon\'e, Mohamed and Thomas, Ashley},
  date = {2005},
  pages = {99--118},
  publisher = {Elsevier},
  doi = {10.1016/B978-012088476-6/50007-1},
  url = {https://linkinghub.elsevier.com/retrieve/pii/B9780120884766500071},
  urldate = {2022-01-12},
  abstract = {The current generation of centralized network intrusion detection systems (NIDS) have various limitations on their performance and effectiveness. In this paper, we argue that intrusion detection analysis should be distributed to network node IDS (NNIDS) running in hardware on the end hosts. An NNIDS can unambiguously inspect traffic to and from the host, and when implemented on the network interface hardware, can function independently of the host operating system to provide better protection with less overhead than software implementations. We discuss the computation and communication characteristics of typical software intrusion detection analysis tasks. Then, we describe our efforts in mapping these tasks to a hardware platform using COTS components including Intel IXP network processors and Xilinx Virtex FPGAs. We report the performance of our prototype NNIDS implementation and provide analysis on how the network processor architecture affects the performance. Our results show that the NNIDS can achieve high performance with a pipeline of processing stages and careful allocation of tasks to the most appropriate hardware resources.},
  isbn = {978-0-12-088476-6},
  langid = {english},
  keywords = {\_read\_urgently}
}

@article{cordero_SphinxColluderResistantTrust_2018,
  title = {Sphinx: A {{Colluder-Resistant Trust Mechanism}} for {{Collaborative Intrusion Detection}}},
  shorttitle = {Sphinx},
  author = {Cordero, Carlos Garcia and Traverso, Giulia and Nojoumian, Mehrdad and Habib, Sheikh Mahbub and M\"uhlh\"auser, Max and Buchmann, Johannes and Vasilomanolakis, Emmanouil},
  date = {2018},
  journaltitle = {IEEE Access},
  volume = {6},
  pages = {72427--72438},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2018.2880297},
  abstract = {The destructive effects of cyber-attacks demand more proactive security approaches. One such promising approach is the idea of collaborative intrusion detection systems (CIDSs). These systems combine the knowledge of multiple sensors (e.g., intrusion detection systems, honeypots, or firewalls) to create a holistic picture of a monitored network. Sensors monitor parts of a network and exchange alert data to learn from each other, improve their detection capabilities and ultimately identify sophisticated attacks. Nevertheless, if one or a group of sensors is unreliable (due to incompetence or malice), the system might miss important information needed to detect attacks. In this paper, we propose Sphinx, an evidence-based trust mechanism capable of detecting unreliable sensors within a CIDS. The Sphinx detects, both, single sensors or coalitions of dishonest sensors that lie about the reliability of others to boost or worsen their trust score. Our evaluation shows that, given an honest majority of sensors, dishonesty is punished in a timely manner. Moreover, if several coalitions exist, even when more than 50\% of all sensors are dishonest, dishonesty is punished.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Clustering,Collaboration,collaborative intrusion detection,Electronic mail,Intrusion detection,machine learning,Machine learning,mixture models,Monitoring,Reliability,sensor reliability,Sensors,trust management}
}

@online{CORE,
  title = {Conference Portal - {{CORE}}},
  url = {http://portal.core.edu.au/conf-ranks/},
  keywords = {pinned}
}

@article{cormode_HowNOTreview_2009,
  title = {How {{NOT}} to Review a Paper: The Tools and Techniques of the Adversarial Reviewer},
  shorttitle = {How {{NOT}} to Review a Paper},
  author = {Cormode, Graham},
  date = {2009-03-20},
  journaltitle = {ACM SIGMOD Record},
  shortjournal = {SIGMOD Rec.},
  volume = {37},
  number = {4},
  pages = {100--104},
  issn = {0163-5808},
  doi = {10.1145/1519103.1519122},
  url = {https://dl.acm.org/doi/10.1145/1519103.1519122},
  urldate = {2024-02-06},
  abstract = {There are several useful guides available for how to review a paper in Computer Science [10, 6, 12, 7, 2]. These are soberly presented, carefully reasoned and sensibly argued. As a result, they are not much fun. So, as a contrast, this note is a checklist of how not to review a paper. It details techniques that are unethical, unfair, or just plain nasty. Since in Computer Science we often present arguments about how an adversary would approach a particular problem, this note describes the adversary's strategy.},
  langid = {english}
}

@article{coss_CIAStrikesBack_2014,
  title = {The {{CIA Strikes Back}}: {{Redefining Confidentiality}}, {{Integrity}} and {{Availability}} in {{Security}}.},
  author = {Coss, David and Samonas, Spyridon},
  date = {2014},
  journaltitle = {Journal of Information System Security},
  volume = {10},
  number = {3},
  pages = {21--45},
  url = {www.jissec.org},
  abstract = {This paper reviews the history of the CIA (Confidentiality, Integrity and Availability) triad from the perspectives of information security practitioners and scholars. Whilst the former have trusted the technical orientation of the triad as a unique point of reference in information security, the latter have questioned the triad's capacity of addressing the breadth of socio-technical issues that have emerged in security since the 2000s. Through a revisiting of the key tenets of the triad, the paper reconciles these two, seemingly fragmented, approaches. The main argument is that the CIA triad will continue to assume a major role in information security practice. However, this is not due to the fact that practitioners have discarded, or rejected the enhancements that socio-technical security scholars have proposed over the years; rather, it is because these enhancements can be accommodated by a broader re-conceptualization of the original CIA triad. The paper concludes with potential areas for future research.},
  keywords = {â›” No DOI found}
}

@article{costa_TurningFederatedLearning_2022,
  title = {Turning {{Federated Learning Systems Into Covert Channels}}},
  author = {Costa, Gabriele and Pinelli, Fabio and Soderi, Simone and Tolomei, Gabriele},
  date = {2022},
  journaltitle = {IEEE Access},
  volume = {10},
  pages = {130642--130656},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3229124},
  abstract = {Federated learning (FL) goes beyond traditional, centralized machine learning by distributing model training among a large collection of edge clients. These clients cooperatively train a global, e.g., cloud-hosted, model without disclosing their local, private training data. The global model is then shared among all the participants which use it for local predictions. This paper proves that FL systems can be turned into covert channels to implement a stealth communication infrastructure. The main intuition is that, during federated training, a malicious sender can poison the global model by submitting purposely crafted examples. Although the effect of the model poisoning is negligible to other participants and does not alter the overall model performance, it can be observed by a malicious receiver and used to transmit a sequence of bits. We mounted our attack on an FL system to verify its feasibility. Experimental evidence shows that this covert channel is reliable, efficient, and extremely hard to counter. These results highlight that our new attacker model threatens FL infrastructures.},
  eventtitle = {{{IEEE Access}}},
  keywords = {adversarial attacks,covert channel,Data models,Federated learning,machine learning security,Predictive models,Security,Servers,Task analysis,Training}
}

@online{CSE-CIC-IDS-2018_url,
  title = {{{IDS}} 2018},
  url = {https://registry.opendata.aws/cse-cic-ids2018/},
  urldate = {2023-03-22},
  abstract = {A collaboration between CSE and CIC. The dataset includes 7 attack scenarios: Brute-force, Heartbleed, Botnet, DoS, DDoS, Web attacks and inside infiltration.},
  langid = {english}
}

@article{cui_CollaborativeIntrusionDetection_2023,
  title = {Collaborative {{Intrusion Detection System}} for {{SDVN}}: {{A Fairness Federated Deep Learning Approach}}},
  shorttitle = {Collaborative {{Intrusion Detection System}} for {{SDVN}}},
  author = {Cui, Jie and Sun, Hu and Zhong, Hong and Zhang, Jing and Wei, Lu and Bolodurina, Irina and He, Debiao},
  date = {2023-09},
  journaltitle = {IEEE Transactions on Parallel and Distributed Systems},
  volume = {34},
  number = {9},
  pages = {2512--2528},
  issn = {1558-2183},
  doi = {10.1109/TPDS.2023.3290650},
  url = {https://ieeexplore.ieee.org/abstract/document/10177377},
  urldate = {2024-04-12},
  abstract = {With the continuous innovations and development in communication technology and intelligent transportation systems, a new generation of vehicular ad hoc networks (VANETs) has become increasingly popular, making VANET communication security increasingly important. An intrusion detection system (IDS) is an important tool for detecting network attacks and is an effective means of improving network security. However, existing IDSs encounter several problems involving inaccurate detections, low detection efficiencies, and incomplete detections owing to extensive changes in vehicle locations in VANETs. This study explores federated learning in software-defined VANETs and designs an efficient and accurate collaborative intrusion detection system (CIDS) model. The model utilizes the collaboration among local software-defined networks (SDNs) to jointly train the CIDS model without directly exchanging local network data flows to improve the expansibility and globality of IDSs. To reduce the model difference between different SDN clients and improve the detection accuracy, this study regards the prediction loss for each SDN client as an objective from the perspective of constrained multi-objective optimization. By optimizing a surrogate maximum function containing all the objectives, the method adopts two-stage gradient optimization to achieve Pareto optimality for SDN clients with the worst fairness constraint maximization performance. In addition, this study evaluates the training model using two open-source datasets and compares it with the latest methods. Experimental results reveal that the proposed model ensures local data privacy and demonstrates high accuracy and efficiency in detecting attacks and is thus superior to the current schemes.},
  eventtitle = {{{IEEE Transactions}} on {{Parallel}} and {{Distributed Systems}}},
  keywords = {Collaboration,collaborative intrusion detection system,Computational modeling,convolutional neural network,Data models,Federated deep learning,gradient optimization,intelligent transportation system,Intrusion detection,Security,Training,Vehicular ad hoc networks}
}

@article{cui_WASSERSTEINGANBASED_,
  title = {A {{WASSERSTEIN GAN BASED FRAMEWORK FOR ADVERSARIAL ATTACKS AGAINST INTRUSION DETECTION SYSTEMS}}},
  author = {Cui, Fangda},
  langid = {english},
  keywords = {â›” No DOI found}
}

@article{cunhaneto_FedSBSFederatedLearningparticipantselection_2024,
  title = {{{FedSBS}}: {{Federated-Learning}} Participant-Selection Method for {{Intrusion Detection Systems}}},
  shorttitle = {{{FedSBS}}},
  author = {Cunha Neto, Helio N. and Hribar, Jernej and Dusparic, Ivana and Fernandes, Natalia C. and Mattos, Diogo M. F.},
  date = {2024-05-01},
  journaltitle = {Computer Networks},
  shortjournal = {Computer Networks},
  volume = {244},
  pages = {110351},
  issn = {1389-1286},
  doi = {10.1016/j.comnet.2024.110351},
  url = {https://www.sciencedirect.com/science/article/pii/S138912862400183X},
  urldate = {2024-04-12},
  abstract = {Federated Learning (FL) is a decentralized machine learning approach in which multiple participants collaboratively train a model. Participants keep data locally, train their local models, and aggregate them in a single global model in a federated server. Collaborative FL-based Intrusion Detection Systems face challenges on an uneven statistical distribution of data and malicious participants trying to subvert the learning process. The statistical hurdles associated with imbalanced data and malicious participants pose a risk of skewing the training with biased or random data. The inability to effectively manage these statistical inconsistencies may degrade system performance, leading to false intrusion detection or opening avenues for cybersecurity breaches. To overcome these challenges, we propose a training method that employs score-based participant selection and utilizes global momentum for model aggregation. Our method improves the global model performance while mitigating the risks posed by malicious participants. The proposal incorporates a scoring system based on an information gain variant to evaluate each participant's contribution. The scoring system and an epsilon greedy selection method ensure robust participant selection in each aggregation round. Furthermore, incorporating a global momentum term helps preserve previous knowledge at each aggregation round, contributing to model stability and overall learning. The proposed solution has demonstrated superior performance, delivering 80\% F1-Score and 90\% accuracy on experiments even in the presence of malicious participants, revealing the robustness and effectiveness of the proposal in mitigating statistical challenges. Consequently, the proposed method significantly enhances the performance of federated learning models, leading to more secure and efficient collaborative intrusion detection systems.},
  keywords = {Collaborative learning,Federated Learning,Intrusion Detection System,Machine learning}
}

@article{dacosta_InternetThingssurvey_2019,
  title = {Internet of {{Things}}: {{A}} Survey on Machine Learning-Based Intrusion Detection Approaches},
  author = {family=Costa, given=Kelton A.P., prefix=da, useprefix=true and Papa, Jo\~ao P. and Lisboa, Celso O. and Munoz, Roberto and family=Albuquerque, given=Victor Hugo C., prefix=de, useprefix=true},
  date = {2019-03},
  journaltitle = {Computer Networks},
  volume = {151},
  pages = {147--157},
  publisher = {Elsevier B.V.},
  issn = {13891286},
  doi = {10.1016/j.comnet.2019.01.023},
  url = {https://doi.org/10.1016/j.comnet.2019.01.023},
  abstract = {In the world scenario, concerns with security and privacy regarding computer networks are always increasing. Computer security has become a necessity due to the proliferation of information technologies in everyday life. The increase in the number of Internet accesses and the emergence of new technologies, such as the Internet of Things (IoT paradigm, are accompanied by new and modern attempts to invade computer systems and networks. Companies are increasingly investing in studies to optimize the detection of these attacks. Institutions are selecting intelligent techniques to test and verify by comparing the best rates of accuracy. This research, therefore, focuses on rigorous state-of-the-art literature on Machine Learning Techniques applied in Internet-of-Things and Intrusion Detection for computer network security. The work aims, therefore, recent and in-depth research of relevant works that deal with several intelligent techniques and their applied intrusion detection architectures in computer networks with emphasis on the Internet of Things and machine learning. More than 95 works on the subject were surveyed, spanning across different themes related to security issues in IoT environments.},
  keywords = {+survey}
}

@online{daga_CanoeSystemCollaborative_2021,
  title = {Canoe : {{A System}} for {{Collaborative Learning}} for {{Neural Nets}}},
  shorttitle = {Canoe},
  author = {Daga, Harshit and Chen, Yiwen and Agrawal, Aastha and Gavrilovska, Ada},
  date = {2021-08-29},
  eprint = {2108.12124},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2108.12124},
  url = {http://arxiv.org/abs/2108.12124},
  urldate = {2022-08-11},
  abstract = {For highly distributed environments such as edge computing, collaborative learning approaches eschew the dependence on a global, shared model, in favor of models tailored for each location. Creating tailored models for individual learning contexts reduces the amount of data transfer, while collaboration among peers provides acceptable model performance. Collaboration assumes, however, the availability of knowledge transfer mechanisms, which are not trivial for deep learning models where knowledge isn't easily attributed to precise model slices. We present Canoe - a framework that facilitates knowledge transfer for neural networks. Canoe provides new system support for dynamically extracting significant parameters from a helper node's neural network and uses this with a multi-model boosting-based approach to improve the predictive performance of the target node. The evaluation of Canoe with different PyTorch and TensorFlow neural network models demonstrates that the knowledge transfer mechanism improves the model's adaptiveness to changes up to 3.5X compared to learning in isolation, while affording several magnitudes reduction in data movement costs compared to federated learning.},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Machine Learning}
}

@inproceedings{dagli_ProposedSolutionBuild_2021,
  title = {A {{Proposed Solution}} to {{Build}} a {{Breast Cancer Detection Model}} on {{Confidential Patient Data}} Using {{Federated Learning}}},
  booktitle = {2021 {{IEEE Bombay Section Signature Conference}} ({{IBSSC}})},
  author = {Dagli, Saloni and Dedhia, Kashvi and Sawant, Vinaya},
  date = {2021-11},
  pages = {1--6},
  doi = {10.1109/IBSSC53889.2021.9672768},
  url = {https://ieeexplore.ieee.org/abstract/document/9672768},
  urldate = {2024-04-12},
  abstract = {Due to the increasing number of privacy breaches of personal data there is a need for the development of methods that function along with the intent of preserving user privacy. Keeping this in mind we have proposed an algorithm using a federated approach to predict whether or not a patient is suffering from breast cancer, using data from multiple hospitals. This approach ensures that the user data is protected. The federated approach provides the hospitals with a safe and secure way to train their models without having to send their data to a central server. We have compared our approach with the standard approach to evaluate the performance of the federated approach. We determined that the federated learning model was able to achieve an accuracy comparable with the conventional model. There are advantages as well as limitations of our approach, that have been discussed further. This paper discusses an overall idea of federated learning, the past works done in this field, and our approach to implement a solution.},
  eventtitle = {2021 {{IEEE Bombay Section Signature Conference}} ({{IBSSC}})},
  keywords = {breast cancer prediction,centralized learning,Collaborative work,Data models,federated learning,healthcare,Hospitals,Prediction algorithms,Predictive models,privacy,Privacy breach,Training}
}

@article{damiani_OpenDigestbasedTechnique_2004,
  title = {An {{Open Digest-based Technique}} for {{Spam Detection}}},
  author = {Damiani, E},
  date = {2004},
  pages = {6},
  abstract = {A promising anti-spam technique consists in collecting users opinions that given email messages are spam and using this collective judgment to block message propagation to other users. To be effective, this strategy requires a way to identify similarity among email messages, even if the program used by the spammer to generate the messages may try to obfuscate their common origin.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@article{darley_MachineLearningIntrusion_2022,
  title = {Machine {{Learning Intrusion Detection}} as a {{Solution}} to {{Security}} and {{Privacy Issues}} in {{IoT}}: {{A Systematic Review}}},
  shorttitle = {Machine {{Learning Intrusion Detection}} as a {{Solution}} to {{Security}} and {{Privacy Issues}} in {{IoT}}},
  author = {Darley, Olufunke G. and Adenowo, Adetokunbo A. and Yussuff, Abayomi I. O.},
  date = {2022-06-30},
  journaltitle = {FUOYE Journal of Engineering and Technology},
  shortjournal = {FUOYEJET},
  volume = {7},
  number = {2},
  pages = {148--156},
  issn = {2579-0625, 2579-0617},
  doi = {10.46792/fuoyejet.v7i2.802},
  url = {https://journal.engineering.fuoye.edu.ng/index.php/engineer/article/view/802},
  urldate = {2022-08-11},
  abstract = {Billions of IoT devices are in use worldwide and generate a humongous amount of data for the IoT system. This continuous stream of data is open to attack during its collection, transportation, processing, dissemination and storage cycle. Also, IoT devices themselves are points of system vulnerability through which the system can be attacked. Machine learning (ML), due to its ability to identify inherent patterns and behaviour in data, has been applied by many researchers to IoT data such that strange patterns or intrusions into IoT systems can be speedily detected and real-time decisions on security and privacy (S\&P) protection implemented in a timely manner. Different ML techniques with their different algorithms have provided solutions in various scenarios such that security and privacy requirements for the IoT system can be met. In particular, ML has been successfully applied in intrusion detection and has been shown to perform better than traditional means in flagging new trends of attacks. This paper presents a systematic literature review on ML intrusion detection in IoT. Academic journals from 2011 to 2021 from two databases (IEEE and ProQuest) were explored using the Preferred Reporting Items for Systematic Reviews and MetaAnalyses (PRISMA) framework. A review of the final selected papers revealed that data preprocessing, feature extraction, model training and deployment of ML-based Intrusion Detection Systems (IDS) increase computational complexity resulting in greater resource requirement (CPU, memory, and energy); enable ML to be used in the execution of adversarial attacks on IoT devices and networks (as seen with emerging attacks); give rise to scalability issues especially due to the heterogeneous nature of IoT networks; require trade-offs between detection accuracy and false-positive events; and highlight the superior performance of deep learning methods over traditional ML ones in anomaly detection. Generally, the changing nature of attacks makes it difficult for any particular IDS to be able to detect all attack types thus making the development of IDS a continuing project.},
  langid = {english},
  keywords = {+survey}
}

@inproceedings{das_HolisticApproachDetecting_2020,
  title = {A {{Holistic Approach}} for {{Detecting DDoS Attacks}} by {{Using Ensemble Unsupervised Machine Learning}}},
  booktitle = {Advances in {{Information}} and {{Communication}}},
  author = {Das, Saikat and Venugopal, Deepak and Shiva, Sajjan},
  editor = {Arai, Kohei and Kapoor, Supriya and Bhatia, Rahul},
  date = {2020},
  series = {Advances in {{Intelligent Systems}} and {{Computing}}},
  pages = {721--738},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-39442-4_53},
  abstract = {Distributed Denial of Service (DDoS) has been the most prominent attack in cyber-physical system over the last decade. Defending against DDoS attack is not only challenging but also strategic. Tons of new strategies and approaches have been proposed to defend against different types of DDoS attacks. The ongoing battle between the attackers and defenders is full-fledged due to its newest strategies and techniques. Machine learning (ML) has promising outcomes in different research fields including cybersecurity. In this paper, ensemble unsupervised ML approach is used to implement an intrusion detection system which has the noteworthy accuracy to detect DDoS attacks. The goal of this research is to increase the DDoS attack detection accuracy while decreasing the false positive rate. The NSL-KDD dataset and twelve feature sets from existing research are used for experimentation to compare our ensemble results with those of our individual and other existing models.},
  isbn = {978-3-030-39442-4},
  langid = {english},
  keywords = {\_read,Accuracy,DDoS detection,False positive rate,IDS,Novelty and outlier detection,Unsupervised machine learning ensemble}
}

@article{data_DataEncodingByzantineResilient_2021,
  title = {Data {{Encoding}} for {{Byzantine-Resilient Distributed Optimization}}},
  author = {Data, Deepesh and Song, Linqi and Diggavi, Suhas N.},
  date = {2021},
  journaltitle = {IEEE Transactions on Information Theory},
  volume = {67},
  number = {2},
  pages = {1117--1140},
  issn = {15579654},
  doi = {10.1109/TIT.2020.3035868},
  abstract = {We study distributed optimization in the presence of Byzantine adversaries, where both data and computation are distributed among m worker machines, t of which may be corrupt. The compromised nodes may collaboratively and arbitrarily deviate from their pre-specified programs, and a designated (master) node iteratively computes the model/parameter vector for generalized linear models. In this work, we primarily focus on two iterative algorithms: Proximal Gradient Descent (PGD) and Coordinate Descent (CD). Gradient descent (GD) is a special case of these algorithms. PGD is typically used in the data-parallel setting, where data is partitioned across different samples, whereas, CD is used in the model-parallelism setting, where data is partitioned across the parameter space. At the core of our solutions to both these algorithms is a method for Byzantine-resilient matrix-vector (MV) multiplication; and for that, we propose a method based on data encoding and error correction over real numbers to combat adversarial attacks. We can tolerate up to t{$\leq$} m-12rfloor corrupt worker nodes, which is information-theoretically optimal. We give deterministic guarantees, and our method does not assume any probability distribution on the data. We develop a sparse encoding scheme which enables computationally efficient data encoding and decoding. We demonstrate a trade-off between the corruption threshold and the resource requirements (storage, computational, and communication complexity). As an example, for t{$\leq$}q m 3 , our scheme incurs only a constant overhead on these resources, over that required by the plain distributed PGD/CD algorithms which provide no adversarial protection. To the best of our knowledge, ours is the first paper that connects MV multiplication with CD and designs a specific encoding matrix for MV multiplication whose structure we can leverage to make CD secure against adversarial attacks. Our encoding scheme extends efficiently to (i) the data streaming model, in which data samples come in an online fashion and are encoded as they arrive, and (ii) making stochastic gradient descent (SGD) Byzantine-resilient. In the end, we give experimental results to show the efficacy of our proposed schemes.}
}

@inproceedings{david_ReproducibleComputerNetwork_2019,
  title = {Reproducible {{Computer Network Experiments}}: {{A Case Study Using Popper}}},
  shorttitle = {Reproducible {{Computer Network Experiments}}},
  booktitle = {Proceedings of the 2nd {{International Workshop}} on {{Practical Reproducible Evaluation}} of {{Computer Systems}}},
  author = {David, Andrea and Souppe, Mariette and Jimenez, Ivo and Obraczka, Katia and Mansfield, Sam and Veenstra, Kerry and Maltzahn, Carlos},
  date = {2019-06-17},
  series = {P-{{RECS}} '19},
  pages = {29--34},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3322790.3330596},
  url = {https://doi.org/10.1145/3322790.3330596},
  urldate = {2022-08-12},
  abstract = {Computer network research experiments can be broadly grouped in three categories: simulated, controlled, and real-world experiments. Simulation frameworks, experiment testbeds and measurement tools, respectively, are commonly used as the platforms for carrying out network experiments. In many cases, given the nature of computer network experiments, properly configuring these platforms is a complex and time-consuming task, which makes replicating and validating research results quite challenging. This complexity can be reduced by leveraging tools that enable experiment reproducibility. In this paper, we show how a recently proposed reproducibility tool called Popper facilitates the reproduction of networking experiments. In particular, we detail the steps taken to reproduce results in two published articles that rely on simulations. The outcome of this exercise is a generic workflow for carrying out network simulation experiments. In addition, we briefly present two additional Popper workflows for running experiments on controlled testbeds, as well as studies that gather real-world metrics (all code is publicly available on Github). We close by providing a list of lessons we learned throughout this process.},
  isbn = {978-1-4503-6756-1},
  keywords = {network experiment simulation,popper,reproducible network experiments,software automation}
}

@article{decaldasfilho_BotnetDetectionMitigation_2023,
  title = {Botnet {{Detection}} and {{Mitigation Model}} for {{IoT Networks Using Federated Learning}}},
  author = {family=Caldas Filho, given=Francisco Lopes, prefix=de, useprefix=true and Soares, Samuel Carlos Meneses and Oroski, Elder and family=Oliveira Albuquerque, given=Robson, prefix=de, useprefix=true and family=Mata, given=Rafael Zerbini Alves, prefix=da, useprefix=true and family=Mendon\c ca, given=F\'abio L\'ucio Lopes, prefix=de, useprefix=true and family=Sousa J\'unior, given=Rafael Tim\'oteo, prefix=de, useprefix=true},
  date = {2023-01},
  journaltitle = {Sensors},
  volume = {23},
  number = {14},
  pages = {6305},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s23146305},
  url = {https://www.mdpi.com/1424-8220/23/14/6305},
  urldate = {2024-04-12},
  abstract = {The Internet of Things (IoT) introduces significant security vulnerabilities, raising concerns about cyber-attacks. Attackers exploit these vulnerabilities to launch distributed denial-of-service (DDoS) attacks, compromising availability and causing financial damage to digital infrastructure. This study focuses on mitigating DDoS attacks in corporate local networks by developing a model that operates closer to the attack source. The model utilizes Host Intrusion Detection Systems (HIDS) to identify anomalous behaviors in IoT devices and employs network-based intrusion detection approaches through a Network Intrusion Detection System (NIDS) for comprehensive attack identification. Additionally, a Host Intrusion Detection and Prevention System (HIDPS) is implemented in a fog computing infrastructure for real-time and precise attack detection. The proposed model integrates NIDS with federated learning, allowing devices to locally analyze their data and contribute to the detection of anomalous traffic. The distributed architecture enhances security by preventing volumetric attack traffic from reaching internet service providers and destination servers. This research contributes to the advancement of cybersecurity in local network environments and strengthens the protection of IoT networks against malicious traffic. This work highlights the efficiency of using a federated training and detection procedure through deep learning to minimize the impact of a single point of failure (SPOF) and reduce the workload of each device, thus achieving accuracy of 89.753\% during detection and increasing privacy issues in a decentralized IoT infrastructure with a near-real-time detection and mitigation system.},
  issue = {14},
  langid = {english},
  keywords = {DDoS,deep learning,federated learning,fog computing,HIDPS,NIDS}
}

@article{decarvalhobertoli_Generalizingintrusiondetection_2023,
  title = {Generalizing Intrusion Detection for Heterogeneous Networks: {{A}} Stacked-Unsupervised Federated Learning Approach},
  shorttitle = {Generalizing Intrusion Detection for Heterogeneous Networks},
  author = {family=Carvalho Bertoli, given=Gustavo, prefix=de, useprefix=true and Alves Pereira Junior, Louren\c co and Saotome, Osamu and family=Santos, given=Aldri Luiz, prefix=dos, useprefix=true},
  date = {2023-04-01},
  journaltitle = {Computers \& Security},
  shortjournal = {Computers \& Security},
  volume = {127},
  pages = {103106},
  issn = {0167-4048},
  doi = {10.1016/j.cose.2023.103106},
  url = {https://www.sciencedirect.com/science/article/pii/S0167404823000160},
  urldate = {2023-03-14},
  abstract = {The constantly evolving digital transformation imposes new requirements on our society. Aspects relating to reliance on the networking domain and the difficulty of achieving security by design pose a challenge today. As a result, data-centric and machine-learning approaches arose as feasible solutions for securing large networks. Although, in the network security domain, ML-based solutions face a challenge regarding the capability to generalize between different contexts. In other words, solutions based on specific network data usually do not perform satisfactorily on other networks. This paper describes the stacked-unsupervised federated learning (FL) approach to generalize on a cross-silo configuration for a flow-based network intrusion detection system (NIDS). The proposed approach we have examined comprises a deep autoencoder in conjunction with an energy flow classifier in an ensemble learning task. Our approach performs better than traditional local learning and naive cross-evaluation (training in one context and testing on another network data). Remarkably, the proposed approach demonstrates a sound performance in the case of non-IID data silos. In conjunction with an informative feature in an ensemble architecture for unsupervised learning, we advise that the proposed FL-based NIDS results in a feasible approach for generalization between heterogeneous networks.},
  langid = {english},
  keywords = {Federated learning,Generalization,Network flows,Network intrusion detection,Unsupervised learning}
}

@article{decker_Distributedproblemsolvingtechniques_1987,
  title = {Distributed Problem-Solving Techniques: {{A}} Survey},
  author = {Decker, Keith S.},
  date = {1987-09},
  journaltitle = {IEEE Transactions on Systems, Man, and Cybernetics},
  volume = {17},
  number = {5},
  pages = {729--740},
  publisher = {IEEE},
  issn = {0018-9472},
  doi = {10.1109/TSMC.1987.6499280},
  url = {https://ieeexplore.ieee.org/document/6499280/},
  abstract = {Distributed problem-solving is defined as a subfield of artificial intelligence that deals with the interaction of groups of intelligent agents attempting to cooperate to solve problems. A taxonomy of distributed artificial intelligence systems is presented, based on the communication and control methodologies used by their constituent agents, along with the theoretical foundations which underly them. Control in distributed problem-solvers is characterized by cooperation, organization, and dynamics. Communications are specified through paradigms, content, and protocols. Several prototypical systems in areas such as natural language processing and medical diagnosis are briefly discussed, along with more mature systems in applications such as air-traffic control, vehicle monitoring, and manufacturing systems.}
}

@article{defuentes_PRACISPrivacypreservingaggregatable_2017,
  title = {{{PRACIS}}: {{Privacy-preserving}} and Aggregatable Cybersecurity Information Sharing},
  author = {family=Fuentes, given=Jos\'e M., prefix=de, useprefix=true and Gonz\'alez-Manzano, Lorena and Tapiador, Juan and Peris-Lopez, Pedro},
  date = {2017-08},
  journaltitle = {Computers \& Security},
  volume = {69},
  pages = {127--141},
  publisher = {Elsevier Ltd},
  issn = {01674048},
  doi = {10.1016/j.cose.2016.12.011},
  url = {http://dx.doi.org/10.1016/j.cose.2016.12.011},
  abstract = {Cooperative cyberdefense has been recognized as an essential strategy to fight against cyberattacks. Cybersecurity Information Sharing (CIS), especially about threats and incidents, is a key aspect in this regard. CIS provides members with an improved situational awareness to prepare for and respond to future cyberthreats. Privacy preservation is critical in this context, since organizations can be reluctant to share information otherwise. This is particularly critical when CIS is facilitated through an untrusted infrastructure provided by a third party (e.g., the cloud). Despite this, current data formats and protocols for CIS do not guarantee any form of privacy preservation to participants. In this paper we introduce PRACIS, a scheme for CIS networks that guarantees private data forwarding and aggregation. PRACIS leverages the well-known Structured Threat Information Expression (STIX) standard data format. Remarkably, PRACIS can be seamlessly integrated with existing STIX-based message brokering middleware such as publish-subscribe architectures. PRACIS achieves these goals by combining standard format-preserving and homomorphic encryption primitives. We discuss experimental results obtained with a prototype implementation developed for a subset of STIX. Results show that entities may create up to 689 incidents per minute, far beyond the estimated average of 81. Moreover, aggregation of 104 incidents can be carried out in just 2.1 s, and the transmission overhead is just 13.5 kbps. Overall, these results suggest that the costs incurred by PRACIS are easily affordable in real-world scenarios.}
}

@inproceedings{demelo_GeneralizingFlowClassification_2022,
  title = {Generalizing {{Flow Classification}} for {{Distributed Denial-of-Service}} over {{Different Networks}}},
  booktitle = {{{GLOBECOM}} 2022 - 2022 {{IEEE Global Communications Conference}}},
  author = {family=Melo, given=Leonardo H, prefix=de, useprefix=true and family=C Bertoli, given=Gustavo, prefix=de, useprefix=true and Pereira, Lourenco A and Saotome, Osamu and Domingues, Marcelo F and family=Santos, given=Aldri Luiz, prefix=dos, useprefix=true},
  date = {2022-12},
  pages = {879--884},
  doi = {10.1109/GLOBECOM48099.2022.10001530},
  abstract = {With the growth in connected devices and network traffic, these systems require automated and fast approaches to achieve secure operations. Hence, machine learning-based network intrusion detection has become the state-of-the-art approach to tackle uncertainties and new attacks. However, the generalization of the models when exposed to different domains and workloads remains an open issue. In this paper, we propose using federated learning (FL) with sampling methods and feature selection to improve the generalization of the trained global model when evaluated in different network contexts. We evaluate this approach to classify network flows representing benign traffic and distributed denial-of-service attacks. Our proposed approach results in an 85\% improvement compared with the naive evaluation of training in one context and evaluating others. Moreover, it presented a similar performance to a statistical algorithm with the reported generalization capability on flow-based network traffic classification. Additionally, this FL-based approach brings data privacy and distributed learning capability to the table.},
  eventtitle = {{{GLOBECOM}} 2022 - 2022 {{IEEE Global Communications Conference}}},
  keywords = {DDoS,Distance learning,Distributed denial-of-service attack,federated learning,Federated learning,network intrusion detection,Network intrusion detection,security,Telecommunication traffic,Training,Uncertainty}
}

@article{demertzis_BlockchainedFederatedLearning_,
  title = {Blockchained {{Federated Learning}} for {{Threat Defense}}},
  author = {Demertzis, Konstantinos},
  pages = {12},
  abstract = {Given the increasing complexity of threats in smart cities, the changing environment and the weakness of traditional security systems, which in most cases fail to detect serious threats such as zero-day attacks, the need for alternative more active and more effective security methods keeps increasing. Such approaches are the adoption of intelligent solutions to prevent, detect and deal with threats or anomalies under the conditions and the operating parameters of the infrastructure in question. Intelligent systems are capable, of displaying logical, empirical, and non-human decision-making, since they are trained appropriately by historical data representative of the problem they are trying to solve. In most cases, it is either not possible or it is inappropriate to centrally store all smart cities data. Thus, we should perform real-time knowledge mining and we should obtain a subset of a data flow containing a small but recent percentage of observations. This fact raises serious objections to the accuracy and reliability of the employed intelligent system classifiers, who have been tame over time and they become incapable of detecting serious threats. This research paper introduces the development of an intelligent Threat Defense system, employing Blockchain Federated Learning, which seeks to fully upgrade the way passive intelligent systems operate, aiming at implementing an Advanced Adaptive Cooperative Learning (AACL) mechanism for smart cities networks. The AACL is based on the most advanced methods of computational intelligence, while ensuring privacy and anonymity for participants and stakeholders. The proposed framework combines Federated Learning for the distributed and continuously validated learning of the tracing algorithms. Learning is achieved through encrypted smart contracts within the blockchain technology, for unambiguous validation and control of the process. The aim of the proposed Framework is to intelligently classify smart cities networks traffic derived from Industrial IoT (IIoT) by Deep Content Inspection (DCI) methods, in order to identify anomalies that are usually due to Advanced Persistent Threat (APT) attacks.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@article{deng_AUCTIONAutomatedQualityAware_2022,
  title = {{{AUCTION}}: {{Automated}} and {{Quality-Aware Client Selection Framework}} for {{Efficient Federated Learning}}},
  shorttitle = {{{AUCTION}}},
  author = {Deng, Yongheng and Lyu, Feng and Ren, Ju and Wu, Huaqing and Zhou, Yuezhi and Zhang, Yaoxue and Shen, Xuemin},
  date = {2022-08},
  journaltitle = {IEEE Transactions on Parallel and Distributed Systems},
  volume = {33},
  number = {8},
  pages = {1996--2009},
  issn = {1558-2183},
  doi = {10.1109/TPDS.2021.3134647},
  url = {https://ieeexplore.ieee.org/abstract/document/9647925},
  urldate = {2024-03-27},
  abstract = {The emergency of federated learning (FL) enables distributed data owners to collaboratively build a global model without sharing their raw data, which creates a new business chance for building data market. However, in practical FL scenarios, the hardware conditions and data resources of the participant clients can vary significantly, leading to different positive/negative effects on the FL performance, where the client selection problem becomes crucial. To this end, we propose AUCTION, an Automated and qUality-aware Client selecTION framework for efficient FL, which can evaluate the learning quality of clients and select them automatically with quality-awareness for a given FL task within a limited budget. To design AUCTION, multiple factors such as data size, data quality, and learning budget that can affect the learning performance should be properly balanced. It is nontrivial since their impacts on the FL model are intricate and unquantifiable. Therefore, AUCTION is designed to encode the client selection policy into a neural network and employ reinforcement learning to automatically learn client selection policies based on the observed client status and feedback rewards quantified by the federated learning performance. In particular, the policy network is built upon an encoder-decoder deep neural network with an attention mechanism, which can adapt to dynamic changes of the number of candidate clients and make sequential client selection actions to reduce the learning space significantly. Extensive experiments are carried out based on real-world datasets and well-known learning models to demonstrate the efficiency, robustness, and scalability of AUCTION.},
  eventtitle = {{{IEEE Transactions}} on {{Parallel}} and {{Distributed Systems}}},
  keywords = {client selection,Collaborative work,Data integrity,Data models,Data privacy,data quality,Distributed databases,distributed system,Federated learning,reinforcement learning,Task analysis,Training}
}

@inproceedings{deng_FAIRQualityAwareFederated_2021,
  title = {{{FAIR}}: {{Quality-Aware Federated Learning}} with {{Precise User Incentive}} and {{Model Aggregation}}},
  shorttitle = {{{FAIR}}},
  booktitle = {{{IEEE INFOCOM}} 2021 - {{IEEE Conference}} on {{Computer Communications}}},
  author = {Deng, Yongheng and Lyu, Feng and Ren, Ju and Chen, Yi-Chao and Yang, Peng and Zhou, Yuezhi and Zhang, Yaoxue},
  date = {2021-05-10},
  pages = {1--10},
  publisher = {IEEE},
  location = {Vancouver, BC, Canada},
  doi = {10.1109/INFOCOM42981.2021.9488743},
  url = {https://ieeexplore.ieee.org/document/9488743/},
  urldate = {2024-03-27},
  abstract = {Federated learning enables distributed learning in a privacy-protected manner, but two challenging reasons can affect learning performance significantly. First, mobile users are not willing to participate in learning due to computation and energy consumption. Second, with various factors (e.g., training data size/quality), the model update quality of mobile devices can vary dramatically, inclusively aggregating low-quality model updates can deteriorate the global model quality. In this paper, we propose a novel system named FAIR, i.e., Federated leArning with qualIty awaReness. FAIR integrates three major components: 1) learning quality estimation: we leverage historical learning records to estimate the user learning quality, where the record freshness is considered and the exponential forgetting function is utilized for weight assignment; 2) quality-aware incentive mechanism: within the recruiting budget, we model a reverse auction problem to encourage the participation of high-quality learning users, and the method is proved to be truthful, individually rational, and computationally efficient; and 3) model aggregation: we devise an aggregation algorithm that integrates the model quality into aggregation and filters out non-ideal model updates, to further optimize the global learning model. Based on real-world datasets and practical learning tasks, extensive experiments are carried out to demonstrate the efficacy of FAIR.},
  eventtitle = {{{IEEE INFOCOM}} 2021 - {{IEEE Conference}} on {{Computer Communications}}},
  isbn = {978-1-66540-325-2},
  langid = {english}
}

@article{deng_ImprovingFederatedLearning_2022,
  title = {Improving {{Federated Learning With Quality-Aware User Incentive}} and {{Auto-Weighted Model Aggregation}}},
  author = {Deng, Yongheng and Lyu, Feng and Ren, Ju and Chen, Yi-Chao and Yang, Peng and Zhou, Yuezhi and Zhang, Yaoxue},
  date = {2022},
  journaltitle = {IEEE Transactions on Parallel and Distributed Systems},
  pages = {1--15},
  issn = {1558-2183},
  doi = {10.1109/TPDS.2022.3195207},
  abstract = {Federated learning enables distributed model training over various computing nodes, e.g., mobile devices, where instead of sharing raw user data, computing nodes can solely commit model updates without compromising data privacy. The quality of federated learning relies on the model updates contributed by computing nodes training with their local data. However, with various factors (e.g., training data size, mislabeled data samples, skewed data distributions), the model update qualities of computing nodes can vary dramatically, while inclusively aggregating low-quality model updates can deteriorate the global model quality. To achieve efficient federated learning, in this paper, we propose a novel framework named FAIR, i.e., Federated leArning with qualIty awaReness. Particularly, FAIR integrates three major components: 1) learning quality estimation: we adopt the model aggregation weight (learned in the third component) to reversely quantify the individual learning quality of nodes in a privacy-preserving manner, and leverage the historical learning records to infer the next-round learning quality; 2) quality-aware incentive mechanism: within the recruiting budget, we model a reverse auction problem to stimulate the participation of high-quality and low-cost computing nodes, and the method is proved to be truthful, individually rational, and computationally efficient; and 3) auto-weighted model aggregation: based on the gradient descent method, we devise an auto-weighted model aggregation algorithm to automatically learn the optimal aggregation weights to further enhance the global model quality. Based on real-world datasets and learning tasks, extensive experiments are conducted to demonstrate the efficacy of FAIR.},
  eventtitle = {{{IEEE Transactions}} on {{Parallel}} and {{Distributed Systems}}},
  keywords = {\_read\_urgently,Collaborative work,Computational modeling,Data models,Edge computing,federated learning,incentive mechanism,learning quality,mobile computing,model aggregation,Resource management,Task analysis,Training,Training data}
}

@article{deng_ImprovingFederatedLearning_2022a,
  title = {Improving {{Federated Learning With Quality-Aware User Incentive}} and {{Auto-Weighted Model Aggregation}}},
  author = {Deng, Yongheng and Lyu, Feng and Ren, Ju and Chen, Yi-Chao and Yang, Peng and Zhou, Yuezhi and Zhang, Yaoxue},
  date = {2022},
  journaltitle = {IEEE Transactions on Parallel and Distributed Systems},
  pages = {1--15},
  issn = {1558-2183},
  doi = {10.1109/TPDS.2022.3195207},
  abstract = {Federated learning enables distributed model training over various computing nodes, e.g., mobile devices, where instead of sharing raw user data, computing nodes can solely commit model updates without compromising data privacy. The quality of federated learning relies on the model updates contributed by computing nodes training with their local data. However, with various factors (e.g., training data size, mislabeled data samples, skewed data distributions), the model update qualities of computing nodes can vary dramatically, while inclusively aggregating low-quality model updates can deteriorate the global model quality. To achieve efficient federated learning, in this paper, we propose a novel framework named FAIR, i.e., Federated leArning with qualIty awaReness. Particularly, FAIR integrates three major components: 1) learning quality estimation: we adopt the model aggregation weight (learned in the third component) to reversely quantify the individual learning quality of nodes in a privacy-preserving manner, and leverage the historical learning records to infer the next-round learning quality; 2) quality-aware incentive mechanism: within the recruiting budget, we model a reverse auction problem to stimulate the participation of high-quality and low-cost computing nodes, and the method is proved to be truthful, individually rational, and computationally efficient; and 3) auto-weighted model aggregation: based on the gradient descent method, we devise an auto-weighted model aggregation algorithm to automatically learn the optimal aggregation weights to further enhance the global model quality. Based on real-world datasets and learning tasks, extensive experiments are conducted to demonstrate the efficacy of FAIR.},
  eventtitle = {{{IEEE Transactions}} on {{Parallel}} and {{Distributed Systems}}},
  keywords = {Collaborative work,Computational modeling,Data models,Edge computing,federated learning,incentive mechanism,learning quality,mobile computing,model aggregation,Resource management,Task analysis,Training,Training data}
}

@article{deraedt_ProbabilisticLogicProgramming_2015,
  title = {Probabilistic ({{Logic}}) {{Programming Concepts}}},
  author = {De Raedt, Luc and Kimmig, Angelika},
  date = {2015-07},
  journaltitle = {Machine Learning},
  shortjournal = {Mach Learn},
  volume = {100},
  number = {1},
  pages = {5--47},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/s10994-015-5494-z},
  url = {http://link.springer.com/10.1007/s10994-015-5494-z},
  urldate = {2024-07-01},
  abstract = {A multitude of different probabilistic programming languages exists today, all extending a traditional programming language with primitives to support modeling of complex, structured probability distributions. Each of these languages employs its own probabilistic primitives, and comes with a particular syntax, semantics and inference procedure. This makes it hard to understand the underlying programming concepts and appreciate the differences between the different languages. To obtain a better understanding of probabilistic programming, we identify a number of core programming concepts underlying the primitives used by various probabilistic languages, discuss the execution mechanisms that they require and use these to position and survey state-of-the-art probabilistic languages and their implementation. While doing so, we focus on probabilistic extensions of logic programming languages such as Prolog, which have been considered for over 20 years.},
  langid = {english}
}

@article{dietz_ComparingTraditionalGANbased_[review],
  title = {Comparing {{Traditional}} and {{GAN-based Approaches}} for the {{Synthesis}} of {{Wide Area Network Topologies}}},
  author = {Dietz, Katharina and Seufert, Michael and Ho\ss feld, Tobias},
  year = {[review]},
  pages = {9},
  abstract = {Wide Area Network (WAN) research benefits from the availability of realistic network topologies, e. g., as input to simulations, emulators, or testbeds. With the rise of Machine Learning (ML) and particularly Deep Learning (DL) methods, this demand for topologies, which can be used as training data, is greater than ever. However, public datasets are limited, thus, it is promising to generate synthetic graphs with realistic properties based on real topologies for the augmentation of existing data sets. As the generation of synthetic graphs has been in the focus of researchers of various applications fields since several decades, we have a variety of traditional model-dependent and modelindependent graph generators at hand, as well as DL-based approaches, such as Generative Adversarial Networks (GANs). In this work, we adapt and evaluate these existing generators for the WAN use case, i. e., for generating synthetic WAN networks with realistic geographical distances between nodes. Moreover, we investigate a hierarchical graph synthesis approach, which divides the synthesis into local clusters. Finally, we compare the similarity of synthetic and real WAN topologies and discuss the suitability of the generators for data augmentation in the WAN use case.},
  langid = {english},
  keywords = {\_unpublished,â›” No DOI found}
}

@inproceedings{dietz_ComparingTraditionalGANbased_2022,
  title = {Comparing {{Traditional}} and {{GAN-based Approaches}} for the {{Synthesis}} of {{Wide Area Network Topologies}}},
  booktitle = {2022 18th {{International Conference}} on {{Network}} and {{Service Management}} ({{CNSM}})},
  author = {Dietz, Katharina and Seufert, Michael and Ho\ss feld, Tobias},
  date = {2022-10},
  pages = {64--72},
  issn = {2165-963X},
  doi = {10.23919/CNSM55787.2022.9964866},
  url = {https://ieeexplore.ieee.org/document/9964866},
  urldate = {2024-07-07},
  abstract = {Wide Area Network (WAN) research benefits from the availability of realistic network topologies, e.g., as input to simulations, emulators, or testbeds. With the rise of Machine Learning (ML) and particularly Deep Learning (DL) methods, this demand for topologies, which can be used as training data, is greater than ever. However, public datasets are limited, thus, it is promising to generate synthetic graphs with realistic properties based on real topologies for the augmentation of existing data sets. As the generation of synthetic graphs has been in the focus of researchers of various applications fields since several decades, we have a variety of traditional model-dependent and model-independent graph generators at hand, as well as DL-based approaches, such as Generative Adversarial Networks (GANs). In this work, we adapt and evaluate these existing generators for the WAN use case, i.e., for generating synthetic WANs with realistic geographical distances between nodes. Moreover, we investigate a hierarchical graph synthesis approach, which divides the synthesis into local clusters. Finally, we compare the similarity of synthetic and real WAN topologies and discuss the suitability of the generators for data augmentation in the WAN use case.},
  eventtitle = {2022 18th {{International Conference}} on {{Network}} and {{Service Management}} ({{CNSM}})},
  keywords = {Adaptation models,Generative adversarial networks,Generative Adversarial Networks (GAN),Graph Generation,Graph Synthesis,Measurement,Network topology,Network Topology,Spectral Clustering,Training data,Weight measurement,Wide area networks,Wide Area Networks (WAN)}
}

@article{djaidja_Federatedlearning5G_2024,
  title = {Federated Learning for {{5G}} and beyond, a Blessing and a Curse- an Experimental Study on Intrusion Detection Systems},
  author = {Djaidja, Taki Eddine Toufik and Brik, Bouziane and Boualouache, Abdelwahab and Senouci, Sidi Mohammed and Ghamri-Doudane, Yacine},
  date = {2024-04-01},
  journaltitle = {Computers \& Security},
  shortjournal = {Computers \& Security},
  volume = {139},
  pages = {103707},
  issn = {0167-4048},
  doi = {10.1016/j.cose.2024.103707},
  url = {https://www.sciencedirect.com/science/article/pii/S0167404824000087},
  urldate = {2024-04-12},
  abstract = {5G's service providers now leverage Deep Learning (DL) to automate their network slice management, provisioning, and security. To this end, each slice owner contributes data to feed a common dataset used to train centralized learning models. However, this method raises privacy considerations that prevent its usage. Therefore, Federated learning (FL), a collaborative approach that ensures data privacy, is being investigated while striving toward the same performance as centralized learning. As 5G and beyond services are so diverse, the local slice's data is not intended to reflect the entire data distribution. Thus, local data of slices are Non-Independently and non-Identically distributed (Non-IID), posing a challenge for FL-based models. In this paper, we investigate the use of FL to secure network slices and detect potential attacks. For that purpose, we first propose an architecture for deploying intrusion detection systems (IDSs) in 5G and beyond networks. Next, we thoroughly evaluate the latest state-of-art FL algorithms, including FedAvg, FedProx, FedPer, and SCAFFOLD, in the context of Independently and Identically Distributed (IID) and Non-IID data distributions. We compare these FL models to centralized and local DL models. We find that SCAFFOLD outperforms all the other FL algorithms and ensures a stable learning loss convergence, a promising finding that strengthens the case for leveraging FL in IDS development. Nevertheless, none of the FL models could achieve the centralized model's performance in Non-IID scenarios.},
  keywords = {5G and beyond,Deep learning,Federated learning,IDS,NON-IID}
}

@inproceedings{doar_bettermodelgenerating_1996,
  title = {A Better Model for Generating Test Networks},
  booktitle = {Proceedings of {{GLOBECOM}}'96. 1996 {{IEEE Global Telecommunications Conference}}},
  author = {Doar, M.B.},
  date = {1996-11},
  volume = {MiniConfInternet},
  pages = {86--93},
  doi = {10.1109/GLOCOM.1996.586131},
  url = {https://ieeexplore.ieee.org/abstract/document/586131},
  urldate = {2024-07-07},
  abstract = {Much of the work on routing algorithms, particularly for multicast, which has been done in the past has used fairly simple models to generate the topological graph which represents the hosts in the network. Some such random graphs bear little resemblance to data communication networks which are actually deployed. This paper proposes a more realistic model, incorporating hierarchy and redundancy, and is developed into a network generation algorithm. The approach described can be developed to provide more refined models in the future.},
  eventtitle = {Proceedings of {{GLOBECOM}}'96. 1996 {{IEEE Global Telecommunications Conference}}},
  keywords = {Costs,Data communication,Euclidean distance,IP networks,Multicast algorithms,Network topology,Routing,Testing,Tree graphs,USA Councils}
}

@inproceedings{doar_bettermodelgenerating_1996a,
  title = {A Better Model for Generating Test Networks},
  booktitle = {Proceedings of {{GLOBECOM}}'96. 1996 {{IEEE Global Telecommunications Conference}}},
  author = {Doar, M.B.},
  date = {1996-11},
  volume = {MiniConfInternet},
  pages = {86--93},
  doi = {10.1109/GLOCOM.1996.586131},
  url = {https://ieeexplore.ieee.org/document/586131},
  urldate = {2024-07-07},
  abstract = {Much of the work on routing algorithms, particularly for multicast, which has been done in the past has used fairly simple models to generate the topological graph which represents the hosts in the network. Some such random graphs bear little resemblance to data communication networks which are actually deployed. This paper proposes a more realistic model, incorporating hierarchy and redundancy, and is developed into a network generation algorithm. The approach described can be developed to provide more refined models in the future.},
  eventtitle = {Proceedings of {{GLOBECOM}}'96. 1996 {{IEEE Global Telecommunications Conference}}},
  keywords = {Costs,Data communication,Euclidean distance,IP networks,Multicast algorithms,Network topology,Routing,Testing,Tree graphs,USA Councils}
}

@thesis{dolstra_purelyfunctionalsoftware_2006,
  title = {The Purely Functional Software Deployment Model},
  author = {Dolstra, Eelco},
  date = {2006},
  institution = {s.n.},
  location = {S.l.},
  langid = {english},
  annotation = {OCLC: 71702886}
}

@inproceedings{dondio_ComputingTrustForm_2014,
  title = {Computing {{Trust}} as a {{Form}} of {{Presumptive Reasoning}}},
  booktitle = {2014 {{IEEE}}/{{WIC}}/{{ACM International Joint Conferences}} on {{Web Intelligence}} ({{WI}}) and {{Intelligent Agent Technologies}} ({{IAT}})},
  author = {Dondio, Pierpaolo and Longo, Luca},
  date = {2014-08},
  volume = {2},
  pages = {274--281},
  publisher = {IEEE},
  doi = {10.1109/WI-IAT.2014.108},
  url = {http://ieeexplore.ieee.org/document/6927635/},
  abstract = {This study describes and evaluates a novel trust model for a range of collaborative applications. The model assumes that humans routinely choose to trust their peers by relying on few recurrent presumptions, which are domain independent and which form a recognisable trust expertise. We refer to these presumptions as trust schemes, a specialised version of Walton's argumentation schemes. Evidence is provided about the efficacy of trust schemes using a detailed experiment on an online community of 80,000 members. Results show how proposed trust schemes are more effective in trust computation when they are combined together and when their plausibility in the selected context is considered.},
  isbn = {978-1-4799-4143-8}
}

@article{dong_AcceleratingWirelessFederated_2023,
  title = {Accelerating {{Wireless Federated Learning}} via {{Nesterov}}'s {{Momentum}} and {{Distributed Principle Component Analysis}}},
  author = {Dong, Yanjie and Wang, Luya and Chi, Yuanfang and Wang, Jia and Zhang, Haijun and Yu, Fei Richard and Leung, Victor C. M. and Hu, Xiping},
  date = {2023},
  publisher = {[object Object]},
  doi = {10.48550/ARXIV.2303.17885},
  url = {https://arxiv.org/abs/2303.17885},
  urldate = {2024-04-02},
  abstract = {A wireless federated learning system is investigated by allowing a server and workers to exchange uncoded information via orthogonal wireless channels. Since the workers frequently upload local gradients to the server via bandwidth-limited channels, the uplink transmission from the workers to the server becomes a communication bottleneck. Therefore, a one-shot distributed principle component analysis (PCA) is leveraged to reduce the dimension of uploaded gradients such that the communication bottleneck is relieved. A PCA-based wireless federated learning (PCA-WFL) algorithm and its accelerated version (i.e., PCA-AWFL) are proposed based on the low-dimensional gradients and the Nesterov's momentum. For the non-convex loss functions, a finite-time analysis is performed to quantify the impacts of system hyper-parameters on the convergence of the PCA-WFL and PCA-AWFL algorithms. The PCA-AWFL algorithm is theoretically certified to converge faster than the PCA-WFL algorithm. Besides, the convergence rates of PCA-WFL and PCA-AWFL algorithms quantitatively reveal the linear speedup with respect to the number of workers over the vanilla gradient descent algorithm. Numerical results are used to demonstrate the improved convergence rates of the proposed PCA-WFL and PCA-AWFL algorithms over the benchmarks.},
  version = {1},
  keywords = {FOS: Computer and information sciences,Information Theory (cs.IT),Machine Learning (cs.LG)}
}

@article{dong_EaSTFLyEfficientsecure_2020,
  title = {{{EaSTFLy}}: {{Efficient}} and Secure Ternary Federated Learning},
  shorttitle = {{{EaSTFLy}}},
  author = {Dong, Ye and Chen, Xiaojun and Shen, Liyan and Wang, Dakui},
  date = {2020-07},
  journaltitle = {Computers \& Security},
  shortjournal = {Computers \& Security},
  volume = {94},
  pages = {101824},
  issn = {01674048},
  doi = {10.1016/j.cose.2020.101824},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167404820300985},
  urldate = {2021-05-18},
  langid = {english}
}

@article{dong_FADngsFederatedLearning_2024,
  title = {{{FADngs}}: {{Federated Learning}} for {{Anomaly Detection}}},
  shorttitle = {{{FADngs}}},
  author = {Dong, Boyu and Chen, Dong and Wu, Yu and Tang, Siliang and Zhuang, Yueting},
  date = {2024},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  pages = {1--15},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2024.3350660},
  url = {https://ieeexplore.ieee.org/abstract/document/10409269},
  urldate = {2024-04-12},
  abstract = {With the increasing demand for data privacy, federated learning (FL) has gained popularity for various applications. Most existing FL works focus on the classification task, overlooking those scenarios where anomaly detection may also require privacy-preserving. Traditional anomaly detection algorithms cannot be directly applied to the FL setting due to false and missing detection issues. Moreover, with common aggregation methods used in FL (e.g., averaging model parameters), the global model cannot keep the capacities of local models in discriminating anomalies deviating from local distributions, which further degrades the performance. For the aforementioned challenges, we propose Federated Anomaly Detection with Noisy Global Density Estimation, and Self-supervised Ensemble Distillation (FADngs). Specifically, FADngs aligns the knowledge of data distributions from each client by sharing processed density functions. Besides, FADngs trains local models in an improved contrastive learning way that learns more discriminative representations specific for anomaly detection based on the shared density functions. Furthermore, FADngs aggregates capacities by ensemble distillation, which distills the knowledge learned from different distributions to the global model. Our experiments demonstrate that the proposed method significantly outperforms state-of-the-art federated anomaly detection methods. We also empirically show that the shared density function is privacy-preserving. The code for the proposed method is provided for research purposes https://github.com/kanade00/Federated\_Anomaly\_detection.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Networks}} and {{Learning Systems}}},
  keywords = {Adaptation models,Anomaly detection,Data models,Density functional theory,distributed learning,federated learning (FL),Noise measurement,Self-supervised learning,Training,unsupervised learning}
}

@inproceedings{dong_FastNetworkIntrusion_2021,
  title = {Towards {{Fast Network Intrusion Detection}} Based on {{Efficiency-preserving Federated Learning}}},
  booktitle = {2021 {{IEEE Intl Conf}} on {{Parallel}} \& {{Distributed Processing}} with {{Applications}}, {{Big Data}} \& {{Cloud Computing}}, {{Sustainable Computing}} \& {{Communications}}, {{Social Computing}} \& {{Networking}} ({{ISPA}}/{{BDCloud}}/{{SocialCom}}/{{SustainCom}})},
  author = {Dong, Tian and Qiu, Han and Lu, Jialiang and Qiu, Meikang and Fan, Chun},
  date = {2021-09},
  pages = {468--475},
  doi = {10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00071},
  url = {https://ieeexplore.ieee.org/document/9644849},
  urldate = {2024-04-12},
  abstract = {Network Intrusion Detection Systems (NIDSs) are extremely important in defending against emergent cyberattacks. However, current NIDSs for Internet-of-Things (IoT) devices have not taken actual device computation limitation into account, and are still based on resource-consuming neural networks. In this paper, we propose a simple but effective FL-based NIDS. Specifically, we leverage the characteristic of network traffic data (a kind of tabular data), i.e. slight value change does not affect inherent feature, and use data binning to extract feature data on clients. The feature data are then used for training the classifier on the server. We also use data masking to further enhance data protection. We evaluate our NIDS on the public DDoS attack classification benchmark, and the result shows that our NIDS can achieve comparable performance as locally trained NIDS while significantly reducing the communication cost.},
  eventtitle = {2021 {{IEEE Intl Conf}} on {{Parallel}} \& {{Distributed Processing}} with {{Applications}}, {{Big Data}} \& {{Cloud Computing}}, {{Sustainable Computing}} \& {{Communications}}, {{Social Computing}} \& {{Networking}} ({{ISPA}}/{{BDCloud}}/{{SocialCom}}/{{SustainCom}})},
  keywords = {Benchmark testing,Communication-efficient,Costs,Feature extraction,Federated Learning,Internet-of-Things,Intrusion Detection,Network intrusion detection,Neural networks,Privacy-preserving,Telecommunication traffic,Training}
}

@unpublished{dong_InterpretableFederatedLearningbased_2022,
  title = {An {{Interpretable Federated Learning-based Network Intrusion Detection Framework}}},
  author = {Dong, Tian and Li, Song and Qiu, Han and Lu, Jialiang},
  date = {2022-01-09},
  eprint = {2201.03134},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2201.03134},
  urldate = {2022-01-31},
  abstract = {Learning-based Network Intrusion Detection Systems (NIDSs) are widely deployed for defending various cyberattacks. Existing learning-based NIDS mainly uses Neural Network (NN) as a classifier that relies on the quality and quantity of cyberattack data. Such NN-based approaches are also hard to interpret for improving efficiency and scalability. In this paper, we design a new local-global computation paradigm, FEDFOREST, a novel learning-based NIDS by combining the interpretable Gradient Boosting Decision Tree (GBDT) and Federated Learning (FL) framework. Specifically, FEDFOREST is composed of multiple clients that extract local cyberattack data features for the server to train models and detect intrusions. A privacy-enhanced technology is also proposed in FEDFOREST to further defeat the privacy of the FL systems. Extensive experiments on 4 cyberattack datasets of different tasks demonstrate that FEDFOREST is effective, efficient, interpretable, and extendable. FEDFOREST ranks first in the collaborative learning and cybersecurity competition 2021 for Chinese college students.},
  langid = {english},
  keywords = {\_read,â›” No DOI found,Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@article{dong_MomentumBasedWirelessFederated_2023,
  title = {A {{Momentum-Based Wireless Federated Learning Acceleration With Distributed Principle Decomposition}}},
  author = {Dong, Yanjie and Wang, Luya and Chi, Yuanfang and Hu, Xiping and Zhang, Haijun and Yu, Fei Richard and Leung, Victor C. M.},
  date = {2023-06-04},
  journaltitle = {2023 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)},
  pages = {1--5},
  publisher = {IEEE},
  location = {Rhodes Island, Greece},
  doi = {10.1109/ICASSPW59220.2023.10193196},
  url = {https://ieeexplore.ieee.org/document/10193196/},
  urldate = {2024-04-02},
  abstract = {In the uplink period of wireless federated learning (WFL), multiple workers frequently upload uncoded training information to a server via orthogonal wireless channels. Due to the scarcity of wireless spectrum, the communication bottleneck appears during the uplink transmission. A one-shot distributed principle component analysis (PCA) method is leveraged to relieve the communication bottleneck by reducing the dimension of uploaded training information. Based on the low-dimensional training information, a Nesterov's momentum accelerated WFL algorithm (i.e., PCA-AWFL) is proposed to reduce the communication rounds for the training of the federated learning system. For the non-convex loss functions, the finite-time convergence rate quantifies the impacts of system hyperparameters on the PCA-AWFL algorithm. Numerical results are used to demonstrate the performance improvement of the proposed PCA-AWFL algorithm over the benchmarks.},
  eventtitle = {2023 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}}, and {{Signal Processing Workshops}} ({{ICASSPW}})},
  isbn = {9798350302615}
}

@online{doriguzzi-corin_FLADAdaptiveFederated_2022,
  title = {{{FLAD}}: {{Adaptive Federated Learning}} for {{DDoS Attack Detection}}},
  shorttitle = {{{FLAD}}},
  author = {Doriguzzi-Corin, Roberto and Siracusa, Domenico},
  date = {2022-05-16},
  eprint = {2205.06661},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2205.06661},
  urldate = {2022-07-05},
  abstract = {Federated Learning (FL) has been recently receiving increasing consideration from the cybersecurity community as a way to collaboratively train deep learning models with distributed profiles of cyberthreats, with no disclosure of training data. Nevertheless, the adoption of FL in cybersecurity is still in its infancy, and a range of practical aspects have not been properly addressed yet. Indeed, the Federated Averaging algorithm at the core of the FL concept requires the availability of test data to control the FL process. Although this might be feasible in some domains, test network traffic of newly discovered attacks cannot be always shared without disclosing sensitive information.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security}
}

@article{doshi_MachineLearningDDoS_2018,
  title = {Machine {{Learning DDoS Detection}} for {{Consumer Internet}} of {{Things Devices}}},
  author = {Doshi, Rohan and Apthorpe, Noah and Feamster, Nick},
  date = {2018-04-11},
  journaltitle = {2018 IEEE Security and Privacy Workshops (SPW)},
  pages = {29--35},
  publisher = {IEEE},
  doi = {10.1109/SPW.2018.00013},
  url = {https://ieeexplore.ieee.org/document/8424629/},
  abstract = {An increasing number of Internet of Things (IoT) devices are connecting to the Internet, yet many of these devices are fundamentally insecure, exposing the Internet to a variety of attacks. Botnets such as Mirai have used insecure consumer IoT devices to conduct distributed denial of service (DDoS) attacks on critical Internet infrastructure. This motivates the development of new techniques to automatically detect consumer IoT attack traffic. In this paper, we demonstrate that using IoT-specific network behaviors (e.g. limited number of endpoints and regular time intervals between packets) to inform feature selection can result in high accuracy DDoS detection in IoT network traffic with a variety of machine learning algorithms, including neural networks. These results indicate that home gateway routers or other network middleboxes could automatically detect local IoT device sources of DDoS attacks using low-cost machine learning algorithms and traffic data that is flow-based and protocol-agnostic.},
  isbn = {978-1-5386-8276-0},
  issue = {Ml}
}

@article{dossantos_Federatedlearningreliable_2023,
  title = {Federated Learning for Reliable Model Updates in Network-Based Intrusion Detection},
  author = {family=Santos, given=Roger R., prefix=dos, useprefix=true and Viegas, Eduardo K. and Santin, Altair O. and Tedeschi, Pietro},
  date = {2023-10-01},
  journaltitle = {Computers \& Security},
  shortjournal = {Computers \& Security},
  volume = {133},
  pages = {103413},
  issn = {0167-4048},
  doi = {10.1016/j.cose.2023.103413},
  url = {https://www.sciencedirect.com/science/article/pii/S0167404823003231},
  urldate = {2024-04-12},
  abstract = {Machine Learning techniques for network-based intrusion detection are widely adopted in the scientific literature. Besides being highly variable, network traffic behavior changes over time, demanding proposed schemes to be periodically updated to ensure their reliability. Unfortunately, their efficiency is significantly limited in production environments. This paper proposes a new Federated Learning model for reliable network-based intrusion detection with highly confident model updates over time. Our proposed scheme assesses the classification reliability in an unsupervised fashion and rejects potential misclassifications even when outdated. In addition, it significantly eases the model update cost by conducting it in a Federated Learning rationale. To evaluate the effectiveness of our solution, we conduct an experimental campaign with a new dataset, MAWIFlow, with over 7 TB of real network traffic spanning a year. The achieved results of our proposed model are striking. It respectively improves the average false-positive and false-negative rates by up to 12\% and 9.6\% when no model updates are conducted. If done so, it can further improve the false-positive rate by up to 13\% while rejecting only 3.6\% of events and demanding only 0.3\% of events for model updates. Further, the comparison against the traditional Federated Learning approach confirms our model's remarkable performance in several scenarios. Finally, the quality and viability of our solution do prove that our approach can be successfully adopted for improving the accuracy and efficiency of classification systems in real-world scenarios where outdated models are prevalent and pave the way for future research in the area.},
  keywords = {Federated learning,Intrusion detection,Network attacks,Reject option,Reliability}
}

@inproceedings{douceur_SybilAttack_2002,
  title = {The {{Sybil Attack}}},
  booktitle = {Peer-to-{{Peer Systems}}},
  author = {Douceur, John R.},
  editor = {Druschel, Peter and Kaashoek, Frans and Rowstron, Antony},
  date = {2002},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {251--260},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/3-540-45748-8_24},
  abstract = {Large-scale peer-to-peer systems face security threats from faulty or hostile remote computing elements. To resist these threats, many such systems employ redundancy. However, if a single faulty entity can present multiple identities, it can control a substantial fraction of the system, thereby undermining this redundancy. One approach to preventing these ``Sybil attacks'' is to have a trusted agency certify identities. This paper shows that, without a logically centralized authority, Sybil attacks are always possible except under extreme and unrealistic assumptions of resource parity and coordination among entities.},
  isbn = {978-3-540-45748-0},
  langid = {english},
  keywords = {Distinct Identity,Hash Function,Local Entity,Multiple Identity,Random Oracle}
}

@inproceedings{draper-gil_CharacterizationEncryptedVPN_2016,
  title = {Characterization of {{Encrypted}} and {{VPN Traffic}} Using {{Time-related Features}}:},
  shorttitle = {Characterization of {{Encrypted}} and {{VPN Traffic}} Using {{Time-related Features}}},
  booktitle = {Proceedings of the 2nd {{International Conference}} on {{Information Systems Security}} and {{Privacy}}},
  author = {Draper-Gil, Gerard and Lashkari, Arash Habibi and Mamun, Mohammad Saiful Islam and A. Ghorbani, Ali},
  date = {2016},
  pages = {407--414},
  publisher = {{SCITEPRESS - Science and and Technology Publications}},
  location = {Rome, Italy},
  doi = {10.5220/0005740704070414},
  url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0005740704070414},
  urldate = {2021-10-15},
  eventtitle = {2nd {{International Conference}} on {{Information Systems Security}} and {{Privacy}}},
  isbn = {978-989-758-167-0},
  langid = {english}
}

@article{driss_federatedlearningframework_2022,
  title = {A Federated Learning Framework for Cyberattack Detection in Vehicular Sensor Networks},
  author = {Driss, Maha and Almomani, Iman and family=Huma, given=Zil, prefix=e, useprefix=true and Ahmad, Jawad},
  date = {2022-10-01},
  journaltitle = {Complex \& Intelligent Systems},
  shortjournal = {Complex Intell. Syst.},
  volume = {8},
  number = {5},
  pages = {4221--4235},
  issn = {2198-6053},
  doi = {10.1007/s40747-022-00705-w},
  url = {https://doi.org/10.1007/s40747-022-00705-w},
  urldate = {2024-04-12},
  abstract = {Vehicular Sensor Networks (VSN) introduced a new paradigm for modern transportation systems by improving traffic management and comfort. However, the increasing adoption of smart sensing technologies with the Internet of Things (IoT) made VSN a high-value target for cybercriminals. In recent years, Machine Learning (ML) and Deep Learning (DL) techniques attracted the research community to develop security solutions for IoT networks. Traditional ML and DL approaches that operate with data stored on a centralized server raise major privacy problems for user data. On the other hand, the resource-constrained nature of a smart sensing network demands lightweight security solutions. To address these issues, this article proposes a Federated Learning (FL)-based attack detection framework for VSN. The proposed scheme utilizes a group of Gated Recurrent Units (GRU) with a Random Forest (RF)-based ensembler unit. The effectiveness of the suggested framework is investigated through multiple performance metrics. Experimental findings indicate that the proposed FL approach successfully detected the cyberattacks in VSN with the highest accuracy of 99.52\%. The other performance scores, precision, recall, and F1 are attained as 99.77\%, 99.54\%, and 99.65\%, respectively.},
  langid = {english},
  keywords = {Cybersecurity,Internet of things,Intrusion detection,Vehicular sensor networks}
}

@misc{ds2os_dataset,
  title = {Ds2ostraffictraces - {{Kaggle}}},
  url = {https://www.kaggle.com/francoisxa/ds2ostraffictraces},
  organization = {Kaggle},
  keywords = {pinned}
}

@online{dunnett_TrustedVerifiableDifferential_2022,
  title = {A {{Trusted}}, {{Verifiable}} and {{Differential Cyber Threat Intelligence Sharing Framework}} Using {{Blockchain}}},
  author = {Dunnett, Kealan and Pal, Shantanu and Putra, Guntur Dharma and Jadidi, Zahra and Jurdak, Raja},
  date = {2022-08-25},
  eprint = {2208.12031},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2208.12031},
  urldate = {2022-08-30},
  abstract = {Cyber Threat Intelligence (CTI) is the knowledge of cyber and physical threats that help mitigate potential cyber attacks. The rapid evolution of the current threat landscape has seen many organisations share CTI to strengthen their security posture for mutual benefit. However, in many cases, CTI data contains attributes (e.g., software versions) that have the potential to leak sensitive information or cause reputational damage to the sharing organisation. While current approaches allow restricting CTI sharing to trusted organisations, they lack solutions where the shared data can be verified and disseminated `differentially' (i.e., selective information sharing) with policies and metrics flexibly defined by an organisation. In this paper, we propose a blockchain-based CTI sharing framework that allows organisations to share sensitive CTI data in a trusted, verifiable and differential manner. We discuss the limitations associated with existing approaches and highlight the advantages of the proposed CTI sharing framework. We further present a detailed proof of concept using the Ethereum blockchain network. Our experimental results show that the proposed framework can facilitate the exchange of CTI without creating significant additional overheads.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Cryptography and Security}
}

@inproceedings{duraz_CyberInformednessNew_2023,
  title = {Cyber {{Informedness}}: {{A New Metric}} Using {{CVSS}} to {{Increase Trust}} in {{Intrusion Detection Systems}}},
  shorttitle = {Cyber {{Informedness}}},
  booktitle = {Proceedings of the 2023 {{European Interdisciplinary Cybersecurity Conference}}},
  author = {Duraz, Robin and Espes, David and Francq, Julien and Vaton, Sandrine},
  date = {2023-06-14},
  series = {{{EICC}} '23},
  pages = {53--58},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3590777.3590786},
  url = {https://dl.acm.org/doi/10.1145/3590777.3590786},
  urldate = {2023-10-10},
  abstract = {Intrusion Detection Systems (IDSs) are essential cybersecurity components. Previous cyberattack detection methods relied more on signatures and rules to detect cyberattacks, although there has been a change in paradigm in the last decade, with Machine Learning (ML) enabling more efficient and flexible statistical methods. However, ML is currently unable to integrate cybersecurity information into its inner workings. This paper introduces Cyber Informedness, a new metric taking into account cybersecurity information to give a more informed representation of performance, influenced by the severity of the attacks encountered. This metric uses a de facto standard in cybersecurity: the Common Vulnerability Scoring System (CVSS). Results on two public datasets show that this new metric validates results obtained with generic metrics. Furthermore, this new metric highlights ML-based IDSs that prioritize high performance on severe attacks, which is not visible with generic metrics. Consequently, this new metric nicely completes generic metrics by bridging the gap between ML and cybersecurity.},
  isbn = {978-1-4503-9829-9},
  keywords = {Cybersecurity metrics,Intrusion Detection Systems,Machine Learning}
}

@article{durbet_ObservationsFuzzyVault_[review],
  title = {Some {{Observations}} on {{Fuzzy Vault Based Biometric Protocols}}},
  author = {DURBET, Axel},
  year = {[review]},
  volume = {86},
  number = {11},
  langid = {english},
  keywords = {\_done,\_unpublished}
}

@inproceedings{duy_Federatedlearningbasedintrusion_2021,
  title = {Federated Learning-Based Intrusion Detection in {{SDN-enabled IIoT}} Networks},
  booktitle = {2021 8th {{NAFOSTED Conference}} on {{Information}} and {{Computer Science}} ({{NICS}})},
  author = {Duy, Phan The and Hung, Tran Van and Ha, Nguyen Hong and Hoang, Hien Do and Pham, Van-Hau},
  date = {2021-12},
  pages = {424--429},
  doi = {10.1109/NICS54270.2021.9701525},
  url = {https://ieeexplore.ieee.org/abstract/document/9701525},
  urldate = {2024-04-12},
  abstract = {Witnessing the explosion in the number of Internet of Things (IoTs) in industries, Software Defined Networking (SDN) is considered as a flexible, efficient, and programmable approach for network management and security policy enforcement. Particularly, it is more suitable in the context of industrial Internet of Things (IIoT) network comprising heterogeneous devices. Meanwhile, the demand of ensuring cyber threat resistance has more become the serious concern from both academia and industry due to incidents, cyberattacks, personal data breaches reported recently. Many intrusion detection systems (IDS) leverage the advances in machine learning (ML) to build the more efficient attack detector against the unknown malicious actions in the network. Such an approach requires gathering a large amount of network traffic for model training in a centralized platform. It obviously violates the data privacy protection since the network traffic is sensitive information if accessed and used by a third party. To take advantage of private network data from various sources for mutually training detection model, federated learning (FL) is recently introduced as a solution that can address the problem of violating data privacy for ML-based cybersecurity solution during training phase. Thus, this work introduces the FL approach for IDS to facilitate the privacy preserving in model training while collaboratively maintaining the efficiency of attack detection in IIoT context with the leverage of SDN.},
  eventtitle = {2021 8th {{NAFOSTED Conference}} on {{Information}} and {{Computer Science}} ({{NICS}})},
  keywords = {Data privacy,federated learning,IDS,Industries,intrusion detection,Intrusion detection,Privacy,Resistance,SDN,Telecommunication traffic,Training}
}

@article{edwards_HajimeAnalysisdecentralized_2016,
  title = {Hajime: {{Analysis}} of a Decentralized Internet Worm for {{IoT}} Devices},
  author = {Edwards, Sam and Profetis, Ioannis},
  date = {2016},
  journaltitle = {Cs.Umd.Edu},
  pages = {1--18},
  abstract = {This paper chronicles the discovery and analysis of a malicious internet worm, dubbed \hspace{0pt} Hajime \hspace{0pt} , which targets embedded/Internet of Things (" IoT ") devices and spreads by scanning the public internet for devices running Telnet servers with insecure default credentials. Though worms which target IoT devices are not new, they are rising in prominence lately due to the generally weak security such devices have. What makes \hspace{0pt} Hajime \hspace{0pt} unique is that it does not rely on centralized malware distribution server(s), but instead communicates over a distributed/decentralized overlay network to receive configuration and software updates. Background},
  keywords = {â›” No DOI found}
}

@online{elgabli_FedNewCommunicationEfficientPrivacyPreserving_2022,
  title = {{{FedNew}}: {{A Communication-Efficient}} and {{Privacy-Preserving Newton-Type Method}} for {{Federated Learning}}},
  shorttitle = {{{FedNew}}},
  author = {Elgabli, Anis and Issaid, Chaouki Ben and Bedi, Amrit S. and Rajawat, Ketan and Bennis, Mehdi and Aggarwal, Vaneet},
  date = {2022-06-17},
  eprint = {2206.08829},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2206.08829},
  urldate = {2022-07-06},
  abstract = {Newton-type methods are popular in federated learning due to their fast convergence. Still, they suffer from two main issues, namely: low communication efficiency and low privacy due to the requirement of sending Hessian information from clients to parameter server (PS). In this work, we introduced a novel framework called FedNew in which there is no need to transmit Hessian information from clients to PS, hence resolving the bottleneck to improve communication efficiency. In addition, FedNew hides the gradient information and results in a privacy-preserving approach compared to the existing state-of-the-art. The core novel idea in FedNew is to introduce a two level framework, and alternate between updating the inverse Hessian-gradient product using only one alternating direction method of multipliers (ADMM) step and then performing the global model update using Newton's method. Though only one ADMM pass is used to approximate the inverse Hessian-gradient product at each iteration, we develop a novel theoretical approach to show the converging behavior of FedNew for convex problems. Additionally, a significant reduction in communication overhead is achieved by utilizing stochastic quantization. Numerical results using real datasets show the superiority of FedNew compared to existing methods in terms of communication costs.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{elgamal_publickeycryptosystem_1985,
  title = {A Public Key Cryptosystem and a Signature Scheme Based on Discrete Logarithms},
  author = {Elgamal, T.},
  date = {1985-07},
  journaltitle = {IEEE Transactions on Information Theory},
  shortjournal = {IEEE Trans. Inform. Theory},
  volume = {31},
  number = {4},
  pages = {469--472},
  issn = {0018-9448},
  doi = {10.1109/TIT.1985.1057074},
  url = {http://ieeexplore.ieee.org/document/1057074/},
  urldate = {2021-05-20},
  abstract = {A new signature scheme is proposed, together with an imple- Hence both A and B are able to compute K,,. But, for an mentation of the Diffie-Hellman key distribution scheme that achieves a intruder, computing KA B appears to be difficult. It is not public key cryptosystem. The security of both systems relies on the yet proved that breaking the system is equivalent to comdifficulty of computing discrete logarithms over finite fields.},
  langid = {english}
}

@inproceedings{elhouda_EnsembleLearningIntrusion_2022,
  title = {Ensemble {{Learning}} for {{Intrusion Detection}} in {{SDN-Based Zero Touch Smart Grid Systems}}},
  booktitle = {2022 {{IEEE}} 47th {{Conference}} on {{Local Computer Networks}} ({{LCN}})},
  author = {El Houda, Zakaria Abou and Brik, Bouziane and Khoukhi, Lyes},
  date = {2022-09-26},
  pages = {149--156},
  publisher = {IEEE},
  location = {Edmonton, AB, Canada},
  doi = {10.1109/LCN53696.2022.9843645},
  url = {https://ieeexplore.ieee.org/document/9843645/},
  urldate = {2022-08-31},
  abstract = {Software-defined network (SDN) is widely deployed on Smart Grid (SG) systems. It consists in decoupling control and data planes, to automate the monitoring and management of the communication network, and thus enabling zero touch management of SG systems. However, SDN-based SG is prone to several security threats and varios type of new attacks. To alleviate these issues, various Machine/Deep learning (ML/DL)based intrusion detection systems (IDS) were designed to improve the detection accuracy of conventional IDS. However, they suffer from high variance and/or bias, which may lead to an inaccurate security threat detection. In this context, ensemble learning is an emerging ML technique that aims at combining several ML models; the objective is to generate less data-sensitive (i.e., less variance) and more flexible (i.e., less bias) machine learning models. In this paper, we design a novel framework, called BoostIDS, that leverages ensemble learning to efficiently detect and mitigate security threats in SDN-based SG system. BoostIDS comprises two main modules: (1) A data monitoring and feature selection module that makes use of an efficient Boosting Feature Selection Algorithm to select the best/relevant SG-based features; and (2) An ensemble learning-based threats detection moel that implements a Lightweight Boosting Algorithm (LBA) to timely and effectively detects SG-based attacks in a SDN environment. We conduct extensive experiments to validate BoostIDS on top of multiple real attacks; the obtained results using NSL-KDD and UNSW-NB15 datasets, confirm that BoostIDS can effectively detect/mitigate security threats in SDN-based SG systems, while optimizing training/test time complexity.},
  eventtitle = {2022 {{IEEE}} 47th {{Conference}} on {{Local Computer Networks}} ({{LCN}})},
  isbn = {978-1-66548-001-7},
  langid = {english}
}

@inproceedings{elhouda_LowLatencyFogbasedFramework_2022,
  title = {A {{Low-Latency Fog-based Framework}} to Secure {{IoT Applications}} Using {{Collaborative Federated Learning}}},
  booktitle = {2022 {{IEEE}} 47th {{Conference}} on {{Local Computer Networks}} ({{LCN}})},
  author = {El Houda, Zakaria Abou and Khoukhi, Lyes and Brik, Bouziane},
  date = {2022-09-26},
  pages = {343--346},
  publisher = {IEEE},
  location = {Edmonton, AB, Canada},
  doi = {10.1109/LCN53696.2022.9843315},
  url = {https://ieeexplore.ieee.org/document/9843315/},
  urldate = {2022-08-31},
  abstract = {Attacks against the IoT network are increasing rapidly, leading to an exponential growth in the number of unsecured IoT devices. Existing security mechanisms are facing several issues due to the lack of real-time decisions, high energy consumption, and high time delays. In this context, we propose a novel Low-Latency Fog-based Framework, called FogFed, to secure IoT applications using Fog computing and Federated Learning (FL). The fog brings security mechanisms near IoT devices reducing delays in communication, while FL enables a privacy-aware collaborative learning between IoT while preserving their privacy. FogFed combines two levels of detection, Fog-based IoT attack detection using a binary FL classifier and cloud-based IoT attack detection using a Multiclass FL classifier. The in-depth experiments results with wellknown IoT attack/malware using, the UNSW-NB15 datastet, show the significant accuracy (99\%) and detection rate (99\%), which outperforms centralized ML/DL models, while significantly reducing delays and preserving the privacy.},
  eventtitle = {2022 {{IEEE}} 47th {{Conference}} on {{Local Computer Networks}} ({{LCN}})},
  isbn = {978-1-66548-001-7},
  langid = {english}
}

@inproceedings{elsadig_BiologicalIntrusionPrevention_2010,
  title = {Biological {{Intrusion Prevention}} and {{Self-Healing Model}} for {{Network Security}}},
  booktitle = {2010 {{Second International Conference}} on {{Future Networks}}},
  author = {Elsadig, Muna and Abduallah, Azween},
  date = {2010-01},
  pages = {337--342},
  publisher = {IEEE},
  location = {Sanya, Hainan},
  doi = {10.1109/ICFN.2010.103},
  url = {https://ieeexplore.ieee.org/document/5431824/},
  urldate = {2022-03-31},
  eventtitle = {2010 {{Second International Conference}} on {{Future Networks}} ({{ICFN}} 2010)},
  isbn = {978-1-4244-5666-6 978-0-7695-3940-9},
  langid = {english}
}

@article{elshoush_Alertcorrelationcollaborative_2011,
  title = {Alert Correlation in Collaborative Intelligent Intrusion Detection Systems---{{A}} Survey},
  author = {Elshoush, Huwaida Tagelsir and Osman, Izzeldin Mohamed},
  date = {2011-10-01},
  journaltitle = {Applied Soft Computing},
  shortjournal = {Applied Soft Computing},
  series = {Soft {{Computing}} for {{Information System Security}}},
  volume = {11},
  number = {7},
  pages = {4349--4365},
  issn = {1568-4946},
  doi = {10.1016/j.asoc.2010.12.004},
  url = {https://www.sciencedirect.com/science/article/pii/S156849461000311X},
  urldate = {2024-06-22},
  abstract = {As complete prevention of computer attacks is not possible, intrusion detection systems (IDSs) play a very important role in minimizing the damage caused by different computer attacks. There are two intrusion detection methods: namely misuse- and anomaly-based. A collaborative, intelligent intrusion detection system (CIIDS) is proposed to include both methods, since it is concluded from recent research that the performance of an individual detection engine is rarely satisfactory. In particular, two main challenges in current collaborative intrusion detection systems (CIDSs) research are highlighted and reviewed: CIDSs system architectures and alert correlation algorithms. Different CIDSs system, architectures are explained and compared. The use of CIDSs together with other multiple security systems raise certain issues and challenges in, alert correlation. Several different techniques for alert correlation are discussed. The focus will be on correlation of CIIDS alerts. Computational, Intelligence approaches, together with their applications on IDSs, are reviewed. Methods in soft computing collectively provide understandable, and autonomous solutions to IDS problems. At the end of the review, the paper suggests fuzzy logic, soft computing and other AI techniques, to be exploited to reduce the rate of false alarms while keeping the detection rate high. In conclusion, the paper highlights opportunities for an integrated solution to large-scale CIIDS.},
  keywords = {+survey,Alert correlation,Collaborative intrusion detection,Computational intelligence approaches,False positive analysis}
}

@inproceedings{engelen_TroubleshootingIntrusionDetection_2021,
  title = {Troubleshooting an {{Intrusion Detection Dataset}}: The {{CICIDS2017 Case Study}}},
  shorttitle = {Troubleshooting an {{Intrusion Detection Dataset}}},
  booktitle = {2021 {{IEEE Security}} and {{Privacy Workshops}} ({{SPW}})},
  author = {Engelen, Gints and Rimmer, Vera and Joosen, Wouter},
  date = {2021-05},
  pages = {7--12},
  doi = {10.1109/SPW53761.2021.00009},
  url = {https://ieeexplore.ieee.org/document/9474286},
  urldate = {2024-06-14},
  abstract = {Numerous studies have demonstrated the effectiveness of machine learning techniques in application to network intrusion detection. And yet, the adoption of machine learning for securing large-scale network environments remains challenging. The community acknowledges that network security presents unique challenges for machine learning, and the lack of training data representative of modern traffic remains one of the most intractable issues. New attempts are continuously made to develop high quality benchmark datasets and proper data collection methodologies. The CICIDS2017 dataset is one of the recent results, created to meet the demanding criterion of representativeness for network intrusion detection. In this paper we revisit CICIDS2017 and its data collection pipeline and analyze correctness, validity and overall utility of the dataset for the learning task. During this in-depth analysis, we uncover a series of problems with traffic generation, flow construction, feature extraction and labelling that severely affect the aforementioned properties. We investigate the causes of these shortcomings and address most of them by applying an improved data processing methodology. As a result, more than 20 percent of original traffic traces are reconstructed or relabelled. Machine learning benchmarks on the final dataset demonstrate significant improvements. Our study exemplifies how data collection issues may have enormous impact on model evaluation and provides recommendations for their anticipation and prevention.},
  eventtitle = {2021 {{IEEE Security}} and {{Privacy Workshops}} ({{SPW}})},
  keywords = {benchmark dataset,Benchmark testing,Data collection,data collection.,Documentation,Feature extraction,machine learning,Machine learning,network intrusion detection,Network intrusion detection,Tools}
}

@report{enisa_IncentivesChallengesInformation_2010,
  title = {Incentives and {{Challenges}} for {{Information Sharing}} in the {{Context}} of {{Network}} and {{Information Security}}},
  author = {{ENISA}},
  date = {2010},
  volume = {10},
  pages = {52},
  url = {http://www.google.com/#sclient=psy&hl=en&safe=off&q=literature+review+information+sharing+law+enforcement&aq=f&aqi=&aql=&oq=&gs_rfai=&pbx=1&fp=9bef8cda26d1a6ec},
  abstract = {The importance of information sharing to ensuring network and information security is widely acknowledged by both policy-makers and by the technical and practitioner community -- for example, in the European Programme on Critical Infrastructure Protection (EPCIP) and in the 2004 Availability and Robustness of Electronic Communications Infrastructures (ARECI) study, which noted that formal means for sharing information should be set up in order to \texthorizontalbar improve the protection and rapid restoration of infrastructure critical to the reliability of communications within and throughout Europe\textbardbl. A 2009 gap analysis conducted by ENISA of good practice in respect of telecommunication network operators identified information sharing as a set of useful best practice. Given the acknowledged importance of information sharing, this report sets out findings from a research project into the barriers to and incentives for information sharing in the field of network and information security, in the context of peer-to-peer groups such as Information Exchanges (IE) and Information Sharing Analysis Centres (ISACs).\textbackslash nMethods and approach The information in this report is drawn from three sources: \textbackslash nï‚· A review of available literature -- both academic and non-academic publications, ï‚· Interviews with key informants working in the field of network and information \textbackslash nsecurity and in IEs, ï‚· A two-round Delphi exercise with network and information security professionals. \textbackslash n The aim of this project is to identify those barriers and incentives which are most important in day-to-day practice in IEs and ISACs. This research differs from other work in this field in being firmly grounded in the experiences of practitioners and those involved in IE and Information Sharing activities. Nonetheless we only managed to speak to a limited number of experts from a handful of countries. Therefore, the findings of this research are a first step to developing an evidence base in this field, but we do not claim they are generalisable to all kinds of IEs. \textbackslash nIncentives and challenges for information sharing Our findings indicate that many of the barriers and incentives commonly identified in the \textbackslash navailable literature are of relatively low importance to practitioners and security officials currently working in IEs. As part of this research we asked practitioners to rank a list of barriers and incentives in terms of their relative importance. Our findings indicate that the incentives which are most important are: \textbackslash nï‚· Economic incentives stemming from cost savings; ï‚· Incentives stemming from the quality, value, and use of information shared. \textbackslash n While the barriers which are the most important are: \textbackslash nï‚· Poor quality information; ï‚· Misaligned economic incentives stemming from reputational risks; ï‚· Poor management.}
}

@report{ENISA2010,
  title = {Incentives and {{Challenges}} for {{Information Sharing}} in the {{Context}} of {{Network}} and {{Information Security}}},
  author = {{ENISA}},
  date = {2010},
  volume = {10},
  pages = {52},
  url = {http://www.google.com/#sclient=psy&hl=en&safe=off&q=literature+review+information+sharing+law+enforcement&aq=f&aqi=&aql=&oq=&gs_rfai=&pbx=1&fp=9bef8cda26d1a6ec},
  abstract = {The importance of information sharing to ensuring network and information security is widely acknowledged by both policy-makers and by the technical and practitioner community -- for example, in the European Programme on Critical Infrastructure Protection (EPCIP) and in the 2004 Availability and Robustness of Electronic Communications Infrastructures (ARECI) study, which noted that formal means for sharing information should be set up in order to \texthorizontalbar improve the protection and rapid restoration of infrastructure critical to the reliability of communications within and throughout Europe\textbardbl. A 2009 gap analysis conducted by ENISA of good practice in respect of telecommunication network operators identified information sharing as a set of useful best practice. Given the acknowledged importance of information sharing, this report sets out findings from a research project into the barriers to and incentives for information sharing in the field of network and information security, in the context of peer-to-peer groups such as Information Exchanges (IE) and Information Sharing Analysis Centres (ISACs).\textbackslash nMethods and approach The information in this report is drawn from three sources: \textbackslash nï‚· A review of available literature -- both academic and non-academic publications, ï‚· Interviews with key informants working in the field of network and information \textbackslash nsecurity and in IEs, ï‚· A two-round Delphi exercise with network and information security professionals. \textbackslash n The aim of this project is to identify those barriers and incentives which are most important in day-to-day practice in IEs and ISACs. This research differs from other work in this field in being firmly grounded in the experiences of practitioners and those involved in IE and Information Sharing activities. Nonetheless we only managed to speak to a limited number of experts from a handful of countries. Therefore, the findings of this research are a first step to developing an evidence base in this field, but we do not claim they are generalisable to all kinds of IEs. \textbackslash nIncentives and challenges for information sharing Our findings indicate that many of the barriers and incentives commonly identified in the \textbackslash navailable literature are of relatively low importance to practitioners and security officials currently working in IEs. As part of this research we asked practitioners to rank a list of barriers and incentives in terms of their relative importance. Our findings indicate that the incentives which are most important are: \textbackslash nï‚· Economic incentives stemming from cost savings; ï‚· Incentives stemming from the quality, value, and use of information shared. \textbackslash n While the barriers which are the most important are: \textbackslash nï‚· Poor quality information; ï‚· Misaligned economic incentives stemming from reputational risks; ï‚· Poor management.},
  keywords = {pinned}
}

@report{ENISA2014,
  title = {Actionable {{Information}} for {{Security Incident Response}}},
  author = {{ENISA}},
  date = {2014},
  journaltitle = {Enisa},
  pages = {1--79},
  abstract = {The European Union Agency for Network and Information Security (ENISA) is a centre of network and information security expertise for the EU, its member states, the private sector and Europe's citizens. ENISA works with these groups to develop advice and recommendations on good practice in information security. It assists EU member states in implementing relevant EU legislation and works to improve the resilience of Europe's critical information infrastructure and networks. ENISA seeks to enhance existing expertise in EU member states by supporting the development of cross-border communities committed to improving network and information security throughout the EU. More information about ENISA and its work can be found at www.enisa.europa.eu.},
  isbn = {9789292041076},
  issue = {November},
  keywords = {pinned}
}

@report{ENISA2017,
  title = {Exploring the Opportunities and Limitations of Current {{Threat Intelligence Platforms}}},
  author = {{ENISA}},
  date = {2017},
  pages = {42},
  abstract = {The main objective of this report is to understand the limitations of threat information sharing and the analysis tools that are currently in use. Moreover, the second objective is to provide the relevant recommendations so that these limitations can be addressed and overcome. To achieve this, the report presents an overview of the users of these platforms, the main functional areas of TIPs as well as the current landscape of the TIPs used by different teams globally (CTI teams, SOCs, CSIRTs/CERTs, ISACs, etc.)},
  issue = {December},
  keywords = {pinned}
}

@incollection{enthoven_OverviewFederatedDeep_2021,
  title = {An {{Overview}} of {{Federated Deep Learning Privacy Attacks}} and {{Defensive Strategies}}},
  booktitle = {Federated {{Learning Systems}}: {{Towards Next-Generation AI}}},
  author = {Enthoven, David and Al-Ars, Zaid},
  editor = {family=Rehman, given=Muhammad Habib, prefix=ur, useprefix=false and Gaber, Mohamed Medhat},
  date = {2021},
  series = {Studies in {{Computational Intelligence}}},
  pages = {173--196},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-70604-3_8},
  url = {https://doi.org/10.1007/978-3-030-70604-3_8},
  urldate = {2024-03-06},
  abstract = {With the increased attention and legislation for data-privacy, collaborative machine learning (ML) algorithms are being developed to ensure the protection of private data used for processing. Federated learning (FL) is the most popular of these methods, which provides privacy preservation by facilitating collaborative training of a shared model without the need to exchange any private data with a centralized server. Rather, an abstraction of the data in the form of a machine learning model update is sent. Recent studies showed that such model updates may still very well leak private information and thus a more structured risk assessment is needed. In this chapter, we analyze existing vulnerabilities of FL and subsequently perform a literature review of the possible attack methods targeting FL privacy protection capabilities. These attack methods are then categorized by a basic taxonomy. Additionally, we provide a literature study of the most recent defensive strategies and algorithms for FL aimed to overcome these attacks. These defensive strategies are categorized by their respective underlying defense principle. The chapter advocates that the application of a single defensive strategy is not enough to provide adequate protection against all available attack methods.},
  isbn = {978-3-030-70604-3},
  langid = {english}
}

@article{etesami_DynamicGamesCyberPhysical_2019,
  title = {Dynamic {{Games}} in {{Cyber-Physical Security}}: {{An Overview}}},
  author = {Etesami, S. Rasoul and Ba\c sar, Tamer},
  date = {2019},
  journaltitle = {Dynamic Games and Applications},
  volume = {9},
  number = {4},
  pages = {884--913},
  issn = {21530793},
  doi = {10.1007/s13235-018-00291-y},
  abstract = {Due to complex dependencies between multiple layers and components of emerging cyber-physical systems, security and vulnerability of such systems have become a major challenge in recent years. In this regard, game theory, a powerful tool for modeling strategic interactions between multiple decision makers with conflicting objectives, offers a natural paradigm to address the security-related issues arising in these systems. While there exists substantial amount of work in modeling and analyzing security problems using game-theoretic techniques, most of the existing literature in this area focuses on static game models, ignoring the dynamic nature of interactions between the main players (defenders vs. attackers). In this paper, we focus only on dynamic game analysis of cyber-physical security problems and provide a general overview of the existing results and recent advances based on application domains. We also discuss several limitations of the existing models and identify several hitherto unaddressed directions for future research.},
  isbn = {1323501800}
}

@online{eustace_Pythondependencymanagement_2018,
  title = {Python Dependency Management and Packaging Made Easy},
  author = {Eustace, S\'ebastien},
  date = {2018},
  url = {https://python-poetry.org/},
  urldate = {2024-07-03},
  organization = {Poetry}
}

@inproceedings{falcao_Quantitativecomparisonunsupervised_2019,
  title = {Quantitative Comparison of Unsupervised Anomaly Detection Algorithms for Intrusion Detection},
  booktitle = {Proceedings of the 34th {{ACM}}/{{SIGAPP Symposium}} on {{Applied Computing}}},
  author = {Falc\~ao, Filipe and Zoppi, Tommaso and Silva, Caio Barbosa Viera and Santos, Anderson and Fonseca, Baldoino and Ceccarelli, Andrea and Bondavalli, Andrea},
  date = {2019-04-08},
  series = {{{SAC}} '19},
  pages = {318--327},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3297280.3297314},
  url = {https://doi.org/10.1145/3297280.3297314},
  urldate = {2023-05-11},
  abstract = {Anomaly detection algorithms aim at identifying unexpected fluctuations in the expected behavior of target indicators, and, when applied to intrusion detection, suspect attacks whenever the above deviations are observed. Through years, several of such algorithms have been proposed, evaluated experimentally, and analyzed in qualitative and quantitative surveys. However, the experimental comparison of a comprehensive set of algorithms for anomaly-based intrusion detection against a comprehensive set of attacks datasets and attack types was not investigated yet. To fill such gap, in this paper we experimentally evaluate a pool of twelve unsupervised anomaly detection algorithms on five attacks datasets. Results allow elaborating on a wide range of arguments, from the behavior of the individual algorithm to the suitability of the datasets to anomaly detection. We identify the families of algorithms that are more effective for intrusion detection, and the families that are more robust to the choice of configuration parameters. Further, we confirm experimentally that attacks with unstable and non-repeatable behavior are more difficult to detect, and that datasets where anomalies are rare events usually result in better detection scores.},
  isbn = {978-1-4503-5933-7},
  keywords = {anomaly detection,attack model,attacks datasets,comparison,intrusion detection,unsupervised algorithms}
}

@article{faloutsos_powerlawrelationshipsInternet_1999,
  title = {On Power-Law Relationships of the {{Internet}} Topology},
  author = {Faloutsos, Michalis and Faloutsos, Petros and Faloutsos, Christos},
  date = {1999-08-30},
  journaltitle = {SIGCOMM Comput. Commun. Rev.},
  volume = {29},
  number = {4},
  pages = {251--262},
  issn = {0146-4833},
  doi = {10.1145/316194.316229},
  url = {https://doi.org/10.1145/316194.316229},
  urldate = {2024-07-07},
  abstract = {Despite the apparent randomness of the Internet, we discover some surprisingly simple power-laws of the Internet topology. These power-laws hold for three snapshots of the Internet, between November 1997 and December 1998, despite a 45\% growth of its size during that period. We show that our power-laws fit the real data very well resulting in correlation coefficients of 96\% or higher.Our observations provide a novel perspective of the structure of the Internet. The power-laws describe concisely skewed distributions of graph properties such as the node outdegree. In addition, these power-laws can be used to estimate important parameters such as the average neighborhood size, and facilitate the design and the performance analysis of protocols. Furthermore, we can use them to generate and select realistic topologies for simulation purposes.}
}

@inproceedings{fan_IoTDefenderFederatedTransfer_2020,
  title = {{{IoTDefender}}: {{A Federated Transfer Learning Intrusion Detection Framework}} for {{5G IoT}}},
  shorttitle = {{{IoTDefender}}},
  booktitle = {2020 {{IEEE}} 14th {{International Conference}} on {{Big Data Science}} and {{Engineering}} ({{BigDataSE}})},
  author = {Fan, Yulin and Li, Yang and Zhan, Mengqi and Cui, Huajun and Zhang, Yan},
  date = {2020-12},
  pages = {88--95},
  publisher = {IEEE},
  location = {Guangzhou, China},
  doi = {10.1109/BigDataSE50710.2020.00020},
  url = {https://ieeexplore.ieee.org/document/9343358/},
  urldate = {2021-10-04},
  eventtitle = {2020 {{IEEE}} 14th {{International Conference}} on {{Big Data Science}} and {{Engineering}} ({{BigDataSE}})},
  isbn = {978-1-66540-396-2},
  langid = {english},
  keywords = {survey-fids}
}

@article{fan_LightweightPrivacySecurity_2023,
  title = {Lightweight {{Privacy}} and {{Security Computing}} for {{Blockchained Federated Learning}} in {{IoT}}},
  author = {Fan, Mochan and Ji, Kailai and Zhang, Zhaofeng and Yu, Hongfang and Sun, Gang},
  date = {2023-09},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {10},
  number = {18},
  pages = {16048--16060},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2023.3267112},
  url = {https://ieeexplore.ieee.org/abstract/document/10102683},
  urldate = {2024-04-12},
  abstract = {The development of Internet of Things (IoT) makes human life more intelligent, and the interconnection of all things has become a reality. However, the surge in the number of devices and centralized management brings severe challenges to IoT, such as single point of failure, poor security, privacy leakage, and low reliability. Due to the decentralization, verifiability, and privacy protection of blockchain federated learning (BFL), some BFL schemes have been proposed to solve these problems, but bring new challenges, such as device privacy leakage and heavy security computing load. In this article, we propose a new decentralized, secure and verifiable consortium BFL privacy protection scheme, named LPBFL, which realizes lightweight computing while ensuring the privacy of the local model and data set of the device. To achieve lightweight privacy protection, LPBFL adopts the Paillier encryption and the newly designed lightweight digital signature and batch verification algorithm. Additionally, considering that devices upload invalid or even toxic local models intentionally or unintentionally, we design a device reputation selection mechanism to make BFL more efficient. Finally, the theoretical analysis proves the security of LPBFL and verifies the unforgeability of the proposed digital signature. Comprehensive comparisons and extensive experiments demonstrate that our LPBFL has significant advantages in multiple aspects.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {Blockchain,Blockchains,Computational modeling,Differential privacy,federated learning,Internet of Things,Internet of Things (IoT),Privacy,privacy protection,Security,Training}
}

@article{fan_TakingAdvantageMistakes_2024,
  title = {Taking {{Advantage}} of the {{Mistakes}}: {{Rethinking Clustered Federated Learning}} for {{IoT Anomaly Detection}}},
  shorttitle = {Taking {{Advantage}} of the {{Mistakes}}},
  author = {Fan, Jiamin and Wu, Kui and Tang, Guoming and Zhou, Yang and Huang, Shengqiang},
  date = {2024-06},
  journaltitle = {IEEE Transactions on Parallel and Distributed Systems},
  volume = {35},
  number = {6},
  pages = {707--721},
  issn = {1558-2183},
  doi = {10.1109/TPDS.2024.3379905},
  url = {https://ieeexplore.ieee.org/abstract/document/10476751},
  urldate = {2024-04-12},
  abstract = {Clustered federated learning (CFL) is a promising solution to address the non-IID problem in the spatial domain for federated learning (FL). However, existing CFL solutions overlook the non-IID issue in the temporal domain and lack consideration of time efficiency. In this work, we propose a novel approach, called ClusterFLADS, which takes advantage of the false predictions of the inappropriate global models, together with knowledge of temperature scaling and catastrophic forgetting to reveal distributional similarities between the training data (of different clusters) and the test data. Additionally, we design an efficient feature extraction scheme by exploiting the role of each layer in a neural network's learning process. By strategically selecting model parameters and using PCA for dimensionality reduction, ClusterFLADS effectively improves clustering speed. We evaluate ClusterFLADS using real-world IoT trace data in various scenarios. Our results show that ClusterFLADS accurately and efficiently clusters clients, achieving a 100\% true positive rate and low false positives across various data distributions in both the spatial and temporal domains.},
  eventtitle = {{{IEEE Transactions}} on {{Parallel}} and {{Distributed Systems}}},
  keywords = {Adaptation models,Anomaly detection,Cluster federated learning,Data models,Feature extraction,Federated learning,Internet of Things,IoT traffic anomaly detection,spatial-temporal non-IID problem,Training}
}

@inproceedings{fang_AFLGuardByzantinerobustAsynchronous_2022,
  title = {{{AFLGuard}}: {{Byzantine-robust Asynchronous Federated Learning}}},
  shorttitle = {{{AFLGuard}}},
  booktitle = {Proceedings of the 38th {{Annual Computer Security Applications Conference}}},
  author = {Fang, Minghong and Liu, Jia and Gong, Neil Zhenqiang and Bentley, Elizabeth S.},
  date = {2022-12-05},
  series = {{{ACSAC}} '22},
  pages = {632--646},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3564625.3567991},
  url = {https://doi.org/10.1145/3564625.3567991},
  urldate = {2022-12-14},
  abstract = {Federated learning (FL) is an emerging machine learning paradigm, in which clients jointly learn a model with the help of a cloud server. A fundamental challenge of FL is that the clients are often heterogeneous, e.g., they have different computing powers, and thus the clients may send model updates to the server with substantially different delays. Asynchronous FL aims to address this challenge by enabling the server to update the model once any client's model update reaches it without waiting for other clients' model updates. However, like synchronous FL, asynchronous FL is also vulnerable to poisoning attacks, in which malicious clients manipulate the model via poisoning their local data and/or model updates sent to the server. Byzantine-robust FL aims to defend against poisoning attacks. In particular, Byzantine-robust FL can learn an accurate model even if some clients are malicious and have Byzantine behaviors. However, most existing studies on Byzantine-robust FL focused on synchronous FL, leaving asynchronous FL largely unexplored. In this work, we bridge this gap by proposing AFLGuard, a Byzantine-robust asynchronous FL method. We show that, both theoretically and empirically, AFLGuard is robust against various existing and adaptive poisoning attacks (both untargeted and targeted). Moreover, AFLGuard outperforms existing Byzantine-robust asynchronous FL methods.},
  isbn = {978-1-4503-9759-9},
  keywords = {Byzantine Robustness,Federated Learning,Poisoning Attacks}
}

@article{fang_ComprehensiveAndroidMalware_2023,
  title = {Comprehensive {{Android Malware Detection Based}} on {{Federated Learning Architecture}}},
  author = {Fang, Wenbo and He, Junjiang and Li, Wenshan and Lan, Xiaolong and Chen, Yang and Li, Tao and Huang, Jiwu and Zhang, Linlin},
  date = {2023},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  volume = {18},
  pages = {3977--3990},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2023.3287395},
  url = {https://ieeexplore.ieee.org/abstract/document/10155173},
  urldate = {2024-04-12},
  abstract = {Android malware and its variants are a major challenge for mobile platforms. However, there are two main problems in the existing detection methods: a ) The detection method lacks the evolution ability for Android malware, which leads to the low detection rate of the detection model for malware and its variants. b ) Traditional detection methods require centralized data for model training, however, the aggregation of training samples is limited due to the infectivity of malware and growing data privacy concerns, centralized detection methods are difficult to be applied in actual detection scenarios. In this paper, we propose FEDriod, a comprehensive Android malware detection method based on federated learning architecture that protects against growing Android malware or emerging Android malware variants. Specifically, we employ genetic evolution strategy to simulate the evolution of Android malware and develop potential malware variants from typical Android malware. Then, we customize the Android malware detection model based on residual neural network to achieve high detection accuracy. Finally, to achieve the protection sensitive data, we develope a federated learning framework to allows multiple Android malware detection agencies to jointly build a comprehensive Android malware detection model. We comprehensively evaluate the performance of FEDriod on the CIC, Drebin, and Contagio authoritative datasets. Experimental results show that our local model outperforms all baseline classifiers. In the federal scenario, our proposed method is superior to the state-of-the-art detection methods, especially in the cross-dataset evaluation, the F1 of FEDriod is 98.53\%. More important, we performed genetic evolution experiments on the Drebin dataset, and the results showed that our proposed method has the ability to detect Android malware variants.},
  eventtitle = {{{IEEE Transactions}} on {{Information Forensics}} and {{Security}}},
  keywords = {android malware detection,Deep learning,Evolution (biology),federated learning,Genetic evolution,Genetics,Malware,Operating systems,residual networks,Smart phones,Training}
}

@inproceedings{fang_LocalModelPoisoning_2020,
  title = {Local {{Model Poisoning Attacks}} to {{Byzantine-Robust Federated Learning}}},
  author = {Fang, Minghong and Cao, Xiaoyu and Jia, Jinyuan and Gong, Neil},
  date = {2020},
  pages = {1605--1622},
  url = {https://www.usenix.org/conference/usenixsecurity20/presentation/fang},
  urldate = {2023-02-23},
  eventtitle = {29th {{USENIX Security Symposium}} ({{USENIX Security}} 20)},
  isbn = {978-1-939133-17-5},
  langid = {english}
}

@inproceedings{fang_LocalModelPoisoning_2020a,
  title = {Local {{Model Poisoning Attacks}} to \{\vphantom\}{{Byzantine-Robust}}\vphantom\{\} {{Federated Learning}}},
  author = {Fang, Minghong and Cao, Xiaoyu and Jia, Jinyuan and Gong, Neil},
  date = {2020},
  pages = {1605--1622},
  url = {https://www.usenix.org/conference/usenixsecurity20/presentation/fang},
  urldate = {2024-03-06},
  eventtitle = {29th {{USENIX Security Symposium}} ({{USENIX Security}} 20)},
  isbn = {978-1-939133-17-5},
  langid = {english}
}

@inproceedings{faraj_Taxonomychallengesmachine_2020,
  title = {Taxonomy and Challenges in Machine Learning-Based Approaches to Detect Attacks in the Internet of Things},
  booktitle = {Proceedings of the 15th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Faraj, Omair and Meg\'ias, David and Ahmad, Abdel-Mehsen and Garcia-Alfaro, Joaquin},
  date = {2020-08-25},
  pages = {1--10},
  publisher = {ACM},
  location = {Virtual Event Ireland},
  doi = {10.1145/3407023.3407048},
  url = {https://dl.acm.org/doi/10.1145/3407023.3407048},
  urldate = {2021-06-23},
  abstract = {The insecure growth of Internet-of-Things (IoT) can threaten its promising benefits to our daily life activities. Weak designs, low computational capabilities, and faulty protocol implementations are just a few examples that explain why IoT devices are nowadays highly prone to cyber-attacks. In this survey paper, we review approaches addressing this problem. We focus on machine learningbased solutions as a representative trend in the related literature. We survey and classify Machine Learning (ML)-based techniques that are suitable for the construction of Intrusion Detection Systems (IDS) for IoT. We contribute with a detailed classification of each approach based on our own taxonomy. Open issues and research challenges are also discussed and provided.},
  eventtitle = {{{ARES}} 2020: {{The}} 15th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  isbn = {978-1-4503-8833-7},
  langid = {english}
}

@article{farwell_StuxnetFutureCyber_2011,
  title = {Stuxnet and the {{Future}} of {{Cyber War}}},
  author = {Farwell, James P. and Rohozinski, Rafal},
  date = {2011-02-28},
  journaltitle = {Survival},
  volume = {53},
  number = {1},
  pages = {23--40},
  issn = {0039-6338},
  doi = {10.1080/00396338.2011.555586},
  url = {https://www.tandfonline.com/doi/full/10.1080/00396338.2011.555586}
}

@article{fedorchenko_ComparativeReviewIntrusion_2022,
  title = {Comparative {{Review}} of the {{Intrusion Detection Systems Based}} on {{Federated Learning}}: {{Advantages}} and {{Open Challenges}}},
  shorttitle = {Comparative {{Review}} of the {{Intrusion Detection Systems Based}} on {{Federated Learning}}},
  author = {Fedorchenko, Elena and Novikova, Evgenia and Shulepov, Anton},
  date = {2022-07},
  journaltitle = {Algorithms},
  volume = {15},
  number = {7},
  pages = {247},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1999-4893},
  doi = {10.3390/a15070247},
  url = {https://www.mdpi.com/1999-4893/15/7/247},
  urldate = {2024-04-24},
  abstract = {In order to provide an accurate and timely response to different types of the attacks, intrusion and anomaly detection systems collect and analyze a lot of data that may include personal and other sensitive data. These systems could be considered a source of privacy-aware risks. Application of the federated learning paradigm for training attack and anomaly detection models may significantly decrease such risks as the data generated locally are not transferred to any party, and training is performed mainly locally on data sources. Another benefit of the usage of federated learning for intrusion detection is its ability to support collaboration between entities that could not share their dataset for confidential or other reasons. While this approach is able to overcome the aforementioned challenges it is rather new and not well-researched. The challenges and research questions appear while using it to implement analytical systems. In this paper, the authors review existing solutions for intrusion and anomaly detection based on the federated learning, and study their advantages as well as open challenges still facing them. The paper analyzes the architecture of the proposed intrusion detection systems and the approaches used to model data partition across the clients. The paper ends with discussion and formulation of the open challenges.},
  issue = {7},
  langid = {english},
  keywords = {+survey,artificial intelligence,data partition,federated learning,Internet of Things,intrusion detection,machine learning,system architecture}
}

@article{feng_SemiSupervisedFederatedHeterogeneous_2022,
  title = {Semi-{{Supervised Federated Heterogeneous Transfer Learning}}},
  author = {Feng, Siwei and Li, Boyang and Yu, Han and Liu, Yang and Yang, Qiang},
  date = {2022-09-27},
  journaltitle = {Knowledge-Based Systems},
  shortjournal = {Knowledge-Based Systems},
  volume = {252},
  pages = {109384},
  issn = {0950-7051},
  doi = {10.1016/j.knosys.2022.109384},
  url = {https://www.sciencedirect.com/science/article/pii/S0950705122006943},
  urldate = {2022-08-11},
  abstract = {Federated learning (FL) is a privacy-preserving paradigm that collaboratively train machine learning models with distributed data stored in different silos without exposing sensitive information. Different from most existing FL approaches requiring data from different parties share either the same feature space or sample ID space, federated transfer learning (FTL), which is a recently proposed FL concept, is designed for situations where data from different parties differ not only in samples but also in feature space. However, like most traditional FL approaches, FTL methods also suffer from issues caused by insufficiency of overlapping data. In this paper, we propose a novel FTL framework referred to as Semi-Supervised Federated Heterogeneous Transfer Learning (SFHTL) to leverage on the unlabeled non-overlapping samples to reduce model overfitting as a result of insufficient overlapping training samples in FL scenarios. Unlike existing FTL approaches, SFHTL makes use of non-overlapping samples from all parties to expand the training set for each party to improve local model performance. Through extensive experimental evaluation based on real-world datasets, we demonstrate significant advantages of SFHTL over state-of-the-art approaches.},
  langid = {english},
  keywords = {\_read\_urgently,Data privacy preservation,Federated transfer learning,Non-overlapping data utilization,Training set expansion}
}

@article{feng_Verticalfederatedlearningbased_2022,
  title = {Vertical Federated Learning-Based Feature Selection with Non-Overlapping Sample Utilization},
  author = {Feng, Siwei},
  date = {2022-12-01},
  journaltitle = {Expert Systems with Applications},
  shortjournal = {Expert Systems with Applications},
  volume = {208},
  pages = {118097},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2022.118097},
  url = {https://www.sciencedirect.com/science/article/pii/S095741742201291X},
  urldate = {2022-08-11},
  abstract = {Vertical federated learning (VFL) is a privacy preserving collaborative machine learning technique designed for distributed learning scenarios in which data from different parties have overlap in the sample space. In this paper, a VFL method for feature selection, which is an effective dimensionality reduction technique that selects a subset of informative features from high-dimensional data by eliminating irrelevant and redundant features, is proposed. Because of the potential insufficiency of useful information for learning informative features and the difficulty in sharing raw data among parties due to the increasing awareness of data privacy protection, it is desirable to exploit information from multiple parties without raw data sharing. In this paper, we propose a VFL-based feature selection method that leverages deep learning models as well as complementary information from features in the same samples at multiple parties without data disclosure. In order to further improve feature selection performance, information of samples that do not have features appearing in all parties are also utilized. Promising results in extensive experiments show the effectiveness of the proposed approach in terms of collaborative feature selection without data sharing.},
  langid = {english},
  keywords = {Deep learning,Feature selection,Privacy protection,Vertical federated learning}
}

@article{fereidooni_SAFELearnSecureAggregation_2021,
  title = {{{SAFELearn}}: {{Secure Aggregation}} for Private {{FEderated Learning}}},
  author = {Fereidooni, Hossein and Marchal, Samuel and Miettinen, Markus and Mirhoseini, Azalia and M\"ollering, Helen and Nguyen, Thien Duc and Rieger, Phillip and Sadeghi, Ahmad-Reza and Schneider, Thomas and Yalame, Hossein and Zeitouni, Shaza},
  date = {2021},
  pages = {8},
  abstract = {Federated learning (FL) is an emerging distributed machine learning paradigm which addresses critical data privacy issues in machine learning by enabling clients, using an aggregation server (aggregator), to jointly train a global model without revealing their training data. Thereby, it improves not only privacy but is also efficient as it uses the computation power and data of potentially millions of clients for training in parallel. However, FL is vulnerable to so-called inference attacks by malicious aggregators which can infer information about clients' data from their model updates. Secure aggregation restricts the central aggregator to only learn the summation or average of the updates of clients. Unfortunately, existing protocols for secure aggregation for FL suffer from high communication, computation, and many communication rounds.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@inproceedings{fernandezvazquez_Conceptualframeworkcyber_2012,
  title = {Conceptual Framework for Cyber Defense Information Sharing within Trust Relationships},
  booktitle = {2012 4th {{International Conference}} on {{Cyber Conflict}} ({{CYCON}} 2012)},
  author = {Fern\'andez V\'azquez, Diego and Pastor Acosta, Oscar and Spirito, Christopher and Brown, Sarah and Reid, Emily},
  date = {2012-06},
  pages = {1--17},
  issn = {2325-5366},
  abstract = {Information and Communication Technologies are increasingly intertwined across the economies and societies of developed countries. Protecting these technologies from cyberthreats requires collaborative relationships for exchanging cyber defense data and an ability to establish trusted relationships. The fact that Communication and Information Systems (CIS) security1 is an international issue increases the complexity of these relationships. Cyber defense collaboration presents specific challenges since most entities would like to share cyber-related data but lack a successful model to do so. We will explore four aspects of cyber defense collaboration to identify approaches for improving cyber defense information sharing. First, incentives and barriers for information sharing, which includes the type of information that may be of interest to share and the motivations that cause social networks to be used or stagnate. Second, collaborative risk management and information value perception. This includes risk management approaches that have built-in mechanisms for sharing and receiving information, increasing transparency, and improving entity peering relationships. Third, we explore procedural models for improving data exchange, with a focus on inter-governmental collaborative challenges. Fourth, we explore automation of sharing mechanisms for commonly shared cyber defense data (e.g., vulnerabilities, threat actors, black/ white lists). In order to reach a common understanding of terminology in this paper, we leverage the NATO CIS Security Capability Breakdown [19], published in November 2011, which is designed to identify and describe (CIS) security and cyber defense terminology and definitions to facilitate NATO, national, and multi-national discussion, coordination, and capability development.},
  isbn = {978-9949-9040-8-2}
}

@article{ferrag_EdgeIIoTsetNewComprehensive_2022,
  title = {Edge-{{IIoTset}}: {{A New Comprehensive Realistic Cyber Security Dataset}} of {{IoT}} and {{IIoT Applications}} for {{Centralized}} and {{Federated Learning}}},
  shorttitle = {Edge-{{IIoTset}}},
  author = {Ferrag, Mohamed Amine and Friha, Othmane and Hamouda, Djallel and Maglaras, Leandros and Janicke, Helge},
  date = {2022},
  journaltitle = {IEEE Access},
  volume = {10},
  pages = {40281--40306},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3165809},
  url = {https://ieeexplore.ieee.org/document/9751703},
  urldate = {2024-04-12},
  abstract = {In this paper, we propose a new comprehensive realistic cyber security dataset of IoT and IIoT applications, called Edge-IIoTset, which can be used by machine learning-based intrusion detection systems in two different modes, namely, centralized and federated learning. Specifically, the dataset has been generated using a purpose-built IoT/IIoT testbed with a large representative set of devices, sensors, protocols and cloud/edge configurations. The IoT data are generated from various IoT devices (more than 10 types) such as Low-cost digital sensors for sensing temperature and humidity, Ultrasonic sensor, Water level detection sensor, pH Sensor Meter, Soil Moisture sensor, Heart Rate Sensor, Flame Sensor, etc.). Furthermore, we identify and analyze fourteen attacks related to IoT and IIoT connectivity protocols, which are categorized into five threats, including, DoS/DDoS attacks, Information gathering, Man in the middle attacks, Injection attacks, and Malware attacks. In addition, we extract features obtained from different sources, including alerts, system resources, logs, network traffic, and propose new 61 features with high correlations from 1176 found features. After processing and analyzing the proposed realistic cyber security dataset, we provide a primary exploratory data analysis and evaluate the performance of machine learning approaches (i.e., traditional machine learning as well as deep learning) in both centralized and federated learning modes. The Edge-IIoTset dataset can be publicly accessed from http://ieee-dataport.org/8939.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Computer crime,Computer security,Cybersecurity applications,deep learning,edge computing,federated learning,Industrial Internet of Things,IoT datasets,Protocols,Security,Sensors,Temperature sensors}
}

@article{foglietta_DetectingCyberAttacksMitigating_2019,
  title = {From {{Detecting Cyber-Attacks}} to {{Mitigating Risk Within}} a {{Hybrid Environment}}},
  author = {Foglietta, Chiara and Masucci, Dario and Palazzo, Cosimo and Santini, Riccardo and Panzieri, Stefano and Rosa, Luis and Cruz, Tiago and Lev, Leonid},
  date = {2019-03},
  journaltitle = {IEEE Systems Journal},
  shortjournal = {IEEE Systems Journal},
  volume = {13},
  number = {1},
  pages = {424--435},
  issn = {1932-8184, 1937-9234, 2373-7816},
  doi = {10.1109/JSYST.2018.2824252},
  url = {https://ieeexplore.ieee.org/document/8352138/},
  urldate = {2021-05-19},
  abstract = {Telecommunication networks based on commonplace technologies (such as Ethernet) often constitute a vulnerable attack vector against modern critical infrastructures (CIs), particularly for supervisory control and data acquisition (SCADA) systems, which rely on them for monitoring and controlling physical components. This paper presents a unique platform that encompasses a range of capabilities, from cyber-attack detection to mitigation strategies, through interdependency and risk evaluation. The platform is made of two main components: a cyber-attack detection subsystem and a risk assessment framework. Both blocks are innovative from research point of view and they have been developed and customized to fit the CIs' features, that are completely different from telecommunication networks. This platform has been tested on a hybrid environment testbed, made of virtual and real components, within the scope of the EU FP7 CockpitCI and EU H2020 ATENA projects. The case study corresponds to a medium voltage power grid controlled by a SCADA control center, where the platform has been validated with optimal results in terms of detection capabilities and time response.},
  langid = {english},
  keywords = {\_read}
}

@article{folino_Ensemblebasedcollaborative_2016,
  title = {Ensemble Based Collaborative and Distributed Intrusion Detection Systems: {{A}} Survey},
  shorttitle = {Ensemble Based Collaborative and Distributed Intrusion Detection Systems},
  author = {Folino, Gianluigi and Sabatino, Pietro},
  date = {2016-05},
  journaltitle = {Journal of Network and Computer Applications},
  shortjournal = {Journal of Network and Computer Applications},
  volume = {66},
  pages = {1--16},
  issn = {10848045},
  doi = {10.1016/j.jnca.2016.03.011},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1084804516300248},
  urldate = {2024-06-22},
  abstract = {Modern network intrusion detection systems must be able to handle large and fast changing data, often also taking into account real-time requirements. Ensemble-based data mining algorithms and their distributed implementations are a promising approach to these issues.},
  langid = {english},
  keywords = {+survey}
}

@article{folino_ensemblebasedevolutionaryframework_2010,
  title = {An Ensemble-Based Evolutionary Framework for Coping with Distributed Intrusion Detection},
  author = {Folino, Gianluigi and Pizzuti, Clara and Spezzano, Giandomenico},
  date = {2010-06-01},
  journaltitle = {Genetic Programming and Evolvable Machines},
  shortjournal = {Genet Program Evolvable Mach},
  volume = {11},
  number = {2},
  pages = {131--146},
  issn = {1573-7632},
  doi = {10.1007/s10710-010-9101-6},
  url = {https://doi.org/10.1007/s10710-010-9101-6},
  urldate = {2024-06-23},
  abstract = {A distributed data mining algorithm to improve the detection accuracy when classifying malicious or unauthorized network activity is presented. The algorithm is based on genetic programming (GP) extended with the ensemble paradigm. GP ensemble is particularly suitable for distributed intrusion detection because it allows to build a network profile by combining different classifiers that together provide complementary information. The main novelty of the algorithm is that data is distributed across multiple autonomous sites and the learner component acquires useful knowledge from this data in a cooperative way. The network profile is then used to predict abnormal behavior. Experiments on the KDD Cup 1999 Data show the capability of genetic programming in successfully dealing with the problem of intrusion detection on distributed data.},
  langid = {english},
  keywords = {Distributed evolutionary algorithms,Ensemble classifiers,Intrusion detection}
}

@inproceedings{fong_InterpretableExplanationsBlack_2017,
  title = {Interpretable {{Explanations}} of {{Black Boxes}} by {{Meaningful Perturbation}}},
  author = {Fong, Ruth C. and Vedaldi, Andrea},
  date = {2017},
  pages = {3429--3437},
  url = {https://openaccess.thecvf.com/content_iccv_2017/html/Fong_Interpretable_Explanations_of_ICCV_2017_paper.html},
  urldate = {2023-03-11},
  eventtitle = {Proceedings of the {{IEEE International Conference}} on {{Computer Vision}}}
}

@inproceedings{fontugne_MAWILabCombiningDiverse_2010,
  title = {{{MAWILab}} : {{Combining Diverse Anomaly Detectors}} for {{Automated Anomaly Labeling}} and {{Performance Benchmarking}}},
  shorttitle = {{{MAWILab}}},
  author = {Fontugne, Romain and Borgnat, Pierre and Abry, Patrice and Fukuda, Kensuke},
  date = {2010-11-30},
  publisher = {ACM},
  url = {https://ens-lyon.hal.science/ensl-00552071},
  urldate = {2024-06-19},
  abstract = {Evaluating anomaly detectors is a crucial task in traffic monitoring made particularly difficult due to the lack of ground truth. The goal of the present article is to assist researchers in the evaluation of detectors by providing them with labeled anomaly traffic traces. We aim at automatically finding anomalies in the MAWI archive using a new methodology that combines different and independent detectors. A key challenge is to compare the alarms raised by these detectors, though they operate at different traffic granularities. The main contribution is to propose a reliable graph-based methodology that combines any anomaly detector outputs. We evaluated four unsupervised combination strategies; the best is the one that is based on dimensionality reduction. The synergy between anomaly detectors permits to detect twice as many anomalies as the most accurate detector, and to reject numerous false positive alarms reported by the detectors. Significant anomalous traffic features are extracted from reported alarms, hence the labels assigned to theMAWI archive are concise. The results on the MAWI traffic are publicly available and updated daily. Also, this approach permits to include the results of upcoming anomaly detectors so as to improve over time the quality and variety of labels.},
  eventtitle = {{{ACM CoNEXT}} 2010},
  langid = {english}
}

@article{fotiadou_IncidentsInformationSharing_2020,
  title = {Incidents {{Information Sharing Platform}} for {{Distributed Attack Detection}}},
  author = {Fotiadou, Konstantina and Velivassaki, Terpsichori-Helen and Voulkidis, Artemis and Railis, Konstantinos and Trakadas, Panagiotis and Zahariadis, Theodore},
  date = {2020},
  journaltitle = {IEEE Open Journal of the Communications Society},
  volume = {1},
  pages = {593--605},
  issn = {2644-125X},
  doi = {10.1109/OJCOMS.2020.2989925},
  abstract = {Intrusion detection plays a critical role in cyber-security domain since malicious attacks cause irreparable damages to cyber-systems. In this work, we propose the I2SP prototype, which is a novel Information Sharing Platform, able to gather, pre-process, model, and distribute network-traffic information. Within the I2SP prototype we build several challenging deep feature learning models for network-traffic intrusion detection. The learnt representations will be utilized for classifying each new network measurement into its corresponding threat level. We evaluate our prototype's performance by conducting case studies using cyber-security data extracted from the Malware Information Sharing Platform (MISP)-API. To the best of our knowledge, we are the first that combine the MISP-API in order to construct an information sharing mechanism that supports multiple novel deep feature learning architectures for intrusion detection. Experimental results justify that the proposed deep feature learning techniques are able to predict accurately MISP threat-levels.},
  eventtitle = {{{IEEE Open Journal}} of the {{Communications Society}}},
  keywords = {{network intrusion detection, anomaly detection},Anomaly detection,Computer architecture,convolutional neural networks,deep feature learning,Feature extraction,Intrusion detection,long-short memory neural networks,Malware,Malware information sharing platform,Prototypes,stacked-sparse autoencoders}
}

@report{francois_ResearchChallengesCoupling_2024,
  type = {Internet Draft},
  title = {Research {{Challenges}} in {{Coupling Artificial Intelligence}} and {{Network Management}}},
  author = {Fran\c cois, J\'er\^ome and Clemm, Alexander and Papadimitriou, Dimitri and Fernandes, Stenio and Schneider, Stefan},
  date = {2024-03-04},
  number = {draft-irtf-nmrg-ai-challenges-03},
  institution = {Internet Engineering Task Force},
  url = {https://datatracker.ietf.org/doc/draft-irtf-nmrg-ai-challenges},
  urldate = {2024-07-10},
  abstract = {This document is intended to introduce the challenges to overcome when Network Management (NM) problems may require to couple with Artificial Intelligence (AI) solutions. On the one hand, there are many difficult problems in NM that to this date have no good solutions, or where any solutions come with significant limitations and constraints. Artificial Intelligence may help produce novel solutions to those problems. On the other hand, for several reasons (computational costs of AI solutions, privacy of data), distribution of AI tasks became primordial. It is thus also expected that network are operated efficiently to support those tasks. To identify the right set of challenges, the document defines a method based on the evolution and nature of NM problems. This will be done in parallel with advances and the nature of existing solutions in AI in order to highlight where AI and NM have been already coupled together or could benefit from a higher integration. So, the method aims at evaluating the gap between NM problems and AI solutions. Challenges are derived accordingly, assuming solving these challenges will help to reduce the gap between NM and AI.},
  pagetotal = {41}
}

@article{fridehparastar_OndeviceMLCurrent_2022,
  title = {On-Device {{ML For}} the {{Current}} and the {{Emerging Networks}}: {{A Survey}} on {{Current Approaches}} and {{Challenges}}},
  shorttitle = {On-Device {{ML For}} the {{Current}} and the {{Emerging Networks}}},
  author = {Frideh Parastar and Sepahi, Mohammad},
  date = {2022},
  publisher = {Unpublished},
  doi = {10.13140/RG.2.2.15410.89288},
  url = {https://rgdoi.net/10.13140/RG.2.2.15410.89288},
  urldate = {2022-07-05},
  abstract = {MU-MIMO Data-Driven Optimization on Downlink Commodity Wi-Fi View project All content following this page was uploaded by Mohammad Sepahi on 19 April 2022. The user has requested enhancement of the downloaded file.},
  langid = {english},
  keywords = {+survey}
}

@article{friha_2DFIDSDecentralizeddifferentially_2023,
  title = {{{2DF-IDS}}: {{Decentralized}} and Differentially Private Federated Learning-Based Intrusion Detection System for Industrial {{IoT}}},
  shorttitle = {{{2DF-IDS}}},
  author = {Friha, Othmane and Ferrag, Mohamed Amine and Benbouzid, Mohamed and Berghout, Tarek and Kantarci, Burak and Choo, Kim-Kwang Raymond},
  date = {2023-04-01},
  journaltitle = {Computers \& Security},
  shortjournal = {Computers \& Security},
  volume = {127},
  pages = {103097},
  issn = {0167-4048},
  doi = {10.1016/j.cose.2023.103097},
  url = {https://www.sciencedirect.com/science/article/pii/S016740482300007X},
  urldate = {2024-04-12},
  abstract = {Advanced technologies, such as the Internet of Things (IoT) and Artificial Intelligence (AI), underpin many of the innovations in Industry 4.0. However, the interconnectivity and open nature of such systems in smart industrial facilities can also be targeted and abused by malicious actors, which reinforces the importance of cyber security. In this paper, we present a secure, decentralized, and Differentially Private (DP) Federated Learning (FL)-based IDS (2DF-IDS), for securing smart industrial facilities. The proposed 2DF-IDS comprises three building blocks, namely: a key exchange protocol (for securing the communicated weights among all peers in the system), a differentially private gradient exchange scheme (achieve improved privacy of the FL approach), and a decentralized FL approach (that mitigates the single point of failure/attack risk associated with the aggregation server in the conventional FL approach). We evaluate our proposed system through detailed experiments using a real-world IoT/IIoT dataset, and the results show that the proposed 2DF-IDS system can identify different types of cyber attacks in an Industrial IoT system with high performance. For instance, the proposed system achieves comparable performance (94.37\%) with the centralized learning approach (94.37\%) and outperforms the FL-based approach (93.91\%) in terms of accuracy. The proposed system is also shown to improve the overall performance by 12\%, 13\%, and 9\% in terms of F1-score, recall, and precision, respectively, under strict privacy settings when compared to other competing FL-based IDS solutions.},
  keywords = {Cybersecurity,Decentralized federated learning,Differential privacy,Industry 4.0,Intrusion detection,IoT/IIoT security,Post-Quantum cryptography,Privacy}
}

@article{friha_FELIDSFederatedlearningbased_2022,
  title = {{{FELIDS}}: {{Federated}} Learning-Based Intrusion Detection System for Agricultural {{Internet}} of {{Things}}},
  shorttitle = {{{FELIDS}}},
  author = {Friha, Othmane and Ferrag, Mohamed Amine and Shu, Lei and Maglaras, Leandros and Choo, Kim-Kwang Raymond and Nafaa, Mehdi},
  date = {2022-07-01},
  journaltitle = {Journal of Parallel and Distributed Computing},
  shortjournal = {Journal of Parallel and Distributed Computing},
  volume = {165},
  pages = {17--31},
  issn = {0743-7315},
  doi = {10.1016/j.jpdc.2022.03.003},
  url = {https://www.sciencedirect.com/science/article/pii/S0743731522000570},
  urldate = {2024-04-12},
  abstract = {In this paper, we propose a federated learning-based intrusion detection system, named FELIDS, for securing agricultural-IoT infrastructures. Specifically, the FELIDS system protects data privacy through local learning, where devices benefit from the knowledge of their peers by sharing only updates from their model with an aggregation server that produces an improved detection model. In order to prevent Agricultural IoTs attacks, the FELIDS system employs three deep learning classifiers, namely, deep neural networks, convolutional neural networks, and recurrent neural networks. We study the performance of the proposed IDS on three different sources, including, CSE-CIC-IDS2018, MQTTset, and InSDN. The results demonstrate that the FELIDS system outperforms the classic/centralized versions of machine learning (non-federated learning) in protecting the privacy of IoT devices data and achieves the highest accuracy in detecting attacks.},
  keywords = {Deep learning,Federated learning,Internet of Things,Privacy,Security}
}

@inproceedings{fu_LabelInferenceAttacks_2022,
  title = {Label {{Inference Attacks Against Vertical Federated Learning}}},
  author = {Fu, Chong and Zhang, Xuhong and Ji, Shouling and Chen, Jinyin and Wu, Jingzheng and Guo, Shanqing and Zhou, Jun and Liu, Alex X. and Wang, Ting},
  date = {2022},
  pages = {1397--1414},
  url = {https://www.usenix.org/conference/usenixsecurity22/presentation/fu-chong},
  urldate = {2022-08-12},
  eventtitle = {31st {{USENIX Security Symposium}} ({{USENIX Security}} 22)},
  isbn = {978-1-939133-31-1},
  langid = {english}
}

@article{fung_DirichletBasedTrustManagement_2011,
  title = {Dirichlet-{{Based Trust Management}} for {{Effective Collaborative Intrusion Detection Networks}}},
  author = {Fung, Carol J and Zhang, Jie and Aib, Issam and Boutaba, Raouf},
  date = {2011-06},
  journaltitle = {IEEE Transactions on Network and Service Management},
  volume = {8},
  number = {2},
  pages = {79--91},
  issn = {1932-4537},
  doi = {10.1109/TNSM.2011.050311.100028},
  abstract = {The accuracy of detecting intrusions within a Collaborative Intrusion Detection Network (CIDN) depends on the efficiency of collaboration between peer Intrusion Detection Systems (IDSes) as well as the security itself of the CIDN. In this paper, we propose Dirichlet-based trust management to measure the level of trust among IDSes according to their mutual experience. An acquaintance management algorithm is also proposed to allow each IDS to manage its acquaintances according to their trustworthiness. Our approach achieves strong scalability properties and is robust against common insider threats, resulting in an effective CIDN. We evaluate our approach based on a simulated CIDN, demonstrating its improved robustness, efficiency and scalability for collaborative intrusion detection in comparison with other existing models.},
  eventtitle = {{{IEEE Transactions}} on {{Network}} and {{Service Management}}},
  keywords = {admission control,Collaboration,Collaborative intrusion detection system,computer security,Equations,Intrusion detection,Mathematical model,Peer to peer computing,Robustness,Scalability,security management,trust management}
}

@article{fung_DirichletBasedTrustManagement_2011a,
  title = {Dirichlet-{{Based Trust Management}} for {{Effective Collaborative Intrusion Detection Networks}}},
  author = {Fung, Carol J and Zhang, Jie and Aib, Issam and Boutaba, Raouf},
  date = {2011-06},
  journaltitle = {IEEE Transactions on Network and Service Management},
  volume = {8},
  number = {2},
  pages = {79--91},
  issn = {1932-4537},
  doi = {10.1109/TNSM.2011.050311.100028},
  abstract = {The accuracy of detecting intrusions within a Collaborative Intrusion Detection Network (CIDN) depends on the efficiency of collaboration between peer Intrusion Detection Systems (IDSes) as well as the security itself of the CIDN. In this paper, we propose Dirichlet-based trust management to measure the level of trust among IDSes according to their mutual experience. An acquaintance management algorithm is also proposed to allow each IDS to manage its acquaintances according to their trustworthiness. Our approach achieves strong scalability properties and is robust against common insider threats, resulting in an effective CIDN. We evaluate our approach based on a simulated CIDN, demonstrating its improved robustness, efficiency and scalability for collaborative intrusion detection in comparison with other existing models.},
  eventtitle = {{{IEEE Transactions}} on {{Network}} and {{Service Management}}},
  keywords = {admission control,Collaboration,Collaborative intrusion detection system,computer security,Equations,Intrusion detection,Mathematical model,Peer to peer computing,Robustness,Scalability,security management,trust management}
}

@article{fung_FACIDtrustbasedcollaborative_2016,
  title = {{{FACID}}: {{A}} Trust-Based Collaborative Decision Framework for Intrusion Detection Networks},
  shorttitle = {{{FACID}}},
  author = {Fung, Carol J. and Zhu, Quanyan},
  date = {2016-12-15},
  journaltitle = {Ad Hoc Networks},
  shortjournal = {Ad Hoc Networks},
  volume = {53},
  pages = {17--31},
  issn = {1570-8705},
  doi = {10.1016/j.adhoc.2016.08.014},
  url = {https://www.sciencedirect.com/science/article/pii/S1570870516302062},
  urldate = {2022-07-07},
  abstract = {Computer systems evolve to be more complex and vulnerable. Cyber attacks have also grown to be more sophisticated and harder to detect. Intrusion detection is the process of monitoring and identifying unauthorized system access or manipulation. It becomes increasingly difficult for a single intrusion detection system (IDS) to detect all attacks due to limited knowledge about attacks. Collaboration among intrusion detection devices can be used to gain higher detection accuracy and cost efficiency as compared to its traditional single host-based counterpart. Through cooperation, a local IDS can detect new attacks that may be known to other IDSs, which may be from different vendors. However, how to utilize the diagnosis from different IDSs to perform intrusion detection is the key challenge. This paper proposes a system architecture of a collaborative intrusion detection network (CIDN), in which trustworthy and efficient feedback aggregation is a key component. To achieve a reliable and trustworthy CIDN, we present a framework called FACID, which leverages data analytical models and hypothesis testing methods for efficient, distributed and sequential feedback aggregations. FACID provides an inherent trust evaluation mechanism and reduces communication overhead needed for IDSs as well as the computational resources and memory needed to achieve satisfactory feedback aggregation results when the number of collaborators of an IDS is large. Our simulation results corroborate our theoretical results and demonstrate the properties of cost efficiency and accuracy compared to other heuristic methods. The analytical result on the lower-bound of the average number of acquaintances for consultation is essential for the design and configuration of IDSs in a collaborative environment.},
  langid = {english},
  keywords = {Cooperative networks,Distributed algorithms,Intrusion detection networks,Resource allocations}
}

@inproceedings{fung_LimitationsFederatedLearning_2020,
  title = {The {{Limitations}} of {{Federated Learning}} in {{Sybil Settings}}},
  booktitle = {23rd {{International Symposium}} on {{Research}} in {{Attacks}}, {{Intrusions}} and {{Defenses}} (\{\vphantom\}{{RAID}}\vphantom\{\} 2020)},
  author = {Fung, Clement and Yoon, Chris J.M. M and Beschastnikh, Ivan},
  date = {2020-10},
  pages = {301--316},
  publisher = {\{USENIX\} Association},
  location = {San Sebastian},
  url = {https://www.usenix.org/conference/raid2020/presentation/fung},
  abstract = {Federated learning over distributed multi-party data is an emerging paradigm that iteratively aggregates updates from a group of devices to train a globally shared model. Relying on a set of devices, however, opens up the door for sybil attacks: malicious devices may be controlled by a single adversary who directs these devices to attack the system. We consider the susceptibility of federated learning to sybil attacks and propose a taxonomy of sybil objectives and strategies in this setting. We describe a new DoS attack that we term training inflation and present several ways to carry out this attack. We then evaluate recent distributed ML fault tolerance proposals and show that these are insufficient to mitigate several sybil-based attacks. Finally, we introduce a defense against targeted sybil-based poisoning called FoolsGold, which identifies sybils based on the diversity of client updates. We show that FoolsGold exceeds state of the art approaches when countering several types of poisoning attacks.},
  isbn = {978-1-939133-18-2}
}

@inproceedings{fung_limitationsfederatedlearning_2020a,
  title = {The Limitations of Federated Learning in Sybil Settings},
  booktitle = {23rd International Symposium on Research in Attacks, Intrusions and Defenses ({{RAID}} 2020)},
  author = {Fung, Clement and Yoon, Chris J. M. and Beschastnikh, Ivan},
  date = {2020-10},
  pages = {301--316},
  publisher = {USENIX Association},
  location = {San Sebastian},
  url = {https://www.usenix.org/conference/raid2020/presentation/fung},
  isbn = {978-1-939133-18-2}
}

@article{fung_MitigatingSybilsFederated_2018,
  title = {Mitigating {{Sybils}} in {{Federated Learning Poisoning}}},
  author = {Fung, Clement and Yoon, Chris J. M. and Beschastnikh, Ivan},
  date = {2018-08-14},
  journaltitle = {arXiv},
  issn = {23318422},
  url = {http://arxiv.org/abs/1808.04866},
  abstract = {Machine learning (ML) over distributed multi-party data is required for a variety of domains. Existing approaches, such as federated learning, collect the outputs computed by a group of devices at a central aggregator and run iterative algorithms to train a globally shared model. Unfortunately, such approaches are susceptible to a variety of attacks, including model poisoning, which is made substantially worse in the presence of sybils. In this paper we first evaluate the vulnerability of federated learning to sybil-based poisoning attacks. We then describe \textbackslash emph\{FoolsGold\}, a novel defense to this problem that identifies poisoning sybils based on the diversity of client updates in the distributed learning process. Unlike prior work, our system does not bound the expected number of attackers, requires no auxiliary information outside of the learning process, and makes fewer assumptions about clients and their data. In our evaluation we show that FoolsGold exceeds the capabilities of existing state of the art approaches to countering sybil-based label-flipping and backdoor poisoning attacks. Our results hold for different distributions of client data, varying poisoning targets, and various sybil strategies. Code can be found at: https://github.com/DistributedML/FoolsGold},
  keywords = {â›” No DOI found}
}

@inproceedings{fung_TrustManagementHostBased_2008,
  title = {Trust {{Management}} for {{Host-Based Collaborative Intrusion Detection}}},
  booktitle = {Managing {{Large-Scale Service Deployment}}},
  author = {Fung, Carol J. and Baysal, Olga and Zhang, Jie and Aib, Issam and Boutaba, Raouf},
  editor = {De Turck, Filip and Kellerer, Wolfgang and Kormentzas, George},
  date = {2008},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {109--122},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-87353-2_9},
  abstract = {The accuracy of detecting an intrusion within a network of intrusion detection systems (IDSes) depends on the efficiency of collaboration between member IDSes. The security itself within this network is an additional concern that needs to be addressed. In this paper, we present a trust-based framework for secure and effective collaboration within an intrusion detection network (IDN). In particular, we define a trust model that allows each IDS to evaluate the trustworthiness of others based on personal experience. We prove the correctness of our approach in protecting the IDN. Additionally, experimental results demonstrate that our system yields a significant improvement in detecting intrusions. The trust model further improves the robustness of the collaborative system against malicious attacks.},
  isbn = {978-3-540-87353-2},
  langid = {english},
  keywords = {Collaboration,Decay,Intrusion detection Network,Peer-to-Peer,Security,Trust Management}
}

@inproceedings{gao_FedSeCRobustDifferential_2022,
  title = {{{FedSeC}}: A {{Robust Differential Private Federated Learning Framework}} in {{Heterogeneous Networks}}},
  shorttitle = {{{FedSeC}}},
  booktitle = {2022 {{IEEE Wireless Communications}} and {{Networking Conference}} ({{WCNC}})},
  author = {Gao, Zhipeng and Duan, Yingwen and Yang, Yang and Rui, Lanlan and Zhao, Chen},
  date = {2022-04},
  pages = {1868--1873},
  issn = {1558-2612},
  doi = {10.1109/WCNC51071.2022.9771929},
  abstract = {Federated learning (FL) is considered to be a promising paradigm to solve data privacy disclosure in large-scale machine learning. To further enhance the privacy protection of federated learning, prior works incorporate the differentially private data perturbation into the federated system. But it is not feasible given the impairment of the model from noise, as adding Gaussian noise to achieve differential privacy (DP) deteriorates the accuracy of the model. In particular, the assumption that the sophisticated system is homogeneous is not realistic for real scenarios. Heterogeneous networks exacerbate noise disruptions. In this paper, we present FedSeC, a novel differential private federated learning (DP-FL) framework which operates with robust convergence and high-accuracy while achieving adequate privacy protection. FedSeC improves upon naive combinations of federated learning and differential privacy approaches with an updates-based optimization of relative-staleness and semi-synchronous approach for fast convergence in heterogeneous networks. Moreover, we propose a valid client selection scheme to trade-off fair resource allocation and discriminatory incentives. Through extensive experimental validation of our method in three different heterogeneities, we show that FedSeC outperforms the previous state-of-the-art method.},
  eventtitle = {2022 {{IEEE Wireless Communications}} and {{Networking Conference}} ({{WCNC}})},
  keywords = {Collaborative work,Differential privacy,Distributed machine learning,Federated learning,Gaussian noise,Heterogeneous networks,Machine learning,Perturbation methods,Privacy}
}

@article{gao_SVeriFLSuccessiveverifiable_2023,
  title = {{{SVeriFL}}: {{Successive}} Verifiable Federated Learning with Privacy-Preserving},
  shorttitle = {{{SVeriFL}}},
  author = {Gao, Hang and He, Ningxin and Gao, Tiegang},
  date = {2023-04-01},
  journaltitle = {Information Sciences},
  shortjournal = {Information Sciences},
  volume = {622},
  pages = {98--114},
  issn = {0020-0255},
  doi = {10.1016/j.ins.2022.11.124},
  url = {https://www.sciencedirect.com/science/article/pii/S0020025522014359},
  urldate = {2022-12-14},
  abstract = {With federated learning, one of the most notable features is that it can update global model parameter without using the users' local data. However, various security and privacy problems still exist in the process of federated learning. The problem of devising a secure and verifiable federated learning framework, so as to obtain high performance federated learning model and protect right and interests of participants has not been sufficiently studied, the malicious server may conduct dishonest data aggregation and return incorrect aggregated gradients to all the participants. What is more, the server with ulterior motives may return correct aggregated results to some participants, but return wrong results to the specific participant. To solve the above problems, we propose the SVeriFL, a successive verifiable federated learning with privacy-preserving in this work. In specific, an elaborately designed protocol based on BLS signature and multi-party security is introduced, such that the integrity of parameter uploaded by participant and correctness of aggregated results of server can be verified; the consistency of aggregation results received from server between any multiple participants can also be testified. Moreover, the CKKS approximate homomorphic encryption is used to protect data privacy of the participant. Experimental results and analyses validate the practical performance and computation efficiency of the presented SVeriFL.},
  langid = {english},
  keywords = {Approximate homomorphic encryption,Privacy-preserving,Successive verifiable federated learning}
}

@article{garcia-teodoro_Anomalybasednetworkintrusion_2009,
  title = {Anomaly-Based Network Intrusion Detection: {{Techniques}}, Systems and Challenges},
  author = {Garc\'ia-Teodoro, P. and D\'iaz-Verdejo, J. and Maci\'a-Fern\'andez, G. and V\'azquez, E.},
  date = {2009-02},
  journaltitle = {Computers \& Security},
  volume = {28},
  number = {1-2},
  pages = {18--28},
  issn = {01674048},
  doi = {10.1016/j.cose.2008.08.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167404808000692},
  abstract = {The Internet and computer networks are exposed to an increasing number of security threats. With new types of attacks appearing continually, developing flexible and adaptive security oriented approaches is a severe challenge. In this context, anomaly-based network intrusion detection techniques are a valuable technology to protect target systems and networks against malicious activities. However, despite the variety of such methods described in the literature in recent years, security tools incorporating anomaly detection functionalities are just starting to appear, and several important problems remain to be solved. This paper begins with a review of the most well-known anomaly-based intrusion detection techniques. Then, available platforms, systems under development and research projects in the area are presented. Finally, we outline the main challenges to be dealt with for the wide scale deployment of anomaly-based intrusion detectors, with special emphasis on assessment issues. \copyright{} 2008 Elsevier Ltd. All rights reserved.}
}

@inproceedings{garg_DecentralizedMachineLearning_2022,
  title = {Decentralized {{Machine Learning}} Based {{Network Data Analytics}} for {{Cognitive Management}} of {{Mobile Communication Networks}}},
  booktitle = {{{NOMS}} 2022-2022 {{IEEE}}/{{IFIP Network Operations}} and {{Management Symposium}}},
  author = {Garg, Sharva and Bag, Tanmoy and Mitschele-Thiel, Andreas},
  date = {2022-04},
  pages = {1--9},
  issn = {2374-9709},
  doi = {10.1109/NOMS54207.2022.9789936},
  abstract = {The importance of network data analytics using advanced Machine Learning (ML) algorithms has been very well realized by the Telco industry and has resulted in the introduction of a dedicated Network Data Analytics Function (NWDAF) in the 5G service-based architecture in order to address the issues of integrating analytics into the network. The standardization of NWDAF by the 3rd Generation Partnership Project (3GPP) would enable third-party data analytics service providers to develop and provide AI-driven data analytics services to the Mobile Network Operators. The next-generation Radio Access Networks would require advanced analytics to drive closed-loop self-organizing network functions that are targeted to cognitively enhance network ef ciency and reduce the operational and capital costs of network operators. The existing solutions in this domain rely on conventional ML approaches that require the training data to be accumulated on a single data center. The concerns in this area would be the network overload and the privacy of the network operators that are sharing huge volumes of sensitive network data to the third-party Network Data Analytics Services (NDAS) executing over edge cloud infrastructures, perhaps even operated by some other players. In this paper, we propose and evaluate a Federated Learning based approach to train ML models for cognitive network management of future mobile networks that can enable network operators to get data analytics services by collaboratively building a shared learning model while retaining their critical data locally within their trusted domains.},
  eventtitle = {{{NOMS}} 2022-2022 {{IEEE}}/{{IFIP Network Operations}} and {{Management Symposium}}},
  keywords = {5G mobile communication,Analytical models,Biological system modeling,Capacity,Costs,Coverage,Data analysis,Federated Learning,Inter-cell Interference,Recommender Systems,Self-Coordination,Self-Organizing networks,Standardization,Training}
}

@legislation{GDPR,
  title = {{{REGULATION}} ({{EU}}) 2016/679 {{OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL}} of 27 {{April}} 2016 on the Protection of Natural Persons with Regard to the Processing of Personal Data and on the Free Movement of Such Data, and Repealing {{Directive}} 95/46/{{EC}} ({{General Data Protection Regulation}})},
  namea = {The European Parliament {and} The Counsil},
  nameatype = {collaborator},
  date = {2016},
  pages = {88},
  url = {https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32016R0679},
  langid = {english},
  keywords = {pinned}
}

@inproceedings{ghimire_DataDrivenQuickestChange_2021,
  title = {Data-{{Driven Quickest Change Detection}} for {{Securing Federated Learning}} for {{Internet-of-Vehicles}}},
  booktitle = {2021 {{IEEE Global Communications Conference}} ({{GLOBECOM}})},
  author = {Ghimire, Bimal and Rawat, Danda B. and Rahman, Abdul},
  date = {2021-12},
  pages = {1--6},
  publisher = {IEEE},
  location = {Madrid, Spain},
  doi = {10.1109/GLOBECOM46510.2021.9685333},
  url = {https://ieeexplore.ieee.org/document/9685333/},
  urldate = {2022-02-15},
  abstract = {Machine Learning (ML) is on the verge of transitioning from centralized, distributed to federated learning (FL) due to the inherent privacy-preserving framework by FL. FL enables collaborative learning among participants just by exchanging updated model parameters with the FL server while keeping training data local in the end devices which is suitable for vehicular communications. However, this learning framework makes the life of the server difficult to detect the malicious behavior of participants. Malicious model updates from participants may affect the accuracy of the learning model considerably and consequently may cause severe consequences in the Internet of Vehicles (IoV) environment. To address this issue, we propose a novel approach to apply Shiryaev's quickest change detection (QCD) technique in the FL realm. QCD is applied to detect abnormal changes in statistical properties of model parameters in FL as quickly as possible. We apply QCD on the server-side in two ways. First, QCD is applied to detect a change in the statistical properties over the model parameters sent by the participating devices. Second, QCD is applied to the history of aggregated FL model parameters. The first approach facilitates identifying malicious clients which can be eliminated in future learning activities. The other approach assists the server to roll back to an earlier version of the model in case of identifying the anomaly in the aggregated FL parameters. As QCD is applied on the server-side, it does not add any computation overhead on the client-side as well as communication overheard during transmission. These two approaches are evaluated with the help of numerical results.},
  eventtitle = {{{GLOBECOM}} 2021 - 2021 {{IEEE Global Communications Conference}}},
  isbn = {978-1-72818-104-2},
  langid = {english}
}

@article{ghimire_RecentAdvancesFederated_2022,
  title = {Recent {{Advances}} on {{Federated Learning}} for {{Cybersecurity}} and {{Cybersecurity}} for {{Federated Learning}} for {{Internet}} of {{Things}}},
  author = {Ghimire, Bimal and Rawat, Danda B.},
  date = {2022-06},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {9},
  number = {11},
  pages = {8229--8249},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2022.3150363},
  url = {https://ieeexplore.ieee.org/abstract/document/9709603},
  urldate = {2024-04-12},
  abstract = {Decentralized paradigm in the field of cybersecurity and machine learning (ML) for the emerging Internet of Things (IoT) has gained a lot of attention from the government, academia, and industries in recent years. Federated cybersecurity (FC) is regarded as a revolutionary concept to make the IoT safer and more efficient in the future. This emerging concept has the potential of detecting security threats, taking countermeasures, and limiting the spreading of threats over the IoT network system efficiently. An objective of cybersecurity is achieved by forming the federation of the learned and shared model on top of various participants. Federated learning (FL), which is regarded as a privacy-aware ML model, is particularly useful to secure the vulnerable IoT environment. In this article, we start with background and comparison of centralized learning, distributed on-site learning, and FL, which is then followed by a survey of the application of FL to cybersecurity for IoT. This survey primarily focuses on the security aspect but it also discusses several approaches that address the performance issues (e.g., accuracy, latency, resource constraint, and others) associated with FL, which may impact the security and overall performance of the IoT. To anticipate the future evolution of this new paradigm, we discuss the main ongoing research efforts, challenges, and research trends in this area. With this article, readers can have a more thorough understanding of FL for cybersecurity as well as cybersecurity for FL, different security attacks, and countermeasures.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {Cloud computing,Collaborative work,Computational modeling,Computer security,Cybersecurity,Data models,data offloading,federated cybersecurity (FC),federated learning (FL),Machine learning,machine learning (ML),Sensors}
}

@article{ghosh_Selfhealingsystemssurvey_2007,
  title = {Self-Healing Systems --- Survey and Synthesis},
  author = {Ghosh, Debanjan and Sharman, Raj and Raghav Rao, H. and Upadhyaya, Shambhu},
  date = {2007-01},
  journaltitle = {Decision Support Systems},
  shortjournal = {Decision Support Systems},
  volume = {42},
  number = {4},
  pages = {2164--2185},
  issn = {01679236},
  doi = {10.1016/j.dss.2006.06.011},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167923606000807},
  urldate = {2022-03-31},
  abstract = {As modern software-based systems and applications gain in versatility and functionality, the ability to manage inconsistent resources and service disparate user requirements becomes increasingly imperative. Furthermore, as systems increase in complexity, rectification of system faults and recovery from malicious attacks become more difficult, labor-intensive, expensive, and error-prone. These factors have actuated research dealing with the concept of self-healing systems. Self-healing systems attempt to ``heal'' themselves in the sense of recovering from faults and regaining normative performance levels independently the concept derives from the manner in which a biological system heals a wound. Such systems employ models, whether external or internal, to monitor system behavior and use inputs obtaining therefore to adapt themselves to the run-time environment. Researchers have approached this concept from several different angles this paper surveys research in this field and proposes a strategy of synthesis and classification. \copyright{} 2006 Elsevier B.V. All rights reserved.},
  langid = {english},
  keywords = {+survey}
}

@online{gill_FedDebugSystematicDebugging_2023,
  title = {{{FedDebug}}: {{Systematic Debugging}} for {{Federated Learning Applications}}},
  shorttitle = {{{FedDebug}}},
  author = {Gill, Waris and Anwar, Ali and Gulzar, Muhammad Ali},
  date = {2023-01-09},
  eprint = {2301.03553},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2301.03553},
  urldate = {2023-01-12},
  abstract = {In Federated Learning (FL), clients train a model locally and share it with a central aggregator to build a global model. Impermissibility to access client's data and collaborative training makes FL appealing for applications with data-privacy concerns such as medical imaging. However, these FL characteristics pose unprecedented challenges for debugging. When a global model's performance deteriorates, finding the round and the clients responsible is a major pain point. Developers resort to trial-and-error debugging with subsets of clients, hoping to increase the accuracy or let future FL rounds retune the model, which are time-consuming and costly.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Software Engineering}
}

@article{gilperez_RepCIDNReputationbasedCollaborative_2013,
  title = {{{RepCIDN}}: {{A Reputation-based Collaborative Intrusion Detection Network}} to {{Lessen}} the {{Impact}} of {{Malicious Alarms}}},
  shorttitle = {{{RepCIDN}}},
  author = {Gil P\'erez, Manuel and G\'omez M\'armol, F\'elix and Mart\'inez P\'erez, Gregorio and Skarmeta G\'omez, Antonio F.},
  date = {2013-03-01},
  journaltitle = {Journal of Network and Systems Management},
  shortjournal = {J Netw Syst Manage},
  volume = {21},
  number = {1},
  pages = {128--167},
  issn = {1573-7705},
  doi = {10.1007/s10922-012-9230-8},
  url = {https://doi.org/10.1007/s10922-012-9230-8},
  urldate = {2022-07-07},
  abstract = {Distributed and coordinated attacks in computer networks are causing considerable economic losses worldwide in recent years. This is mainly due to the transition of attackers' operational patterns towards a more sophisticated and more global behavior. This fact is leading current intrusion detection systems to be more likely to generate false alarms. In this context, this paper describes the design of a collaborative intrusion detection network (CIDN) that is capable of building and sharing collective knowledge about isolated alarms in order to efficiently and accurately detect distributed attacks. It has been also strengthened with a reputation mechanism aimed to improve the detection coverage by dropping false or bogus alarms that arise from malicious or misbehaving nodes. This model will enable a CIDN to detect malicious behaviors according to the trustworthiness of the alarm issuers, calculated from previous interactions with the system. Experimental results will finally demonstrate how entities are gradually isolated as their behavior worsens throughout the time.},
  langid = {english},
  keywords = {Collaboration networks,Group reputation,Intrusion detection systems,Reputation systems,Security,Trust management}
}

@incollection{gjorgiev_TimeSeriesAnomaly_2020,
  title = {Time {{Series Anomaly Detection}} with {{Variational Autoencoder Using Mahalanobis Distance}}},
  booktitle = {{{ICT Innovations}} 2020. {{Machine Learning}} and {{Applications}}},
  author = {Gjorgiev, Laze and Gievska, Sonja},
  editor = {Dimitrova, Vesna and Dimitrovski, Ivica},
  date = {2020},
  volume = {1316},
  pages = {42--55},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-62098-1_4},
  url = {https://link.springer.com/10.1007/978-3-030-62098-1_4},
  urldate = {2023-01-13},
  abstract = {Two themes have dominated the research on anomaly detection in time series data, one related to explorations of deep architectures for the task, and the other, equally important, the creation of large benchmark datasets. In line with the current trends, we have proposed several deep learning architectures based on Variational Autoencoders that have been evaluated for detecting cyber-attacks on water distribution system on the BATADAL challenge task and dataset. The second research aim of this study was to examine the impact of using Mahalanobis distance as a reconstruction error on the performance of the proposed models.},
  isbn = {978-3-030-62097-4 978-3-030-62098-1},
  langid = {english}
}

@article{gong_BLOCISBlockchainBasedCyber_2020,
  title = {{{BLOCIS}}: {{Blockchain-Based Cyber Threat Intelligence Sharing Framework}} for {{Sybil-Resistance}}},
  author = {Gong, Seonghyeon and Lee, Changhoon},
  date = {2020-03-21},
  journaltitle = {Electronics},
  volume = {9},
  number = {3},
  pages = {521},
  issn = {2079-9292},
  doi = {10.3390/electronics9030521},
  url = {https://www.mdpi.com/2079-9292/9/3/521},
  abstract = {The convergence of fifth-generation (5G) communication and the Internet-of-Things (IoT) has dramatically increased the diversity and complexity of the network. This change diversifies the attacker's attack vectors, increasing the impact and damage of cyber threats. Cyber threat intelligence (CTI) technology is a proof-based security system which responds to these advanced cyber threats proactively by analyzing and sharing security-related data. However, the performance of CTI systems can be significantly compromised by creating and disseminating improper security policies if an attacker intentionally injects malicious data into the system. In this paper, we propose a blockchain-based CTI framework that improves confidence in the source and content of the data and can quickly detect and eliminate inaccurate data for resistance to a Sybil attack. The proposed framework collects CTI by a procedure validated through smart contracts and stores information about the metainformation of data in a blockchain network. The proposed system ensures the validity and reliability of CTI data by ensuring traceability to the data source and proposes a system model that can efficiently operate and manage CTI data in compliance with the de facto standard. We present the simulation results to prove the effectiveness and Sybil-resistance of the proposed framework in terms of reliability and cost to attackers.}
}

@book{goodfellow_Deeplearning_2016,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date = {2016},
  series = {Adaptive Computation and Machine Learning},
  publisher = {The MIT Press},
  location = {Cambridge, Massachusetts},
  isbn = {978-0-262-03561-3},
  pagetotal = {775},
  keywords = {Machine learning}
}

@inproceedings{gopalan_BalancingApproachesML_2021,
  title = {Balancing {{Approaches}} towards {{ML}} for {{IDS}}: {{A Survey}} for the {{CSE-CIC IDS Dataset}}},
  shorttitle = {Balancing {{Approaches}} towards {{ML}} for {{IDS}}},
  booktitle = {2020 {{International Conference}} on {{Communications}}, {{Signal Processing}}, and Their {{Applications}} ({{ICCSPA}})},
  author = {Gopalan, Subiksha Srinivasa and Ravikumar, Dharshini and Linekar, Dino and Raza, Ali and Hasib, Maheen},
  date = {2021-03},
  pages = {1--6},
  doi = {10.1109/ICCSPA49915.2021.9385742},
  abstract = {Balanced datasets play a key role in the bias observed in machine learning algorithms towards classification and prediction. The CSE-CIC IDS datasets published in 2017 and 2018 have both attracted considerable scholarly attention towards research in intrusion detection systems. Recent work published using this dataset indicates little attention paid to the imbalance of the dataset. The study presented in this paper sets out to explore the degree to which imbalance has been treated and provide a taxonomy of the machine learning approaches developed using these datasets. A survey of published works related to these datasets was done to deliver a combined qualitative and quantitative methodological approach for our analysis towards deriving a taxonomy. The research presented here confirms that the impact of bias due to the imbalance datasets is rarely addressed. This data supports further research and development of supervised machine learning techniques which reduce the impact of bias in classification or prediction due to these imbalance datasets.},
  eventtitle = {2020 {{International Conference}} on {{Communications}}, {{Signal Processing}}, and Their {{Applications}} ({{ICCSPA}})},
  keywords = {balance,dataset,intrusion detection system,machine learning,Machine learning,Machine learning algorithms,Measurement,Predictive models,Research and development,Signal processing,Taxonomy}
}

@article{gosselin_PrivacySecurityFederated_2022,
  title = {Privacy and {{Security}} in {{Federated Learning}}: {{A Survey}}},
  shorttitle = {Privacy and {{Security}} in {{Federated Learning}}},
  author = {Gosselin, R\'emi and Vieu, Lo\"ic and Loukil, Faiza and Benoit, Alexandre},
  date = {2022-10-01},
  journaltitle = {Applied Sciences},
  shortjournal = {Applied Sciences},
  volume = {12},
  number = {19},
  pages = {9901},
  issn = {2076-3417},
  doi = {10.3390/app12199901},
  url = {https://www.mdpi.com/2076-3417/12/19/9901},
  urldate = {2024-04-12},
  abstract = {In recent years, privacy concerns have become a serious issue for companies wishing to protect economic models and comply with end-user expectations. In the same vein, some countries now impose, by law, constraints on data use and protection. Such context thus encourages machine learning to evolve from a centralized data and computation approach to decentralized approaches. Specifically, Federated Learning (FL) has been recently developed as a solution to improve privacy, relying on local data to train local models, which collaborate to update a global model that improves generalization behaviors. However, by definition, no computer system is entirely safe. Security issues, such as data poisoning and adversarial attack, can introduce bias in the model predictions. In addition, it has recently been shown that the reconstruction of private raw data is still possible. This paper presents a comprehensive study concerning various privacy and security issues related to federated learning. Then, we identify the state-of-the-art approaches that aim to counteract these problems. Findings from our study confirm that the current major security threats are poisoning, backdoor, and Generative Adversarial Network (GAN)-based attacks, while inference-based attacks are the most critical to the privacy of FL. Finally, we identify ongoing research directions on the topic. This paper could be used as a reference to promote cybersecurity-related research on designing FL-based solutions for alleviating future challenges.},
  langid = {english}
}

@book{gough_introductionsystematicreviews_2017,
  title = {An Introduction to Systematic Reviews},
  author = {Gough, David and Oliver, Sandy and Thomas, James},
  date = {2017},
  publisher = {Sage}
}

@article{gu_BadNetsEvaluatingBackdooring_2019,
  title = {{{BadNets}}: {{Evaluating Backdooring Attacks}} on {{Deep Neural Networks}}},
  shorttitle = {{{BadNets}}},
  author = {Gu, Tianyu and Liu, Kang and Dolan-Gavitt, Brendan and Garg, Siddharth},
  date = {2019},
  journaltitle = {IEEE Access},
  volume = {7},
  pages = {47230--47244},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2019.2909068},
  url = {https://ieeexplore.ieee.org/document/8685687},
  urldate = {2024-04-22},
  abstract = {Deep learning-based techniques have achieved state-of-the-art performance on a wide variety of recognition and classification tasks. However, these networks are typically computationally expensive to train, requiring weeks of computation on many GPUs; as a result, many users outsource the training procedure to the cloud or rely on pre-trained models that are then fine-tuned for a specific task. In this paper, we show that the outsourced training introduces new security risks: an adversary can create a maliciously trained network (a backdoored neural network, or a BadNet) that has the state-of-the-art performance on the user's training and validation samples but behaves badly on specific attacker-chosen inputs. We first explore the properties of BadNets in a toy example, by creating a backdoored handwritten digit classifier. Next, we demonstrate backdoors in a more realistic scenario by creating a U.S. street sign classifier that identifies stop signs as speed limits when a special sticker is added to the stop sign; we then show in addition that the backdoor in our U.S. street sign detector can persist even if the network is later retrained for another task and cause a drop in an accuracy of 25\% on average when the backdoor trigger is present. These results demonstrate that backdoors in neural networks are both powerful and-because the behavior of neural networks is difficult to explicate-stealthy. This paper provides motivation for further research into techniques for verifying and inspecting neural networks, just as we have developed tools for verifying and debugging software.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Biological neural networks,Computational modeling,Computer security,machine learning,Machine learning,neural networks,Perturbation methods,Security,Training}
}

@inproceedings{guembe_TrustworthyMachineLearning_2022,
  title = {Trustworthy {{Machine Learning Approaches}} for {{Cyberattack Detection}}: {{A Review}}},
  shorttitle = {Trustworthy {{Machine Learning Approaches}} for {{Cyberattack Detection}}},
  booktitle = {Computational {{Science}} and {{Its Applications}} -- {{ICCSA}} 2022 {{Workshops}}},
  author = {Guembe, Blessing and Azeta, Ambrose and Misra, Sanjay and Ahuja, Ravin},
  editor = {Gervasi, Osvaldo and Murgante, Beniamino and Misra, Sanjay and Rocha, Ana Maria A. C. and Garau, Chiara},
  date = {2022},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {265--278},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-10548-7_20},
  abstract = {In recent years, machine learning techniques have been~utilized in sensitive areas such as health, medical diagnosis, facial recognition, cybersecurity, etc. With this exponential growth comes potential large-scale ethical, safety, and social ramifications. With this enhanced ubiquity and sensitivity, concerns about ethics, trust, transparency, and accountability inevitably arise. Given the threat of sophisticated cyberattacks, it's critical to establish cybersecurity trustworthy concepts and to develop methodologies and concepts for a wide range of explainable machine cybersecurity models that will assure reliable threat identification and detection, more research is needed. This survey examines a variety of explainable machine learning techniques that can be used to implement~a reliable cybersecurity infrastructure in the cybersecurity domain. The main aim of this study is to execute an in-depth review and identification~of existing explainable machine learning algorithms for cyberattack detection. This study employed the seven-step survey model to determine the research domain, implement search queries, and compile all retrieved articles from digital databases. This research looks at the literature on trustworthy machine learning algorithms for detecting cyberattacks. An extensive search of electronic databases such as ArXiv, Semantic Scholar, IEEE Xplore, Wiley Library, Scopus, Google Scholar, ACM, and Springer was carried~out to find relevant literature in the subject domain. From 2016 to 2022, this study looked at white papers, conference papers, and journals. Only 25 research papers were chosen for this research paper describing trustworthy cybersecurity and explainable AI cybersecurity after we retrieved 800 articles from web databases. The study reveals that the decision tree technique outperforms other state-of-the-art machine learning models in terms of transparency and interpretability. Finally, this research suggests that incorporating explainable into machine learning cybersecurity models will help uncover the root causes of defensive failures, making it easier for cybersecurity experts to enhance both cybersecurity infrastructures and development, rather than just model results, policy, and management.},
  isbn = {978-3-031-10548-7},
  langid = {english},
  keywords = {+survey,Machine learning,Trustworthiness,Trustworthy cybersecurity}
}

@article{guichard_Detectionanomaliespar_2020,
  entrysubtype = {magazine},
  title = {D\'etection d'anomalies Par {{ACP}}},
  author = {Guichard, Jean-Philip and Johnson, Jack and Parrat, Pierre and Perez, Christian},
  date = {2020-09},
  journaltitle = {MISC : Le magazine de la cybers\'ecurit\'e offensive et d\'efensive},
  volume = {111},
  url = {https://connect.ed-diamond.com/MISC/MISC-111/Detection-d-anomalies-par-ACP},
  abstract = {Retour de vacances. L'analyse du SIEM apr\`es un mois d'absence montre que dix incidents ont \'et\'e d\'eclench\'es sur la base des alertes automatiques et ont pu \^etre g\'er\'es convenablement par la cha\^ine de traitement d'incidents. Tout est-il sous contr\^ole ? Un analyste aimerait rapidement s'en assurer en compl\'etant cette supervision par sa propre analyse du mois \'ecoul\'e. Mais par o\`u commencer ? Il est inenvisageable de regarder un mois de logs << rapidement >> et d'autant plus quand on ne sait pas pr\'ecis\'ement ce que l'on cherche\dots{} Une solution possible est de recourir \`a des outils statistiques qui permettent d'identifier des p\'eriodes d'activit\'e atypiques sur lesquelles concentrer son analyse. L'analyse en composantes principales (ACP ou PCA en anglais) est une m\'ethode statistique qui peut r\'epondre relativement efficacement \`a cette probl\'ematique. L'article pr\'esente cette m\'ethode et son apport dans la d\'etection d'anomalies, en prenant comme exemple l'analyse de flux r\'eseaux.}
}

@inproceedings{guilloteau_PainlessTranspositionReproducible_2022,
  title = {Painless {{Transposition}} of {{Reproducible Distributed Environments}} with {{NixOS Compose}}},
  author = {Guilloteau, Quentin and Bleuzen, Jonathan and Poquet, Millian and Richard, Olivier},
  date = {2022-09-06},
  volume = {CLUSTER 2022 - IEEE International Conference on Cluster Computing},
  pages = {1},
  url = {https://hal.science/hal-03723771},
  urldate = {2023-01-17},
  abstract = {Development of environments for distributed systems is a tedious and time-consuming iterative process. The reproducibility of such environments is a crucial factor for rigorous scientific contributions. We think that being able to smoothly test environments both locally and on a target distributed platform makes development cycles faster and reduces the friction to adopt better experimental practices. To address this issue, this paper introduces the notion of environment transposition and implements it in NixOS Compose, a tool that generates reproducible distributed environments. It enables users to deploy their environments on virtualized (docker, QEMU) or physical (Grid'5000) platforms with the same unique description of the environment. We show that NixOS Compose enables to build reproducible environments without overhead by comparing it to state-of-the-art solutions for the generation of distributed environments (EnOSlib and Kameleon). NixOS Compose actually enables substantial performance improvements on image building time over Kameleon (up to 11x faster for initial builds and up to 19x faster when building a variation of an existing environment).},
  eventtitle = {{{CLUSTER}} 2022 - {{IEEE International Conference}} on {{Cluster Computing}}},
  langid = {english},
  keywords = {\_read\_urgently}
}

@article{guo_GLDNetDeepLearning_2022,
  title = {{{GLD-Net}}: {{Deep Learning}} to {{Detect DDoS Attack}} via {{Topological}} and {{Traffic Feature Fusion}}},
  shorttitle = {{{GLD-Net}}},
  author = {Guo, Wei and Qiu, Han and Liu, Zimian and Zhu, Junhu and Wang, Qingxian},
  date = {2022-08-16},
  journaltitle = {Computational Intelligence and Neuroscience},
  volume = {2022},
  pages = {e4611331},
  publisher = {Hindawi},
  issn = {1687-5265},
  doi = {10.1155/2022/4611331},
  url = {https://www.hindawi.com/journals/cin/2022/4611331/},
  urldate = {2022-08-23},
  abstract = {Distributed denial of service (DDoS) attacks are the most common means of cyberattacks against infrastructure, and detection is the first step in combating them. The current DDoS detection mainly uses the improvement or fusion of machine learning and deep learning methods to improve classification performance. However, most classifiers are trained with statistical flow features as input, ignoring topological connection changes. This one-sidedness affects the detection accuracy and cannot provide a basis for the distribution of attack sources for defense deployment. In this study, we propose a topological and flow feature-based deep learning method (GLD-Net), which simultaneously extracts flow and topological features from time-series flow data and exploits graph attention network (GAT) to mine correlations between non-Euclidean features to fuse flow and topological features. The long short-term memory (LSTM) network connected behind GAT obtains the node neighborhood relationship, and the fully connected layer is utilized to achieve feature dimension reduction and traffic type mapping. Experiments on the NSL-KDD2009 and CIC-IDS2017 datasets show that the detection accuracy of the GLD-Net method for two classifications (normal and DDoS flow) and three classifications (normal, fast DDoS flow, and slow DDoS flow) reaches 0.993 and 0.942, respectively. Compared with the existing DDoS attack detection methods, its average improvement is 0.11 and 0.081, respectively. In addition, the correlation coefficient between the detection accuracy of attack flow and the four source distribution indicators ranges from 0.7 to 0.83, which lays a foundation for the inference of attack source distribution. Notably, we are the first to fuse topology and flow features and achieve high-performance DDoS attack intrusion detection through graph-style neural networks. This study has important implications for related research and development of network security systems in other fields.},
  langid = {english},
  keywords = {\_read\_urgently}
}

@incollection{guo_MultilevelFederatedLearning_2022,
  title = {Multi-Level {{Federated Learning Mechanism}} with {{Reinforcement Learning Optimizing}} in {{Smart City}}},
  booktitle = {Artificial {{Intelligence}} and {{Security}}},
  author = {Guo, Shaoyong and Xiang, Baoyu and Chen, Liandong and Yang, Huifeng and Yu, Dongxiao},
  editor = {Sun, Xingming and Zhang, Xiaorui and Xia, Zhihua and Bertino, Elisa},
  date = {2022},
  volume = {13340},
  pages = {441--454},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-06791-4_35},
  url = {https://link.springer.com/10.1007/978-3-031-06791-4_35},
  urldate = {2022-07-25},
  abstract = {While taking account into data privacy protection, federated learning can mine local data knowledge and gather data value, which has been widely concerned by the Smart city and Internet of Things. At present, a large amount of data is generated by the massive edge network in the smart city, but the resources of the edge side are limited. How to reduce the communication overhead between the edge and the centralized cloud server, improve the convergence speed of data model, and avoid resource waste caused by synchronized blocking of federated learning has become the core issue for the integration of federated learning and the Internet of Things in the smart city. For this reason, this paper designs a multi-level federated learning mechanism in the smart city, and uses reinforcement learning agents to select nodes to offset the influence of the non-IID data that is not independent and identically distributed. At the same time, asynchronous nonblocking updating method is used to perform model aggregation and updating of federated learning to release the resources of faster devices and improving the efficiency and stability of federated learning. Finally, simulation results show that the proposed method can improve the efficiency of federated learning tasks in edge network scenarios with a lot of devices in the smart city.},
  isbn = {978-3-031-06790-7 978-3-031-06791-4},
  langid = {english}
}

@inproceedings{guo_NewFederatedLearning_2023,
  title = {A {{New Federated Learning Model}} for {{Host Intrusion Detection System Under Non-IID Data}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  author = {Guo, Wei and Yao, Zhiwei and Liu, Yongfei and Zhang, Lanxue and Li, Liangxiong and Li, Tong and Wu, Bingzhen},
  date = {2023-10},
  pages = {494--500},
  issn = {2577-1655},
  doi = {10.1109/SMC53992.2023.10393972},
  url = {https://ieeexplore.ieee.org/document/10393972},
  urldate = {2024-06-11},
  abstract = {Host Intrusion Detection System (HIDS) is an important research topic in the field of cyberspace security. With the explosion in the number of malicious attacks in recent years, machine learning-based detection method is now the most common and efficient approach. While traditional centralized machine learning needs to transmit data to the central server for training, which not only requires the central server to have large computing resources, but also causes problems such as sensitive data leakage and communication overhead. As a distributed machine learning paradigm, Federated Learning (FL) can achieve multi-party collaborative training and aggregate a unified global model without data sharing, which can well alleviate these problems. It is worth noting that existing studies on the use of FL in HIDS are all conducted in the scenario where the data is independent and identically distributed (IID). However, due to the different context of hosts, the data generated by hosts is usually non-independent and identically distributed (Non-IID) in reality. Therefore, We investigate the impact of Non-IID data with different skew levels on FL in HIDS. On this basis, we propose a data augmentation FL algorithm based on Synthetic Minority Over-Sampling Technique (SMOTE) to reduce the impact of Non-IID data. We also develop a data collection module using extended Berkeley Packet Filter (eBPF) technology to collect a dataset for experiments. Experimental results show that our proposed FL algorithm can effectively improve the performance of HIDS under Non-IID data.},
  eventtitle = {2023 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  keywords = {Data augmentation,Data collection,Distributed databases,eBPF,Federated learning,Federated Learning,Filtering algorithms,HIDS,Intrusion detection,Non-IID data,SMOTE,Training}
}

@inproceedings{guo_NewFederatedLearning_2023a,
  title = {A {{New Federated Learning Model}} for {{Host Intrusion Detection System Under Non-IID Data}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  author = {Guo, Wei and Yao, Zhiwei and Liu, Yongfei and Zhang, Lanxue and Li, Liangxiong and Li, Tong and Wu, Bingzhen},
  date = {2023-10},
  pages = {494--500},
  issn = {2577-1655},
  doi = {10.1109/SMC53992.2023.10393972},
  url = {https://ieeexplore.ieee.org/document/10393972},
  urldate = {2024-06-18},
  abstract = {Host Intrusion Detection System (HIDS) is an important research topic in the field of cyberspace security. With the explosion in the number of malicious attacks in recent years, machine learning-based detection method is now the most common and efficient approach. While traditional centralized machine learning needs to transmit data to the central server for training, which not only requires the central server to have large computing resources, but also causes problems such as sensitive data leakage and communication overhead. As a distributed machine learning paradigm, Federated Learning (FL) can achieve multi-party collaborative training and aggregate a unified global model without data sharing, which can well alleviate these problems. It is worth noting that existing studies on the use of FL in HIDS are all conducted in the scenario where the data is independent and identically distributed (IID). However, due to the different context of hosts, the data generated by hosts is usually non-independent and identically distributed (Non-IID) in reality. Therefore, We investigate the impact of Non-IID data with different skew levels on FL in HIDS. On this basis, we propose a data augmentation FL algorithm based on Synthetic Minority Over-Sampling Technique (SMOTE) to reduce the impact of Non-IID data. We also develop a data collection module using extended Berkeley Packet Filter (eBPF) technology to collect a dataset for experiments. Experimental results show that our proposed FL algorithm can effectively improve the performance of HIDS under Non-IID data.},
  eventtitle = {2023 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  keywords = {Data augmentation,Data collection,Distributed databases,eBPF,Federated learning,Federated Learning,Filtering algorithms,HIDS,Intrusion detection,Non-IID data,SMOTE,Training}
}

@unpublished{guo_RobustPrivacyPreservingCollaborative_2021,
  title = {Robust and {{Privacy-Preserving Collaborative Learning}}: {{A Comprehensive Survey}}},
  shorttitle = {Robust and {{Privacy-Preserving Collaborative Learning}}},
  author = {Guo, Shangwei and Zhang, Xu and Yang, Fei and Zhang, Tianwei and Gan, Yan and Xiang, Tao and Liu, Yang},
  date = {2021-12-19},
  eprint = {2112.10183},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2112.10183},
  urldate = {2022-01-31},
  abstract = {With the rapid demand of data and computational resources in deep learning systems, a growing number of algorithms to utilize collaborative machine learning techniques, for example, federated learning, to train a shared deep model across multiple participants. It could effectively take advantage of resource of each participant and obtain a more powerful learning system. However, integrity and privacy threats in such systems have greatly obstructed the applications of collaborative learning. And a large amount of works have been proposed to maintain the model integrity and mitigate the privacy leakage of training data during the training phase for different collaborate learning systems. Compared with existing surveys that mainly focus on one specific collaborate learning system, this survey aims to provide a systematic and comprehensive review of security and privacy researches in collaborative learning. Our survey first provides the system overview of collaborative learning, followed by an brief introduction of integrity and privacy threats. In an organized way, we then detail the existing integrity and privacy attacks as well as their defenses. We also list some open problems in this area and opensource the related papers on GitHub: https://github.com/csl-cqu/awesome-secure-collebrativelearning-papers.},
  langid = {english},
  keywords = {â›” No DOI found,Computer Science - Cryptography and Security}
}

@online{guo_RobustPrivacyPreservingCollaborative_2021a,
  title = {Robust and {{Privacy-Preserving Collaborative Learning}}: {{A Comprehensive Survey}}},
  shorttitle = {Robust and {{Privacy-Preserving Collaborative Learning}}},
  author = {Guo, Shangwei and Zhang, Xu and Yang, Fei and Zhang, Tianwei and Gan, Yan and Xiang, Tao and Liu, Yang},
  date = {2021-12-19},
  eprint = {2112.10183},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2112.10183},
  url = {http://arxiv.org/abs/2112.10183},
  urldate = {2022-09-01},
  abstract = {With the rapid demand of data and computational resources in deep learning systems, a growing number of algorithms to utilize collaborative machine learning techniques, for example, federated learning, to train a shared deep model across multiple participants. It could effectively take advantage of the resources of each participant and obtain a more powerful learning system. However, integrity and privacy threats in such systems have greatly obstructed the applications of collaborative learning. And a large amount of works have been proposed to maintain the model integrity and mitigate the privacy leakage of training data during the training phase for different collaborative learning systems. Compared with existing surveys that mainly focus on one specific collaborative learning system, this survey aims to provide a systematic and comprehensive review of security and privacy researches in collaborative learning. Our survey first provides the system overview of collaborative learning, followed by a brief introduction of integrity and privacy threats. In an organized way, we then detail the existing integrity and privacy attacks as well as their defenses. We also list some open problems in this area and opensource the related papers on GitHub: https://github.com/csl-cqu/awesome-secure-collebrative-learning-papers.},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security}
}

@article{guo_Seeingbelievinginteractive_2023,
  title = {Seeing Is Believing: {{Towards}} Interactive Visual Exploration of Data Privacy in Federated Learning},
  shorttitle = {Seeing Is Believing},
  author = {Guo, Yeting and Liu, Fang and Zhou, Tongqing and Cai, Zhiping and Xiao, Nong},
  date = {2023-03-01},
  journaltitle = {Information Processing \& Management},
  shortjournal = {Information Processing \& Management},
  volume = {60},
  number = {2},
  pages = {103162},
  issn = {0306-4573},
  doi = {10.1016/j.ipm.2022.103162},
  url = {https://www.sciencedirect.com/science/article/pii/S0306457322002631},
  urldate = {2022-12-14},
  abstract = {Federated learning (FL), as a popular distributed machine learning paradigm, has driven the integration of knowledge in ubiquitous data owners under one roof. Although designed for privacy-preservation by nature, the supposed well-sanitized parameters still convey sensitive information (e.g., reconstruction attack), while existing technical countermeasures provide weak explainability for privacy understanding and protection practices of general users. This work investigates these privacy concerns with an exploratory study and elaborates on data owners' expectations in FL. Based on the analysis, we design the first interactive visualization system for FL privacy that supports intelligible privacy inspection and adjustment for data owners. Specifically, our proposal facilitates sample recommendation for joint privacy--performance training at cold start. Then it provides visual interpretation and attention rendering of privacy risks in view of multiple attacking channels and a holistic view. Further it supports interactive privacy enhancement involving both user initiative and differential privacy technique, and iterative trade-off with real-time inference accuracy estimation. We evaluate the effectiveness of the system and collect qualitative feedbacks from users. The results demonstrate that 96.7\% of users acknowledge the benefits to privacy inspection and adjustment and 90.3\% are willing to use our system. More importantly, 87.1\% increase the willingness of contributing data for FL.},
  langid = {english},
  keywords = {Federated learning,Privacy protection,Visualization}
}

@article{guo_Seeingbelievinginteractive_2023a,
  title = {Seeing Is Believing: {{Towards}} Interactive Visual Exploration of Data Privacy in Federated Learning},
  shorttitle = {Seeing Is Believing},
  author = {Guo, Yeting and Liu, Fang and Zhou, Tongqing and Cai, Zhiping and Xiao, Nong},
  date = {2023-03-01},
  journaltitle = {Information Processing \& Management},
  shortjournal = {Information Processing \& Management},
  volume = {60},
  number = {2},
  pages = {103162},
  issn = {0306-4573},
  doi = {10.1016/j.ipm.2022.103162},
  url = {https://www.sciencedirect.com/science/article/pii/S0306457322002631},
  urldate = {2024-07-07},
  abstract = {Federated learning (FL), as a popular distributed machine learning paradigm, has driven the integration of knowledge in ubiquitous data owners under one roof. Although designed for privacy-preservation by nature, the supposed well-sanitized parameters still convey sensitive information (e.g., reconstruction attack), while existing technical countermeasures provide weak explainability for privacy understanding and protection practices of general users. This work investigates these privacy concerns with an exploratory study and elaborates on data owners' expectations in FL. Based on the analysis, we design the first interactive visualization system for FL privacy that supports intelligible privacy inspection and adjustment for data owners. Specifically, our proposal facilitates sample recommendation for joint privacy--performance training at cold start. Then it provides visual interpretation and attention rendering of privacy risks in view of multiple attacking channels and a holistic view. Further it supports interactive privacy enhancement involving both user initiative and differential privacy technique, and iterative trade-off with real-time inference accuracy estimation. We evaluate the effectiveness of the system and collect qualitative feedbacks from users. The results demonstrate that 96.7\% of users acknowledge the benefits to privacy inspection and adjustment and 90.3\% are willing to use our system. More importantly, 87.1\% increase the willingness of contributing data for FL.},
  keywords = {Federated learning,Privacy protection,Visualization}
}

@unpublished{gupta_HierarchicalFederatedLearning_2021,
  title = {Hierarchical {{Federated Learning}} Based {{Anomaly Detection}} Using {{Digital Twins}} for {{Smart Healthcare}}},
  author = {Gupta, Deepti and Kayode, Olumide and Bhatt, Smriti and Gupta, Maanak and Tosun, Ali Saman},
  date = {2021-11-25},
  eprint = {2111.12241},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2111.12241},
  urldate = {2022-01-31},
  abstract = {Internet of Medical Things (IoMT) is becoming ubiquitous with a proliferation of smart medical devices and applications used in smart hospitals, smart-home based care, and nursing homes. It utilizes smart medical devices and cloud computing services along with core Internet of Things (IoT) technologies to sense patients' vital body parameters, monitor health conditions and generate multivariate data to support justin-time health services. Mostly, this large amount of data is analyzed in centralized servers. Anomaly Detection (AD) in a centralized healthcare ecosystem is often plagued by significant delays in response time with high performance overhead. Moreover, there are inherent privacy issues associated with sending patients' personal health data to a centralized server, which may also introduce several security threats to the AD model, such as possibility of data poisoning. To overcome these issues with centralized AD models, here we propose a Federated Learning (FL) based AD model which utilizes edge cloudlets to run AD models locally without sharing patients' data. Since existing FL approaches perform aggregation on a single server which restricts the scope of FL, in this paper, we introduce a hierarchical FL that allows aggregation at different levels enabling multiparty collaboration. We introduce a novel disease-based grouping mechanism where different AD models are grouped based on specific types of diseases. Furthermore, we develop a new Federated Time Distributed (FEDTIMEDIS) Long Short-Term Memory (LSTM) approach to train the AD model. We present a Remote Patient Monitoring (RPM) use case to demonstrate our model, and illustrate a proof-of-concept implementation using Digital Twin (DT) and edge cloudlets.},
  langid = {english},
  keywords = {\_read\_urgently,â›” No DOI found,Computer Science - Cryptography and Security}
}

@article{ha_ExplainableAnomalyDetection_2022,
  title = {Explainable {{Anomaly Detection}} for {{Industrial Control System Cybersecurity}}},
  author = {Ha, Do Thu and Hoang, Nguyen Xuan and Hoang, Nguyen Viet and Du, Nguyen Huu and Huong, Truong Thu and Tran, Kim Phuc},
  date = {2022-04},
  pages = {7},
  abstract = {Industrial Control Systems (ICSs) are becoming more and more important in managing the operation of many important systems in smart manufacturing, such as power stations, water supply systems, and manufacturing sites. While massive digital data can be a driving force for system performance, data security has raised serious concerns. Anomaly detection, therefore, is essential for preventing network security intrusions and system attacks. Many AI-based anomaly detection methods have been proposed and achieved high detection performance, however, are still a ''black box'' that is hard to be interpreted. In this study, we suggest using Explainable Artificial Intelligence to enhance the perspective and reliable results of an LSTMbased Autoencoder-OCSVM learning model for anomaly detection in ICS. We demonstrate the performance of our proposed method based on a well-known SCADA dataset.},
  langid = {english},
  keywords = {\_read,â›” No DOI found}
}

@article{habeeb_Networkintrusiondetection_2022,
  title = {Network Intrusion Detection System: {{A}} Survey on Artificial Intelligence-Based Techniques},
  shorttitle = {Network Intrusion Detection System},
  author = {Habeeb, Mohammed Sayeeduddin and Babu, T. Ranga},
  date = {2022-07-19},
  journaltitle = {Expert Systems},
  volume = {n/a},
  number = {n/a},
  pages = {e13066},
  issn = {1468-0394},
  doi = {10.1111/exsy.13066},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13066},
  urldate = {2022-08-11},
  abstract = {High data rate requirements in recent years have resulted in the massive expansion of communication systems, network size and the amount of data generated and processed. This has eventually caused many threats to the communication networks as well due to a more frequent generation of security attacks that are either novel or the mutation of the existing attacks. To secure the networks against such threats, an intrusion detection system (IDS) is considered as one of the promising solutions. The main problem with the IDS is its increased false alarm rate (FAR) in detecting the zero-day attacks. To improve the detection accuracy and minimizing the FAR, the researchers proposed IDS solutions using artificial intelligence (AI) approaches. In this research, we have systematically reviewed the recent AI-based network IDS (NIDS) solutions proposed during the period 2016--2021 by the research community. We systematically analysed the proposed NIDS solutions based on their strengths, shortcomings, AI methodology adopted, datasets, and the evaluation metrics used for evaluation purposes. From the review, we observed that the hybrid approach is mostly adopted by the researchers to propose AI-based NIDS solutions, with a trend shifting to deep learning-based approaches over the last 2 years. Also, most of the proposed solutions are evaluated using a very old dataset with only a few studies opting for the latest datasets. Finally based on our observations, we highlighted the research challenges and the future research directions to help young researchers to contribute to this field.},
  langid = {english},
  keywords = {+survey,deep learning,machine learning,network attacks,network intrusion detection system,network security}
}

@inproceedings{habibilashkari_CharacterizationTorTraffic_2017,
  title = {Characterization of {{Tor Traffic}} Using {{Time}} Based {{Features}}:},
  shorttitle = {Characterization of {{Tor Traffic}} Using {{Time}} Based {{Features}}},
  booktitle = {Proceedings of the 3rd {{International Conference}} on {{Information Systems Security}} and {{Privacy}}},
  author = {Habibi Lashkari, Arash and Draper Gil, Gerard and Mamun, Mohammad Saiful Islam and Ghorbani, Ali A.},
  date = {2017},
  pages = {253--262},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  location = {Porto, Portugal},
  doi = {10.5220/0006105602530262},
  url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006105602530262},
  urldate = {2021-10-15},
  abstract = {Tor, Network Traffic Characterization, Network Traffic Analysis, Time-based Features, Machine Learning.},
  eventtitle = {3rd {{International Conference}} on {{Information Systems Security}} and {{Privacy}}},
  isbn = {978-989-758-209-7},
  langid = {english}
}

@article{haddadi_Networktopologiesinference_2008a,
  title = {Network Topologies: Inference, Modeling, and Generation},
  shorttitle = {Network Topologies},
  author = {Haddadi, Hamed and Rio, Miguel and Iannaccone, Gianluca and Moore, Andrew and Mortier, Richard},
  date = {2008},
  journaltitle = {IEEE Communications Surveys \& Tutorials},
  volume = {10},
  number = {2},
  pages = {48--69},
  issn = {1553-877X},
  doi = {10.1109/COMST.2008.4564479},
  url = {https://ieeexplore.ieee.org/abstract/document/4564479},
  urldate = {2024-07-07},
  abstract = {Accurate measurement, inference and modeling techniques are fundamental to Internet topology research. Spatial analysis of the Internet is needed to develop network planning, optimal routing algorithms, and failure detection measures. A first step toward achieving such goals is the availability of network topologies at different levels of granularity, facilitating realistic simulations of new Internet systems. The main objective of this survey is to familiarize the reader with research on network topology over the past decade. We study techniques for inference, modeling, and generation of the Internet topology at both the router and administrative levels. We also compare the mathematical models assigned to various topologies and the generation tools based on them. We conclude with a look at emerging areas of research and potential future research directions.},
  eventtitle = {{{IEEE Communications Surveys}} \& {{Tutorials}}},
  keywords = {Algorithm design and analysis,Educational institutions,Failure analysis,Inference algorithms,Internet,IP networks,Laboratories,Mathematical model,Network topology,Routing}
}

@article{haddadpajouh_AI4SAFEIoTAIpoweredsecure_2020,
  title = {{{AI4SAFE-IoT}}: An {{AI-powered}} Secure Architecture for Edge Layer of {{Internet}} of Things},
  author = {HaddadPajouh, Hamed and Khayami, Raouf and Dehghantanha, Ali and Choo, Kim-Kwang Raymond and Parizi, Reza M.},
  date = {2020-10-25},
  journaltitle = {Neural Computing and Applications},
  volume = {32},
  number = {20},
  pages = {16119--16133},
  publisher = {Springer London},
  issn = {0941-0643},
  doi = {10.1007/s00521-020-04772-3},
  url = {https://doi.org/10.1007/s00521-020-04772-3},
  abstract = {With the increasing use of the Internet of things (IoT) in diverse domains, security concerns and IoT threats are constantly rising. The computational and memory limitations of IoT devices have resulted in emerging vulnerabilities in most IoT-run environments. Due to the low processing ability, IoT devices are often not capable of running complex defensive mechanisms. Lack of an architecture for a safer IoT environment is referred to as the most important barrier in developing a secure IoT system. In this paper, we propose a secure architecture for IoT edge layer infrastructure, called AI4SAFE-IoT. This architecture is built upon AI-powered security modules at the edge layer for protecting IoT infrastructure. Cyber threat attribution, intelligent web application firewall, cyber threat hunting, and cyber threat intelligence are the main modules proposed in our architecture. The proposed modules detect, attribute, and further identify the stage of an attack life cycle based on the Cyber Kill Chain model. In the proposed architecture, we define each security module and show its functionality against different threats in real-world applications. Moreover, due to the integration of AI security modules in a different layer of AI4SAFE-IoT, each threat in the edge layer will be handled by its corresponding security module delivered by a service. We compared the proposed architecture with the existing models and discussed our architecture independence of the underlying IoT layer and its comparatively low overhead according to delivering security as service for the edge layer of IoT architecture instead of embed implementation. Overall, we evaluated our proposed architecture based on the IoT service management score. The proposed architecture obtained 84.7 out of 100 which is the highest score among peer IoT edge layer security architectures.},
  isbn = {0123456789}
}

@article{hafeez_SecureEdgeNetworks_2017,
  title = {Toward {{Secure Edge Networks Taming Device}} to {{Device}} ({{D2D}}) {{Communication}} in {{IoT}}},
  author = {Hafeez, Ibbad and Ding, Aaron Yi and Antikainen, Markku and Tarkoma, Sasu},
  date = {2017-12-16},
  pages = {1--15},
  url = {http://arxiv.org/abs/1712.05958},
  abstract = {The growing popularity of Internet-of-Things (IoT) has created the need for network-based traffic anomaly detection systems that could identify misbehaving devices. In this work, we propose a lightweight technique, IoT-guard, for identifying malicious traffic flows. IoT-guard uses semi-supervised learning to distinguish between malicious and benign device behaviours using the network traffic generated by devices. In order to achieve this, we extracted 39 features from network logs and discard any features containing redundant information. After feature selection, fuzzy C-Mean (FCM) algorithm was trained to obtain clusters discriminating benign traffic from malicious traffic. We studied the feature scores in these clusters and use this information to predict the type of new traffic flows. IoT-guard was evaluated using a real-world testbed with more than 30 devices. The results show that IoTguard achieves high accuracy (98\%), in differentiating various types of malicious and benign traffic, with low false positive rates. Furthermore, it has low resource footprint and can operate on OpenWRT enabled access points and COTS computing boards.}
}

@article{haines_1999DARPAIntrusion_2001,
  title = {1999 {{DARPA Intrusion Detection Evaluation}}: {{Design}} and {{Procedures}}},
  author = {Haines, J W and Lippmann, R P and family=Fried, given=DJ, given-i=DJ and Zissman, M A and Tran, E and Boswell, S B},
  date = {2001},
  pages = {188},
  langid = {english},
  keywords = {â›” No DOI found}
}

@article{hajimirzaee_CHFLCollaborativeHierarchical_[review],
  title = {{{CHFL}}: {{A Collaborative Hierarchical Federated Intrusion Detection System}} for {{Vehicular Networks}}},
  author = {Hajimirzaee, Parya and Shojafar, Mohammad and Cruickshank, Haitham and Tafazolli, Rahim},
  year = {[review]},
  pages = {7},
  abstract = {Wireless interfaces, remote control schemes, and increased autonomy have raised the attacks surface of vehicular networks. As powerful monitoring entities, intrusion detection systems (IDS) must be updated and customised to respond to emerging networks' requirements. As server-based monitoring schemes were prone to significant privacy concerns, new privacy constrained learning methods such as federated learning (FL) have received considerable attention in designing IDS. However, to alleviate the efficiency and enhance the scalability of the original FL, this paper proposes a novel collaborative hierarchical federated IDS, named CHFL for the vehicular network. In the CHFL model, a group of vehicles assisted by vehicle-to-everything (V2X) communication technologies can exchange intrusion detection information collaboratively in a private format. Each group nominates a leader, and the leading vehicle serves as the intermediate in the second level detection system of the hierarchical federated model. The leader communicates directly with the server to transmit and receive model updates of its nearby end vehicles. By reducing the number of direct communications to the server, our proposed system reduces network uplink traffic and queuing-processing latency. In addition, CHFL improved the prediction loss and the accuracy of the whole system. We are achieving an accuracy of 99.10\% compared with 97.01\% accuracy of the original FL.},
  langid = {english},
  keywords = {\_unpublished,â›” No DOI found}
}

@article{hajj_CrossLayerFederatedLearning_2023,
  title = {Cross-{{Layer Federated Learning}} for {{Lightweight IoT Intrusion Detection Systems}}},
  author = {Hajj, Suzan and Azar, Joseph and Bou Abdo, Jacques and Demerjian, Jacques and Guyeux, Christophe and Makhoul, Abdallah and Ginhac, Dominique},
  date = {2023-01},
  journaltitle = {Sensors},
  volume = {23},
  number = {16},
  pages = {7038},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s23167038},
  url = {https://www.mdpi.com/1424-8220/23/16/7038},
  urldate = {2024-04-12},
  abstract = {With the proliferation of IoT devices, ensuring the security and privacy of these devices and their associated data has become a critical challenge. In this paper, we propose a federated sampling and lightweight intrusion-detection system for IoT networks that use K-meansfor sampling network traffic and identifying anomalies in a semi-supervised way. The system is designed to preserve data privacy by performing local clustering on each device and sharing only summary statistics with a central aggregator. The proposed system is particularly suitable for resource-constrained IoT devices such as sensors with limited computational and storage capabilities. We evaluate the system's performance using the publicly available NSL-KDD dataset. Our experiments and simulations demonstrate the effectiveness and efficiency of the proposed intrusion-detection system, highlighting the trade-offs between precision and recall when sharing statistics between workers and the coordinator. Notably, our experiments show that the proposed federated IDS can increase the true-positive rate up to 10\% when the workers and the coordinator collaborate.},
  issue = {16},
  langid = {english},
  keywords = {federated learning,internet of things,lightweight intrusion detection,lightweight sampling,semi-supervised learning}
}

@online{halimi_FederatedUnlearningHow_2022,
  title = {Federated {{Unlearning}}: {{How}} to {{Efficiently Erase}} a {{Client}} in {{FL}}?},
  shorttitle = {Federated {{Unlearning}}},
  author = {Halimi, Anisa and Kadhe, Swanand and Rawat, Ambrish and Baracaldo, Nathalie},
  date = {2022-07-12},
  eprint = {2207.05521},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2207.05521},
  urldate = {2022-08-11},
  abstract = {With privacy legislation empowering users with the right to be forgotten, it has become essential to make a model forget about some of its training data. We explore the problem of removing any client's contribution in federated learning (FL). During FL rounds, each client performs local training to learn a model that minimizes the empirical loss on their private data. We propose to perform unlearning at the client (to be erased) by reversing the learning process, i.e., training a model to maximize the local empirical loss. In particular, we formulate the unlearning problem as a constrained maximization problem by restricting to an 2-norm ball around a suitably chosen reference model to help retain some knowledge learnt from the other clients' data. This allows the client to use projected gradient descent to perform unlearning. The method does neither require global access to the data used for training nor the history of the parameter updates to be stored by the aggregator (server) or any of the clients. Experiments on the MNIST dataset show that the proposed unlearning method is efficient and effective.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@article{hamad_BINIoTBehaviouralNetwork_[review],
  title = {{{BIN-IoT}} : {{Behavioural Network Traffic Identification}}},
  author = {Hamad, Salma Abdalla and Sheng, Quan Z. and Tran, Dai Hoang and Zhang, Wei Emma and Nepal, Surya},
  year = {[review]},
  journaltitle = {EEE Transactions on Network and Service Management},
  keywords = {\_unpublished,â›” No DOI found}
}

@article{hamdi_Federatedlearningbasedintrusion_2023,
  title = {Federated Learning-Based Intrusion Detection System for {{Internet}} of {{Things}}},
  author = {Hamdi, Najet},
  date = {2023-12-01},
  journaltitle = {International Journal of Information Security},
  shortjournal = {Int. J. Inf. Secur.},
  volume = {22},
  number = {6},
  pages = {1937--1948},
  issn = {1615-5270},
  doi = {10.1007/s10207-023-00727-6},
  url = {https://doi.org/10.1007/s10207-023-00727-6},
  urldate = {2024-04-12},
  abstract = {Intrusion detection in the Internet of Things is becoming increasingly important as the number of connected devices grows. Machine learning algorithms can be applied to detect anomalies in large data sets, making them useful for identifying potential intrusions. However, traditional centralized learning techniques entail collecting data from end devices in one central device for training. Allowing a single entity to have access to vast amounts of personal data raises many security concerns as any issue experienced with the system can lead to widespread data leakage. To prevent these issues, it is critical to seek more secure alternatives such as federated learning. It enables multiple parties to collaborate on the same model without having to share the data between them. This process not only helps protect data privacy, but also reduces the risk of data leakage and improves training efficiency. In this paper, we propose a federated-based intrusion detection system. To better investigate the performance of the proposed model, we considered client-side evaluation whereby in the same round, the clients transfer the local models to the server which aggregates them in an updated global model. Then, the server transfers the updated global model to the clients for evaluation. The clients evaluate the global model locally and send back the results to the server to be aggregated using metric aggregation function. The experimental results show that the proposed federated-IDS achieves a high detection rate.},
  langid = {english},
  keywords = {Centralized learning,Communication overhead,Cyberattacks,Federated learning,Internet of Things}
}

@inproceedings{hamouda_IntrusionDetectionSystems_2021,
  title = {Intrusion {{Detection Systems}} for {{Industrial Internet}} of {{Things}}: {{A Survey}}},
  shorttitle = {Intrusion {{Detection Systems}} for {{Industrial Internet}} of {{Things}}},
  booktitle = {2021 {{International Conference}} on {{Theoretical}} and {{Applicative Aspects}} of {{Computer Science}} ({{ICTAACS}})},
  author = {Hamouda, Djallel and Ferrag, Mohamed Amine and Benhamida, Nadjette and Seridi, Hamid},
  date = {2021-12-15},
  pages = {1--8},
  publisher = {IEEE},
  location = {Skikda, Algeria},
  doi = {10.1109/ICTAACS53298.2021.9715177},
  url = {https://ieeexplore.ieee.org/document/9715177/},
  urldate = {2022-02-25},
  abstract = {Industrial Internet of Things (IIoT) applies Internet of Things (IoT) technology in industrial systems, to optimize business processes efficiency, service quality, and reliability. However, with a large of isolated IoT networks deployed in various industries, many vulnerabilities have been exposed to security incidents and posed threats to IIoT security. An intrusion detection system (IDS) is a security monitoring mechanism that promotes cyber security solutions for information systems. The system's role is to detect abnormal activities of intruders and enable preventive measures to avoid risks. However, applying a traditional IDS-based solution to IIoT is challenging due to its particular characteristics such as resource-constrained, data privacy, and heterogeneity. Researchers are using the new emerging technologies such as Fog/Edge computing, Machine Learning (ML), Deep Learning (DL) to deploy an effective and adaptive IDS for various IIoT operating environments. This study focus is on the development of IDS in particular industrial environments. To this end, we provide a systemic review that addresses IDS deployment strategies, detection approaches, and methodologies and data sources used for evaluation. We also present some suggestions and challenges to be considered when designing IDSbased security for Industrial IoT as future research.},
  eventtitle = {2021 {{International Conference}} on {{Theoretical}} and {{Applicative Aspects}} of {{Computer Science}} ({{ICTAACS}})},
  isbn = {978-1-66549-655-1},
  langid = {english},
  keywords = {+survey}
}

@inproceedings{hamza_DetectingVolumetricAttacks_2019,
  title = {Detecting {{Volumetric Attacks}} on {{loT Devices}} via {{SDN-Based Monitoring}} of {{MUD Activity}}},
  booktitle = {Proceedings of the 2019 {{ACM Symposium}} on {{SDN Research}}},
  author = {Hamza, Ayyoob and Gharakheili, Hassan Habibi and Benson, Theophilus A. and Sivaraman, Vijay},
  date = {2019-04-03},
  pages = {36--48},
  publisher = {ACM},
  location = {New York, NY, USA},
  doi = {10.1145/3314148.3314352},
  url = {https://dl.acm.org/doi/10.1145/3314148.3314352},
  abstract = {Smart environments equipped with IoT devices are increasingly under threat from an escalating number of sophisticated cyber-attacks. Current security approaches are inaccurate, expensive, or unscalable, as they require static signatures of known attacks, specialized hardware, or full packet inspection. The IETF Manufacturer Usage Description (MUD) framework aims to reduce the attack surface on an IoT device by formally defining its expected network behavior. In this paper, we use SDN to monitor compliance with the MUD behavioral profile, and develop machine learning methods to detect volumetric attacks such as DoS, reflective TCP/UDP/ICMP flooding, and ARP spoofing to IoT devices. Our first contribution develops a machine for detecting anomalous patterns of MUD-compliant network activity via coarse-grained (device-level) and fine-grained (flow-level) SDN telemetry for each IoT device, thereby giving visibility into flows that contribute to a volumetric attack. For our second contribution we measure network behavior of IoT devices by collecting benign and volumetric attacks traffic traces in our lab, label our dataset, and make it available to the public. Our last contribution prototypes a full working system (built with an OpenFlow switch, Faucet SDN controller, and a MUD policy engine), demonstrates its application in detecting volumetric attacks on several consumer IoT devices with high accuracy, and provides insights into cost and performance of our system. Our data and solution modules are released as open source to the community.},
  isbn = {978-1-4503-6710-3}
}

@article{han_HeterogeneousDataAwareFederated_2024,
  title = {Heterogeneous {{Data-Aware Federated Learning}} for {{Intrusion Detection Systems}} via {{Meta-Sampling}} in {{Artificial Intelligence}} of {{Things}}},
  author = {Han, Weixiang and Peng, Jialiang and Yu, Jiahua and Kang, Jiawen and Lu, Jiaxun and Niyato, Dusit},
  date = {2024-04},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {11},
  number = {8},
  pages = {13340--13354},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2023.3337755},
  url = {https://ieeexplore.ieee.org/abstract/document/10334467},
  urldate = {2024-04-12},
  abstract = {Intrusion detection systems (IDSs) integrated with machine learning (ML) techniques have proven to be effective defenses against the increasing cybersecurity attacks in the Artificial Intelligence of Things (AIoT) domain. Privacy concerns have prompted the emergence of federated learning (FL) as a promising solution for AIoT intrusion detection. Despite their potential, FL-based IDSs still face challenges related to class-imbalanced data and Non-Independent and Identically Distributed (non-IID) data among AIoT devices. These challenges hinder FL from learning meaningful features from the data, thus impeding the convergence of the learning process. To tackle these issues, this article proposes a clustering-enabled federated meta-training (CFMT) framework for AIoT intrusion detection. The proposed CFMT framework effectively addresses the negative impact of imbalanced and non-IID data. Specifically, we design a data- and model-agnostic meta-sampler that adaptively balances local data sets, thereby mitigating the data imbalance problem. Additionally, we propose a dynamic clustering algorithm that selectively eliminates the local models affected by the training state bias caused by non-IID data, thereby addressing the non-IID data issue. Extensive case studies on two real-world data sets demonstrate the superior performance of the proposed CFMT framework compared to existing solutions, including federated non-IID algorithms and federated imbalanced learning algorithms, in terms of IDS performance. Our code and data are available at https://gitee.com/mindspore/models/tree/master/research/cv/HDFL-IDS-Meta.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {Artificial Intelligence of Things (AIoT),Behavioral sciences,class imbalance,Data models,Data privacy,Federated learning,federated learning (FL),intrusion detection,Intrusion detection,non-IID,Security,Training}
}

@article{hand_noteusingFmeasure_2018,
  title = {A Note on Using the {{F-measure}} for Evaluating Record Linkage Algorithms},
  author = {Hand, David and Christen, Peter},
  date = {2018-05},
  journaltitle = {Statistics and Computing},
  shortjournal = {Stat Comput},
  volume = {28},
  number = {3},
  pages = {539--547},
  issn = {0960-3174, 1573-1375},
  doi = {10/gfw6dw},
  url = {http://link.springer.com/10.1007/s11222-017-9746-6},
  urldate = {2021-11-10},
  langid = {english}
}

@article{hao_InaccurateLabelsWeaklySupervised_2020,
  title = {Inaccurate {{Labels}} in {{Weakly-Supervised Deep Learning}}: {{Automatic Identification}} and {{Correction}} and {{Their Impact}} on {{Classification Performance}}},
  shorttitle = {Inaccurate {{Labels}} in {{Weakly-Supervised Deep Learning}}},
  author = {Hao, Degan and Zhang, Lei and Sumkin, Jules and Mohamed, Aly and Wu, Shandong},
  date = {2020-09},
  journaltitle = {IEEE Journal of Biomedical and Health Informatics},
  volume = {24},
  number = {9},
  pages = {2701--2710},
  issn = {2168-2208},
  doi = {10.1109/JBHI.2020.2974425},
  url = {https://ieeexplore.ieee.org/abstract/document/9000595},
  urldate = {2024-03-28},
  abstract = {In data-driven deep learning-based modeling, data quality may substantially influence classification performance. Correct data labeling for deep learning modeling is critical. In weakly-supervised learning, a challenge lies in dealing with potentially inaccurate or mislabeled training data. In this paper, we proposed an automated methodological framework to identify mislabeled data using two metric functions, namely, Cross-entropy Loss that indicates divergence between a prediction and ground truth, and Influence function that reflects the dependence of a model on data. After correcting the identified mislabels, we measured their impact on the classification performance. We also compared the mislabeling effects in three experiments on two different real-world clinical questions. A total of 10,500 images were studied in the contexts of clinical breast density category classification and breast cancer malignancy diagnosis. We used intentionally flipped labels as mislabels to evaluate the proposed method at a varying proportion of mislabeled data included in model training. We also compared the effects of our method to two published schemes for breast density category classification. Experiment results show that when the dataset contains 10\% of mislabeled data, our method can automatically identify up to 98\% of these mislabeled data by examining/checking the top 30\% of the full dataset. Furthermore, we show that correcting the identified mislabels leads to an improvement in the classification performance. Our method provides a feasible solution for weakly-supervised deep learning modeling in dealing with inaccurate labels.},
  eventtitle = {{{IEEE Journal}} of {{Biomedical}} and {{Health Informatics}}},
  keywords = {Breast cancer,Data models,Deep learning,Imaging,inaccurate label,mammogram,metric function,Noise measurement,Training,weakly-supervised learning}
}

@unpublished{hardy_Privatefederatedlearning_2017,
  title = {Private Federated Learning on Vertically Partitioned Data via Entity Resolution and Additively Homomorphic Encryption},
  author = {Hardy, Stephen and Henecka, Wilko and Ivey-Law, Hamish and Nock, Richard and Patrini, Giorgio and Smith, Guillaume and Thorne, Brian},
  date = {2017-11-28},
  eprint = {1711.10677},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1711.10677},
  urldate = {2021-10-04},
  abstract = {Consider two data providers, each maintaining private records of different feature sets about common entities. They aim to learn a linear model jointly in a federated setting, namely, data is local and a shared model is trained from locally computed updates. In contrast with most work on distributed learning, in this scenario (i) data is split vertically, i.e. by features, (ii) only one data provider knows the target variable and (iii) entities are not linked across the data providers. Hence, to the challenge of private learning, we add the potentially negative consequences of mistakes in entity resolution. Our contribution is twofold. First, we describe a three-party end-to-end solution in two phases---privacy-preserving entity resolution and federated logistic regression over messages encrypted with an additively homomorphic scheme---, secure against a honest-but-curious adversary. The system allows learning without either exposing data in the clear or sharing which entities the data providers have in common. Our implementation is as accurate as a naive non-private solution that brings all data in one place, and scales to problems with millions of entities with hundreds of features. Second, we provide what is to our knowledge the first formal analysis of the impact of entity resolution's mistakes on learning, with results on how optimal classifiers, empirical losses, margins and generalisation abilities are affected. Our results bring a clear and strong support for federated learning: under reasonable assumptions on the number and magnitude of entity resolution's mistakes, it can be extremely beneficial to carry out federated learning in the setting where each peer's data provides a significant uplift to the other.},
  langid = {english},
  keywords = {\_read,â›” No DOI found,Computer Science - Machine Learning}
}

@inproceedings{harilal_TWOSDatasetMalicious_2017,
  title = {{{TWOS}}: {{A Dataset}} of {{Malicious Insider Threat Behavior Based}} on a {{Gamified Competition}}},
  shorttitle = {{{TWOS}}},
  booktitle = {Proceedings of the 2017 {{International Workshop}} on {{Managing Insider Security Threats}}},
  author = {Harilal, Athul and Toffalini, Flavio and Castellanos, John and Guarnizo, Juan and Homoliak, Ivan and Ochoa, Mart\'in},
  date = {2017-10-30},
  series = {{{MIST}} '17},
  pages = {45--56},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3139923.3139929},
  url = {https://doi.org/10.1145/3139923.3139929},
  urldate = {2022-08-12},
  abstract = {In this paper we present the design and outcome of a gamified competition that was devised in order to obtain a dataset containing realistic instances of insider threats. The competition simulated user interactions in/among competing companies, where two types of behaviors (normal and malicious) were incentivized. For the case of malicious behavior, we designed sessions for two types of insider threats (masqueraders and traitors). The game involved the participation of 6 teams consisting of 4 students who competed with each other for a period of 5 days, while their activities were monitored considering several heterogeneous sources (mouse, keyboard, process and file-system monitor, network traffic, emails and login/logout). In sum, we obtained 320 hours of active participation that included 18 hours of masquerader data and at least two instances of traitor data. Additionally to malicious behaviors, the students explored various defensive and offensive strategies, such as denial of service attacks and obfuscation techniques, in an effort to get ahead in the competition. The TWOS dataset is publicly accessible for further research purposes.},
  isbn = {978-1-4503-5177-5},
  keywords = {\_read\_urgently,dataset,malicious insider threat,masquerader,multi player game,traitor,user behavior monitoring}
}

@inproceedings{harrison_Informationsharingrequirements_2012,
  title = {Information Sharing Requirements and Framework Needed for Community Cyber Incident Detection and Response},
  booktitle = {2012 {{IEEE Conference}} on {{Technologies}} for {{Homeland Security}} ({{HST}})},
  author = {Harrison, Keith and White, Gregory},
  date = {2012-11},
  pages = {463--469},
  publisher = {IEEE},
  doi = {10.1109/THS.2012.6459893},
  url = {http://ieeexplore.ieee.org/document/6459893/},
  abstract = {Communities, and the critical infrastructure that they rely upon, are becoming ever increasingly integrated into cyberspace. At the same time, communities are experiencing increasing activity and sophistication from a variety of threat agents. The effect of cyber attacks on communities has been observed, and the frequency and devastation of these attacks can only increase in the foreseeable future. Early detection of these attacks is critical for a fast and effective response. We propose detecting community cyber incidents by comparing indicators from community members across space and time. Performing spatiotemporal differentiation on these indicators requires that community members, such as private and governmental organizations, share information about these indicators. However, community members are, for good reasons, reluctant to share sensitive security related information. Additionally, sharing large amounts of information with a trusted, centralized location introduces scalability and reliability problems. In this paper we define the information sharing requirements necessary for fast, effective community cyber incident detection and response, while addressing both privacy and scalability concerns. Furthermore, we introduce a framework to meet these requirements, and analyze a proof of concept implementation. \copyright{} 2012 IEEE.},
  isbn = {978-1-4673-2709-1}
}

@inproceedings{hartmann_MOFLFederatedMultiobjective_2023,
  title = {{{MOFL}}/{{D}}: {{A Federated Multi-objective Learning Framework}} with {{Decomposition}}},
  shorttitle = {{{MOFL}}/{{D}}},
  author = {Hartmann, Maria and Danoy, Gr\'egoire and Alswaitti, Mohammed and Bouvry, Pascal},
  date = {2023-10-28},
  url = {https://openreview.net/forum?id=Pj6BPHZy56},
  urldate = {2023-12-05},
  abstract = {Multi-objective learning problems occur in all aspects of life and have been studied for decades, including in the field of machine learning. Many such problems also exist in distributed settings, where data cannot easily be shared. In recent years, joint machine learning has been made possible in such settings through the development of the Federated Learning (FL) paradigm. However, there is as of now very little research on the general problem of extending the FL concept to multi- objective learning, limiting such problems to non-cooperative individual learning. We address this gap by presenting a general framework for multi-objective FL, based on decomposition (MOFL/D). Our framework addresses the a posteriori type of multi-objective problem, where user preferences are not known during the optimisation process, allowing multiple participants to jointly find a set of solutions, each optimised for some distribution of preferences. We present an instantiation of the framework and validate it through experiments on a set of multi-objective benchmarking problems that are extended from well-known single- objective benchmarks.},
  eventtitle = {International {{Workshop}} on {{Federated Learning}} in the {{Age}} of {{Foundation Models}} in {{Conjunction}} with {{NeurIPS}} 2023},
  langid = {english}
}

@inproceedings{hbaieb_Federatedlearningbased_2022,
  title = {Federated Learning Based {{IDS}} Approach for the {{IoV}}},
  booktitle = {Proceedings of the 17th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Hbaieb, Amal and Ayed, Samiha and Chaari, Lamia},
  date = {2022-08-23},
  series = {{{ARES}} '22},
  pages = {1--6},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3538969.3544422},
  url = {https://doi.org/10.1145/3538969.3544422},
  urldate = {2022-08-23},
  abstract = {The Internet of Vehicles (IoV) is an Internet of Things (IoT) application that offers several utilities such as traffic analysis, safe driving, road optimization, and travel comfort. Software-Defined Networking (SDN) technology has been shown to provide various benefits to support the IoV. However, the construction of IoV makes it a complex system posing several challenges among which the important ones are security and privacy of data. Intrusion Detection Systems (IDSs) have been proposed in the IoV to identify cyber attacks and protect private data. Recently work has started to implement IDSs based on Federated learning as collaborative IDSs have proved effective security of IoV. In another hand, trust management has revolutionized the IoV filed, providing decision-making support to secure the network. Stating that an SDN-driven IoV architecture in which nodes trustworthiness gets assessed can provide a promising framework for IDS, we propose in this paper a Federated learning-based IDS for the IoV under the SDN structure. We integrate trust metrics to assist in securing the IoV network. Simulation experiments are conducted to validate the proposal.},
  isbn = {978-1-4503-9670-7},
  keywords = {Federated learning,IDS,IoV,SDN,Trust management,VANET,Vehicular networks}
}

@inproceedings{hbaieb_Federatedlearningbased_2022a,
  title = {Federated Learning Based {{IDS}} Approach for the {{IoV}}},
  booktitle = {Proceedings of the 17th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Hbaieb, Amal and Ayed, Samiha and Chaari, Lamia},
  date = {2022-08-23},
  series = {{{ARES}} '22},
  pages = {1--6},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3538969.3544422},
  url = {https://dl.acm.org/doi/10.1145/3538969.3544422},
  urldate = {2024-04-12},
  abstract = {The Internet of Vehicles (IoV) is an Internet of Things (IoT) application that offers several utilities such as traffic analysis, safe driving, road optimization, and travel comfort. Software-Defined Networking (SDN) technology has been shown to provide various benefits to support the IoV. However, the construction of IoV makes it a complex system posing several challenges among which the important ones are security and privacy of data. Intrusion Detection Systems (IDSs) have been proposed in the IoV to identify cyber attacks and protect private data. Recently work has started to implement IDSs based on Federated learning as collaborative IDSs have proved effective security of IoV. In another hand, trust management has revolutionized the IoV filed, providing decision-making support to secure the network. Stating that an SDN-driven IoV architecture in which nodes trustworthiness gets assessed can provide a promising framework for IDS, we propose in this paper a Federated learning-based IDS for the IoV under the SDN structure. We integrate trust metrics to assist in securing the IoV network. Simulation experiments are conducted to validate the proposal.},
  isbn = {978-1-4503-9670-7},
  keywords = {Federated learning,IDS,IoV,SDN,Trust management,VANET,Vehicular networks}
}

@article{he_6GenabledConsumerElectronics_2023,
  title = {{{6G-enabled Consumer Electronics Device Intrusion Detection}} with {{Federated Meta-Learning}} and {{Digital Twins}} in a {{Meta-Verse Environment}}},
  author = {He, Suli and Du, Chengwen and Hossain, M. Shamim},
  date = {2023},
  journaltitle = {IEEE Transactions on Consumer Electronics},
  pages = {1--1},
  issn = {1558-4127},
  doi = {10.1109/TCE.2023.3321846},
  url = {https://ieeexplore.ieee.org/abstract/document/10271257},
  urldate = {2024-04-12},
  abstract = {The widespread adoption of consumer electronics devices coupled with the emergence of 6G technology has led to the establishment of an extensive network of interconnected devices, forming the underlying infrastructure of the Internet of Things (IoT). Nevertheless, this interconnectivity introduces a myriad of security concerns, given that these devices become susceptible to malicious activities and unauthorized breaches. Moreover, conventional intrusion detection systems encounter difficulties in managing imbalanced data scenarios, wherein the count of normal instances vastly exceeds that of intrusion instances. To address this issue, we propose a novel framework for 6G-enabled consumer electronics device intrusion detection, leveraging the power of federated meta-learning and digital twins within a Meta-Verse environment. By leveraging the distributed intelligence of meta-learning across a network of devices, our framework enables efficient and accurate detection of intrusions while mitigating the impact of imbalanced data. Furthermore, by utilizing digital twins within a Meta-Verse environment, we create a scalable and controlled setting for experimentation, enabling the development and evaluation of intrusion detection algorithms in a realistic yet controlled manner. Our experimental results demonstrate the effectiveness of the proposed framework in detecting intrusions on 6G-enabled consumer electronics devices. The federated meta-learning approach achieves superior performance compared to traditional intrusion detection methods, especially in imbalanced data scenarios.},
  eventtitle = {{{IEEE Transactions}} on {{Consumer Electronics}}},
  keywords = {6G mobile communication,Consumer Electronics,Data models,Data privacy,Digital Twin,Federated Meta Learning,Intrusion detection,Intrusion Detection,Meta Learning,Metaverse,Security,Training}
}

@article{he_CGANBasedCollaborativeIntrusion_2023,
  title = {{{CGAN-Based Collaborative Intrusion Detection}} for {{UAV Networks}}: {{A Blockchain-Empowered Distributed Federated Learning Approach}}},
  shorttitle = {{{CGAN-Based Collaborative Intrusion Detection}} for {{UAV Networks}}},
  author = {He, Xiaoqiang and Chen, Qianbin and Tang, Lun and Wang, Weili and Liu, Tong},
  date = {2023-01},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {10},
  number = {1},
  pages = {120--132},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2022.3200121},
  url = {https://ieeexplore.ieee.org/abstract/document/9863068},
  urldate = {2024-04-12},
  abstract = {Numerous resource-constrained Internet of Things (IoT) devices make the edge IoT consisting of unmanned aerial vehicles (UAVs) vulnerable to network intrusion. Therefore, it is critical to design an effective intrusion detection system (IDS). However, the differences in local data sets among UAVs show small samples and uneven distribution, further reducing the detection accuracy of network intrusion. This article proposes a conditional generative adversarial net (CGAN)-based collaborative intrusion detection algorithm with blockchain-empowered distributed federated learning to solve the above problems. This study introduces long short-term memory (LSTM) into the CGAN training to improve the effect of generative networks. Based on the feature extraction ability of LSTM networks, the generated data with CGAN are used as augmented data and applied in the detection and classification of intrusion data. Distributed federated learning with differential privacy ensures data security and privacy and allows collaborative training of CGAN models using multiple distributed data sets. Blockchain stores and shares the training models to ensure security when the global model's aggregation and updating. The proposed method has good generalization ability, which can greatly improve the detection of intrusion data.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {blockchain,Blockchain,Blockchains,Collaborative work,conditional generative adversarial network,conditional generative adversarial network (CGAN),Data models,Data privacy,distributed federated learning,Internet of Things,Intrusion detection,intrusion detection system,intrusion detection system (IDS),long short-term memory,long short-term memory (LSTM),Training,UAV network,unmanned aerial vehicle (UAV) network}
}

@article{he_FederatedContinuousLearning_2023,
  title = {Federated {{Continuous Learning Based}} on {{Stacked Broad Learning System Assisted}} by {{Digital Twin Networks}}: {{An Incremental Learning Approach}} for {{Intrusion Detection}} in {{UAV Networks}}},
  shorttitle = {Federated {{Continuous Learning Based}} on {{Stacked Broad Learning System Assisted}} by {{Digital Twin Networks}}},
  author = {He, Xiaoqiang and Chen, Qianbin and Tang, Lun and Wang, Weili and Liu, Tong and Li, Li and Liu, Qinghai and Luo, Jia},
  date = {2023-11},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {10},
  number = {22},
  pages = {19825--19838},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2023.3282648},
  url = {https://ieeexplore.ieee.org/abstract/document/10143925},
  urldate = {2024-04-12},
  abstract = {The edge of the Internet of Things (IoT), which consists of unmanned aerial vehicles (UAVs), is vulnerable to network intrusion because software and wireless connections are used extensively in the IoT. Designing an efficient intrusion detection system (IDS) model is imperative. However, when creating IDS models with distributed data collected by UAVs, it is necessary to take precautions to protect the data's security and privacy. Furthermore, most of the IDS models are focused on one-time learning but not on continuous learning. To this end, we propose a federated continuous learning framework with a stacked broad learning system (FCL-SBLS) based on the digital twin network (DTN), which can learn and train the IDS model on new data quickly and continuously. In order to improve the efficiency and quality of the IDS model when training and aggregation, we employ an asynchronous federated learning (FL) architecture, and a deep deterministic policy gradient (DDPG)-based UAV selection scheme assisted by DTN is proposed to help the global IDS model aggregation. The presented algorithm is validated using the CIC-IDS2017 data set, and the simulation results reveal that our algorithm achieves higher efficiency and accuracy than the existing FL scheme.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {Computational modeling,Data models,Data privacy,Digital twin network (DTN),federated continuous learning (FCL),Internet of Things,Intrusion detection,intrusion detection system (IDS),Learning systems,stacked broad learning system (SBLS),Training,unmanned aerial vehicle (UAV) network}
}

@article{he_GameTheoryBasedIncentive_2023,
  title = {A {{Game Theory-Based Incentive Mechanism}} for {{Collaborative Security}} of {{Federated Learning}} in {{Energy Blockchain Environment}}},
  author = {He, Yunhua and Luo, Mingshun and Wu, Bin and Sun, Limin and Wu, Yongdong and Liu, Zhiquan and Xiao, Ke},
  date = {2023-12},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {10},
  number = {24},
  pages = {21294--21308},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2023.3282732},
  url = {https://ieeexplore.ieee.org/abstract/document/10143974},
  urldate = {2024-04-12},
  abstract = {With the digital transformation of the energy industry, energy blockchain is playing an important role in application areas, such as energy data sharing and distributed power trading. In this process, the use of energy data is a top priority. Federated learning (FL) can enable the analysis and computation of energy data while protecting their privacy. However, traditional FL relies on a central server and parties involved are not fully trusted. In energy blockchain environment, FL also faces data poisoning attacks launched by energy departments, besides, the supervisory committee carrying out checking models can launch deception attacks. Therefore, we propose a game theory-based incentive mechanism for collaborative security of FL in energy blockchain environment, which can discourage nodes from taking malicious behaviors in iterative training of FL. First, we propose an FL model in energy blockchain environment, which can protect privacy and achieve collaborative security. Considering that game theory can be used to analyze the strategies of participants, we build a game model with energy departments and supervisory committee as players and design our incentive mechanism based on game theory, which is implemented by smart contracts. Even if the accuracy of model checking algorithm is low, malicious behaviors in FL can be reduced by using our incentive mechanism. In particular, we prove that our mechanism can lead game model to a Nash equilibrium (NE) that achieve collaborative security. Security analysis and experimental evaluation show that our incentive mechanism is feasible in energy blockchain with robustness, reliability, and low complexity.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {Behavioral sciences,Blockchains,Collaboration,Computational modeling,Data models,Energy blockchain,Energy management,Federated learning,federated learning (FL),game theory,Game theory,incentive mechanism,poisoning attacks,Security}
}

@inproceedings{he_Lightweightnetworkintrusion_2022,
  title = {Lightweight Network Intrusion Detection Method Based on Improved Federated Learning},
  booktitle = {International {{Conference}} on {{Computer}}, {{Artificial Intelligence}}, and {{Control Engineering}} ({{CAICE}} 2022)},
  author = {He, Yang and Jia, Yongliang and Tao, Peng},
  date = {2022-12-02},
  volume = {12288},
  pages = {394--399},
  publisher = {SPIE},
  doi = {10.1117/12.2641086},
  url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12288/122881M/Lightweight-network-intrusion-detection-method-based-on-improved-federated-learning/10.1117/12.2641086.full},
  urldate = {2022-12-14},
  abstract = {Computer network has been widely used in all walks of life, network security has also received unprecedented attention, network intrusion detection technology is one of the key technologies to maintain network security. Traditional intrusion detection methods based on rules have some disadvantages, such as dependence on manual intervention, difficulty in updating rules database, and difficulty in detecting unknown intrusion. Therefore, a lightweight network intrusion detection method is designed based on improved federated learning. Firstly a network intrusion detection model is constructed based on improved federated learning to realize lightweight network intrusion detection. The experimental results show that the designed network intrusion detection method has good detection effect and has certain application value, which can be used as a reference for subsequent network intrusion detection.},
  eventtitle = {International {{Conference}} on {{Computer}}, {{Artificial Intelligence}}, and {{Control Engineering}} ({{CAICE}} 2022)}
}

@article{he_Reinforcementlearningmeets_[review],
  entrysubtype = {newspaper},
  title = {Reinforcement Learning Meets Network Intrusion Detection: A Transferable and Adaptable Framework for Anomaly Behavior Identification},
  author = {He, Mingshu and Wang, Xiaojuan and Wei, Peng and Jin, Lei and Yang, Liu and Li, Ziyang},
  year = {[review]},
  journaltitle = {IEEE Transactions on Network and Service Management},
  abstract = {Anomaly detection plays an important role in network security and traffic classification. Many works have focused on anomaly detection to improve network security, including traditional machine learning (ML) methods and deep learning (DL) methods. In the process of training models, these methods often require a large number of samples and need to get the results by classifying the whole dataset, which lead to their inflexibility. Meanwhile, the model trained on one dataset cannot be transferable to another dataset. These problems limit the application of previous methods in the network security management. To address these challenges, we consider using deep reinforcement learning (DRL) for anomaly detection, and propose a transferable and adaptable network intrusion detection system (TA-NIDS) based on DRL. The interaction process between the agent and the environment is different every time. A small scale dataset can also produce a large number of interactive processes. Therefore, few-shot learning is feasible. Then, a reasonable reward function can let the agent learn to choose outliers first without classifying the whole dataset. The real-time changing environment in reinforcement learning (RL) is also closer to the real environment. These make TA-NIDS more adaptable for the actual scene. More importantly, the original feature is transformed into many state, so there is no requirement for the feature dimension. And the general rather than specific state of one dataset makes the model transferable to other datasets. Experiments on IDS2017, IDS2018, NSL-KDD and UNSW-NB15 show that the framework which gives priority to selecting outliers can realize few-shot learning, has high accuracy, good transferability, and it is adaptable to the actual scene.},
  keywords = {\_done,\_unpublished}
}

@article{he_ReinforcementLearningMeets_2024,
  title = {Reinforcement {{Learning Meets Network Intrusion Detection}}: {{A Transferable}} and {{Adaptable Framework}} for {{Anomaly Behavior Identification}}},
  shorttitle = {Reinforcement {{Learning Meets Network Intrusion Detection}}},
  author = {He, Mingshu and Wang, Xiaojuan and Wei, Peng and Yang, Liu and Teng, Yinglei and Lyu, Renjian},
  date = {2024-04},
  journaltitle = {IEEE Transactions on Network and Service Management},
  volume = {21},
  number = {2},
  pages = {2477--2492},
  issn = {1932-4537},
  doi = {10.1109/TNSM.2024.3352586},
  url = {https://ieeexplore.ieee.org/document/10399344},
  urldate = {2024-06-30},
  abstract = {Anomaly detection plays an essential role in network security and traffic classification. Many studies have focused on anomaly detection to improve network security, including machine learning and deep learning methods. These methods often require numerous samples and must obtain the results by classifying the entire data set, thereby limiting their inflexibility. Although transfer and multitask learning have achieved some results in the model's transferability, these methods must manually label or reprocess the test set. These problems limit the application of previous methods in network security management. To solve these problems, we propose a transferable and adaptable network intrusion detection system (TA-NIDS) based on deep reinforcement learning. The interaction process between the agent and the environment varies every time. A small-scale data set can be used to produce many interactive processes. Therefore, robustness is guaranteed when there are few samples. Then, a reasonable reward function allows the agent to learn how to first choose outliers without classifying the entire data set. This makes the TA-NIDS more adaptable to the scene when we prioritize apparent outliers. More importantly, the original features are transformed into the state of the environment, so no requirement exists for the feature dimension. Furthermore, the general rather than the specific state of one data set makes the model transferable to other data sets. The experimental results for IDS2017, IDS2018, NSL-KDD, UNSW-NB15 and CIC-IoT2023 show that the proposed framework maintains good accuracy when prioritizing outliers and transferability are prioritized simultaneously.},
  eventtitle = {{{IEEE Transactions}} on {{Network}} and {{Service Management}}},
  keywords = {adaptable framework,anomaly detection,Anomaly detection,Behavioral sciences,Data models,Deep reinforcement learning,Feature extraction,Reinforcement learning,robustness,Telecommunication traffic,Training,transferable framework}
}

@incollection{hegedus_GossipLearningDecentralized_2019,
  title = {Gossip {{Learning}} as a {{Decentralized Alternative}} to {{Federated Learning}}},
  booktitle = {Distributed {{Applications}} and {{Interoperable Systems}}},
  author = {Heged\H us, Istv\'an and Danner, G\'abor and Jelasity, M\'ark},
  editor = {Pereira, Jos\'e and Ricci, Laura},
  date = {2019},
  volume = {11534},
  pages = {74--90},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-22496-7_5},
  url = {http://link.springer.com/10.1007/978-3-030-22496-7_5},
  urldate = {2022-02-04},
  abstract = {Federated learning is a distributed machine learning approach for computing models over data collected by edge devices. Most importantly, the data itself is not collected centrally, but a master-worker architecture is applied where a master node performs aggregation and the edge devices are the workers, not unlike the parameter server approach. Gossip learning also assumes that the data remains at the edge devices, but it requires no aggregation server or any central component. In this empirical study, we present a thorough comparison of the two approaches. We examine the aggregated cost of machine learning in both cases, considering also a compression technique applicable in both approaches. We apply a real churn trace as well collected over mobile phones, and we also experiment with different distributions of the training data over the devices. Surprisingly, gossip learning actually outperforms federated learning in all the scenarios where the training data are distributed uniformly over the nodes, and it performs comparably to federated learning overall.},
  isbn = {978-3-030-22495-0 978-3-030-22496-7},
  langid = {english},
  keywords = {\_read}
}

@article{hei_trustedfeatureaggregator_2020,
  title = {A Trusted Feature Aggregator Federated Learning for Distributed Malicious Attack Detection},
  author = {Hei, Xinhong and Yin, Xinyue and Wang, Yichuan and Ren, Ju and Zhu, Lei},
  date = {2020-12},
  journaltitle = {Computers \& Security},
  shortjournal = {Computers \& Security},
  volume = {99},
  pages = {102033},
  issn = {01674048},
  doi = {10.1016/j.cose.2020.102033},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167404820303060},
  urldate = {2021-10-25},
  langid = {english},
  keywords = {survey-fids}
}

@online{hejazinia_FELHighCapacity_2022,
  title = {{{FEL}}: {{High Capacity Learning}} for {{Recommendation}} and {{Ranking}} via {{Federated Ensemble Learning}}},
  shorttitle = {{{FEL}}},
  author = {Hejazinia, Meisam and Huba, Dzmitry and Leontiadis, Ilias and Maeng, Kiwan and Malek, Mani and Melis, Luca and Mironov, Ilya and Nasr, Milad and Wang, Kaikai and Wu, Carole-Jean},
  date = {2022-06-07},
  eprint = {2206.03852},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2206.03852},
  urldate = {2022-07-05},
  abstract = {Federated learning (FL) has emerged as an effective approach to address consumer privacy needs. FL has been successfully applied to certain machine learning tasks, such as training smart keyboard models and keyword spotting. Despite FL's initial success, many important deep learning use cases, such as ranking and recommendation tasks, have been limited from on-device learning. One of the key challenges faced by practical FL adoption for DL-based ranking and recommendation is the prohibitive resource requirements that cannot be satisfied by modern mobile systems. We propose Federated Ensemble Learning (FEL) as a solution to tackle the large memory requirement of deep learning ranking and recommendation tasks. FEL enables large-scale ranking and recommendation model training on-device by simultaneously training multiple model versions on disjoint clusters of client devices. FEL integrates the trained sub-models via an over-arch layer into an ensemble model that is hosted on the server. Our experiments demonstrate that FEL leads to 0.43--2.31\% model quality improvement over traditional on-device federated learning --- a significant improvement for ranking and recommendation system use cases.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {\_read\_urgently,Computer Science - Information Retrieval,Computer Science - Machine Learning}
}

@article{heldens_litstudyPythonpackage_2022,
  title = {Litstudy: {{A Python}} Package for Literature Reviews},
  shorttitle = {Litstudy},
  author = {Heldens, Stijn and Sclocco, Alessio and Dreuning, Henk and family=Werkhoven, given=Ben, prefix=van, useprefix=true and Hijma, Pieter and Maassen, Jason and family=Nieuwpoort, given=Rob V., prefix=van, useprefix=true},
  date = {2022-12-01},
  journaltitle = {SoftwareX},
  shortjournal = {SoftwareX},
  volume = {20},
  pages = {101207},
  issn = {2352-7110},
  doi = {10.1016/j.softx.2022.101207},
  url = {https://www.sciencedirect.com/science/article/pii/S235271102200125X},
  urldate = {2024-06-06},
  abstract = {Researchers are often faced with exploring new research domains. Broad questions about the research domain, such as who are the influential authors or what are important topics, are difficult to answer due to the overwhelming number of relevant publications. Therefore, we present litstudy: a Python package that enables answering such questions using simple scripts or Jupyter notebooks. The package enables selecting scientific publications and studying their metadata using visualizations, bibliographic network analysis, and natural language processing. The software was previously used in a publication on the landscape of Exascale computing, and we envision great potential for reuse.},
  keywords = {Bibliometrics,Jupyter,Literature review,Python}
}

@online{hendrycks_DeepAnomalyDetection_2019,
  title = {Deep {{Anomaly Detection}} with {{Outlier Exposure}}},
  author = {Hendrycks, Dan and Mazeika, Mantas and Dietterich, Thomas},
  date = {2019-01-28},
  eprint = {1812.04606},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1812.04606},
  url = {http://arxiv.org/abs/1812.04606},
  urldate = {2022-12-14},
  abstract = {It is important to detect anomalous inputs when deploying machine learning systems. The use of larger and more complex inputs in deep learning magnifies the difficulty of distinguishing between anomalous and in-distribution examples. At the same time, diverse image and text data are available in enormous quantities. We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure (OE). This enables anomaly detectors to generalize and detect unseen anomalies. In extensive experiments on natural language processing and small- and large-scale vision tasks, we find that Outlier Exposure significantly improves detection performance. We also observe that cutting-edge generative models trained on CIFAR-10 may assign higher likelihoods to SVHN images than to CIFAR-10 images; we use OE to mitigate this issue. We also analyze the flexibility and robustness of Outlier Exposure, and identify characteristics of the auxiliary dataset that improve performance.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{hernandez_WiFederatedScalableWiFi_2021,
  title = {{{WiFederated}}: {{Scalable WiFi Sensing}} Using {{Edge Based Federated Learning}}},
  shorttitle = {{{WiFederated}}},
  author = {Hernandez, Steven M. and Bulut, Eyuphan},
  date = {2021},
  journaltitle = {IEEE Internet of Things Journal},
  shortjournal = {IEEE Internet Things J.},
  pages = {1--1},
  issn = {2327-4662, 2372-2541},
  doi = {10/gpbg3t},
  url = {https://ieeexplore.ieee.org/document/9659826/},
  urldate = {2022-01-31},
  abstract = {WiFi sensing using Channel State Information (CSI) offers a device-free and non-intrusive method for human activity monitoring. However, the data-hungry and location-specific training process hinders its scalable deployment at large sizes. In this work, we propose WiFederated, a federated learning (FL) approach to train machine learning models for WiFi sensing tasks. Using WiFederated, client devices can not only perform training in parallel at the edge instead of sequentially at a central server but can also collaboratively learn and share generalizable location-independent traits about physical actions being monitored. We demonstrate that an FL model trained on as few as 2-3 locations can provide high prediction accuracy in new locations even without any data available from them. We also demonstrate how new locations can achieve higher prediction accuracy even with a small number of available samples when using the pretrained FL model rather than training from scratch. The results show that the FL model can save local training epochs and reduce the need for large data collection at each new location. Thus, the proposed WiFederated system scales as more locations are added. We show that WiFederated provides a more accurate and time efficient solution compared to existing transfer learning and adversarial learning solutions thanks to the parallel training ability at multiple clients. By introducing new client selection methods during the FL process, we also show that accuracy can further increase. Finally, we evaluate the feasibility of training models at the edge and introduce continuous annotation to allow for continuous learning over time.},
  langid = {english}
}

@online{herzberg_BreakingMiraiIoT_2016,
  title = {Breaking {{Down Mirai}}: {{An IoT DDoS Botnet Analysis}}},
  author = {Herzberg, Ben and Zeifman, Igal and Bekerman, Dima},
  date = {2016},
  url = {https://www.imperva.com/blog/malware-analysis-mirai-ddos-botnet/?redirect=Incapsula},
  urldate = {2021-03-12}
}

@article{hidayat_MachineLearningBasedIntrusion_2022,
  title = {Machine {{Learning-Based Intrusion Detection System}}: {{An Experimental Comparison}}},
  shorttitle = {Machine {{Learning-Based Intrusion Detection System}}},
  author = {Hidayat, Imran and Ali, Muhammad Zulfiqar and Arshad, Arshad},
  date = {2022-07-13},
  journaltitle = {Journal of Computational and Cognitive Engineering},
  issn = {2810-9503},
  doi = {10.47852/bonviewJCCE2202270},
  url = {https://ojs.bonviewpress.com/index.php/JCCE/article/view/270},
  urldate = {2023-05-11},
  abstract = {Recently, networks are moving toward automation and getting more and more intelligent. With the advent of big data and cloud computing technologies, lots and lots of data are being produced on the internet. Every day, petabytes of data are produced from websites, social media sites, or the internet. As more and more data are produced, a continuous threat of network attacks is also growing. An intrusion detection system (IDS) is used to detect such types of attacks in the network. IDS inspects packet headers and data and decides whether the traffic is anomalous or normal based on the contents of the packet. In this research, ML techniques are being used for intrusion detection purposes. Feature selection is also used for efficient and optimal feature selection. The research proposes a hybrid feature selection technique composed of the Pearson correlation coefficient and random forest model. For the machine learning (ML) model, decision tree, AdaBoost, and K-nearest neighbor are trained and tested on the TON\_IoT dataset. The dataset is new and contains new and recent attack types and features. For deep learning (DL), multilayer perceptron (MLP) and long short-term memory are trained and tested. Evaluation is done on the basis of accuracy, precision, and recall. It is concluded from the results that the decision tree for ML and MLP for DL provides optimal accuracy with fewer false-positive and false-negative rates. It is also concluded from the results that the ML techniques are effective for detecting intrusion in the networks.},
  langid = {english},
  keywords = {machine learning}
}

@report{hideya_LANSecurityMonitoringProject_2018,
  type = {Whitepaper},
  title = {{{LAN-Security Monitoring Project}}},
  author = {Hideya, Ochiai},
  date = {2018},
  url = {https://lan-security.net/whitepaper.pdf},
  urldate = {2021-10-22},
  langid = {english}
}

@article{hoffmannsouza_surveydecisionmakingbased_2020,
  title = {A Survey on Decision-Making Based on System Reliability in the Context of {{Industry}} 4.0},
  author = {Hoffmann Souza, Marcos Leandro and family=Costa, given=Cristiano Andr\'e, prefix=da, useprefix=true and family=Oliveira Ramos, given=Gabriel, prefix=de, useprefix=true and family=Rosa Righi, given=Rodrigo, prefix=da, useprefix=true},
  date = {2020-07},
  journaltitle = {Journal of Manufacturing Systems},
  volume = {56},
  pages = {133--156},
  issn = {02786125},
  doi = {10.1016/j.jmsy.2020.05.016},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0278612520300807},
  abstract = {The business world is continually changing. Dynamic environments, full of uncertainties, complexities, and ambiguities, demand faster and more confident decisions. To compete in this environment, Industry 4.0 emerges as an essential alternative. In this context, the reliability of manufacturing is an essential aspect for companies to make successful decisions. In the literature, several technologies associated with Industry 4.0 have been applied to improve the availability of equipment, including the Internet of Things (IoT), Cyber-Physical Systems (CPS), blockchain, and data mining. Nevertheless, there is still no survey study that seeks to show how reliability has collaborated to support decision-making in organizations, in the context of Industry 4.0. In general, most applications still focus on the productivity and health of individual equipment. However, in today's volatile and complex businesses, local decisions are no longer sufficient; it is necessary to analyze the organization entirely. Thus, being aware of the impacts that a local failure can impose on the entire company has significant weight in the decision-making process. In this context, this article presents a survey to identify how researches on systems reliability has contributed to and supported the development of decision-making in Industry 4.0. The main contribution of this article is to highlight how reliability can be used to support different types of strategic decisions in the context of Industry 4.0. Finally, it highlights the need for research associating management decisions with the technologies of Industry 4.0.},
  issue = {May}
}

@article{hogan_CausalInferenceStatistics_2019,
  title = {Causal {{Inference}} in {{Statistics}}: {{A Primer}} (Book Review)},
  shorttitle = {Causal {{Inference}} in {{Statistics}}},
  author = {Hogan, Joseph W.},
  date = {2019-06-01},
  journaltitle = {Biometrics},
  volume = {75},
  number = {2},
  pages = {708--709},
  issn = {0006-341X, 1541-0420},
  doi = {10.1111/biom.13079},
  url = {https://academic.oup.com/biometrics/article/75/2/708-709/7517335},
  urldate = {2024-07-01},
  langid = {english}
}

@unpublished{hossain_AdversarialAnalysisDifferentiallyPrivate_2022,
  title = {Adversarial {{Analysis}} of the {{Differentially-Private Federated Learning}} in {{Cyber-Physical Critical Infrastructures}}},
  author = {Hossain, Md Tamjid and Badsha, Shahriar and Hung and La and Shen, Haoting and Islam, Shafkat and Khalil, Ibrahim and Yi, Xun},
  date = {2022-04-06},
  eprint = {2204.02654},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2204.02654},
  urldate = {2022-04-13},
  abstract = {Differential privacy (DP) is considered to be an effective privacy-preservation method to secure the promising distributed machine learning (ML) paradigm- federated learning (FL) from privacy attacks (e.g., membership inference attack). Nevertheless, while the DP mechanism greatly alleviates the privacy concerns, recent studies have shown that it can be exploited to conduct security attacks (e.g., false data injection attacks). To address such attacks on FL-based applications in critical infrastructures, in this paper, we perform the first systematic study on the DP-exploited poisoning attacks from an adversarial point of view. We demonstrate that the DP method, despite providing a level of privacy guarantee, can effectively open a new poisoning attack vector for the adversary. Our theoretical analysis and empirical evaluation on a smart grid dataset show the FL performance degradation (sub-optimal model generation) scenario due to the differential noise-exploited selective model poisoning attacks. As a countermeasure, we propose a reinforcement learning-based differential privacy level selection (rDP) process. The rDP process utilizes the differential privacy parameters (privacy loss, information leakage probability, etc.) and the losses to intelligently generate an optimal privacy level for the nodes. The evaluation shows the accumulated reward and errors of the proposed technique converge to an optimal privacy policy.},
  langid = {english},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},â›” No DOI found,Computer Science - Cryptography and Security}
}

@article{hou_FederatedLearningBasedFault_2022,
  title = {A {{Federated Learning-Based Fault Detection Algorithm}} for {{Power Terminals}}},
  author = {Hou, Shuai and Lu, Jizhe and Zhu, Enguo and Zhang, Hailong and Ye, Aliaosha},
  date = {2022-07-19},
  journaltitle = {Mathematical Problems in Engineering},
  volume = {2022},
  pages = {e9031701},
  publisher = {Hindawi},
  issn = {1024-123X},
  doi = {10.1155/2022/9031701},
  url = {https://www.hindawi.com/journals/mpe/2022/9031701/},
  urldate = {2022-08-11},
  abstract = {Power terminal is an important part of the power grid, and fault detection of power terminals is essential for the safety of the power grid. Existing fault detection of power terminals is usually based on artificial intelligent or deep learning models in the cloud or edge servers to achieve high accuracy and low latency. However, these methods cannot protect the privacy of the terminals and update the detection model incrementally. A terminal-edge-server collaborative fault detection model based on federated learning is proposed in this study to improve the accuracy of fault detection, reduce the data transmission and protect the privacy of the terminals. The fault detection model is initially trained in the server using historical data and updated using the parameters of local models from edge servers according to different updating strategies, then the parameters will be sent to each edge server and further to all terminals. Each edge server updates the local model via the compressed system log from terminals in its coverage region, and each terminal uses the model to detect fault according to the system behavior in the log. Experiment results show that this fault detection algorithm has high accuracy and low latency, and the accuracy increases with more model updating.},
  langid = {english}
}

@article{hou_Networkintrusiondetection_2022,
  title = {Network Intrusion Detection Based on {{DNA}} Spatial Information},
  author = {Hou, Tianhao and Xing, Hongyan and Liang, Xinyi and Su, Xin and Wang, Zenghui},
  date = {2022-08-28},
  journaltitle = {Computer Networks},
  shortjournal = {Computer Networks},
  pages = {109318},
  issn = {1389-1286},
  doi = {10.1016/j.comnet.2022.109318},
  url = {https://www.sciencedirect.com/science/article/pii/S1389128622003620},
  urldate = {2022-08-31},
  abstract = {There is an ever-increasing risk of illegal access-induced Network Intrusion (NI), which calls for prompt detection of illegal network behavior through profound Network Traffic (NT) analyses. However, current intrusion detection methods are limited in accuracy due to insufficient data standardization. This paper puts forward a deoxyribonucleic acid (DNA)-Spatial Information (SI) method to overcome these limitations. A DNA encoding model is formed, which defines a mapping relationship between NT attributes and nucleobases to reconstruct NT samples expressed as DNA sequences. Then, a feature extraction algorithm is constructed that deduces a Spatial Information Feature Matrix (SIFM) to represent sequence statistical features. A Random Forest (RF) algorithm is adopted as a matching process to determine NI behaviors considering the detection efficiency. Following experiments evaluate its method performance on two datasets, NSL-KDD and UNSW-NB15. Results demonstrate that DNA-SI obtains better results than state-of-the-art works, where the accuracy, F1-score, recall, far are 95.75\%, 94.41\%, 94.12\%, 3.26\% and 92.30\%, 92.78\%, 89.82\%, 4.66\% respectively. The fact that it is insusceptible to minority intrusion samples is another point worth attention. In sum, this quick and accurate network intrusion detection points to a new orientation for safeguarding network security.},
  langid = {english},
  keywords = {Cybersecurity,DNA encoding,IDS,Intrusion detection}
}

@article{houda_BlockchainEnabledFederatedLearning_2024,
  title = {Blockchain-{{Enabled Federated Learning}} for {{Enhanced Collaborative Intrusion Detection}} in {{Vehicular Edge Computing}}},
  author = {Houda, Zakaria Abou El and Moudoud, Hajar and Brik, Bouziane and Khoukhi, Lyes},
  date = {2024},
  journaltitle = {IEEE Transactions on Intelligent Transportation Systems},
  pages = {1--0},
  issn = {1558-0016},
  doi = {10.1109/TITS.2024.3351699},
  url = {https://ieeexplore.ieee.org/abstract/document/10414404},
  urldate = {2024-04-12},
  abstract = {Intelligent Transportation Systems (ITSs) are transforming the global monitoring of road safety. These systems, including vehicular networks and transportation infrastructure, are vulnerable to several security issues, which could disrupt services and potentially cause harm to the users. It is crucial to establish robust security measures to protect against evolving attacks and ensure the safe and reliable operation of ITS. Artificial Intelligence (AI)-based Intrusion Detection Systems (IDS) are mainly used to enhance the security of ITS. The adoption of AI-based techniques to secure ITS against new emerging threats has been limited due to a lack of realistic and recent data on these types of attacks ( i.e., zero-day attacks). In this context, we introduce a novel Edge-based Framework that uses Federated Learning (FL) and blockchain to secure ITS against new emerging threats. In particular, our proposed framework consists of (1) a novel distributed Edge-based architecture that allows multiple Edge nodes to securely collaborate while preserving their privacy; and (2) a decentralized and secure reputation system based on blockchain technology to maintain the reliability and trustworthiness of the FL process within the ITS; This system manages reputation data for individual nodes (such as vehicles), guaranteeing the integrity of the FL training process. Experiment results using the UNSW-NB15 dataset show that our proposed framework achieves high accuracy and F1 score (99\%) in detecting new threats while ensuring the privacy and reliability of the whole ITS. These results demonstrate the effectiveness of our proposed framework in securing ITS.},
  eventtitle = {{{IEEE Transactions}} on {{Intelligent Transportation Systems}}},
  keywords = {blockchain,Blockchains,Data privacy,edge computing,Federated learning,federated learning(FL),green vehicular networks,Intrusion detection,intrusion detection systems,Privacy,Reliability,Security,Sustainable intelligent transportation systems}
}

@inproceedings{hsieh_NonIIDDataQuagmire_2020,
  title = {The {{Non-IID Data Quagmire}} of {{Decentralized Machine Learning}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Hsieh, Kevin and Phanishayee, Amar and Mutlu, Onur and Gibbons, Phillip},
  date = {2020-11-21},
  pages = {4387--4398},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v119/hsieh20a.html},
  urldate = {2022-09-01},
  abstract = {Many large-scale machine learning (ML) applications need to perform decentralized learning over datasets generated at different devices and locations. Such datasets pose a significant challenge to decentralized learning because their different contexts result in significant data distribution skew across devices/locations. In this paper, we take a step toward better understanding this challenge by presenting a detailed experimental study of decentralized DNN training on a common type of data skew: skewed distribution of data labels across devices/locations. Our study shows that: (i) skewed data labels are a fundamental and pervasive problem for decentralized learning, causing significant accuracy loss across many ML applications, DNN models, training datasets, and decentralized learning algorithms; (ii) the problem is particularly challenging for DNN models with batch normalization; and (iii) the degree of data skew is a key determinant of the difficulty of the problem. Based on these findings, we present SkewScout, a system-level approach that adapts the communication frequency of decentralized learning algorithms to the (skew-induced) accuracy loss between data partitions. We also show that group normalization can recover much of the accuracy loss of batch normalization.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@article{hu_ContributionParticipationbasedFederated_2022,
  title = {Contribution- and {{Participation-based Federated Learning}} on Non-{{IID Data}}},
  author = {Hu, Fei and Zhou, Wuneng and Liao, Kaili and Li, Hongliang},
  date = {2022},
  journaltitle = {IEEE Intelligent Systems},
  shortjournal = {IEEE Intell. Syst.},
  pages = {1--1},
  issn = {1541-1672, 1941-1294},
  doi = {10.1109/MIS.2022.3168298},
  url = {https://ieeexplore.ieee.org/document/9760086/},
  urldate = {2022-07-05},
  abstract = {The learning process takes place inside clients in federated learning (FL). How to effectively motivate clients and avoid the impact of statistical heterogeneity are challenges in FL. This paper proposes contribution- and participationbased federated learning (CPFL) to address these challenges. CPFL can effectively allocate client incentives and aggregate models according to client contribution ratios, by which it can reduce the impact of heterogeneous data. To get effective and approximately fair client contributions faster, we propose an extended Raiffa solution (ERS). Compared to the conventional solution Shapley Value, the time complexity of ERS goes from O(2n) down to O(n). We perform extensive experiments with the MNIST/EMNIST datasets, heterogeneous datasets, and with different ratios of participation reward. Experimental results demonstrate that CPFL generally has a better learning effect in the heterogeneous case.},
  langid = {english}
}

@article{hu_DecentralizedFederatedLearning_2019,
  title = {Decentralized {{Federated Learning}}: {{A Segmented Gossip Approach}}},
  shorttitle = {Decentralized {{Federated Learning}}},
  author = {Hu, Chenghao and Jiang, Jingyan and Wang, Zhi},
  date = {2019-08-21},
  journaltitle = {ArXiv},
  url = {https://www.semanticscholar.org/paper/Decentralized-Federated-Learning%3A-A-Segmented-Hu-Jiang/df4fa94897ce02d2f394d8ae7304da639d3e7b5c},
  urldate = {2023-09-11},
  abstract = {The emerging concern about data privacy and security has motivated the proposal of federated learning, which allows nodes to only synchronize the locally-trained models instead their own original data. Conventional federated learning architecture, inherited from the parameter server design, relies on highly centralized topologies and the assumption of large nodes-to-server bandwidths. However, in real-world federated learning scenarios the network capacities between nodes are highly uniformly distributed and smaller than that in a datacenter. It is of great challenges for conventional federated learning approaches to efficiently utilize network capacities between nodes. In this paper, we propose a model segment level decentralized federated learning to tackle this problem. In particular, we propose a segmented gossip approach, which not only makes full utilization of node-to-node bandwidth, but also has good training convergence. The experimental results show that even the training time can be highly reduced as compared to centralized federated learning.},
  keywords = {â›” No DOI found}
}

@article{hu_DistributedFireDetection_2023,
  title = {Distributed {{Fire Detection}} and {{Localization Model Using Federated Learning}}},
  author = {Hu, Yue and Fu, Xinghao and Zeng, Wei},
  date = {2023-01},
  journaltitle = {Mathematics},
  volume = {11},
  number = {7},
  pages = {1647},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2227-7390},
  doi = {10.3390/math11071647},
  url = {https://www.mdpi.com/2227-7390/11/7/1647},
  urldate = {2024-04-12},
  abstract = {Fire detection and monitoring systems based on machine vision have been gradually developed in recent years. Traditional centralized deep learning model training methods transfer large amounts of video image data to the cloud, making image data privacy and confidentiality difficult. In order to protect the data privacy in the fire detection system with heterogeneous data and to enhance its efficiency, this paper proposes an improved federated learning algorithm incorporating computer vision: FedVIS, which uses a federated dropout and gradient selection algorithm to reduce communication overhead, and uses a transformer to replace a traditional neural network to improve the robustness of federated learning in the context of heterogeneous data. FedVIS can reduce the communication overhead in addition to reducing the catastrophic forgetting of previous devices, improving convergence, and producing superior global models. In this paper's experimental results, FedVIS outperforms the common federated learning methods FedSGD, FedAVG, FedAWS, and CMFL, and improves the detection effect by reducing communication costs. As the amount of clients increases, the accuracy of other algorithmic models decreases by 2--5\%, and the number of communication rounds required increases significantly; meanwhile, our method maintains a superior detection performance while requiring roughly the same number of communication rounds.},
  issue = {7},
  langid = {english},
  keywords = {deep learning,federated learning,fire detection system,privacy preservation}
}

@article{hu_PrivacypreservingFewshotTraffic_2023,
  title = {Privacy-Preserving {{Few-shot Traffic Detection}} against {{Advanced Persistent Threats}} via {{Federated Meta Learning}}},
  author = {Hu, Yilun and Wu, Jun and Li, Gaolei and Li, Jianhua and Cheng, Jinke},
  date = {2023},
  journaltitle = {IEEE Transactions on Network Science and Engineering},
  pages = {1--11},
  issn = {2327-4697},
  doi = {10.1109/TNSE.2023.3304556},
  url = {https://ieeexplore.ieee.org/abstract/document/10214668},
  urldate = {2024-04-12},
  abstract = {Advanced Persistent Threats (APT) utilizes multiple zero-day vulnerabilities to threaten critical industrial infrastructure, having the characteristics of burst, unknown and cross-domain. To resist APT attacks, existing wisdom usually establish a security monitoring platform that remotely links to the cloud-based threat intelligence center. However, the real scenario where few victim users are willing to share raw attack samples considering privacy-preservation, such mentality is hysteretic and cannot identify APT attacks quickly without sacrificing additional incentives. To address this issue, a novel privacy-preserving few-shot traffic detection (PFTD) method based on federated meta learning (FML) is proposed. The PFTD treats the APT detection task as a model generalization optimization process, that transfers the learned knowledge to identify local unknown samples. Client-side models in FML achieve knowledge transferring by two-phase updating over both support dataset and query dataset, while the server-side model obtains global knowledge with model aggregation. These processes compile useful knowledge against APT attacks. With a novel wisdom, we obtained three advantages: 1) High accuracy with a few attack samples; 2) Low latency detection for removing rules matching process; 3) High personalizing to cross-domain APT attacks. Extensive experiments based on multiple benchmark datasets like CICIDS2017 and DAPT 2020 prove the superiority of proposed PFTD.},
  eventtitle = {{{IEEE Transactions}} on {{Network Science}} and {{Engineering}}},
  keywords = {Advanced Persistent Threats,Behavioral sciences,Data models,Federated Meta Learning,Few-shot Traffic Detection,Image edge detection,Intrusion detection,Metalearning,Privacy-preserving,Telecommunication traffic,Training}
}

@article{huang_EEFEDPersonalizedfederated_2022,
  title = {{{EEFED}}: {{Personalized}} Federated Learning of {{Execution}}\&{{Evaluation}} Dual Network for {{CPS}} Intrusion Detection},
  shorttitle = {{{EEFED}}},
  author = {Huang, Xianting and Liu, Jing and Lai, Yingxu and Mao, Beifeng and Lyu, Hongshuo},
  date = {2022},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  pages = {1--1},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2022.3214723},
  abstract = {In the modern interconnected world, intelligent networks and computing technologies are increasingly being incorporated in industrial systems. However, this adoption of advanced technology has resulted in increased cyber threats to cyber-physical systems. Existing intrusion detection systems are continually challenged by constantly evolving cyber threats. Machine learning algorithms have been applied for intrusion detection. In these techniques, a classification model is trained by learning cyber behavior patterns. However, these models typically require considerable high-quality datasets. Limited attack samples are available because of the unpredictability and constant evolution of cyber threats. To address these problems, we propose a novel federated Execution\&Evaluation dual network framework (EEFED), which allows multiple federal participants to personalize their local detection models undermining the original purpose of Federated Learning. Thus, a general global detection model was developed for collaboratively improving the performance of a single local model against cyberattacks. The proposed personalized update algorithm and the optimizing backtracking parameters replacement policy effectively reduced the negative influence of federated learning in imbalanced and non-i.i.d distribution of data. The proposed method improved model stability. Furthermore, extensive experiments conducted on a network dataset in various cyber scenarios revealed that the proposed method outperformed single model and state-of-the-art methods.},
  eventtitle = {{{IEEE Transactions}} on {{Information Forensics}} and {{Security}}},
  keywords = {\_read,Computational modeling,Computer crime,cyber security,cyber-physical system (CPS),Data models,Federated learning,intrusion detection,Intrusion detection,personalized model,Security,Training}
}

@article{huang_EEFEDPersonalizedfederated_2022a,
  title = {{{EEFED}}: {{Personalized}} Federated Learning of {{Execution}}\&{{Evaluation}} Dual Network for {{CPS}} Intrusion Detection},
  shorttitle = {{{EEFED}}},
  author = {Huang, Xianting and Liu, Jing and Lai, Yingxu and Mao, Beifeng and Lyu, Hongshuo},
  date = {2022},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  pages = {1--1},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2022.3214723},
  abstract = {In the modern interconnected world, intelligent networks and computing technologies are increasingly being incorporated in industrial systems. However, this adoption of advanced technology has resulted in increased cyber threats to cyber-physical systems. Existing intrusion detection systems are continually challenged by constantly evolving cyber threats. Machine learning algorithms have been applied for intrusion detection. In these techniques, a classification model is trained by learning cyber behavior patterns. However, these models typically require considerable high-quality datasets. Limited attack samples are available because of the unpredictability and constant evolution of cyber threats. To address these problems, we propose a novel federated Execution\&Evaluation dual network framework (EEFED), which allows multiple federal participants to personalize their local detection models undermining the original purpose of Federated Learning. Thus, a general global detection model was developed for collaboratively improving the performance of a single local model against cyberattacks. The proposed personalized update algorithm and the optimizing backtracking parameters replacement policy effectively reduced the negative influence of federated learning in imbalanced and non-i.i.d distribution of data. The proposed method improved model stability. Furthermore, extensive experiments conducted on a network dataset in various cyber scenarios revealed that the proposed method outperformed single model and state-of-the-art methods.},
  eventtitle = {{{IEEE Transactions}} on {{Information Forensics}} and {{Security}}},
  keywords = {Computational modeling,Computer crime,cyber security,cyber-physical system (CPS),Data models,Federated learning,intrusion detection,Intrusion detection,personalized model,Security,Training}
}

@article{huang_EEFEDPersonalizedFederated_2023,
  title = {{{EEFED}}: {{Personalized Federated Learning}} of {{Execution}}\&{{Evaluation Dual Network}} for {{CPS Intrusion Detection}}},
  shorttitle = {{{EEFED}}},
  author = {Huang, Xianting and Liu, Jing and Lai, Yingxu and Mao, Beifeng and Lyu, Hongshuo},
  date = {2023},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  volume = {18},
  pages = {41--56},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2022.3214723},
  url = {https://ieeexplore.ieee.org/document/9919869},
  urldate = {2024-04-12},
  abstract = {In the modern interconnected world, intelligent networks and computing technologies are increasingly being incorporated in industrial systems. However, this adoption of advanced technology has resulted in increased cyber threats to cyber-physical systems. Existing intrusion detection systems are continually challenged by constantly evolving cyber threats. Machine learning algorithms have been applied for intrusion detection. In these techniques, a classification model is trained by learning cyber behavior patterns. However, these models typically require considerable high-quality datasets. Limited attack samples are available because of the unpredictability and constant evolution of cyber threats. To address these problems, we propose a novel federated Execution \& Evaluation dual network framework (EEFED), which allows multiple federal participants to personalize their local detection models undermining the original purpose of Federated Learning. Thus, a general global detection model was developed for collaboratively improving the performance of a single local model against cyberattacks. The proposed personalized update algorithm and the optimizing backtracking parameters replacement policy effectively reduced the negative influence of federated learning in imbalanced and non-i.i.d distribution of data. The proposed method improved model stability. Furthermore, extensive experiments conducted on a network dataset in various cyber scenarios revealed that the proposed method outperformed single model and state-of-the-art methods.},
  eventtitle = {{{IEEE Transactions}} on {{Information Forensics}} and {{Security}}},
  keywords = {Computational modeling,Computer crime,cyber security,cyber-physical system (CPS),Data models,Federated learning,intrusion detection,Intrusion detection,personalized model,Security,Training}
}

@unpublished{huang_EFMVFLEfficientFlexible_2022,
  title = {{{EFMVFL}}: {{An Efficient}} and {{Flexible Multi-party Vertical Federated Learning}} without a {{Third Party}}},
  shorttitle = {{{EFMVFL}}},
  author = {Huang, Yimin and Feng, Xinyu and Wang, Wanwan and He, Hao and Wang, Yukun and Yao, Ming},
  date = {2022-01-17},
  eprint = {2201.06244},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2201.06244},
  urldate = {2022-01-31},
  abstract = {Federated learning allows multiple participants to conduct joint modeling without disclosing their local data. Vertical federated learning (VFL) handles the situation where participants share the same ID space and different feature spaces. In most VFL frameworks, to protect the security and privacy of the participants' local data, a third party is needed to generate homomorphic encryption key pairs and perform decryption operations. In this way, the third party is granted the right to decrypt information related to model parameters. However, it isn't easy to find such a credible entity in the real world. Existing methods for solving this problem are either communication-intensive or unsuitable for multi-party scenarios. By combining secret sharing and homomorphic encryption, we propose a novel VFL framework without a third party called EFMVFL, which supports flexible expansion to multiple participants with low communication overhead and is applicable to generalized linear models. We give instantiations of our framework under logistic regression and Poisson regression. Theoretical analysis and experiments show that our framework is secure, more efficient, and easy to be extended to multiple participants.},
  langid = {english},
  keywords = {â›” No DOI found,Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@article{huang_PersonalizedCrossSiloFederated_2021,
  title = {Personalized {{Cross-Silo Federated Learning}} on {{Non-IID Data}}},
  author = {Huang, Yutao and Chu, Lingyang and Zhou, Zirui and Wang, Lanjun and Liu, Jiangchuan and Pei, Jian and Zhang, Yong},
  date = {2021-05-18},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  shortjournal = {AAAI},
  volume = {35},
  number = {9},
  pages = {7865--7873},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v35i9.16960},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/16960},
  urldate = {2022-09-26},
  abstract = {Non-IID data present a tough challenge for federated learning. In this paper, we explore a novel idea of facilitating pairwise collaborations between clients with similar data. We propose FedAMP, a new method employing federated attentive message passing to facilitate similar clients to collaborate more. We establish the convergence of FedAMP for both convex and non-convex models, and propose a heuristic method to further improve the performance of FedAMP when clients adopt deep neural networks as personalized models. Our extensive experiments on benchmark data sets demonstrate the superior performance of the proposed methods.},
  langid = {english}
}

@misc{Hydra,
  title = {Hydra - {{A}} Framework for Elegantly Configuring Complex Applications},
  author = {Yadan, Omry},
  date = {2019},
  url = {https://github.com/facebookresearch/hydra},
  howpublished = {Github},
  keywords = {pinned}
}

@article{idrissi_FedANIDSFederatedlearning_2023,
  title = {Fed-{{ANIDS}}: {{Federated}} Learning for Anomaly-Based Network Intrusion Detection Systems},
  shorttitle = {Fed-{{ANIDS}}},
  author = {Idrissi, Meryem Janati and Alami, Hamza and El Mahdaouy, Abdelkader and El Mekki, Abdellah and Oualil, Soufiane and Yartaoui, Zakaria and Berrada, Ismail},
  date = {2023-12-30},
  journaltitle = {Expert Systems with Applications},
  shortjournal = {Expert Systems with Applications},
  volume = {234},
  pages = {121000},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2023.121000},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417423015026},
  urldate = {2024-04-12},
  abstract = {As computer networks and interconnected systems continue to gain widespread adoption, ensuring cybersecurity has become a prominent concern for organizations, regardless of their scale or size. Meanwhile, centralized machine learning-based Anomaly Detection (AD) methods have shown promising results in improving the accuracy and efficiency of Network Intrusion Detection Systems (NIDS). However, new challenges arise such as privacy concerns and regulatory restrictions that must be tackled. Federated Learning (FL) has emerged as a solution that allows distributed clients to collaboratively train a shared model while preserving the privacy of their local data. In this paper, we propose Fed-ANIDS, a NIDS that leverages AD and FL to address the privacy concerns associated with centralized models. To detect intrusions, we compute an intrusion score based on the reconstruction error of normal traffic using various AD models, including simple autoencoders, variational autoencoders, and adversarial autoencoders. We thoroughly evaluate Fed-ANIDS using various settings and popular datasets, including USTC-TFC2016, CIC-IDS2017, and CSE-CIC-IDS2018. The proposed method demonstrates its effectiveness by achieving high performance in terms of different metrics while preserving the data privacy of distributed clients. Our findings highlight that autoencoder-based models outperform other generative adversarial network-based models, achieving high detection accuracy coupled with fewer false alarms. In addition, the FL framework (FedProx), which is a generalization and re-parametrization of the standard method for FL (FedAvg), achieves better results. The code is available at https://github.com/meryemJanatiIdrissi/Fed-ANIDS.},
  keywords = {Anomaly detection,Autoencoders,Federated learning,Network intrusion detection,Network security and privacy}
}

@article{ioannou_GEMLIDSMIOTGreenEffective_2024,
  title = {{{GEMLIDS-MIOT}}: {{A Green Effective Machine Learning Intrusion Detection System}} Based on {{Federated Learning}} for {{Medical IoT}} Network Security Hardening},
  shorttitle = {{{GEMLIDS-MIOT}}},
  author = {Ioannou, Iacovos and Nagaradjane, Prabagarane and Angin, Pelin and Balasubramanian, Palaniappan and Kavitha, Karthick Jeyagopal and Murugan, Palani and Vassiliou, Vasos},
  date = {2024-03},
  journaltitle = {Computer Communications},
  shortjournal = {Computer Communications},
  volume = {218},
  pages = {209--239},
  issn = {01403664},
  doi = {10.1016/j.comcom.2024.02.023},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0140366424000793},
  urldate = {2024-04-12},
  abstract = {The increasing use of Internet of Things (IoT) gadgets in a daily rate has heightened security apprehension, particularly within the healthcare sector. To prevent the unauthorized disclosure of sensitive data, it is imperative for Internet of Things (IoT) systems to promptly and effectively respond to harmful activities. Nevertheless, the act of transferring data to distant cloud servers for analysis gives rise to both temporal delays and apprehensions regarding privacy. To ensure the security of medical Internet of Things (MIoT) networks, a power-efficient Intrusion Detection System (IDS) is employed for three primary objectives that it will result in three stages of execution: i) The objective is to categorize different types of attacks, such as Man-in-the-Middle (MitM) and Distributed Denial of Service (DDoS), by utilizing well-established machine learning (ML) techniques. This classification stage will serve to enhance the Intrusion Detection System (IDS) and the reporting system. ii) Anomaly detection (unknown attack identification), or detection of unknown attacks, will be employed to identify previously unknown attacks. This identification stage involves retraining the ML model to enable future recognition and classification of these unknown attacks when the anomaly attack detector identifies that an unknown attack is recognized. Then, a retraining of the first stage classification model is executed due to the anomaly detection. iii) To ensure that a remote cloud server remains current with the latest classification model changes, Federated Learning (FL) will be utilized. FL allows for collaborative model training while preserving data privacy and security. The experimental findings indicate that the Enhanced Random Forest (also called ensemble random forest) algorithm achieves a remarkable accuracy rate of 99.98\% in classifying attacks. Thus, it will be our first stage classifier. Continuing, the One-Class Support Vector Machine (SVM) algorithm demonstrates a high level of accuracy, reaching 99.7\% in detecting anomalies and, hence, it will be our second stage identifier. Finally, the third-stage approach, which has as a target the overall system model updater, will be our introduced Federated Learning approach that works with the Enhanced Random Forests and identifies the ERF differences from the old model in an optimal way. The efficacy of our technique is confirmed through the implementation of experiments involving an Internet of Things (IoT) system and a Raspberry Pi MIoT gateway and with simulations that simulate the FL updating process. These experiments successfully identify known and unknown attacks with a high-reliability level while limiting resource utilization and energy consumption. Future studies of this work will focus on enhancing the scalability and efficiency of our Intrusion Detection System in MIoT networks.},
  langid = {english}
}

@inproceedings{islam_DisparityAwareFederatedLearning_2023,
  title = {Disparity-{{Aware Federated Learning}} for {{Intrusion Detection Systems}} in {{Imbalanced Non-IID Settings}}},
  booktitle = {Proceedings of the 10th {{International Conference}} on {{Networking}}, {{Systems}} and {{Security}}},
  author = {Islam, Md Mohaiminul and Islam, A. B. M. Alim Al},
  date = {2023-12-21},
  series = {{{NSysS}} '23},
  pages = {42--50},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3629188.3629197},
  url = {https://dl.acm.org/doi/10.1145/3629188.3629197},
  urldate = {2024-04-12},
  abstract = {Many variants of Federated Learning have been proposed to settle different challenges that come with numerous practical applications, one of which is dealing with non-IID data sources. As decentralized data sources in real life are bound to be non-IID, this is one of the hardest challenges, and yet the earliest federated algorithms struggle to resolve this issue, resulting in worse non-IID performance. Also, applications that require capturing really intricate insights from data while upholding the latest data privacy standards, such as Intrusion Detection Systems (IDS) have enabled the use of FL in those domains. In this article, we propose a novel Disparity-Aware federated learning approach that tackles non-IID and data imbalance from both global and local learning steps of FL. Our method capitalizes on state-of-the-art loss functions to tackle data imbalance at the client level and a class distribution-dependent clustering algorithm at the server to tackle class distribution skew. The nature of the process renders it applicable even in asynchronous federated learning schemes. Experiments with multiple benchmark intrusion detection datasets reveal improved performance over traditional deep learning approaches as well as earlier federated learning techniques.},
  isbn = {9798400708787},
  keywords = {Disparity-awareness,Federated Learning,Imbalanced Learning,Intrusion Detection,Non-IID,NSL-KDD,UNSW-NB15}
}

@article{ismaila_ReviewApproachesFederated_2024,
  title = {Review on {{Approaches}} of {{Federated Modeling}} in {{Anomaly-Based Intrusion Detection}} for {{IoT Devices}}},
  author = {Isma'ila, Umar Audi and Danyaro, Kamaluddeen Usman and Muazu, Aminu Aminu and Maiwada, Umar Danjuma},
  date = {2024},
  journaltitle = {IEEE Access},
  volume = {12},
  pages = {30941--30961},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3369915},
  url = {https://ieeexplore.ieee.org/document/10445150},
  urldate = {2024-04-24},
  abstract = {The novelty of Federated Learning (FL) has emerged as a promising alternative to centralized machine learning systems in the context of anomaly-based intrusion detection systems (AIDS) deployed on Internet of Things (IoT) devices. Unlike traditional centralized models, FL allows on-device model training and updates, reducing privacy concerns and issues such as single points of failure and high false alarm rates (FAR). This approach, termed `Fed-AIDS,' offers a more secure and efficient solution. However, the development of Fed-AIDS models faces challenges related to limited training data and the diverse nature of IoT datasets. Additionally, FL's decentralized nature introduces weight divergence issues arising from non-Independently and Identically Distributed (non-IID) clients. To address these challenges and optimize Fed-AIDS modeling, interdisciplinary research efforts are vital. The primary objective of this study is to conduct an up-to-date review by adopting a Systematic Literature Review (SLR) approach to analyze existing studies of Fed-AIDS modeling procedures for IoT devices. Data from the published studies were retrieved from Scopus database, which covered major publishers such as IEEE, Elsevier and others. Specifically, our review conducted from the following Fed-AIDS perspectives: workflow and tools, training dataset, complexities of non-IID data in Fed-AIDS models, classification tasks, aggregation tasks, and model validation metrics. Based on the research findings, the study highlights a series of challenges and proposes potential solutions to stand in future research in Fed-AIDS modeling, aiming to advance the field of IoT device security.},
  eventtitle = {{{IEEE Access}}},
  keywords = {aggregation function,Anomaly detection,anomaly-based intrusion detection,Data models,Federated learning,Federated learning modeling,Internet of Things,Intrusion detection,IoT devices,Machine learning,non-IDD data,Performance evaluation,Reviews,Security,Systematics,Training}
}

@online{jadidi_SecurityMachineLearningBased_2022,
  title = {Security of {{Machine Learning-Based Anomaly Detection}} in {{Cyber Physical Systems}}},
  author = {Jadidi, Zahra and Pal, Shantanu and K, Nithesh Nayak and Selvakkumar, Arawinkumaar and Chang, Chih-Chia and Beheshti, Maedeh and Jolfaei, Alireza},
  date = {2022-06-12},
  eprint = {2206.05678},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2206.05678},
  urldate = {2022-07-05},
  abstract = {With the emergence of the Internet of Things (IoT) and Artificial Intelligence (AI) services and applications in the Cyber Physical Systems (CPS), the methods of protecting CPS against cyber threats is becoming more and more challenging. Various security solutions are implemented to protect CPS networks from cyber attacks. For instance, Machine Learning (ML) methods have been deployed to automate the process of anomaly detection in CPS environments. The core of ML is deep learning. However, it has been found that deep learning is vulnerable to adversarial attacks. Attackers can launch the attack by applying perturbations to input samples to mislead the model, which results in incorrect predictions and low accuracy. For example, the Fast Gradient Sign Method (FGSM) is a white-box attack that calculates gradient descent oppositely to maximize the loss and generates perturbations by adding the gradient to unpolluted data. In this study, we focus on the impact of adversarial attacks on deep learning-based anomaly detection in CPS networks and implement a mitigation approach against the attack by retraining models using adversarial samples. We use the Bot-IoT and Modbus IoT datasets to represent the two CPS networks. We train deep learning models and generate adversarial samples using these datasets. These datasets are captured from IoT and Industrial IoT (IIoT) networks. They both provide samples of normal and attack activities. The deep learning model trained with these datasets showed high accuracy in detecting attacks. An Artificial Neural Network (ANN) is adopted with one input layer, four intermediate layers, and one output layer. The output layer has two nodes representing the binary classification results. To generate adversarial samples for the experiment, we used a function called the `fast gradient method' from the Cleverhans library. The experimental result demonstrates the influence of FGSM adversarial samples on the accuracy of the predictions and proves the effectiveness of using the retrained model to defend against adversarial attacks.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing}}
}

@inproceedings{jahromi_DeepFederatedLearningBased_2021,
  title = {Deep {{Federated Learning-Based Cyber-Attack Detection}} in {{Industrial Control Systems}}},
  booktitle = {2021 18th {{International Conference}} on {{Privacy}}, {{Security}} and {{Trust}} ({{PST}})},
  author = {Jahromi, Amir Namavar and Karimipour, Hadis and Dehghantanha, Ali},
  date = {2021-12},
  pages = {1--6},
  doi = {10.1109/PST52912.2021.9647838},
  url = {https://ieeexplore.ieee.org/abstract/document/9647838},
  urldate = {2024-04-12},
  abstract = {Due to the differences between Information Technology (IT) and Industrial Control System (ICS) networks, current IT security solutions are not working effectively on ICS networks. Moreover, due to security and privacy issues, ICS owners usually do not share their network data with third parties to train specific machine learning-based ICS security solutions. To rectify the mentioned issues, a scalable deep federated learning-based method is presented in this paper. In the proposed method, each client trains an unsupervised deep neural network model using local data and shares its parameters with a server. The server aggregates the clients' parameters, makes a generalized public model, and shares it with all clients. The proposed model is evaluated using a real-world ICS dataset in a water treatment system and compared with two non-federated learning-based methods. Findings show that the proposed method outperformed the other two methods with the same computational complexity as other deep neural network-based methods in the literature.},
  eventtitle = {2021 18th {{International Conference}} on {{Privacy}}, {{Security}} and {{Trust}} ({{PST}})},
  keywords = {Computational modeling,Cyber-attack detection,Cyber-physical systems,Data models,Data privacy,Deep neural networks,Federated learning,Industrial control,Industrial Control System (ICS),Industrial Internet of Things (IIoT),Integrated circuits,Learning systems,Training}
}

@article{jahromi_ensembledeepfederated_2023,
  title = {An Ensemble Deep Federated Learning Cyber-Threat Hunting Model for {{Industrial Internet}} of {{Things}}},
  author = {Jahromi, Amir Namavar and Karimipour, Hadis and Dehghantanha, Ali},
  date = {2023-01-15},
  journaltitle = {Computer Communications},
  shortjournal = {Computer Communications},
  volume = {198},
  pages = {108--116},
  issn = {0140-3664},
  doi = {10.1016/j.comcom.2022.11.009},
  url = {https://www.sciencedirect.com/science/article/pii/S0140366422004327},
  urldate = {2024-04-12},
  abstract = {Industrial Internet of Things (IIoT) is an emerging technology with prompt evolution in diverse applications, including critical infrastructure. While the increasing number of IIoT devices in today's critical infrastructure enhances their efficiency and reliability, it also increases their vulnerability towards cyber-attacks. Ambient Intelligence (AmI), including machine learning techniques, is a way to handle such challenges with minimizing the human role. Although using machine learning-based techniques is increased in some applications these days, they are not widely used in IIoT environments due to the privacy issues of transferring all the data into a single machine to train the models. This paper proposes an ensemble-based deep federated learning cyber-threat hunting model to hunt the attack samples without data sharing. The proposed hunting model consists of two parallel federated-based components, one analyzes the IIoT status based on the normal situation of the network, and the other analyzes it with considering the threat situation. This model used an ensemble of classifiers to make the final decision. The proposed cyber-threat hunting model is evaluated using two test cases and compared with some works in the literature and outperformed them in the f1-score metric. Moreover, evaluations show that the proposed model acts stable in facing different numbers of clients, and its training time is faster than the centralized models with the same computational complexity.},
  keywords = {Aambient Intelligence (AmI),Critical infrastructure,Cyber-threat hunting,Deep learning,Ensemble model,Federated learning,Industrial control systems,Industrial Internet of Things (IIoT),Industry4.0,Representation learning}
}

@inproceedings{jain_OverviewImportanceData_2020,
  title = {Overview and {{Importance}} of {{Data Quality}} for {{Machine Learning Tasks}}},
  booktitle = {Proceedings of the 26th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Jain, Abhinav and Patel, Hima and Nagalapatti, Lokesh and Gupta, Nitin and Mehta, Sameep and Guttula, Shanmukha and Mujumdar, Shashank and Afzal, Shazia and Sharma Mittal, Ruhi and Munigala, Vitobha},
  date = {2020-08-20},
  series = {{{KDD}} '20},
  pages = {3561--3562},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3394486.3406477},
  url = {https://dl.acm.org/doi/10.1145/3394486.3406477},
  urldate = {2024-03-28},
  abstract = {It is well understood from literature that the performance of a machine learning (ML) model is upper bounded by the quality of the data. While researchers and practitioners have focused on improving the quality of models (such as neural architecture search and automated feature selection), there are limited efforts towards improving the data quality. One of the crucial requirements before consuming datasets for any application is to understand the dataset at hand and failure to do so can result in inaccurate analytics and unreliable decisions. Assessing the quality of the data across intelligently designed metrics and developing corresponding transformation operations to address the quality gaps helps to reduce the effort of a data scientist for iterative debugging of the ML pipeline to improve model performance. This tutorial highlights the importance of analysing data quality in terms of its value for machine learning applications. This tutorial surveys all the important data quality related approaches discussed in literature, focusing on the intuition behind them, highlighting their strengths and similarities, and illustrates their applicability to real-world problems. Finally we will discuss the interesting work IBM Research is doing in this space.},
  isbn = {978-1-4503-7998-4},
  keywords = {data quality,machine learning,quality metrics}
}

@online{jayalaxmi_DeBotdeeplearningbased_2022,
  title = {{{DeBot}}: {{A}} Deep Learning-Based Model for Bot Detection in Industrial Internet-of-Things \textbar{} {{Elsevier Enhanced Reader}}},
  shorttitle = {{{DeBot}}},
  author = {Jayalaxmi, P. L. S. and Kumar, Gulshan and Saha, Rahul and Conti, Mauro and Kim, Tai-hoon and Thomas, Reji},
  date = {2022},
  doi = {10.1016/j.compeleceng.2022.108214},
  url = {https://reader.elsevier.com/reader/sd/pii/S0045790622004530?token=4E14C31C17A9FF85CDC88A77D85258F179CBBA6C3A1FD68BA24FF99B40E096CBAE42EBCF9408CE7BF160E1A559785314&originRegion=eu-west-1&originCreation=20220811054018},
  urldate = {2022-08-11},
  abstract = {In this paper, we show a deep learning model for bot detection, named as DeBot, for industrial network traffic. DeBot uses a novel Cascade Forward Back Propagation Neural Network (CFBPNN) model with a subset of features using the Correlation-based Feature Selection (CFS) technique. A time series-based Nonlinear Auto-regressive Network with eXogenous inputs (NARX) technique analyzes the factors having a higher impact on the target variable and predict the behavioral pattern. To the best of our knowledge, we pioneer the use of optimal feature selection and integration with the cascading model of deep learning in bot detection of IIoTs. We conduct a thorough set of experiments on five popular bot datasets: NF-UNSW-NB15, NFToN-IoT, NF-BoT-IoT, NF-CSE-CIC-IDS2018, and ToN-IoT-Windows. We compare CFBPNN with other existing neural network models. We observe that CFBPNN in DeBot shows 100\% accuracy in all the datasets with subset evaluation and obtains optimum F1-score and zero precision.},
  langid = {english}
}

@article{jayasinghe_FederatedLearningbased_2022,
  title = {Federated {{Learning}} Based {{Anomaly Detection}} as an {{Enabler}} for {{Securing Network}} and {{Service Management Automation}} in {{Beyond 5G Networks}}},
  author = {Jayasinghe, Suwani and Siriwardhana, Yushan and Porambage, Pawani and Liyanage, Madhusanka and Ylianttila, Mika},
  date = {2022-06},
  pages = {7},
  abstract = {Network automation is a necessity in order to meet the unprecedented demand in the future networks and zero touch network architecture is proposed to cater such requirements. Closed-loop and artificial intelligence are key enablers in this proposed architecture in critical elements such as security. Apart from the arising privacy concerns, machine learning models can also face resource limitations. Federated learning is a machine learning based techniques which address both privacy and communication efficiency issues. Therefore, we propose a federated learning based model incorporating ZSM architecture for network automation. The paper also contains the simulations and its results of the proposed multi-stage federated learning based which use UNSW-NB15 Dataset.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@inproceedings{ji_NovelMethodIntrusion_2022,
  title = {A {{Novel Method}} of {{Intrusion Detection Based}} on {{Federated Transfer Learning}} and {{Convolutional Neural Network}}},
  booktitle = {2022 {{IEEE}} 10th {{Joint International Information Technology}} and {{Artificial Intelligence Conference}} ({{ITAIC}})},
  author = {Ji, Xiang and Zhang, Hong and Ma, Xulun},
  date = {2022-06},
  volume = {10},
  pages = {338--343},
  issn = {2693-2865},
  doi = {10.1109/ITAIC54216.2022.9836871},
  url = {https://ieeexplore.ieee.org/abstract/document/9836871},
  urldate = {2024-04-12},
  abstract = {As a network security defense technology, intrusion detection system can effectively protect network security. At present, machine learning is widely used in intrusion detection and has achieved good application results. The detection methods based on traditional machine learning need enough available intrusion detection data samples, and the samples meet the conditions of independent and identically distributed. However, in reality, the intrusion detection data generated by a single institution is insufficient, and various institutions protect users' privacy and data security in the form of islands, which makes it difficult to maintain the same data distribution. In addition, there is the problem of data imbalance. To solve the above problems, this paper proposes a new intrusion detection method FTLCNN, which integrates federal transfer learning and convolutional neural network. FTLCNN constructs a transfer convolution neural network framework to solve the problems of sample scarcity, imbalance and probability adaptation; under the mechanism of federal learning, FTLCNN use the model to learn without sharing training data, protect data privacy and solve the problem of data island. The experimental on UNSW-NB15 shows that compared with the other four benchmark algorithms, FTLCNN has higher detection rate and lower false positive rate, and has significant advantages in solving the problem of scarcity and imbalance of in intrusion detection.},
  eventtitle = {2022 {{IEEE}} 10th {{Joint International Information Technology}} and {{Artificial Intelligence Conference}} ({{ITAIC}})},
  keywords = {Convolutional neural network,Data privacy,Distributed databases,Federal transfer learning,Intrusion detection,Network security,Organizations,Training data,Transfer learning,Unbalanced data}
}

@inproceedings{jia_ContexIoTProvidingContextual_2017,
  title = {{{ContexIoT}}: {{Towards Providing Contextual Integrity}} to {{Appified IoT Platforms}}},
  booktitle = {Proceedings 2017 {{Network}} and {{Distributed System Security Symposium}}},
  author = {Jia, Yunhan Jack and Chen, Qi Alfred and Wang, Shiqi and Rahmati, Amir and Fernandes, Earlence and Mao, Z. Morley and Prakash, Atul},
  date = {2017},
  publisher = {Internet Society},
  location = {Reston, VA},
  doi = {10.14722/ndss.2017.23051},
  url = {https://www.ndss-symposium.org/ndss2017/ndss-2017-programme/contexlot-towards-providing-contextual-integrity-appified-iot-platforms/},
  abstract = {The Internet-of-Things (IoT) has quickly evolved to a new appified era where third-party developers can write apps for IoT platforms using programming frameworks. Like other appified platforms, e.g., the smartphone platform, the permission system plays an important role in platform security. However, design flaws in current IoT platform permission models have been reported recently, exposing users to significant harm such as break-ins and theft. To solve these problems, a new access control model is needed for both current and future IoT platforms. In this paper, we propose ContexIoT, a context-based permission system for appified IoT platforms that provides contextual integrity by supporting fine-grained context identification for sensitive actions, and runtime prompts with rich context information to help users perform effective access control. Context definition in ContexIoT is at the inter-procedure control and data flow levels, that we show to be more comprehensive than previous context-based permission systems for the smartphone platform. ContexIoT is designed to be backward compatible and thus can be directly adopted by current IoT platforms. We prototype ContexIoT on the Samsung SmartThings platform, with an automatic app patching mechanism developed to support unmodified commodity SmartThings apps. To evaluate the system's effectiveness, we perform the first extensive study of possible attacks on appified IoT platforms by reproducing reported IoT attacks and constructing new IoT attacks based on smartphone malware classes. We categorize these attacks based on lifecycle and adversary techniques, and build the first taxonomized IoT attack app dataset. Evaluating ContexIoT on this dataset, we find that it can effectively distinguish the attack context for all the tested apps. The performance evaluation on 283 commodity IoT apps shows that the app patching adds nearly negligible delay to the event triggering latency, and the permission request frequency is far below the threshold that is considered to risk user habituation or annoyance.},
  isbn = {1-891562-46-0}
}

@inproceedings{jia_EfficientDataValuation_2019,
  title = {Towards {{Efficient Data Valuation Based}} on the {{Shapley Value}}},
  booktitle = {Proceedings of the {{Twenty-Second International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Jia, Ruoxi and Dao, David and Wang, Boxin and Hubis, Frances Ann and Hynes, Nick and G\"urel, Nezihe Merve and Li, Bo and Zhang, Ce and Song, Dawn and Spanos, Costas J.},
  date = {2019-04-11},
  pages = {1167--1176},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v89/jia19a.html},
  urldate = {2022-08-25},
  abstract = {\{\textbackslash em ``How much is my data worth?''\} is an increasingly common question posed by organizations and individuals alike. An answer to this question could allow, for instance, fairly distributing profits among multiple data contributors and determining prospective compensation when data breaches happen. In this paper, we study the problem of \textbackslash emph\{data valuation\} by utilizing the Shapley value, a popular notion of value which originated in coopoerative game theory. The Shapley value defines a unique payoff scheme that satisfies many desiderata for the notion of data value. However, the Shapley value often requires \textbackslash emph\{exponential\} time to compute. To meet this challenge, we propose a repertoire of efficient algorithms for approximating the Shapley value. We also demonstrate the value of each training instance for various benchmark datasets.},
  eventtitle = {The 22nd {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  langid = {english}
}

@article{jiang_BFLSBlockchainFederated_2023,
  title = {{{BFLS}}: {{Blockchain}} and {{Federated Learning}} for Sharing Threat Detection Models as {{Cyber Threat Intelligence}}},
  shorttitle = {{{BFLS}}},
  author = {Jiang, Tongtong and Shen, Guowei and Guo, Chun and Cui, Yunhe and Xie, Bo},
  date = {2023-04-01},
  journaltitle = {Computer Networks},
  shortjournal = {Computer Networks},
  volume = {224},
  pages = {109604},
  issn = {1389-1286},
  doi = {10.1016/j.comnet.2023.109604},
  url = {https://www.sciencedirect.com/science/article/pii/S138912862300049X},
  urldate = {2024-04-12},
  abstract = {Recently, Cyber Threat Intelligence (CTI) sharing has become an important weapon for cyber defenders to mitigate the increasing number of cyber attacks in a proactive and collaborative manner. However, with the dramatic increase in the deployment of shared communications between organizations, data has been a major priority to detect threats in the CTI sharing platform. In the modern environment, a valuable asset is the user's threat data. Privacy policies are necessary to ensure the security of user data in the threat intelligence sharing community. Federated learning acts as a special machine learning technique for privacy preservation and offers to contextualize data in a CTI sharing platform. Therefore, this article proposes a new approach to threat intelligence sharing called BFLS (Blockchain and Federated Learning for sharing threat detection models as Cyber Threat Intelligence), where blockchain-based CTI sharing platforms are used for security and privacy. Federated learning technology is adopted for scalable machine learning applications, such as threat detection. Furthermore, users can obtain a well-trained threat detection model without sending personal data to the central server. Experimental results on the ISCX-IDS-2012 and CIC-DDoS-2019 datasets showed that BFLS can securely share CTI and has high accuracy in threat detection. The accuracies of BFLS are 98.92\% and 98.56\%~on the two datasets, respectively.},
  keywords = {Blockchain,Cyber Threat Intelligence,Federated learning,Threat detection}
}

@article{jiang_DataQualityDetection_2023,
  title = {Data {{Quality Detection Mechanism Against Label Flipping Attacks}} in {{Federated Learning}}},
  author = {Jiang, Yifeng and Zhang, Weiwen and Chen, Yanxi},
  date = {2023},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  volume = {18},
  pages = {1625--1637},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2023.3249568},
  url = {https://ieeexplore.ieee.org/abstract/document/10054157},
  urldate = {2024-03-27},
  abstract = {Federated learning (FL) is an emerging framework that enables massive clients (e.g., mobile devices or enterprises) to collaboratively construct a global model without sharing their local data. However, due to the lack of direct access to clients' data, the global model is vulnerable to be attacked by malicious clients with their poisoned data. Many strategies have been proposed to mitigate the threat of label flipping attacks, but they either require considerable computational overhead, or lack robustness, and some even cause privacy concerns. In this paper, we propose Malicious Clients Detection Federated Learning (MCDFL) to defense against the label flipping attack. It can identify malicious clients by recovering a distribution over a latent feature space to detect the data quality of each client. We demonstrate the effectiveness of our proposed strategy on two benchmark datasets, i.e., CIFAR-10 and Fashion-MNIST, by considering different neural network models and different attack scenarios. The results show that, our solution is robust to detect malicious clients without excessive costs under various conditions, where the proportion of malicious clients is in the range of 5\% and 40\%.},
  eventtitle = {{{IEEE Transactions}} on {{Information Forensics}} and {{Security}}},
  keywords = {Computational modeling,Data integrity,Data models,data poisoning,Data privacy,deep learning,Federated learning,label flipping,Servers,Training,Training data}
}

@article{jiang_DeepFedWTfederateddeep_2022,
  title = {{{DeepFedWT}}: {{A}} Federated Deep Learning Framework for Fault Detection of Wind Turbines},
  shorttitle = {{{DeepFedWT}}},
  author = {Jiang, Guoqian and Fan, WeiPeng and Li, Wenyue and Wang, Lijin and He, Qun and Xie, Ping and Li, Xiaoli},
  date = {2022-08-01},
  journaltitle = {Measurement},
  shortjournal = {Measurement},
  volume = {199},
  pages = {111529},
  issn = {0263-2241},
  doi = {10.1016/j.measurement.2022.111529},
  url = {https://www.sciencedirect.com/science/article/pii/S0263224122007497},
  urldate = {2024-04-12},
  abstract = {Data-driven fault detection of wind turbines has gained increasingly attention. Currently, most existing methods require sufficient labeled data to train a reliable model in a centralized way. However, it is difficult to collect enough labeled data due to data privacy and strict confidentiality of wind farm owners. To this end, we propose a federated deep learning framework (DeepFedWT), which allows multiple decentralized WTs to collaboratively build a fault detection model using their local private data. Specifically, we designed a multi-scale residual attention network (MSRAN) model to extract informative features from raw multivariate sensor data, which first integrates a multiscale residual learning block to extract spatial features among different sensor variables at multiple scales and adopts a feature attention block to highlight important features highly associated with faults, and finally enables an enhanced fault detection. Experimental results on two real WT datasets demonstrate the effectiveness of our proposed DeepFedWT framework.},
  keywords = {Deep learning,Fault detection,Feature attention,Federated learning,Multi-scale spatial feature extraction,Wind turbines (WTs)}
}

@article{jiang_DOLLDistributedOnLine_2022,
  title = {{{DOLL}}: {{Distributed OnLine Learning Using Preemptible Cloud Instances}} - {{Technical Report}}},
  author = {Jiang, Harry and Zhang, Xiaoxi and Joe-Wong, Carlee},
  date = {2022},
  pages = {12},
  abstract = {Many companies are increasingly making machine learning integral to their businesses. To defray the resulting compute costs, much work has proposed using preemptible cloud instances, a discount tier of virtual machine rentals that may be interrupted at the cloud provider's discretion, to run machine learning jobs. However, processing data streams on preemptible instances presents new challenges: processing data points as they arrive may lead to bottlenecks when scaling the system to handle higher throughput, particularly if the instances are frequently interrupted. Ours is the first work to design, analyze, and optimize a system that trains a machine learning model on a set of data streams with online stochastic gradient descent (SGD) on preemptible instances. Our system, DOLL, uses queueing and batching to parallelize and scale SGD to large numbers of workers and incoming data streams, as well as heterogeneous data arrival rates across streams. An expected error convergence guarantee is then derived for DOLL's training process. We use this guarantee to optimize the cost of requisitioning preemptible and on-demand instances in the face of a performance target and wall-clock time deadline; this optimization is validated on experiments demonstrating substantial cost savings with little impact on model error, compared to on-demand instances.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@article{jiang_FedHGCDroidAdaptiveMultiDimensional_2022,
  title = {{{FedHGCDroid}}: {{An Adaptive Multi-Dimensional Federated Learning}} for {{Privacy-Preserving Android Malware Classification}}},
  shorttitle = {{{FedHGCDroid}}},
  author = {Jiang, Changnan and Yin, Kanglong and Xia, Chunhe and Huang, Weidong},
  date = {2022-07-01},
  journaltitle = {Entropy},
  shortjournal = {Entropy},
  volume = {24},
  number = {7},
  pages = {919},
  issn = {1099-4300},
  doi = {10.3390/e24070919},
  url = {https://www.mdpi.com/1099-4300/24/7/919},
  urldate = {2022-08-11},
  abstract = {With the popularity of Android and its open source, the Android platform has become an attractive target for hackers, and the detection and classification of malware has become a research hotspot. Existing malware classification methods rely on complex manual operation or large-volume high-quality training data. However, malware data collected by security providers contains user privacy information, such as user identity and behavior habit information. The increasing concern for user privacy poses a challenge to the current malware classification scheme. Based on this problem, we propose a new android malware classification scheme based on Federated learning, named FedHGCDroid, which classifies malware on Android clients in a privacy-protected manner. Firstly, we use a convolutional neural network and graph neural network to design a novel multi-dimensional malware classification model HGCDroid, which can effectively extract malicious behavior features to classify the malware accurately. Secondly, we introduce an FL framework to enable distributed Android clients to collaboratively train a comprehensive Android malware classification model in a privacy-preserving way. Finally, to adapt to the non-IID distribution of malware on Android clients, we propose a contribution degree-based adaptive classifier training mechanism FedAdapt to improve the adaptability of the malware classifier based on Federated learning. Comprehensive experimental studies on the Androzoo dataset (under different non-IID data settings) show that the FedHGCDroid achieves more adaptability and higher accuracy than the other state-of-the-art methods.},
  langid = {english}
}

@incollection{jiang_MachineLearningIndustrial_2020,
  title = {Machine {{Learning}} in {{Industrial Control System Security}}: {{A Survey}}},
  booktitle = {Proceedings of 2019 {{Chinese Intelligent Systems Conference}}},
  author = {Jiang, Dianbin and Zhao, Jingling},
  editor = {Jia, Yingmin and Du, Junping and Zhang, Weicun},
  date = {2020},
  pages = {310--317},
  publisher = {Springer Singapore},
  location = {Singapore},
  doi = {10.1007/978-981-32-9698-5_35},
  url = {http://link.springer.com/10.1007/978-981-32-9698-5_35},
  abstract = {Industrial control system (ICS) is becoming more and more open to the outside world for the advancement of Industrial Internet, which means people can have access to the industrial control system with traditional internet-based methods. However, the connections with outside world make ICS exposed to numerous unpredictable dangers. In addition, artificial intelligence (AI) has made great progress and applying AI to other fields is the trend in both academia and industry. This paper will introduce the basic information of ICS and review related works in anomaly detection based on AI. Based on the analysis of previous researches and the features of ICS, the prospect of anomaly detection of ICS is forecasted.},
  isbn = {978-981-329-698-5}
}

@article{jin_FederatedIncrementalLearning_2023,
  title = {Federated {{Incremental Learning}} Based {{Evolvable Intrusion Detection System}} for {{Zero-Day Attacks}}},
  author = {Jin, Dong and Chen, Shuangwu and He, Huasen and Jiang, Xiaofeng and Cheng, Siyu and Yang, Jian},
  date = {2023-01},
  journaltitle = {IEEE Network},
  volume = {37},
  number = {1},
  pages = {125--132},
  issn = {1558-156X},
  doi = {10.1109/MNET.018.2200349},
  url = {https://ieeexplore.ieee.org/abstract/document/10110017},
  urldate = {2024-04-12},
  abstract = {Smart community networks bring great comfort and convenience for people, but also increase security risks of exposing system vulnerabilities and private data to network intruders. This problem has become more prominent as the ever-increasing zero-day attacks which may escape the existing intrusion detection system (IDS) through unknown vulnerabilities. In this article, to keep up with the continuous change of attacks, we conceive an evolvable IDS (EIDS), where the detection model is incrementally updated to turn newfound ``unknown'' attacks into ``known'' attacks. In order to discover zero-day attacks, we develop an open-set intrusion detection model based on discriminative auto-encoder. Since the geographically dispersed detectors may suffer from different attack variants, we propose a federated incremental learning based model update method to aggregate the knowledge from different detectors and update the detection model incrementally, which avoids the cumbersome model retraining. To the best of our knowledge, there are rarely few studies considering the federated incremental update of the distributed intrusion detection models. In this way, the ``detecting-learning-updating'' process forms an evolution cycle, which enables the EIDS to evolve in an autonomous manner. Finally, the experiments conducted on three public datasets demonstrate that EIDS can conduct open-set intrusion detection with an accuracy over 0.86 and significantly reduce over 90 percent of the model update time compared to the centralized model retraining.},
  eventtitle = {{{IEEE Network}}},
  keywords = {Detectors,Intrusion detection,Security,Smart cities}
}

@article{jin_FLIIDSnovelfederated_2024,
  title = {{{FL-IIDS}}: {{A}} Novel Federated Learning-Based Incremental Intrusion Detection System},
  shorttitle = {{{FL-IIDS}}},
  author = {Jin, Zhigang and Zhou, Junyi and Li, Bing and Wu, Xiaodong and Duan, Chenxu},
  date = {2024-02-01},
  journaltitle = {Future Generation Computer Systems},
  shortjournal = {Future Generation Computer Systems},
  volume = {151},
  pages = {57--70},
  issn = {0167-739X},
  doi = {10.1016/j.future.2023.09.019},
  url = {https://www.sciencedirect.com/science/article/pii/S0167739X23003503},
  urldate = {2024-04-12},
  abstract = {With the advantage of analyzing data of multiple work sites comprehensively while ensuring data privacy, federated learning-based intrusion detection systems (IDS) are emerging as a distributed intrusion detection paradigm. Most of these IDS are assumed to work on static data. However, in the actual network environment, the practice of setting data as static will lead to the phenomenon known as catastrophic forgetting, where old classes that have already appeared would be forgotten. In this paper, we propose a novel IDS framework called FL-IIDS to effectively address the catastrophic forgetting problem. Firstly, a new loss function is synthetically designed for local model training. With the new function, the class gradient balance loss function assigns different learning weights to data of the new and old classes so that the learning rate of the new classes would decrease and the memory of the overall old classes would be deepened. Moreover, the sample label smoothing loss function leverages the knowledge distillation method to enhance the local model memory for every specific class of old classes. Secondly, the relay client fusing sample reconstruction is employed to mitigate the spread of catastrophic forgetting globally without compromising data privacy. Extensive experimental results on the UNSW-NB15 dataset and the CICIDS2018 dataset show that our proposed framework improves the memory capability for old classes substantially without affecting the detection effectiveness of the IDS for new classes.},
  keywords = {Catastrophic forgetting,Continual learning,Distributed computation,Federated learning,Incremental learning,Intrusion detection system}
}

@report{johnson_GuideCyberThreat_2016,
  title = {Guide to {{Cyber Threat Information Sharing}}},
  author = {Johnson, Christopher S. and Badger, Mark Lee and Waltermire, David A. and Snyder, Julie and Skorupka, Clem},
  date = {2016-10},
  journaltitle = {NIST Special Publication},
  pages = {800--150},
  institution = {{National Institute of Standards and Technology}},
  location = {Gaithersburg, MD},
  doi = {10.6028/NIST.SP.800-150},
  url = {http://dx.doi.org/10.6028/NIST.SP.800-150},
  abstract = {Authority This publication has been developed by NIST in accordance with its statutory responsibilities under the Federal Information Security Modernization Act (FISMA) of 2014, 44 U.S.C. 3551 et seq., Public Law (P.L.) 113-283. NIST is responsible for developing information security standards and guidelines, including minimum requirements for federal information systems, but such standards and guidelines shall not apply to national security systems without the express approval of appropriate federal officials exercising policy authority over such systems. This guideline is consistent with the requirements of the Office of Management and Budget (OMB) Circular A-130.}
}

@unpublished{johnson_IntrinsicPropensityVulnerability_2021,
  title = {Intrinsic {{Propensity}} for {{Vulnerability}} in {{Computers}}? {{Arbitrary Code Execution}} in the {{Universal Turing Machine}}},
  shorttitle = {Intrinsic {{Propensity}} for {{Vulnerability}} in {{Computers}}?},
  author = {Johnson, Pontus},
  date = {2021-04-22},
  eprint = {2105.02124},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2105.02124},
  urldate = {2021-06-01},
  abstract = {The universal Turing machine is generally considered to be the simplest, most abstract model of a computer. This paper reports on the discovery of an accidental arbitrary code execution vulnerability in Marvin Minsky's 1967 implementation of the universal Turing machine. By submitting crafted data, the machine may be coerced into executing user-provided code. The article presents the discovered vulnerability in detail and discusses its potential implications. To the best of our knowledge, an arbitrary code execution vulnerability has not previously been reported for such a simple system.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@article{johnson_MIMICIIIfreelyaccessible_2016,
  title = {{{MIMIC-III}}, a Freely Accessible Critical Care Database},
  author = {Johnson, Alistair E.W. and Pollard, Tom J. and Shen, Lu and Lehman, Li-wei H. and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Anthony Celi, Leo and Mark, Roger G.},
  date = {2016-05-24},
  journaltitle = {Scientific Data},
  shortjournal = {Scientific Data},
  volume = {3},
  number = {1},
  pages = {160035},
  issn = {2052-4463},
  doi = {10.1038/sdata.2016.35},
  url = {https://doi.org/10.1038/sdata.2016.35},
  abstract = {MIMIC-III (`Medical Information Mart for Intensive Care') is a large, single-center database comprising information relating to patients admitted to critical care units at a large tertiary care hospital. Data includes vital signs, medications, laboratory measurements, observations and notes charted by care providers, fluid balance, procedure codes, diagnostic codes, imaging reports, hospital length of stay, survival data, and more. The database supports applications including academic and industrial research, quality improvement initiatives, and higher education coursework.}
}

@report{juszczyk_ProactiveDetectionNetwork_2011,
  title = {Proactive {{Detection}} of {{Network Security Incidents}}},
  author = {Juszczyk, Lukasz and Grudziecki, T and Jacewicz, P and Kijewski, Piotr and Pawlinski, Pawel},
  date = {2011},
  journaltitle = {European Network and security information Agency},
  pages = {135},
  url = {https://www.enisa.europa.eu/activities/cert/support/proactive-detection/proactive-detection-report},
  abstract = {This document is the final report of the `Proactive Detection of Network Security Incidents' study. The goal of the study was to investigate ways in which CERTs -- national and governmental ones in particular -- proactively detect incidents concerning their constituencies, identify good practice and recommended measures for new and already established CERTs, analyse problems they face and offer recommendations to relevant stakeholders on what can be done to further this process. It is important to note that the results of the study are largely community driven. That is, they are based not just on research and the experience of the experts who conducted the study, but to a large extent on the results of a survey carried out amongst 105 different CERTs (which resulted in 45 responses overall) and external expert group input. The outcome is thus a work by the community for the CERT community.}
}

@unpublished{kairouz_AdvancesOpenProblems_2021,
  title = {Advances and {{Open Problems}} in {{Federated Learning}}},
  author = {Kairouz, Peter and McMahan, H. Brendan and Avent, Brendan and Bellet, Aur\'elien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and D'Oliveira, Rafael G. L. and Eichner, Hubert and Rouayheb, Salim El and Evans, David and Gardner, Josh and Garrett, Zachary and Gasc\'on, Adri\`a and Ghazi, Badih and Gibbons, Phillip B. and Gruteser, Marco and Harchaoui, Zaid and He, Chaoyang and He, Lie and Huo, Zhouyuan and Hutchinson, Ben and Hsu, Justin and Jaggi, Martin and Javidi, Tara and Joshi, Gauri and Khodak, Mikhail and Kone\v cn\'y, Jakub and Korolova, Aleksandra and Koushanfar, Farinaz and Koyejo, Sanmi and Lepoint, Tancr\`ede and Liu, Yang and Mittal, Prateek and Mohri, Mehryar and Nock, Richard and \"Ozg\"ur, Ayfer and Pagh, Rasmus and Raykova, Mariana and Qi, Hang and Ramage, Daniel and Raskar, Ramesh and Song, Dawn and Song, Weikang and Stich, Sebastian U. and Sun, Ziteng and Suresh, Ananda Theertha and Tram\`er, Florian and Vepakomma, Praneeth and Wang, Jianyu and Xiong, Li and Xu, Zheng and Yang, Qiang and Yu, Felix X. and Yu, Han and Zhao, Sen},
  date = {2021-03-08},
  eprint = {1912.04977},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1912.04977},
  urldate = {2022-04-01},
  abstract = {Federated learning (FL) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized. FL embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in FL research, this paper discusses recent advances and presents an extensive collection of open problems and challenges.},
  langid = {english},
  keywords = {â›” No DOI found,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@inproceedings{kale_HybridDeepLearning_2022,
  title = {A {{Hybrid Deep Learning Anomaly Detection Framework}} for {{Intrusion Detection}}},
  booktitle = {2022 {{IEEE}} 8th {{Intl Conference}} on {{Big Data Security}} on {{Cloud}} ({{BigDataSecurity}}), {{IEEE Intl Conference}} on {{High Performance}} and {{Smart Computing}}, ({{HPSC}}) and {{IEEE Intl Conference}} on {{Intelligent Data}} and {{Security}} ({{IDS}})},
  author = {Kale, Rahul and Lu, Zhi and Fok, Kar Wai and Thing, Vrizlynn L. L.},
  date = {2022-05},
  pages = {137--142},
  doi = {10.1109/BigDataSecurityHPSCIDS54978.2022.00034},
  abstract = {Cyber intrusion attacks that compromise the users' critical and sensitive data are escalating in volume and intensity, especially with the growing connections between our daily life and the Internet. The large volume and high complexity of such intrusion attacks have impeded the effectiveness of most traditional defence techniques. While at the same time, the remarkable performance of the machine learning methods, especially deep learning, in computer vision, had garnered research interests from the cyber security community to further enhance and automate intrusion detections. However, the expensive data labeling and limitation of anomalous data make it challenging to train an intrusion detector in a fully supervised manner. Therefore, intrusion detection based on unsupervised anomaly detection is an important feature too. In this paper, we propose a three-stage deep learning anomaly detection based network intrusion attack detection framework. The framework comprises an integration of unsupervised (K-means clustering), semi-supervised (GANomaly) and supervised learning (CNN) algorithms. We then evaluated and showed the performance of our implemented framework on three benchmark datasets: NSL-KDD, CIC-IDS2018, and TON IoT.},
  eventtitle = {2022 {{IEEE}} 8th {{Intl Conference}} on {{Big Data Security}} on {{Cloud}} ({{BigDataSecurity}}), {{IEEE Intl Conference}} on {{High Performance}} and {{Smart Computing}}, ({{HPSC}}) and {{IEEE Intl Conference}} on {{Intelligent Data}} and {{Security}} ({{IDS}})},
  keywords = {Anomaly Detection,Conferences,Deep learning,Deep Learning,Feature extraction,Intrusion detection,Intrusion Detection,Machine learning algorithms,Neural Networks,Security,Supervised learning,Unsupervised Learning}
}

@article{kaloroumakis_KnowledgeGraphCybersecurity_2021,
  title = {Toward a {{Knowledge Graph}} of {{Cybersecurity Countermeasures}}},
  author = {Kaloroumakis, Peter E and Smith, Michael J},
  date = {2021},
  pages = {11},
  abstract = {This paper describes our research and development toward a precise, unambiguous, and information-dense knowledge graph of cybersecurity countermeasures. In project work for our sponsors we have repeatedly encountered the need for a model that can identify and precisely specify cybersecurity countermeasure components and capabilities. Furthermore, it is necessary that practitioners know not only what threats a capability claims to address, but, specifically how those threats are addressed from an engineering perspective, and under what circumstances the solution would work. This knowledge is essential to estimate operational applicability, vulnerabilities, and develop enterprise solutions comprising multiple capabilities. To address this recurring need in the near-term, we created D3FEND, a framework in which we encode a countermeasure knowledge base, but more specifically, a knowledge graph. The graph contains semantically rigorous types and relations that define both the key concepts in the cybersecurity countermeasure domain and the relations necessary to link those concepts to each other. We ground each of the concepts and relations to particular references in the cybersecurity literature. Numerous sources of research and development literature were analyzed, including a targeted sample of over 500 countermeasure patents drawn from the U.S. Patent Office corpus over the years 2001 to 2018. To demonstrate the value of this approach in practice, we describe how the graph supports queries that can inferentially map cybersecurity countermeasures to offensive TTPs. As part of a larger vision, we outline future D3FEND work to leverage the linked open data available on research literature and apply machine learning, in particular semi-supervised methods, to assist in maintaining the D3FEND knowledge graph over time. Finally, we welcome community feedback on D3FEND.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@online{kamp_FederatedLearningSmall_2023,
  title = {Federated {{Learning}} from {{Small Datasets}}},
  author = {Kamp, Michael and Fischer, Jonas and Vreeken, Jilles},
  date = {2023-10-12},
  eprint = {2110.03469},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2110.03469},
  url = {http://arxiv.org/abs/2110.03469},
  urldate = {2023-11-02},
  abstract = {Federated learning allows multiple parties to collaboratively train a joint model without sharing local data. This enables applications of machine learning in settings of inherently distributed, undisclosable data such as in the medical domain. In practice, joint training is usually achieved by aggregating local models, for which local training objectives have to be in expectation similar to the joint (global) objective. Often, however, local datasets are so small that local objectives differ greatly from the global objective, resulting in federated learning to fail. We propose a novel approach that intertwines model aggregations with permutations of local models. The permutations expose each local model to a daisy chain of local datasets resulting in more efficient training in data-sparse domains. This enables training on extremely small local datasets, such as patient data across hospitals, while retaining the training efficiency and privacy benefits of federated learning.},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
}

@article{kang_BlockchainSecureEfficient_2019,
  title = {Blockchain for {{Secure}} and {{Efficient Data Sharing}} in {{Vehicular Edge Computing}} and {{Networks}}},
  author = {Kang, Jiawen and Yu, Rong and Huang, Xumin and Wu, Maoqiang and Maharjan, Sabita and Xie, Shengli and Zhang, Yan},
  date = {2019-06},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {6},
  number = {3},
  pages = {4660--4670},
  publisher = {IEEE},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2018.2875542},
  url = {https://ieeexplore.ieee.org/document/8489897/},
  abstract = {The drastically increasing volume and the growing trend on the types of data have brought in the possibility of realizing advanced applications such as enhanced driving safety, and have enriched existing vehicular services through data sharing among vehicles and data analysis. Due to limited resources with vehicles, vehicular edge computing and networks (VECONs) i.e., the integration of mobile edge computing and vehicular networks, can provide powerful computing and massive storage resources. However, road side units that primarily presume the role of vehicular edge computing servers cannot be fully trusted, which may lead to serious security and privacy challenges for such integrated platforms despite their promising potential and benefits. We exploit consortium blockchain and smart contract technologies to achieve secure data storage and sharing in vehicular edge networks. These technologies efficiently prevent data sharing without authorization. In addition, we propose a reputation-based data sharing scheme to ensure high-quality data sharing among vehicles. A three-weight subjective logic model is utilized for precisely managing reputation of the vehicles. Numerical results based on a real dataset show that our schemes achieve reasonable efficiency and high-level of security for data sharing in VECONs.}
}

@article{kang_IncentiveMechanismReliable_2019,
  title = {Incentive {{Mechanism}} for {{Reliable Federated Learning}}: {{A Joint Optimization Approach}} to {{Combining Reputation}} and {{Contract Theory}}},
  shorttitle = {Incentive {{Mechanism}} for {{Reliable Federated Learning}}},
  author = {Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Xie, Shengli and Zhang, Junshan},
  date = {2019-12},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {6},
  number = {6},
  pages = {10700--10714},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2019.2940820},
  abstract = {Federated learning is an emerging machine learning technique that enables distributed model training using local datasets from large-scale nodes, e.g., mobile devices, but shares only model updates without uploading the raw training data. This technique provides a promising privacy preservation for mobile devices while simultaneously ensuring high learning performance. The majority of existing work has focused on designing advanced learning algorithms with an aim to achieve better learning performance. However, the challenges, such as incentive mechanisms for participating in training and worker (i.e., mobile devices) selection schemes for reliable federated learning, have not been explored yet. These challenges have hindered the widespread adoption of federated learning. To address the above challenges, in this article, we first introduce reputation as the metric to measure the reliability and trustworthiness of the mobile devices. We then design a reputation-based worker selection scheme for reliable federated learning by using a multiweight subjective logic model. We also leverage the blockchain to achieve secure reputation management for workers with nonrepudiation and tamper-resistance properties in a decentralized manner. Moreover, we propose an effective incentive mechanism combining reputation with contract theory to motivate high-reputation mobile devices with high-quality data to participate in model learning. Numerical results clearly indicate that the proposed schemes are efficient for reliable federated learning in terms of significantly improving the learning accuracy.},
  keywords = {Blockchain,contract theory,Contracts,Data models,federated learning,Mobile handsets,mobile networks,Reliability,reputation,security and privacy,Task analysis,Training}
}

@article{kang_IncentiveMechanismReliable_2019a,
  title = {Incentive {{Mechanism}} for {{Reliable Federated Learning}}: {{A Joint Optimization Approach}} to {{Combining Reputation}} and {{Contract Theory}}},
  shorttitle = {Incentive {{Mechanism}} for {{Reliable Federated Learning}}},
  author = {Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Xie, Shengli and Zhang, Junshan},
  date = {2019-12},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {6},
  number = {6},
  pages = {10700--10714},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2019.2940820},
  abstract = {Federated learning is an emerging machine learning technique that enables distributed model training using local datasets from large-scale nodes, e.g., mobile devices, but shares only model updates without uploading the raw training data. This technique provides a promising privacy preservation for mobile devices while simultaneously ensuring high learning performance. The majority of existing work has focused on designing advanced learning algorithms with an aim to achieve better learning performance. However, the challenges, such as incentive mechanisms for participating in training and worker (i.e., mobile devices) selection schemes for reliable federated learning, have not been explored yet. These challenges have hindered the widespread adoption of federated learning. To address the above challenges, in this article, we first introduce reputation as the metric to measure the reliability and trustworthiness of the mobile devices. We then design a reputation-based worker selection scheme for reliable federated learning by using a multiweight subjective logic model. We also leverage the blockchain to achieve secure reputation management for workers with nonrepudiation and tamper-resistance properties in a decentralized manner. Moreover, we propose an effective incentive mechanism combining reputation with contract theory to motivate high-reputation mobile devices with high-quality data to participate in model learning. Numerical results clearly indicate that the proposed schemes are efficient for reliable federated learning in terms of significantly improving the learning accuracy.},
  keywords = {Blockchain,contract theory,Contracts,Data models,federated learning,Mobile handsets,mobile networks,Reliability,reputation,security and privacy,Task analysis,Training}
}

@article{kang_ReliableFederatedLearning_2020,
  title = {Reliable {{Federated Learning}} for {{Mobile Networks}}},
  author = {Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Zou, Yuze and Zhang, Yang and Guizani, Mohsen},
  date = {2020-04},
  journaltitle = {IEEE Wireless Communications},
  volume = {27},
  number = {2},
  pages = {72--80},
  issn = {1558-0687},
  doi = {10.1109/MWC.001.1900119},
  abstract = {Federated learning, as a promising machine learning approach, has emerged to leverage a distributed personalized dataset from a number of nodes, for example, mobile devices, to improve performance while simultaneously providing privacy preservation for mobile users. In federated learning, training data is widely distributed and maintained on the mobile devices as workers. A central aggregator updates a global model by collecting local updates from mobile devices using their local training data to train the global model in each iteration. However, unreliable data may be uploaded by the mobile devices (i.e., workers), leading to frauds in tasks of federated learning. The workers may perform unreliable updates intentionally, for example, the data poisoning attack, or unintentionally, for example, low-quality data caused by energy constraints or high-speed mobility. Therefore, finding out trusted and reliable workers in federated learning tasks becomes critical. In this article, the concept of reputation is introduced as a metric. Based on this metric, a reliable worker selection scheme is proposed for federated learning tasks. Consortium blockchain is leveraged as a decentralized approach for achieving efficient reputation management of the workers without repudiation and tampering. By numerical analysis, the proposed approach is demonstrated to improve the reliability of federated learning tasks in mobile networks.},
  eventtitle = {{{IEEE Wireless Communications}}},
  keywords = {Data models,Data privacy,Machine learning,Metasearch,Mobile handsets,Task analysis,Training data}
}

@article{kang_ReliableFederatedLearning_2020a,
  title = {Reliable {{Federated Learning}} for {{Mobile Networks}}},
  author = {Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Zou, Yuze and Zhang, Yang and Guizani, Mohsen},
  date = {2020-04},
  journaltitle = {IEEE Wireless Communications},
  volume = {27},
  number = {2},
  pages = {72--80},
  issn = {1558-0687},
  doi = {10.1109/MWC.001.1900119},
  abstract = {Federated learning, as a promising machine learning approach, has emerged to leverage a distributed personalized dataset from a number of nodes, for example, mobile devices, to improve performance while simultaneously providing privacy preservation for mobile users. In federated learning, training data is widely distributed and maintained on the mobile devices as workers. A central aggregator updates a global model by collecting local updates from mobile devices using their local training data to train the global model in each iteration. However, unreliable data may be uploaded by the mobile devices (i.e., workers), leading to frauds in tasks of federated learning. The workers may perform unreliable updates intentionally, for example, the data poisoning attack, or unintentionally, for example, low-quality data caused by energy constraints or high-speed mobility. Therefore, finding out trusted and reliable workers in federated learning tasks becomes critical. In this article, the concept of reputation is introduced as a metric. Based on this metric, a reliable worker selection scheme is proposed for federated learning tasks. Consortium blockchain is leveraged as a decentralized approach for achieving efficient reputation management of the workers without repudiation and tampering. By numerical analysis, the proposed approach is demonstrated to improve the reliability of federated learning tasks in mobile networks.},
  eventtitle = {{{IEEE Wireless Communications}}},
  keywords = {\_obsidian,Data models,Data privacy,Machine learning,Metasearch,Mobile handsets,Task analysis,Training data}
}

@article{karantzas_EmpiricalAssessmentEndpoint_2021,
  title = {An {{Empirical Assessment}} of {{Endpoint Detection}} and {{Response Systems}} against {{Advanced Persistent Threats Attack Vectors}}},
  author = {Karantzas, George and Patsakis, Constantinos},
  date = {2021-07-09},
  journaltitle = {Journal of Cybersecurity and Privacy},
  shortjournal = {JCP},
  volume = {1},
  number = {3},
  pages = {387--421},
  issn = {2624-800X},
  doi = {10.3390/jcp1030021},
  url = {https://www.mdpi.com/2624-800X/1/3/21},
  urldate = {2021-07-20},
  abstract = {Advanced persistent threats pose a significant challenge for blue teams as they apply various attacks over prolonged periods, impeding event correlation and their detection. In this work, we leverage various diverse attack scenarios to assess the efficacy of EDRs against detecting and preventing APTs. Our results indicate that there is still a lot of room for improvement as state-of-theart EDRs fail to prevent and log the bulk of the attacks that are reported in this work. Additionally, we discuss methods to tamper with the telemetry providers of EDRs, allowing an adversary to perform a more stealth attack.},
  langid = {english}
}

@inproceedings{karimireddy_LearningHistoryByzantine_2021,
  title = {Learning from {{History}} for {{Byzantine Robust Optimization}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {Karimireddy, Sai Praneeth and He, Lie and Jaggi, Martin},
  date = {2021-07-01},
  pages = {5311--5319},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v139/karimireddy21a.html},
  urldate = {2022-10-21},
  abstract = {Byzantine robustness has received significant attention recently given its importance for distributed and federated learning. In spite of this, we identify severe flaws in existing algorithms even when the data across the participants is identically distributed. First, we show realistic examples where current state of the art robust aggregation rules fail to converge even in the absence of any Byzantine attackers. Secondly, we prove that even if the aggregation rules may succeed in limiting the influence of the attackers in a single round, the attackers can couple their attacks across time eventually leading to divergence. To address these issues, we present two surprisingly simple strategies: a new robust iterative clipping procedure, and incorporating worker momentum to overcome time-coupled attacks. This is the first provably robust method for the standard stochastic optimization setting.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@inproceedings{karimireddy_SCAFFOLDStochasticControlled_2020,
  title = {{{SCAFFOLD}}: {{Stochastic Controlled Averaging}} for {{Federated Learning}}},
  shorttitle = {{{SCAFFOLD}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  date = {2020-11-21},
  pages = {5132--5143},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v119/karimireddy20a.html},
  urldate = {2024-06-23},
  abstract = {Federated learning is a key scenario in modern large-scale machine learning where the data remains distributed over a large number of clients and the task is to learn a centralized model without transmitting the client data. The standard optimization algorithm used in this setting is Federated Averaging (FedAvg) due to its low communication cost. We obtain a tight characterization of the convergence of FedAvg and prove that heterogeneity (non-iid-ness) in the client's data results in a `drift' in the local updates resulting in poor performance. As a solution, we propose a new algorithm (SCAFFOLD) which uses control variates (variance reduction) to correct for the `client drift'. We prove that SCAFFOLD requires significantly fewer communication rounds and is not affected by data heterogeneity or client sampling. Further, we show that (for quadratics) SCAFFOLD can take advantage of similarity in the client's data yielding even faster convergence. The latter is the first result to quantify the usefulness of local-steps in distributed optimization.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@article{kashani_DEEPLEARNINGINTERVIEWS_2021,
  title = {{{DEEP LEARNING INTERVIEWS}}},
  author = {Kashani, Shlomo},
  date = {2021-10},
  pages = {401},
  langid = {english},
  keywords = {â›” No DOI found}
}

@article{katevas_PolicyBasedFederatedLearning_2020,
  title = {Policy-{{Based Federated Learning}}},
  author = {Katevas, Kleomenis and Bagdasaryan, Eugene and Waterman, Jason and Safadieh, Mohamad Mounir and Birrell, Eleanor and Haddadi, Hamed and Estrin, Deborah},
  date = {2020-03-14},
  url = {http://arxiv.org/abs/2003.06612},
  abstract = {In this paper we present PoliFL, a decentralized, edge-based framework that supports heterogeneous privacy policies for federated learning. We evaluate our system on three use cases that train models with sensitive user data collected by mobile phones - predictive text, image classification, and notification engagement prediction - on a Raspberry Pi edge device. We find that PoliFL is able to perform accurate model training and inference within reasonable resource and time budgets while also enforcing heterogeneous privacy policies.},
  keywords = {â›” No DOI found}
}

@article{kazmi_ThreatIntelligenceNonIID_2023,
  title = {Threat {{Intelligence}} with {{Non-IID Data}} in {{Federated Learning}} Enabled {{Intrusion Detection}} for {{SDN}}: {{An Experimental Study}}},
  shorttitle = {Threat {{Intelligence}} with {{Non-IID Data}} in {{Federated Learning}} Enabled {{Intrusion Detection}} for {{SDN}}},
  author = {Kazmi, Syed Hussain Ali and Qamar, Faizan and Hassan, Rosilah and Nisar, Kashif and Dahnil, Dahlila Putri Binti and Al-Betar, Mohammed Azmi},
  date = {2023-12-06},
  journaltitle = {2023 24th International Arab Conference on Information Technology (ACIT)},
  pages = {1--6},
  publisher = {IEEE},
  location = {Ajman, United Arab Emirates},
  doi = {10.1109/ACIT58888.2023.10453867},
  url = {https://ieeexplore.ieee.org/document/10453867/},
  urldate = {2024-04-02},
  abstract = {In the realm of cybersecurity, the ever-evolving threat landscape necessitates innovative approaches to design Intrusion Detection Systems (IDS). Software-Defined Networking (SDN) integrated with Deep Learning (DL) has emerged as a transformative paradigm of threat intelligence in IDS. However, centralized data processing in DL based IDS causes privacy issues. Within this context, Federated Learning (FL) has gained significant attention for its potential to enhance intrusion detection while maintaining privacy. This study presents an experimental investigation into the efficacy of FL-enabled intrusion detection in SDN environments, specifically addressing the challenging aspect of threat specific features selection in Non-IID (Non-Independently and Identically Distributed) data. We used the InSDN intrusion dataset containing different attacks including Denial-of-Service (DoS), Distributed-DoS (DDoS), brute force, probe, web and botnet attacks. After data pre-processing, Principal Component Analysis (PCA) is applied to analyze the impact of Non-IID data on features importance. The detailed results of simulations show large variations in features importance for Non-IID data in terms of quantity and threat type distribution. Furthermore, we discuss the implications of our results for future research directions.},
  eventtitle = {2023 24th {{International Arab Conference}} on {{Information Technology}} ({{ACIT}})},
  isbn = {9798350384307}
}

@online{kddcup99,
  title = {{{KDD Cup}} 1999 {{Dataset}}},
  author = {{SigKDD}},
  date = {1999},
  url = {https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html},
  urldate = {2021-04-26},
  keywords = {pinned}
}

@article{kephart_visionautonomiccomputing_2003,
  title = {The Vision of Autonomic Computing},
  author = {Kephart, J.O. and Chess, D.M.},
  date = {2003-01},
  journaltitle = {Computer},
  volume = {36},
  number = {1},
  pages = {41--50},
  issn = {0018-9162},
  doi = {10.1109/MC.2003.1160055},
  url = {http://ieeexplore.ieee.org/document/1160055/},
  abstract = {A 2001 IBM manifesto observed that a looming software complexity crisis - caused by applications and environments that number into the tens of millions of lines of code - threatened to halt progress in computing. The manifesto noted the almost impossible difficulty of managing current and planned computing systems, which require integrating several heterogeneous environments into corporate-wide computing systems that extend into the Internet. Autonomic computing, perhaps the most attractive approach to solving this problem, creates systems that can manage themselves when given high-level objectives from administrators. Systems manage themselves according to an administrator's goals. New components integrate as effortlessly as a new cell establishes itself in the human body. These ideas are not science fiction, but elements of the grand challenge to create self-managing computing systems.}
}

@article{keshav_Howreadpaper_2007,
  title = {How to Read a Paper},
  author = {Keshav, S.},
  date = {2007},
  journaltitle = {acm special interest group on data communication},
  volume = {37},
  number = {3},
  pages = {83--84},
  keywords = {â›” No DOI found}
}

@book{khan_FederatedLearningBased_2022,
  title = {A {{Federated Learning Based Security}} for {{Controller Pilot Data Link Communication}}},
  author = {Khan, Suleman and Gaba, Gurjot and Gurtov, Andrei},
  date = {2022-09-09},
  abstract = {The safety of the passengers and goods in airplanes depends upon a number of combined factors. An airplane's condition and the pilot's experience are pivotal but another very crucial element is the synchronization among the pilots and the air traffic controller (ATC). The communication link between the two carries many uncertain aspects. The aviation sector often tends to give more priority to safety rather than cybersecurity. Although the controller-pilot data communication link (CPDLC) system has been proposed for consistent and reliable communication recently, it has some serious drawbacks. In this paper, we highlight the shortcomings of the CPDLC system from a cyber security perspective. We propose a federated learning-based privacypreserving intrusion detection system (IDS) to protect the CPDLC from uplink and downlink cyber attacks. To ensure a realistic and viable solution, we created our own training dataset by eavesdropping on the air-ground communication at a site near Arlanda airport, Sweden. The anomaly detection model constructed through federated learning has achieved higher accuracy, precision, recall and F1 score as compared to the centrally and locally trained models, enabling higher security. Due to the lower training loss and time, the proposed approach is highly suitable for the sensitive aviation communications.}
}

@article{khan_FederatedSRUsFederatedSimple_2022,
  title = {Federated-{{SRUs}}: {{A Federated Simple Recurrent Units-based IDS}} for {{Accurate Detection}} of {{Cyber Attacks Against IoT-augmented Industrial Control Systems}}},
  shorttitle = {Federated-{{SRUs}}},
  author = {Khan, Izhar Ahmed and Pi, Dechang and Abbas, Muhammad Zahid and Zia, Umar and Hussain, Yasir and Soliman, Hatem},
  date = {2022},
  journaltitle = {IEEE Internet of Things Journal},
  pages = {1--1},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2022.3200048},
  abstract = {The security of Industrial Control Systems (ICS) against cyber-attacks is essential in modern era since ICSs are vital constituent of modern societies and smart cities. However, the augmentation of legacy ICS networks with smart computing and networking technologies (such as, IoT) have intensely enlarged the surface of attacks against these critical infrastructures. This augmentation makes these networks more vulnerable to cyber-attacks and despite the current security solutions, attackers still find ways to proliferate these networks. Intrusion Detection System (IDS) is one of the key security aspect to prevent these networks from contemporary cyber-attacks. Therefore, this paper proposes a new IDS model named Federated-SRUs (simple recurrent units) for the security of IoT-based ICSs. Specifically, the Federated-SRUs IDS model uses an improved simple recurrent units architecture to reduce computational cost and alleviate the gradient vanishing issue in recurrent networks. Then, it performs data aggregation through several communication rounds in federated architecture which allows multiple ICS networks and stakeholders to build a comprehensive IDS model in a privacy-preserving manner. The performance of Federated-SRUs IDS model is validated through experiments using real-world gas pipeline-based ICS network data, which indicates that it is able to accurately detect intrusions in real-time without compromising privacy and security. Experiments also verify that the Federated-SRUs model outperforms existing state-of-the-art approaches and thus can serve as a viable IDS method in IoT-based ICS networks.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {Computational modeling,Computer architecture,cyber-attacks,Data models,industrial control systems,Industrial Internet of Things,industrial networks,Integrated circuits,intrusion detection,Intrusion detection,IoT,Security}
}

@unpublished{khoa_DeepTransferLearning_2021,
  title = {Deep {{Transfer Learning}}: {{A Novel Collaborative Learning Model}} for {{Cyberattack Detection Systems}} in {{IoT Networks}}},
  shorttitle = {Deep {{Transfer Learning}}},
  author = {Khoa, Tran Viet and Hoang, Dinh Thai and Trung, Nguyen Linh and Nguyen, Cong T. and Quynh, Tran Thi Thuy and Nguyen, Diep N. and Ha, Nguyen Viet and Dutkiewicz, Eryk},
  date = {2021-12-02},
  eprint = {2112.00988},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2112.00988},
  urldate = {2022-01-31},
  abstract = {Federated Learning (FL) has recently become an effective approach for cyberattack detection systems, especially in Internet-of-Things (IoT) networks. By distributing the learning process across IoT gateways, FL can improve learning efficiency, reduce communication overheads and enhance privacy for cyberattack detection systems. Challenges in implementation of FL in such systems include unavailability of labeled data and dissimilarity of data features in different IoT networks. In this paper, we propose a novel collaborative learning framework that leverages Transfer Learning (TL) to overcome these challenges. Particularly, we develop a novel collaborative learning approach that enables a target network with unlabeled data to effectively and quickly learn ``knowledge'' from a source network that possesses abundant labeled data. It is important that the stateof-the-art studies require the participated datasets of networks to have the same features, thus limiting the efficiency, flexibility as well as scalability of intrusion detection systems. However, our proposed framework can address these problems by exchanging the learning ``knowledge'' among various deep learning models, even when their datasets have different features. Extensive experiments on recent real-world cybersecurity datasets show that the proposed framework can improve more than 40\% as compared to the state-of-the-art deep learning based approaches.},
  langid = {english},
  keywords = {â›” No DOI found,Computer Science - Machine Learning}
}

@article{khraisat_criticalreviewintrusion_2021,
  title = {A Critical Review of Intrusion Detection Systems in the Internet of Things: Techniques, Deployment Strategy, Validation Strategy, Attacks, Public Datasets and Challenges},
  shorttitle = {A Critical Review of Intrusion Detection Systems in the Internet of Things},
  author = {Khraisat, Ansam and Alazab, Ammar},
  date = {2021-12},
  journaltitle = {Cybersecurity},
  shortjournal = {Cybersecur},
  volume = {4},
  number = {1},
  pages = {1--27},
  publisher = {SpringerOpen},
  issn = {2523-3246},
  doi = {10.1186/s42400-021-00077-7},
  url = {https://cybersecurity.springeropen.com/articles/10.1186/s42400-021-00077-7},
  urldate = {2022-08-18},
  abstract = {The Internet of Things (IoT) has been rapidly evolving towards making a greater impact on everyday life to large industrial systems. Unfortunately, this has attracted the attention of cybercriminals who made IoT a target of malicious activities, opening the door to a possible attack on the end nodes. To this end, Numerous IoT intrusion detection Systems (IDS) have been proposed in the literature to tackle attacks on the IoT ecosystem, which can be broadly classified based on detection technique, validation strategy, and deployment strategy. This survey paper presents a comprehensive review of contemporary IoT IDS and an overview of techniques, deployment Strategy, validation strategy and datasets that are commonly applied for building IDS. We also review how existing IoT IDS detect intrusive attacks and secure communications on the IoT. It also presents the classification of IoT attacks and discusses future research challenges to counter such IoT attacks to make IoT more secure. These purposes help IoT security researchers by uniting, contrasting, and compiling scattered research efforts. Consequently, we provide a unique IoT IDS taxonomy, which sheds light on IoT IDS techniques, their advantages and disadvantages, IoT attacks that exploit IoT communication systems, corresponding advanced IDS and detection capabilities to detect IoT attacks.},
  issue = {1},
  langid = {english},
  keywords = {+survey}
}

@article{khraisat_Surveyintrusiondetection_2019,
  title = {Survey of Intrusion Detection Systems: Techniques, Datasets and Challenges},
  shorttitle = {Survey of Intrusion Detection Systems},
  author = {Khraisat, Ansam and Gondal, Iqbal and Vamplew, Peter and Kamruzzaman, Joarder},
  date = {2019-12},
  journaltitle = {Cybersecurity},
  shortjournal = {Cybersecur},
  volume = {2},
  number = {1},
  pages = {20},
  issn = {2523-3246},
  doi = {10.1186/s42400-019-0038-7},
  url = {https://cybersecurity.springeropen.com/articles/10.1186/s42400-019-0038-7},
  urldate = {2022-03-11},
  abstract = {Cyber-attacks are becoming more sophisticated and thereby presenting increasing challenges in accurately detecting intrusions. Failure to prevent the intrusions could degrade the credibility of security services, e.g. data confidentiality, integrity, and availability. Numerous intrusion detection methods have been proposed in the literature to tackle computer security threats, which can be broadly classified into Signature-based Intrusion Detection Systems (SIDS) and Anomaly-based Intrusion Detection Systems (AIDS). This survey paper presents a taxonomy of contemporary IDS, a comprehensive review of notable recent works, and an overview of the datasets commonly used for evaluation purposes. It also presents evasion techniques used by attackers to avoid detection and discusses future research challenges to counter such techniques so as to make computer systems more secure.},
  langid = {english},
  keywords = {+survey}
}

@article{kilincer_Machinelearningmethods_2021,
  title = {Machine Learning Methods for Cyber Security Intrusion Detection: {{Datasets}} and Comparative Study},
  shorttitle = {Machine Learning Methods for Cyber Security Intrusion Detection},
  author = {Kilincer, Ilhan Firat and Ertam, Fatih and Sengur, Abdulkadir},
  date = {2021-04-07},
  journaltitle = {Computer Networks},
  shortjournal = {Computer Networks},
  volume = {188},
  pages = {107840},
  issn = {1389-1286},
  doi = {10.1016/j.comnet.2021.107840},
  url = {https://www.sciencedirect.com/science/article/pii/S1389128621000141},
  urldate = {2022-08-18},
  abstract = {The increase in internet usage brings security problems with it. Malicious software can affect the operation of the systems and disrupt data confidentiality due to the security gaps in the systems. Intrusion Detection Systems (IDS) have been developed to detect and report attacks. In order to develop IDS systems, artificial intelligence-based approaches have been used more frequently. In this study, literature studies using CSE-CIC IDS-2018, UNSW-NB15, ISCX-2012, NSL-KDD and CIDDS-001 data sets, which are widely used to develop IDS systems, are reviewed in detail. In addition, max-min normalization was performed on these data sets and classification was made with support vector machine (SVM), K-Nearest neighbor (KNN), Decision Tree (DT) algorithms, which are among the classical machine learning approaches. As a result, more successful results have been obtained in some of the studies given in the literature. The study is thought to be useful for developing IDS systems on the basis of artificial intelligence with approaches such as machine learning.},
  langid = {english},
  keywords = {Cyber security,DT,IDS,KNN,Machine learning,SVM}
}

@inproceedings{kim_CollaborativeAnomalyDetection_2020,
  title = {Collaborative {{Anomaly Detection}} for {{Internet}} of {{Things}} Based on {{Federated Learning}}},
  booktitle = {2020 {{IEEE}}/{{CIC International Conference}} on {{Communications}} in {{China}} ({{ICCC}})},
  author = {Kim, Seongwoo and Cai, He and Hua, Cunqing and Gu, Pengwenlong and Xu, Wenchao and Park, Jeonghyeok},
  date = {2020-08-09},
  pages = {623--628},
  publisher = {IEEE},
  location = {Chongqing, China},
  doi = {10.1109/ICCC49849.2020.9238913},
  url = {https://ieeexplore.ieee.org/document/9238913/},
  urldate = {2021-10-25},
  abstract = {In this paper, we propose a federated learning(FL)-based collaborative anomaly detection system. This system consists of multiple edge nodes and a server node. The edge nodes are in charge of not only monitoring and collecting data, but also to train an anomaly detection neural network classification model based on the local data. On the other hand, the server aggregates the parameters from the edges and generates a new model for the next round. This system structure achieves light weight transmission between the server and the edge nodes, and user privacy can be well protected since raw data are not communicated directly. We implement the proposed scheme in the practical system and present experimental results that demonstrate results competitive with those of state-ofthe-art models.},
  eventtitle = {2020 {{IEEE}}/{{CIC International Conference}} on {{Communications}} in {{China}} ({{ICCC}})},
  isbn = {978-1-72817-327-6},
  langid = {english},
  keywords = {survey-fids}
}

@inproceedings{kim_ExploringClusteredFederated_2023,
  title = {Exploring {{Clustered Federated Learning}}'s {{Vulnerability}} against {{Property Inference Attack}}},
  booktitle = {Proceedings of the 26th {{International Symposium}} on {{Research}} in {{Attacks}}, {{Intrusions}} and {{Defenses}}},
  author = {Kim, Hyunjun and Cho, Yungi and Lee, Younghan and Bae, Ho and Paek, Yunheung},
  date = {2023-10-16},
  series = {{{RAID}} '23},
  pages = {236--249},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3607199.3607218},
  url = {https://dl.acm.org/doi/10.1145/3607199.3607218},
  urldate = {2024-01-10},
  abstract = {Clustered federated learning (CFL) is an advanced technique in the field of federated learning (FL) that addresses the issue of catastrophic forgetting caused by non-independent and identically distributed (non-IID) datasets. CFL achieves this by clustering clients based on the similarity of their datasets and training a global model for each cluster. Despite the effectiveness of CFL in mitigating performance degradation resulting from non-IID datasets, the potential risk of privacy leakages in CFL has not been thoroughly studied. Previous work evaluated the risk of privacy leakages in FL using the property inference attack (PIA), which extracts information about unintended properties (i.e., attributes that differ from the target attribute of the global model's main task). In this paper, we explore the potential risk of unintended property leakage in CFL by subjecting it to both passive and active PIAs. Our empirical analysis shows that the passive PIA performance on CFL is substantially better than that on FL in terms of the attack AUC score. Moreover, we propose an enhanced active PIA method tailored for CFL to improve the attack performance. Our method introduces a scale-up parameter that amplifies the impact of malicious local updates, resulting in better performance than the previous technique. Furthermore, we demonstrate that the vulnerability of CFL can be alleviated by applying differential privacy (DP) mechanisms at the client-level. Unlike previous works, which have shown that applying DP to FL can induce a high utility loss, our empirical results indicate that DP can be used as a defense mechanism in CFL, leading to a better trade-off between privacy and utility.},
  isbn = {9798400707650},
  keywords = {\_read\_urgently,clustered federated learning,differential privacy,property inference attack}
}

@article{kim_FederatedLearningLocal_2021,
  title = {Federated {{Learning}} with {{Local Differential Privacy}}: {{Trade-offs}} between {{Privacy}}, {{Utility}}, and {{Communication}}},
  author = {Kim, Muah and Gunlu, Onur and Schaefer, Rafael F},
  date = {2021},
  keywords = {â›” No DOI found}
}

@article{kiss_KharondatasetAndroid_2016,
  title = {Kharon Dataset: {{Android}} Malware under a Microscope},
  author = {Kiss, N and Lalande, J.-F. and Leslous, M. and Viet Triem Tong, V.},
  date = {2016},
  pages = {12},
  abstract = {Background -- This study is related to the understanding of Android malware that now populate smartphone's markets. Aim -- Our main objective is to help other malware researchers to better understand how malware works. Additionally, we aim at supporting the reproducibility of experiments analyzing malware samples: such a collection should improve the comparison of new detection or analysis methods. Methodology -- In order to achieve these goals, we describe here an Android malware collection called Kharon. This collection gives as much as possible a representation of the diversity of malware types. With such a dataset, we manually dissected each malware by reversing their code. We run them in a controlled and monitored real smartphone in order to extract their precise behavior. We also summarized their behavior using a graph representations of the information flows induced by an execution. With such a process, we obtained a precise knowledge of their malicious code and actions. Results and conclusions -- Researchers can figure out the engineering efforts of malware developers and understand their programming patterns. Another important result of this study is that most of malware now include triggering techniques that delay and hide their malicious activities. We also think that this collection can initiate a reference test set for future research works.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@report{kitchenham_Guidelinesperformingsystematic_2007,
  title = {Guidelines for Performing Systematic Literature Reviews in Software Engineering},
  author = {Kitchenham, B. and Charters, S},
  date = {2007},
  number = {EBSE-2007-01},
  abstract = {The objective of this report is to propose comprehensive guidelines for systematic literature reviews appropriate for software engineering researchers, including PhD students. A systematic literature review is a means of evaluating and interpreting all available research relevant to a particular research question, topic area, or phenomenon of interest. Systematic reviews aim to present a fair evaluation of a research topic by using a trustworthy, rigorous, and auditable methodology. The guidelines presented in this report were derived from three existing guidelines used by medical researchers, two books produced by researchers with social science backgrounds and discussions with researchers from other disciplines who are involved in evidence-based practice. The guidelines have been adapted to reflect the specific problems of software engineering research. The guidelines cover three phases of a systematic literature review: planning the review, conducting the review and reporting the review. They provide a relatively high level description. They do not consider the impact of the research questions on the review procedures, nor do they specify in detail the mechanisms needed to perform meta-analysis.}
}

@inproceedings{kokkonen_Modelsharinginformation_2016,
  title = {Model for Sharing the Information of Cyber Security Situation Awareness between Organizations},
  booktitle = {2016 23rd {{International Conference}} on {{Telecommunications}} ({{ICT}})},
  author = {Kokkonen, Tero and Hautamaki, Jari and Siltanen, Jarmo and Hamalainen, Timo},
  date = {2016-05},
  pages = {1--5},
  publisher = {IEEE},
  doi = {10.1109/ICT.2016.7500406},
  url = {http://ieeexplore.ieee.org/document/7500406/},
  abstract = {Exchanging of Situation Awareness information is extremely important for organizations in order to survive as part of the cyber domain. The situation Awareness is required for decision making and for an early warning of upcoming threats. Situation Awareness and the security information in the cyber domain differ from the kinetic domain. Because of that, Situation Awareness has different requirements and use cases, for example when considering time or geographical distances. There is always a risk when sharing security information due to the classified nature of the information. It might contain information of weaknesses or vulnerabilities of the organization, and if used wrongly it jeopardizes the continuity of the business or mission. The model introduced in this paper for creating information sharing topologies enables sharing of classified security related information between multiple organizations with the lowest possible risks levels.},
  isbn = {978-1-5090-1990-8}
}

@article{kolias_DDoSIoTMirai_2017,
  title = {{{DDoS}} in the {{IoT}}: {{Mirai}} and {{Other Botnets}}},
  author = {Kolias, Constantinos and Kambourakis, Georgios and Stavrou, Angelos and Voas, Jeffrey},
  date = {2017},
  journaltitle = {Computer},
  volume = {50},
  number = {7},
  pages = {80--84},
  publisher = {IEEE},
  issn = {0018-9162},
  doi = {10.1109/MC.2017.201},
  url = {http://ieeexplore.ieee.org/document/7971869/},
  abstract = {The Mirai botnet and its variants and imitators are a wake-up call to the industry to better secure Internet of Things devices or risk exposing the Internet infrastructure to increasingly disruptive distributed denial-of-service attacks.},
  isbn = {978-1-5090-4862-5}
}

@article{kolias_IntrusionDetection802_2016,
  title = {Intrusion {{Detection}} in 802.11 {{Networks}}: {{Empirical Evaluation}} of {{Threats}} and a {{Public Dataset}}},
  author = {Kolias, Constantinos and Kambourakis, Georgios and Stavrou, Angelos and Gritzalis, Stefanos},
  date = {2016},
  journaltitle = {IEEE Communications Surveys \& Tutorials},
  volume = {18},
  number = {1},
  pages = {184--208},
  publisher = {IEEE},
  issn = {1553-877X},
  doi = {10.1109/COMST.2015.2402161},
  url = {http://ieeexplore.ieee.org/document/7041170/},
  abstract = {WiFi has become the de facto wireless technology for achieving short- to medium-range device connectivity. While early attempts to secure this technology have been proved inadequate in several respects, the current more robust security amendments will inevitably get outperformed in the future, too. In any case, several security vulnerabilities have been spotted in virtually any version of the protocol rendering the integration of external protection mechanisms a necessity. In this context, the contribution of this paper is multifold. First, it gathers, categorizes, thoroughly evaluates the most popular attacks on 802.11 and analyzes their signatures. Second, it offers a publicly available dataset containing a rich blend of normal and attack traffic against 802.11 networks. A quite extensive first-hand evaluation of this dataset using several machine learning algorithms and data features is also provided. Given that to the best of our knowledge the literature lacks such a rich and well-tailored dataset, it is anticipated that the results of the work at hand will offer a solid basis for intrusion detection in the current as well as next-generation wireless networks.},
  keywords = {+survey}
}

@article{kollu_CloudBasedSmartContract_2023,
  title = {Cloud-{{Based Smart Contract Analysis}} in {{FinTech Using IoT-Integrated Federated Learning}} in {{Intrusion Detection}}},
  author = {Kollu, Venkatagurunatham Naidu and Janarthanan, Vijayaraj and Karupusamy, Muthulakshmi and Ramachandran, Manikandan},
  date = {2023-05},
  journaltitle = {Data},
  volume = {8},
  number = {5},
  pages = {83},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2306-5729},
  doi = {10.3390/data8050083},
  url = {https://www.mdpi.com/2306-5729/8/5/83},
  urldate = {2024-04-12},
  abstract = {Data sharing is proposed because the issue of data islands hinders advancement of artificial intelligence technology in the 5G era. Sharing high-quality data has a direct impact on how well machine-learning models work, but there will always be misuse and leakage of data. The field of financial technology, or FinTech, has received a lot of attention and is growing quickly. This field has seen the introduction of new terms as a result of its ongoing expansion. One example of such terminology is ``FinTech''. This term is used to describe a variety of procedures utilized frequently in the financial technology industry. This study aims to create a cloud-based intrusion detection system based on IoT federated learning architecture as well as smart contract analysis. This study proposes a novel method for detecting intrusions using a cyber-threat federated graphical authentication system and cloud-based smart contracts in FinTech data. Users are required to create a route on a world map as their credentials under this scheme. We had 120 people participate in the evaluation, 60 of whom had a background in finance or FinTech. The simulation was then carried out in Python using a variety of FinTech cyber-attack datasets for accuracy, precision, recall, F-measure, AUC (Area under the ROC Curve), trust value, scalability, and integrity. The proposed technique attained accuracy of 95\%, precision of 85\%, RMSE of 59\%, recall of 68\%, F-measure of 83\%, AUC of 79\%, trust value of 65\%, scalability of 91\%, and integrity of 83\%.},
  issue = {5},
  langid = {english},
  keywords = {cloud computing,FinTech,intrusion detection system,IoT federated learning architecture,smart contract analysis}
}

@article{konecny_FederatedLearningStrategies_2016,
  title = {Federated {{Learning}}: {{Strategies}} for {{Improving Communication Efficiency}}},
  author = {Kone\v cn\'y, Jakub and McMahan, H. Brendan and Yu, Felix X. and Richt\'arik, Peter and Suresh, Ananda Theertha and Bacon, Dave},
  date = {2016-10-18},
  pages = {1--10},
  url = {http://arxiv.org/abs/1610.05492},
  abstract = {Federated Learning is a machine learning setting where the goal is to train a high-quality centralized model while training data remains distributed over a large number of clients each with unreliable and relatively slow network connections. We consider learning algorithms for this setting where on each round, each client independently computes an update to the current model based on its local data, and communicates this update to a central server, where the client-side updates are aggregated to compute a new global model. The typical clients in this setting are mobile phones, and communication efficiency is of the utmost importance. In this paper, we propose two ways to reduce the uplink communication costs: structured updates, where we directly learn an update from a restricted space parametrized using a smaller number of variables, e.g. either low-rank or a random mask; and sketched updates, where we learn a full model update and then compress it using a combination of quantization, random rotations, and subsampling before sending it to the server. Experiments on both convolutional and recurrent networks show that the proposed methods can reduce the communication cost by two orders of magnitude.}
}

@article{konecny_FederatedOptimizationDistributed_2016,
  title = {Federated {{Optimization}}: {{Distributed Machine Learning}} for {{On-Device Intelligence}}},
  author = {Kone\v cn\'y, Jakub and McMahan, H. Brendan and Ramage, Daniel and Richt\'arik, Peter},
  date = {2016-10-08},
  pages = {1--38},
  url = {http://arxiv.org/abs/1610.02527},
  abstract = {We introduce a new and increasingly relevant setting for distributed optimization in machine learning, where the data defining the optimization are unevenly distributed over an extremely large number of nodes. The goal is to train a high-quality centralized model. We refer to this setting as Federated Optimization. In this setting, communication efficiency is of the utmost importance and minimizing the number of rounds of communication is the principal goal. A motivating example arises when we keep the training data locally on users' mobile devices instead of logging it to a data center for training. In federated optimziation, the devices are used as compute nodes performing computation on their local data in order to update a global model. We suppose that we have extremely large number of devices in the network --- as many as the number of users of a given service, each of which has only a tiny fraction of the total data available. In particular, we expect the number of data points available locally to be much smaller than the number of devices. Additionally, since different users generate data with different patterns, it is reasonable to assume that no device has a representative sample of the overall distribution. We show that existing algorithms are not suitable for this setting, and propose a new algorithm which shows encouraging experimental results for sparse convex problems. This work also sets a path for future research needed in the context of \textbackslash federated optimization.}
}

@article{koroniotis_developmentrealisticbotnet_2019,
  title = {Towards the Development of Realistic Botnet Dataset in the {{Internet}} of {{Things}} for Network Forensic Analytics: {{Bot-IoT}} Dataset},
  shorttitle = {Towards the Development of Realistic Botnet Dataset in the {{Internet}} of {{Things}} for Network Forensic Analytics},
  author = {Koroniotis, Nickolaos and Moustafa, Nour and Sitnikova, Elena and Turnbull, Benjamin},
  date = {2019-11},
  journaltitle = {Future Generation Computer Systems},
  shortjournal = {Future Generation Computer Systems},
  volume = {100},
  pages = {779--796},
  issn = {0167739X},
  doi = {10.1016/j.future.2019.05.041},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X18327687},
  urldate = {2021-10-23},
  abstract = {The proliferation of IoT systems, has seen them targeted by malicious third parties. To address this challenge, realistic protection and investigation countermeasures, such as network intrusion detection and network forensic systems, need to be effectively developed. For this purpose, a well-structured and representative dataset is paramount for training and validating the credibility of the systems. Although there are several network datasets, in most cases, not much information is given about the Botnet scenarios that were used. This paper proposes a new dataset, so-called Bot-IoT, which incorporates legitimate and simulated IoT network traffic, along with various types of attacks. We also present a realistic testbed environment for addressing the existing dataset drawbacks of capturing complete network information, accurate labeling, as well as recent and complex attack diversity. Finally, we evaluate the reliability of the BoT-IoT dataset using different statistical and machine learning methods for forensics purposes compared with the benchmark datasets. This work provides the baseline for allowing botnet identification across IoT-specific networks. The Bot-IoT dataset can be accessed at Bot-iot (2018) [1].},
  langid = {english}
}

@article{koroniotis_developmentrealisticbotnet_2019a,
  title = {Towards the Development of Realistic Botnet Dataset in the {{Internet}} of {{Things}} for Network Forensic Analytics: {{Bot-IoT}} Dataset},
  shorttitle = {Towards the Development of Realistic Botnet Dataset in the {{Internet}} of {{Things}} for Network Forensic Analytics},
  author = {Koroniotis, Nickolaos and Moustafa, Nour and Sitnikova, Elena and Turnbull, Benjamin},
  date = {2019-11-01},
  journaltitle = {Future Generation Computer Systems},
  shortjournal = {Future Generation Computer Systems},
  volume = {100},
  pages = {779--796},
  issn = {0167-739X},
  doi = {10.1016/j.future.2019.05.041},
  url = {https://www.sciencedirect.com/science/article/pii/S0167739X18327687},
  urldate = {2023-03-22},
  abstract = {The proliferation of IoT systems, has seen them targeted by malicious third parties. To address this challenge, realistic protection and investigation countermeasures, such as network intrusion detection and network forensic systems, need to be effectively developed. For this purpose, a well-structured and representative dataset is paramount for training and validating the credibility of the systems. Although there are several network datasets, in most cases, not much information is given about the Botnet scenarios that were used. This paper proposes a new dataset, so-called Bot-IoT, which incorporates legitimate and simulated IoT network traffic, along with various types of attacks. We also present a realistic testbed environment for addressing the existing dataset drawbacks of capturing complete network information, accurate labeling, as well as recent and complex attack diversity. Finally, we evaluate the reliability of the BoT-IoT dataset using different statistical and machine learning methods for forensics purposes compared with the benchmark datasets. This work provides the baseline for allowing botnet identification across IoT-specific networks. The Bot-IoT dataset can be accessed at Bot-iot (2018) [1].},
  langid = {english},
  keywords = {Bot-IoT dataset,Forensics analytics,Network flow,Network forensics}
}

@article{koutrouli_Taxonomyattacksdefense_2012,
  title = {Taxonomy of Attacks and Defense Mechanisms in {{P2P}} Reputation Systems---{{Lessons}} for Reputation System Designers},
  author = {Koutrouli, Eleni and Tsalgatidou, Aphrodite},
  date = {2012-05-01},
  journaltitle = {Computer Science Review},
  shortjournal = {Computer Science Review},
  volume = {6},
  number = {2},
  pages = {47--70},
  issn = {1574-0137},
  doi = {10.1016/j.cosrev.2012.01.002},
  url = {https://www.sciencedirect.com/science/article/pii/S1574013712000093},
  urldate = {2024-07-03},
  abstract = {Robust and credible reputation systems are essential for the functionality of Peer-to-Peer (P2P) applications. However, they themselves are susceptible to various types of attacks. Since most current efforts lack an exploration of a comprehensive adversary model, we try to fill in this gap by providing a thorough view of the various credibility threats against a decentralized reputation system and the respective defense mechanisms. Therefore, we explore and classify the types of potential attacks against reputation systems for P2P applications. We also study and classify the defense mechanisms which have been proposed for each type of attack and identify conflicts between defense mechanisms and/or desirable characteristics of credible reputations systems. We finally propose a roadmap for reputation system designers on how to use the results of our survey for the design of robust reputation systems for P2P applications.},
  keywords = {Credibility,Peer-to-Peer,Reputation attacks,Reputation attacks taxonomy,Reputation systems,Threat analysis}
}

@article{kristianto_Misbehaviordetectionsystem_2023,
  title = {Misbehavior Detection System with Semi-Supervised Federated Learning},
  author = {Kristianto, Edy and Lin, Po-Ching and Hwang, Ren-Hung},
  date = {2023-06-01},
  journaltitle = {Vehicular Communications},
  shortjournal = {Vehicular Communications},
  volume = {41},
  pages = {100597},
  issn = {2214-2096},
  doi = {10.1016/j.vehcom.2023.100597},
  url = {https://www.sciencedirect.com/science/article/pii/S221420962300027X},
  urldate = {2024-04-12},
  abstract = {V2X communications can enhance transportation safety by exchanging safety information between vehicles, road infrastructures, networks, and pedestrians. However, the safety messages are vulnerable to disruption from faulty components or an attack that can cause misinformation. Recently, a machine learning-based misbehavior detection system (MDS) has been widely investigated to detect the misbehaving vehicles to secure the V2X communications. Nonetheless, machine learning models need sufficient labeled data for learning purposes. However, the volume of unlabeled data is usually larger than that of labeled data in practice. Moreover, transferring the large dataset to a centralized learning model will consume much bandwidth. Thus, we propose a semi-supervised federated learning MDS to overcome the limitations of unlabeled data and bring the training close to the data sources to reduce the bandwidth to the core network. Overall, our model with only limited labeled data training (5\%--30\%) can achieve the F1-score up to 0.96 and the recall up to 0.95. The F1-score is up to 0.26 higher and the recall is up to 0.29 higher than the performance of centralized supervised learning. The federated learning model can reduce the core network bandwidth utilization by up to 95\%.},
  keywords = {Federated learning,Misbehavior detection system,Semi-supervised learning,V2X communications}
}

@incollection{kruegel_UsingDecisionTrees_2003,
  title = {Using {{Decision Trees}} to {{Improve Signature-Based Intrusion Detection}}},
  booktitle = {Recent {{Advances}} in {{Intrusion Detection}}},
  author = {Kruegel, Christopher and Toth, Thomas},
  date = {2003},
  pages = {173--191},
  abstract = {Most deployed intrusion detection systems (IDSs) follow a signature-based approach where attacks are identified by matching each input event against predefined signatures that model malicious activity. This matching process accounts for the most resource intensive task of an IDS. Many systems perform the matching by comparing each input event to all rules sequentially. This is far from being optimal. Although sometimes ad-hoc optimizations are utilized, no general solution to this problem has been proposed so far.},
  langid = {english}
}

@incollection{krzyszton_NADMachineLearning_2022,
  title = {{{NAD}}: {{Machine Learning Based Component}} for {{Unknown Attack Detection}} in {{Network Traffic}}},
  shorttitle = {{{NAD}}},
  booktitle = {Cybersecurity of {{Digital Service Chains}}},
  author = {Krzyszto\'n, Mateusz and Lew, Marcin and Marks, Micha\l},
  editor = {Ko\l odziej, Joanna and Repetto, Matteo and Duzha, Armend},
  date = {2022},
  volume = {13300},
  pages = {83--102},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-04036-8_4},
  url = {https://link.springer.com/10.1007/978-3-031-04036-8_4},
  urldate = {2022-07-05},
  abstract = {Detection of unknown attacks is challenging due to the lack of exemplary attack vectors. However, previously unknown attacks are a significant danger for systems due to a lack of tools for protecting systems against them, especially in fast-evolving Internet of Things (IoT) technology. The most widely used approach for malicious behaviour of the monitored system is detecting anomalies. The vicious behaviour might result from an attack (both known and unknown) or accidental breakdown. We present a Net Anomaly Detector (NAD) system that uses one-class classification Machine Learning techniques to detect anomalies in the network traffic. The highly modular architecture allows the system to be expanded with adapters for various types of networks. We propose and discuss multiple approaches for increasing detection quality and easing the component deployment in unknown networks by known attacks emulation, exhaustive feature extraction, hyperparameter tuning, detection threshold adaptation and ensemble models strategies. Furthermore, we present both centralized and decentralized deployment schemes and present preliminary results of experiments for the TCP/IP network traffic conducted on the CIC-IDS2017 dataset.},
  isbn = {978-3-031-04035-1 978-3-031-04036-8},
  langid = {english},
  keywords = {\_read}
}

@article{kumar_BlockchainDeepLearning_2022,
  title = {Blockchain and {{Deep Learning}} for {{Secure Communication}} in {{Digital Twin Empowered Industrial IoT Network}}},
  author = {Kumar, Prabhat and Kumar, Randhir and Kumar, Abhinav and Franklin, A. Antony and Garg, Sahil and Singh, Satinder},
  date = {2022},
  journaltitle = {IEEE Transactions on Network Science and Engineering},
  pages = {1--13},
  issn = {2327-4697},
  doi = {10.1109/TNSE.2022.3191601},
  abstract = {The rapid expansion of the Industrial Internet of Things (IIoT) necessitates the digitization of industrial processes in order to increase network efficiency. The integration of Digital Twin (DT) with IIoT digitizes physical objects into virtual representations to improve data analytics performance. Nevertheless, DT empowered IIoT generates a massive amount of data that is mostly sent to the cloud or edge servers for real-time analysis. However, unreliable public communication channels and lack of trust among participating entities causes various types of threats and attacks on the ongoing communication. Motivated from the aforementioned discussion, we present a blockchain and Deep Learning (DL) integrated framework for delivering decentralized data processing and learning in IIoT network. The framework first present a new DT model that facilitates construction of a virtual environment to simulate and replicate security-critical processes of IIoT. Second, we propose a blockchain-based data transmission scheme that uses smart contracts to ensure integrity and authenticity of data. Finally, the DL scheme is designed to apply the Intrusion Detection System (IDS) against valid data retrieved from blockchain. In DL scheme, a Long Short Term Memory-Sparse AutoEncoder (LSTMSAE) technique is proposed to learn the spatial-temporal representation. The extracted characteristics are further used by the proposed Multi-Head Self-Attention (MHSA)-based Bidirectional Gated Recurrent Unit (BiGRU) algorithm to learn long-distance features and accurately detect attacks. The practical implementation of our proposed framework proves considerable enhancement of communication security and data privacy in DT empowered IIoT network.},
  eventtitle = {{{IEEE Transactions}} on {{Network Science}} and {{Engineering}}},
  keywords = {Blockchain,Blockchains,Computational modeling,Data models,Deep Learning (DL),Digital Twin (DT),Digital twins,Industrial Internet of Things,Industrial Internet of Things (IIoT),Security,Smart Contract,Virtual environments}
}

@article{kumar_DistributedIntrusionDetection_2022,
  title = {A {{Distributed Intrusion Detection System}} to {{Detect DDoS Attacks}} in {{Blockchain-enabled IoT Network}}},
  author = {Kumar, Randhir and Kumar, Prabhat and Tripathi, Rakesh and Gupta, Govind P. and Garg, Sahil and Hassan, Mohammad Mehedi},
  date = {2022-02},
  journaltitle = {Journal of Parallel and Distributed Computing},
  shortjournal = {Journal of Parallel and Distributed Computing},
  pages = {S0743731522000351},
  issn = {07437315},
  doi = {10.1016/j.jpdc.2022.01.030},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0743731522000351},
  urldate = {2022-02-25},
  abstract = {The Internet of Things (IoT) is emerging as a new technology for the development of various critical applications. However, these applications are still working on centralized storage architecture and have various key challenges like privacy, security, and single point of failure. Recently, the blockchain technology has emerged as a backbone for the IoT-based application development. The blockchain can be leveraged to solve privacy, security, and single point of failure (third-part dependency) issues of IoT applications. The integration of blockchain with IoT can benefit both individual and society. However, 2017 Distributed Denial of Service (DDoS) attack on mining pool exposed the critical fault-lines among blockchain-enabled IoT network. Moreover, these application generates huge amount of data. Machine Learning (ML) gives complete autonomy in big data analysis, capabilities of decision making and therefore is used as an analytical tool. Thus, in order to address above challenges, this paper proposes a novel distributed Intrusion Detection System (IDS) using fog computing to detect DDoS attacks against mining pool in blockchain-enabled IoT Network. The performance is evaluated by training Random Forest (RF) and an optimized gradient tree boosting system (XGBoost) on distributed fog nodes. The proposed model eâ†µectiveness is assessed using an actual IoT-based dataset i.e., BoT-IoT, which includes most recent attacks found in blockchain-enabled IoT network. The results indicate, for binary attack-detection XGBoost outperforms whereas for multi-attack detection Random Forest outperforms. Overall on distributed fog nodes RF takes less time for training and testing compared to XGBoost.},
  langid = {english}
}

@article{kumar_FEDCLEANDEFENSEMECHANISM_,
  title = {{{FEDCLEAN}}: {{A DEFENSE MECHANISM AGAINST PARAMETER POISONING ATTACKS IN FEDERATED LEARNING}}},
  author = {Kumar, Abhishek and Khimani, Vivek and Chatzopoulos, Dimitris and Hui, Pan},
  pages = {5},
  doi = {10.1109/ICASSP43922.2022.9747497},
  abstract = {In Federated learning (FL) systems, a centralized entity (server), instead of access to the training data, has access to model parameter updates computed by each participant independently and based solely on their samples. Unfortunately, FL is susceptible to model poisoning attacks, in which malicious or malfunctioning entities share polluted updates that can compromise the model's accuracy. In this study, we propose FedClean, an FL mechanism that is robust to model poisoning attacks. The accuracy of the models trained with the assistance of FedClean is close to the one where malicious entities do not participate.},
  langid = {english},
  keywords = {agent selection,cosin similarity}
}

@article{kumar_FedCleanDefenseMechanism_2022,
  title = {{{FedClean}}: {{A Defense Mechanism}} against {{Parameter Poisoning Attacks}} in {{Federated Learning}}},
  author = {Kumar, Abhishek and Khimani, Vivek and Chatzopoulos, Dimitris and Hui, Pan},
  date = {2022-04},
  pages = {5},
  abstract = {In Federated learning (FL) systems, a centralized entity (server), instead of access to the training data, has access to model parameter updates computed by each participant independently and based solely on their samples. Unfortunately, FL is susceptible to model poisoning attacks, in which malicious or malfunctioning entities share polluted updates that can compromise the model's accuracy. In this study, we propose FedClean, an FL mechanism that is robust to model poisoning attacks. The accuracy of the models trained with the assistance of FedClean is close to the one where malicious entities do not participate.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@inproceedings{kumari_BayBFedBayesianBackdoor_2022,
  title = {{{BayBFed}}: {{Bayesian Backdoor Defense}} for {{Federated Learning}}},
  shorttitle = {{{BayBFed}}},
  author = {Kumari, Kavita and Rieger, Phillip and Fereidooni, Hossein and Jadliwala, Murtuza and Sadeghi, Ahmad-Reza},
  date = {2022-12-28},
  pages = {1747--1764},
  publisher = {IEEE Computer Society},
  doi = {10.1109/SP46215.2023.00100},
  url = {https://www.computer.org/csdl/proceedings-article/sp/2023/933600b747/1Js0Ej4gSME},
  urldate = {2023-01-09},
  abstract = {Federated learning (FL) is an emerging technology that allows participants to jointly train a machine learning model without sharing their private data with others. However, FL is vulnerable to poisoning attacks such as backdoor attacks. Consequently, a variety of defenses have recently been proposed, which have primarily utilized intermediary states of the global model (i.e., logits) or distance of the local models (i.e., L2\&\#x2212;norm) with respect to the global model to detect malicious backdoors in FL. However, as these approaches directly operate on client updates (or weights), their effectiveness depends on factors such as clients\&\#x2019; data distribution or the adversary\&\#x2019;s attack strategies. In this paper, we introduce a novel and more generic backdoor defense framework, called BayBFed, which proposes to utilize probability distributions over client updates to detect malicious updates in FL: BayBFed computes a probabilistic measure over the clients\&\#x2019; updates to keep track of any adjustments made in the updates, and uses a novel detection algorithm that can leverage this probabilistic measure to efficiently detect and filter out malicious updates. Thus, it overcomes the shortcomings of previous approaches that arise due to the direct usage of client updates; nevertheless, our probabilistic measure will include all aspects of the local client training strategies. BayBFed utilizes two Bayesian Non-Parametric (BNP) extensions: (i) a Hierarchical Beta-Bernoulli process to draw a probabilistic measure given the clients\&\#x2019; updates, and (ii) an adaptation of the Chinese Restaurant Process (CRP), referred by us as CRP-Jensen, which leverages this probabilistic measure to detect and filter out malicious updates. We extensively evaluate our defense approach on five benchmark datasets: CIFAR10, Reddit, IoT intrusion detection, MNIST, and FMNIST, and show that it can effectively detect and eliminate malicious updates in FL without deteriorating the benign performance of the global model.},
  eventtitle = {2023 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  isbn = {978-1-66549-336-9},
  langid = {english},
  keywords = {{$\warning$}ï¸ Invalid DOI}
}

@article{kundu_DetectionClassificationBotnet_2022,
  title = {Detection and {{Classification}} of {{Botnet Traffic}} Using {{Deep Learning}} with {{Model Explanation}}},
  author = {Kundu, Partha Pratim and Truong-Huu, Tram and Chen, Ling and Zhou, Luying and Teo, Sin G.},
  date = {2022},
  journaltitle = {IEEE Transactions on Dependable and Secure Computing},
  pages = {1--15},
  issn = {1941-0018},
  doi = {10.1109/TDSC.2022.3183361},
  abstract = {Distributed denial-of-service attacks are a kind of malicious attempts among many others that make target services unavailable to legitimate users by using a large number of bots, which send many service requests exceeding the processing capacity of the services. Detection of botnet traffic is therefore critical to maintaining the availability and quality of the services. In contrast, identifying the type of botnet attacks helps system administrators quickly determine which part of the computer and network system is under attack. Current works focus on rule-based detection, which sets rules in the network firewall to drop suspicious traffic that matches the rules. With the emergence of machine learning and deep learning (ML/DL), several preliminary works have been developed to learn botnet traffic behavior and perform detection. However, the performance of existing ML/DL models can be further improved and their decision/prediction are not transparent, making it hard for users to interpret and trust the results. In this work, we develop a novel deep learning model for botnet detection and classification combined with its ability of explaining the decision of the model. We first leverage latent representation of traffic features generated using convolutional neural networks to detect whether a traffic record is generated by a bot then determine the type of bots. We adopt an existing explainable framework to interpret the prediction of the developed deep learning model. We perform extensive experiments with real network traffic as well as synthetic traffic generated by IXIA BreakingPoint System. We compare the developed model with existing models on various performance metrics. The experimental results show that the developed model outperforms the existing machine learning models with an improvement of up to {$<$}inline-formula{$><$}tex-math notation="LaTeX"{$>\$$}15\%\${$<$}/tex-math{$><$}/inline-formula{$>$} for all performance metrics while providing a clear explanation of the model decision.},
  eventtitle = {{{IEEE Transactions}} on {{Dependable}} and {{Secure Computing}}},
  keywords = {Behavioral sciences,Botnet,Botnet Detection and Classification,Convolutional neural networks,Deep learning,Deep Learning,Explainable AI,Feature extraction,Monitoring,Network Security,Servers}
}

@online{kundu_RobustnessPersonalizationFederated_2022,
  title = {Robustness and {{Personalization}} in {{Federated Learning}}: {{A Unified Approach}} via {{Regularization}}},
  shorttitle = {Robustness and {{Personalization}} in {{Federated Learning}}},
  author = {Kundu, Achintya and Yu, Pengqian and Wynter, Laura and Lim, Shiau Hong},
  date = {2022-07-12},
  eprint = {2009.06303},
  eprinttype = {arXiv},
  eprintclass = {cs, math, stat},
  doi = {10.48550/arXiv.2009.06303},
  url = {http://arxiv.org/abs/2009.06303},
  urldate = {2023-05-16},
  abstract = {We present a class of methods for robust, personalized federated learning, called Fed+, that unifies many federated learning algorithms. The principal advantage of this class of methods is to better accommodate the real-world characteristics found in federated training, such as the lack of IID data across parties, the need for robustness to outliers or stragglers, and the requirement to perform well on party-specific datasets. We achieve this through a problem formulation that allows the central server to employ robust ways of aggregating the local models while keeping the structure of local computation intact. Without making any statistical assumption on the degree of heterogeneity of local data across parties, we provide convergence guarantees for Fed+ for convex and non-convex loss functions under different (robust) aggregation methods. The Fed+ theory is also equipped to handle heterogeneous computing environments including stragglers without additional assumptions; specifically, the convergence results cover the general setting where the number of local update steps across parties can vary. We demonstrate the benefits of Fed+ through extensive experiments across standard benchmark datasets.},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning}
}

@inproceedings{kundu_RobustnessPersonalizationFederated_2022a,
  title = {Robustness and {{Personalization}} in {{Federated Learning}}: {{A Unified Approach}} via {{Regularization}}},
  shorttitle = {Robustness and {{Personalization}} in {{Federated Learning}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Edge Computing}} and {{Communications}} ({{EDGE}})},
  author = {Kundu, Achintya and Yu, Pengqian and Wynter, Laura and Lim, Shiau Hong},
  date = {2022-07},
  pages = {1--11},
  issn = {2767-9918},
  doi = {10.1109/EDGE55608.2022.00014},
  url = {https://ieeexplore.ieee.org/document/9860349},
  urldate = {2024-07-01},
  abstract = {We present a class of methods for robust, personalized federated learning, called Fed+, that unifies many federated learning algorithms. The principal advantage of this class of methods is to better accommodate the real-world characteristics found in federated training, such as the lack of IID data across parties, the need for robustness to outliers or stragglers, and the requirement to perform well on party-specific datasets. We achieve this through a problem formulation that allows the central server to employ robust ways of aggregating the local models while keeping the structure of local computation intact. Without making any statistical assumption on the degree of heterogeneity of local data across parties, we provide convergence guarantees for Fed+ for convex and non-convex loss functions under different (robust) aggregation methods. The Fed+ theory is also equipped to handle heterogeneous computing environments including stragglers without additional assumptions; specifically, the convergence results cover the general setting where the number of local update steps across parties can vary. We demonstrate the benefits of Fed+ through extensive experiments across standard benchmark datasets.},
  eventtitle = {2022 {{IEEE International Conference}} on {{Edge Computing}} and {{Communications}} ({{EDGE}})},
  keywords = {Collaborative work,Computational modeling,Federated Learning,Heterogeneous networks,Neural networks,Personalization,Robustness,Servers,Training}
}

@incollection{kurniawan_SemanticQueryFederation_2018,
  title = {Semantic {{Query Federation}} for {{Scalable Security Log Analysis}}},
  booktitle = {The {{Semantic Web}}: {{ESWC}} 2018 {{Satellite Events}}},
  author = {Kurniawan, Kabul},
  editor = {Gangemi, Aldo and Gentile, Anna Lisa and Nuzzolese, Andrea Giovanni and Rudolph, Sebastian and Maleshkova, Maria and Paulheim, Heiko and Pan, Jeff Z and Alam, Mehwish},
  date = {2018},
  volume = {11155},
  pages = {294--303},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-98192-5_48},
  url = {http://link.springer.com/10.1007/978-3-319-98192-5_48},
  urldate = {2021-10-12},
  abstract = {The digitalization of business processes increasingly exposes organizations to sophisticated cyber-security threats. To contain attacks and minimize their impact, it is essential to detect them early. To this end, it is necessary to analyze a wide range of log files that potentially provide clues about malicious activity. However, these logs are typically voluminous, heterogeneous, difficult to interpret, and stored in disparate locations, which makes it difficult to analyze them. Current approaches to analyze security logs mainly focus on regular expressions and statistical indicators and do not directly provide actionable insight to security analysts. To address these limitations, we propose a distributed approach that enables semantic querying of dispersed log sources in large-scale infrastructures. To automatically integrate and reason about security log information, we will leverage linked data technologies and state-ofthe-art federated query processing systems. In this proposal, we discuss the research problem, methodology, approach and evaluation plan for scalable federated semantic security log analysis.},
  isbn = {978-3-319-98191-8 978-3-319-98192-5},
  langid = {english}
}

@article{kurt_OnlinePrivacyPreservingDataDriven_2022,
  title = {Online {{Privacy-Preserving Data-Driven Network Anomaly Detection}}},
  author = {Kurt, Mehmet Necip and Yilmaz, Yasin and Wang, Xiaodong and Mosterman, Pieter J.},
  date = {2022},
  journaltitle = {IEEE Journal on Selected Areas in Communications},
  shortjournal = {IEEE J. Select. Areas Commun.},
  pages = {1--1},
  issn = {0733-8716, 1558-0008},
  doi = {10/gpbg4r},
  url = {https://ieeexplore.ieee.org/document/9690092/},
  urldate = {2022-01-31},
  abstract = {We study online privacy-preserving anomaly detection in a setting in which the data are distributed over a network and locally sensitive to each node, and a probabilistic data model is unknown. We design and analyze a data-driven solution scheme where each node observes a high-dimensional data stream for which it computes a local outlierness score. This score is then perturbed, encrypted, and sent to a network operator. The network operator then decrypts an aggregate statistic over the network and performs online network anomaly detection via the proposed generalized cumulative sum (CUSUM) algorithm. We derive an asymptotic lower bound and an asymptotic approximation for the average false alarm period of the proposed algorithm. Additionally, we derive an asymptotic upper bound and asymptotic approximation for the average detection delay of the proposed algorithm under a certain anomaly. We show the analytical tradeoff between the anomaly detection performance and the differential privacy level, controlled via the local perturbation noise. Experiments illustrate that the proposed algorithm offers a good tradeoff between privacy and quick anomaly detection against the UDP flooding and spam attacks in a real Internet of Things (IoT) network.},
  langid = {english}
}

@inproceedings{kurtanovic_AutomaticallyClassifyingFunctional_2017,
  title = {Automatically {{Classifying Functional}} and {{Non-functional Requirements Using Supervised Machine Learning}}},
  booktitle = {2017 {{IEEE}} 25th {{International Requirements Engineering Conference}} ({{RE}})},
  author = {Kurtanovi\'c, Zijad and Maalej, Walid},
  date = {2017-09},
  pages = {490--495},
  issn = {2332-6441},
  doi = {10.1109/RE.2017.82},
  abstract = {In this paper, we take up the second RE17 data challenge: the identification of requirements types using the "Quality attributes (NFR)" dataset provided. We studied how accurately we can automatically classify requirements as functional (FR) and non-functional (NFR) in the dataset with supervised machine learning. Furthermore, we assessed how accurately we can identify various types of NFRs, in particular usability, security, operational, and performance requirements. We developed and evaluated a supervised machine learning approach employing meta-data, lexical, and syntactical features. We employed under-and over-sampling strategies to handle the imbalanced classes in the dataset and cross-validated the classifiers using precision, recall, and F1 metrics in a series of experiments based on the Support Vector Machine classifier algorithm. We achieve a precision and recall up to 92\% for automatically identifying FRs and NFRs. For the identification of specific NFRs, we achieve the highest precision and recall for security and performance NFRs with 92\% precision and 90\% recall. We discuss the most discriminating features of FRs and NFRs as well as the sampling strategies used with an additional dataset and their impact on the classification accuracy.},
  eventtitle = {2017 {{IEEE}} 25th {{International Requirements Engineering Conference}} ({{RE}})},
  keywords = {Classification,Feature extraction,Imbalanced Data,Machine Learning,Requirements,Security,Support vector machines,Training,Usability,Vegetation}
}

@inproceedings{kye_Partialfederatedlearning_2022,
  title = {Partial Federated Learning Based Network Intrusion System for Mobile Devices: Poster},
  shorttitle = {Partial Federated Learning Based Network Intrusion System for Mobile Devices},
  booktitle = {Proceedings of the {{Twenty-Third International Symposium}} on {{Theory}}, {{Algorithmic Foundations}}, and {{Protocol Design}} for {{Mobile Networks}} and {{Mobile Computing}}},
  author = {Kye, Hyoseon and Kwon, Minhae},
  date = {2022-10-03},
  series = {{{MobiHoc}} '22},
  pages = {283--284},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3492866.3561257},
  url = {https://dl.acm.org/doi/10.1145/3492866.3561257},
  urldate = {2024-04-12},
  abstract = {We propose a partial federated learning based network intrusion system to utilize the limited communication resources of mobile devices. The key to our algorithm is that we share only part of the model to enable efficient communication and strengthen data privacy. The proposed method is evaluated using two network traffic datasets and three performance measures. Our simulation results confirm that the model can reach the performance of centralized learning, although the ratio of a shared layer is reduced up to 25\%.},
  isbn = {978-1-4503-9165-8},
  keywords = {anomaly detection,autoencoder,federated learning,network intrusion system}
}

@article{lai_TwophaseDefensePoisoning_2023,
  title = {Two-Phase {{Defense Against Poisoning Attacks}} on {{Federated Learning-based Intrusion Detection}}},
  author = {Lai, Yuan-Cheng and Lin, Jheng-Yan and Lin, Ying-Dar and Hwang, Ren-Hung and Lin, Po-Chin and Wu, Hsiao-Kuang and Chen, Chung-Kuan},
  date = {2023-06-01},
  journaltitle = {Computers \& Security},
  shortjournal = {Computers \& Security},
  volume = {129},
  pages = {103205},
  issn = {0167-4048},
  doi = {10.1016/j.cose.2023.103205},
  url = {https://www.sciencedirect.com/science/article/pii/S0167404823001153},
  urldate = {2024-04-12},
  abstract = {The Machine Learning-based Intrusion Detection System (ML-IDS) becomes more popular because it doesn't need to manually update the rules and can recognize variants better, However, due to the data privacy issue in ML-IDS, the Federated Learning-based IDS (FL-IDS) was proposed. In each round of federated learning, each participant first trains its local model and sends the model's weights to the global server, which then aggregates the received weights and distributes the aggregated global model to participants. An attacker will use poisoning attacks, including label-flipping attacks and backdoor attacks, to directly generate a malicious local model and indirectly pollute the global model. Currently, a few studies defend against poisoning attacks, but they only discuss label-flipping attacks in the image field. Therefore, we propose a two-phase defense mechanism, called Defending Poisoning Attacks in Federated Learning (DPA-FL), applied to intrusion detection. The first phase employs relative differences to quickly compare weights between participants because the local models of attackers and benign participants are quite different. The second phase tests the aggregated model with the dataset and tries to find the attackers when its accuracy is low. Experiment results show that DPA-FL can reach 96.5\% accuracy in defending against poisoning attacks. Compared with other defense mechanisms, DPA-FL can improve F1-score by 20{$\sim$}64\% under backdoor attacks. Also, DPA-FL can exclude the attackers within twelve rounds when the attackers are few.},
  keywords = {Backdoor Attack,Federated Learning,Intrusion Detection,Local Outlier Factor,Poisoning Attack}
}

@inproceedings{lalitha_FullyDecentralizedFederated_2018,
  title = {Fully {{Decentralized Federated Learning}}},
  author = {Lalitha, Anusha},
  date = {2018},
  url = {https://www.semanticscholar.org/paper/Fully-Decentralized-Federated-Learning-Lalitha/2ecc7707aa49b7baa2f4bbc5d8491d0d464bdb9c},
  urldate = {2023-09-11},
  abstract = {We consider the problem of training a machine learning model over a network of users in a fully decentralized framework. The users take a Bayesian-like approach via the introduction of a belief over the model parameter space. We propose a distributed learning algorithm in which users update their belief by aggregate information from their one-hop neighbors to learn a model that best fits the observations over the entire network. In addition, we also obtain sufficient conditions to ensure that the probability of error is small for every user in the network. Finally, we discuss approximations required for applying this algorithm for training Neural Networks.},
  keywords = {â›” No DOI found}
}

@inproceedings{lalouani_RobustDistributedIntrusion_2021,
  title = {Robust {{Distributed Intrusion Detection System}} for {{Edge}} of {{Things}}},
  booktitle = {2021 {{IEEE Global Communications Conference}} ({{GLOBECOM}})},
  author = {Lalouani, Wassila and Younis, Mohamed},
  date = {2021-12},
  pages = {01--06},
  publisher = {IEEE},
  location = {Madrid, Spain},
  doi = {10.1109/GLOBECOM46510.2021.9685361},
  url = {https://ieeexplore.ieee.org/document/9685361/},
  urldate = {2022-02-15},
  abstract = {The edge computing paradigm has been adopted in many Internet-of-Things (IoT) applications to improve responsiveness and conserve communication resources. However, such high agility and efficiency come with increased cyber threats. Intrusion detection systems (IDS) have been the primary means for guarding networked computing assets against hacking attempts. The popular design methodology for IDS relies on the application of machine learning (ML) techniques that use intelligence data to classify malicious activities. However, in the realm of IoT, insufficient data is available to build IDS; hence a distributed intrusion system with continual data collection is primordial to refine the detection model. Such IDS is also subject to privacy constraints and should sustain robustness against data manipulation from internal attackers that degrade the ML model. This paper opts to fulfill these requirements by proposing a novel distributed IDS for IoT. The proposed system employs federated learning to enable privacy preservation and diminish the communication overhead. Our system promotes a reinforcement mechanism to ensure resiliency to data manipulation attacks by single or colluding internal actors. The validation results using recently released datasets demonstrate the effectiveness of our approach.},
  eventtitle = {{{GLOBECOM}} 2021 - 2021 {{IEEE Global Communications Conference}}},
  isbn = {978-1-72818-104-2},
  langid = {english}
}

@incollection{lamport_Byzantinegeneralsproblem_1982,
  title = {The {{Byzantine}} Generals Problem},
  booktitle = {Concurrency: The {{Works}} of {{Leslie Lamport}}},
  author = {Lamport, Leslie and Shostak, Robert and Pease, Marshall},
  date = {1982-07},
  pages = {203--226},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  url = {https://doi.org/10.1145/3335772.3335936},
  urldate = {2024-03-12},
  isbn = {978-1-4503-7270-1},
  keywords = {interactive consistency}
}

@article{langner_StuxnetDissectingCyberwarfare_2011,
  title = {Stuxnet: {{Dissecting}} a {{Cyberwarfare Weapon}}},
  author = {Langner, Ralph},
  date = {2011-05},
  journaltitle = {IEEE Security \& Privacy Magazine},
  volume = {9},
  number = {3},
  pages = {49--51},
  issn = {1540-7993},
  doi = {10.1109/MSP.2011.67},
  url = {http://ieeexplore.ieee.org/document/5772960/},
  abstract = {Ralph Langner, an expert in industrial control system security, explores the technical side of Stuxnet, dangerous malware that attacks SCADA systems. \copyright{} 2011 IEEE.}
}

@inproceedings{lanvin_ErrorsCICIDS2017dataset_2022,
  title = {Errors in the {{CICIDS2017}} Dataset and the Significant Differences in Detection Performances It Makes},
  booktitle = {{{CRiSIS}} 2022 - {{International Conference}} on {{Risks}} and {{Security}} of {{Internet}} and {{Systems}}},
  author = {Lanvin, Maxime and Gimenez, Pierre-Fran\c cois and Han, Yufei and Majorczyk, Fr\'ed\'eric and M\'e, Ludovic and Totel, Eric},
  date = {2022-12},
  pages = {1--16},
  location = {Sousse, Tunisia},
  url = {https://hal.archives-ouvertes.fr/hal-03775466},
  urldate = {2022-09-29},
  abstract = {Among the difficulties encountered in building datasets to evaluate intrusion detection tools, a tricky part is the process of labelling the events into malicious and benign classes. The labelling correctness is paramount for the quality of the evaluation of intrusion detection systems but is often considered as the ground truth by practitioners and is rarely verified. Another difficulty lies in the correct capture of the network packets. If it is not the case, the characteristics of the network flows generated from the capture could be modified and lead to false results. In this paper, we present several flaws we identified in the labelling of the CICIDS2017 dataset and in the traffic capture, such as packet misorder, packet duplication and attack that were performed but not correctly labelled. Finally, we assess the impact of these different corrections on the evaluation of supervised intrusion detection approaches.},
  keywords = {\_read\_urgently,dataset labelling,intrusion detection,machine learning}
}

@inproceedings{laurito_TopoGennetworktopology_2017,
  title = {{{TopoGen}}: {{A}} Network Topology Generation Architecture with Application to Automating Simulations of Software Defined Networks},
  shorttitle = {{{TopoGen}}},
  booktitle = {2017 {{Winter Simulation Conference}} ({{WSC}})},
  author = {Laurito, Andr\'es and Bonaventura, Mat\'ias and Pozo Astigarraga, Mikel Eukeni and Castro, Rodrigo},
  date = {2017-12},
  pages = {1049--1060},
  issn = {1558-4305},
  doi = {10.1109/WSC.2017.8247854},
  url = {https://ieeexplore.ieee.org/abstract/document/8247854},
  urldate = {2024-07-07},
  abstract = {Simulation is an important tool to validate the performance impact of control decisions in Software Defined Networks (SDN). Yet, the manual modeling of complex topologies that may change often during a design process can be a tedious error-prone task. We present TopoGen, a general purpose architecture and tool for systematic translation and generation of network topologies. TopoGen can be used to generate network simulation models automatically by querying information available at diverse sources, notably SDN controllers. The DEVS modeling and simulation framework facilitates a systematic translation of structured knowledge about a network topology into a formal modular and hierarchical coupling of preexisting or new models of network entities (physical or logical). TopoGen can be flexibly extended with new parsers and generators to grow its scope of applicability. This allows to design arbitrary workflows of topology transformations. We tested TopoGen in a network engineering project for the ATLAS detector at CERN.},
  eventtitle = {2017 {{Winter Simulation Conference}} ({{WSC}})},
  keywords = {Computational modeling,Computer architecture,Network topology,Object oriented modeling,Software,Tools,Topology}
}

@inproceedings{lautert_fogarchitectureprivacypreserving_2020,
  title = {A Fog Architecture for Privacy-Preserving Data Provenance Using Blockchains},
  booktitle = {2020 {{IEEE Symposium}} on {{Computers}} and {{Communications}} ({{ISCC}})},
  author = {Lautert, Filipe and Pigatto, Daniel F. and Gomes, Luiz},
  date = {2020-07},
  volume = {2020-July},
  pages = {1--6},
  publisher = {IEEE},
  issn = {15301346},
  doi = {10.1109/ISCC50000.2020.9219724},
  url = {https://ieeexplore.ieee.org/document/9219724/},
  abstract = {Data provenance tracks the origin of information with the goal of improving trust among interested parties. Data provenance is an important requirement for a range of applications such as food safety, supply chains, and tracking of epidemic outbreaks. Many of these applications are inherently distributed and require high levels of privacy and trust.Fog computing and Blockchains are recent technological solutions that were born from advancements in cloud and distributed computing. Fog focuses on bringing the cloud closer to the edge user while Blockchain provides transparency without the need for a trusted centralized entity. Both can be complimentary as Fog spreads the data and computer storage while the Blockchain can keep it consistent and trustworthy. These technologies can be used to improve several aspects in a Data provenance context.In this paper we describe an architecture that allows the tracking of data provenance in a wide-area distributed fog. While we employ blockchains to provide transparency, localized Fogs have control over what is made public on the cloud. The architecture proposed in this paper enables fast and reliable data provenance for clients executing in the Fog using software services that keep the information consistent across all interested parties in the cloud. Any information in the system is associated with a proof of authenticity, but authors have control over the eventual publication of the information.Our proposal was built upon the well established provenance model W3C Prov, which simplifies adoption of the framework.We developed an application consisting of a client and web services that is able to store and share provenance information using open standards in a blockchain. The relate work, architecture and tests for the proposal are presented showing performance improvements when Fog is used when compared to a solution that only runs in the cloud.},
  isbn = {978-1-72818-086-1}
}

@article{lavaur_EvolutionFederatedLearningbased_2022,
  title = {The {{Evolution}} of {{Federated Learning-based Intrusion Detection}} and {{Mitigation}}: A {{Survey}}},
  author = {Lavaur, Leo and Pahl, Marc-Oliver and Busnel, Yann and Autrel, Fabien},
  date = {2022-06},
  journaltitle = {IEEE Transactions on Network and Service Management},
  shortjournal = {TNSM},
  series = {Special {{Issue}} on {{Network Security Management}}},
  abstract = {In 2016, Google introduced the concept of Federated Learning (FL), enabling collaborative Machine Learning (ML). FL does not share local data but ML models, offering applications in diverse domains. This paper focuses on the application of FL to Intrusion Detection Systems (IDSs). There, common criteria to compare existing solutions are missing. In particular, this survey shows: (i) how FL-based IDSs are used in different domains; (ii) what differences exist between architectures; (iii) the state of the art of FL-based IDS. With a structured literature survey, this work identifies the relevant state of the art in FL--based intrusion detection from its creation in 2016 until 2021. It provides a reference architecture and a taxonomy to serve as guidelines to compare and design FL- based IDSs. Both are validated with the existing works. Finally, it identifies research directions for the application of FL to intrusion detection systems.},
  keywords = {+survey}
}

@inproceedings{lavaur_Federatedlearningenabler_2022,
  title = {Federated Learning as Enabler for Collaborative Security between Not Fully-Trusting Distributed Parties},
  booktitle = {Proceedings of the 29th Computer \& Electronics Security Application Rendezvous ({{C}}\&{{ESAR}}): {{Ensuring}} Trust in a Decentralized World},
  author = {Lavaur, Leo and Coste, Benjamin and Pahl, Marc-Oliver and Busnel, Yann and Autrel, Fabien},
  date = {2022},
  pages = {65--80},
  url = {http://ceur-ws.org/Vol-3329/paper-04.pdf},
  crossref = {CESAR2022},
  keywords = {â›” No DOI found}
}

@inproceedings{lavaur_Federatedsecurityapproaches_2021,
  title = {Federated Security Approaches for {{IT}} and {{OT}}},
  author = {Lavaur, Leo and Pahl, Marc-Oliver and Busnel, Yann and Autrel, Fabien},
  date = {2021},
  pages = {2},
  abstract = {The Internet of Things has begun to spread over a variety of domains, including industry and finance. It represents an increasing threat for both IT and OT. The lack of collaboration results in the same attacks targeting different organizations one after the other. Often employed as an answer to this problem, cyber threat-intelligence sharing induces its own set of challenges: trust, privacy, and traceability.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@article{lavaur_MetricsStrategiesAdversarial_,
  title = {Metrics and {{Strategies}} for {{Adversarial Mitigation}} in {{Federated Learning-based Intrusion Detection}}},
  author = {Lavaur, L\'eo and Busnel, Yann and Lechevalier, Pierre-Marie and Pahl, Marc-Oliver and Autrel, Fabien},
  abstract = {Since its introduction in 2016, federated learning (FL) has been used in multiple domains, such as intrusion detection. However, FL literature shows that the heterogeneity of most realworld FL applications makes it difficult for clients to converge in a suitable global model. Furthermore, as a collaborative system, FL is vulnerable to attacks, such as model poisoning. While strategies have been identified in the literature, they often rely on the assumption that the data distribution among participants is homogeneous. In this paper, we review the current challenges in clustering and adversarial mitigation in heterogeneous FL, and propose different strategies to address them. Namely, we present a cross-evaluation framework for exhaustive gathering, and a set of algorithmic countermeasures based on principal component analysis. We show preliminary results of our clustering mechanism, which validates the effectiveness of the cross-evaluation framework.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@online{layeghy_GeneralisabilityMachineLearningbased_2022,
  title = {On {{Generalisability}} of {{Machine Learning-based Network Intrusion Detection Systems}}},
  author = {Layeghy, Siamak and Portmann, Marius},
  date = {2022-05-09},
  eprint = {2205.04112},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2205.04112},
  urldate = {2023-03-23},
  abstract = {Many of the proposed machine learning (ML) based network intrusion detection systems (NIDSs) achieve near perfect detection performance when evaluated on synthetic benchmark datasets. Though, there is no record of if and how these results generalise to other network scenarios, in particular to real-world networks. In this paper, we investigate the generalisability property of ML-based NIDSs by extensively evaluating seven supervised and unsupervised learning models on four recently published benchmark NIDS datasets. Our investigation indicates that none of the considered models is able to generalise over all studied datasets. Interestingly, our results also indicate that the generalisability has a high degree of asymmetry, i.e., swapping the source and target domains can significantly change the classification performance. Our investigation also indicates that overall, unsupervised learning methods generalise better than supervised learning models in our considered scenarios. Using SHAP values to explain these results indicates that the lack of generalisability is mainly due to the presence of strong correspondence between the values of one or more features and Attack/Benign classes in one datasetmodel combination and its absence in other datasets that have different feature distributions.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Computer Science - Networking and Internet Architecture}
}

@article{lazzarini_FederatedLearningIoT_2023,
  title = {Federated {{Learning}} for {{IoT Intrusion Detection}}},
  author = {Lazzarini, Riccardo and Tianfield, Huaglory and Charissis, Vassilis},
  date = {2023-09},
  journaltitle = {AI},
  volume = {4},
  number = {3},
  pages = {509--530},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2673-2688},
  doi = {10.3390/ai4030028},
  url = {https://www.mdpi.com/2673-2688/4/3/28},
  urldate = {2024-04-12},
  abstract = {The number of Internet of Things (IoT) devices has increased considerably in the past few years, resulting in a large growth of cyber attacks on IoT infrastructure. As part of a defense in depth approach to cybersecurity, intrusion detection systems (IDSs) have acquired a key role in attempting to detect malicious activities efficiently. Most modern approaches to IDS in IoT are based on machine learning (ML) techniques. The majority of these are centralized, which implies the sharing of data from source devices to a central server for classification. This presents potentially crucial issues related to privacy of user data as well as challenges in data transfers due to their volumes. In this article, we evaluate the use of federated learning (FL) as a method to implement intrusion detection in IoT environments. FL is an alternative, distributed method to centralized ML models, which has seen a surge of interest in IoT intrusion detection recently. In our implementation, we evaluate FL using a shallow artificial neural network (ANN) as the shared model and federated averaging (FedAvg) as the aggregation algorithm. The experiments are completed on the ToN\_IoT and CICIDS2017 datasets in binary and multiclass classification. Classification is performed by the distributed devices using their own data. No sharing of data occurs among participants, maintaining data privacy. When compared against a centralized approach, results have shown that a collaborative FL IDS can be an efficient alternative, in terms of accuracy, precision, recall and F1-score, making it a viable option as an IoT IDS. Additionally, with these results as baseline, we have evaluated alternative aggregation algorithms, namely FedAvgM, FedAdam and FedAdagrad, in the same setting by using the Flower FL framework. The results from the evaluation show that, in our scenario, FedAvg and FedAvgM tend to perform better compared to the two adaptive algorithms, FedAdam and FedAdagrad.},
  issue = {3},
  langid = {english},
  keywords = {deep learning,federated learning,Internet of Things,intrusion detection systems}
}

@article{le_XGBoostImbalancedMulticlass_2022,
  title = {{{XGBoost}} for {{Imbalanced Multiclass Classification-Based Industrial Internet}} of {{Things Intrusion Detection Systems}}},
  author = {Le, Thi-Thu-Huong and Oktian, Yustus Eko and Kim, Howon},
  date = {2022-07-16},
  journaltitle = {Sustainability},
  shortjournal = {Sustainability},
  volume = {14},
  number = {14},
  pages = {8707},
  issn = {2071-1050},
  doi = {10.3390/su14148707},
  url = {https://www.mdpi.com/2071-1050/14/14/8707},
  urldate = {2022-08-11},
  abstract = {The Industrial Internet of Things (IIoT) has advanced digital technology and the fastest interconnection, which creates opportunities to substantially grow industrial businesses today. Although IIoT provides promising opportunities for growth, the massive sensor IoT data collected are easily attacked by cyber criminals. Hence, IIoT requires different high security levels to protect the network. An Intrusion Detection System (IDS) is one of the crucial security solutions, which aims to detect the network's abnormal behavior and monitor safe network traffic to avoid attacks. In particular, the effectiveness of the Machine Learning (ML)-based IDS approach to building a secure IDS application is attracting the security research community in both the general cyber network and the specific IIoT network. However, most available IIoT datasets contain multiclass output data with imbalanced distributions. This is the main reason for the reduction in the detection accuracy of attacks of the ML-based IDS model. This research proposes an IDS for IIoT imbalanced datasets by applying the eXtremely Gradient Boosting (XGBoost) model to overcome this issue. Two modern IIoT imbalanced datasets were used to assess our proposed method's effectiveness and robustness, X-IIoTDS and TON\_IoT. The XGBoost model achieved excellent attack detection with F1 scores of 99.9\% and 99.87\% on the two datasets. This result demonstrated that the proposed approach improved the detection attack performance in imbalanced multiclass IIoT datasets and was superior to existing IDS frameworks.},
  langid = {english}
}

@article{lecun_Gradientbasedlearningapplied_1998,
  title = {Gradient-Based Learning Applied to Document Recognition},
  author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  date = {1998-11},
  journaltitle = {Proceedings of the IEEE},
  volume = {86},
  number = {11},
  pages = {2278--2324},
  issn = {1558-2256},
  doi = {10.1109/5.726791},
  url = {https://ieeexplore.ieee.org/document/726791},
  urldate = {2023-11-09},
  abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
  eventtitle = {Proceedings of the {{IEEE}}}
}

@article{lefoane_UnsupervisedLearningFeature_2022,
  title = {Unsupervised {{Learning}} for {{Feature Selection}}: {{A}} Proposed {{Solution}} for {{Botnet Detection}} in {{5G Networks}}},
  shorttitle = {Unsupervised {{Learning}} for {{Feature Selection}}},
  author = {Lefoane, Moemedi and Ghafir, Ibrahim and Kabir, Sohag and Awan, Irfan-Ullah},
  date = {2022},
  journaltitle = {IEEE Transactions on Industrial Informatics},
  pages = {1--9},
  issn = {1941-0050},
  doi = {10.1109/TII.2022.3192044},
  abstract = {The world has seen exponential growth in deploying Internet of Things (IoT) devices. In recent years, connected IoT devices have surpassed the number of connected non-IoT devices. The number of IoT devices continues to grow and they are becoming a critical component of the national infrastructure. IoT devices' characteristics and inherent limitations make them attractive targets for hackers and cyber criminals. Botnet attack is one of the serious threats on the Internet today. This article proposes pattern-based feature selection methods as part of a machine learning (ML) based botnet detection system. Specifically, two methods are proposed: the first is based on the most dominant pattern feature values and the second is based on Maximal Frequent Itemset (MFI) mining. The proposed feature selection method uses Gini Impurity (GI) and an unsupervised clustering method to select the most influential features automatically. The evaluation results show that the proposed methods have improved the performance of the detection system. The developed system has a True Positive Rate (TPR) of 100\% and a False Positive Rate (FPR) of 0\% for best performing models. In addition, the proposed methods reduce the computational cost of the system as evidenced by the detection speed of the system.},
  eventtitle = {{{IEEE Transactions}} on {{Industrial Informatics}}},
  keywords = {5G mobile communication,Botnet,Botnet attack,Feature extraction,feature selection,Informatics,Internet of Things,intrusion detection system,machine learning,network security,Security,Telecommunication traffic}
}

@incollection{leichtnam_Sec2graphNetworkAttack_2020,
  title = {Sec2graph: {{Network Attack Detection Based}} on {{Novelty Detection}} on {{Graph Structured Data}}},
  shorttitle = {Sec2graph},
  booktitle = {Detection of {{Intrusions}} and {{Malware}}, and {{Vulnerability Assessment}}},
  author = {Leichtnam, Laetitia and Totel, Eric and Prigent, Nicolas and M\'e, Ludovic},
  editor = {Maurice, Cl\'ementine and Bilge, Leyla and Stringhini, Gianluca and Neves, Nuno},
  date = {2020},
  volume = {12223},
  pages = {238--258},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-52683-2_12},
  url = {http://link.springer.com/10.1007/978-3-030-52683-2_12},
  urldate = {2022-06-10},
  abstract = {Being able to timely detect new kinds of attacks in highly distributed, heterogeneous and evolving networks without generating too many false alarms is especially challenging. Many researchers proposed various anomaly detection techniques to identify events that are inconsistent with past observations. While supervised learning is often used to that end, security experts generally do not have labeled datasets and labeling their data would be excessively expensive. Unsupervised learning, that does not require labeled data should then be used preferably, even if these approaches have led to less relevant results. We introduce in this paper a unified and unique graph representation called security objects' graphs. This representation mixes and links events of different kinds and allows a rich description of the activities to be analyzed. To detect anomalies in these graphs, we propose an unsupervised learning approach based on auto-encoder. Our hypothesis is that as security objects' graphs bring a rich vision of the normal situation, an auto-encoder is able to build a relevant model of this situation. To validate this hypothesis, we apply our approach to the CICIDS2017 dataset and show that although our approach is unsupervised, its detection results are as good, and even better than those obtained by many supervised approaches.},
  isbn = {978-3-030-52682-5 978-3-030-52683-2},
  langid = {english},
  keywords = {\_read\_urgently}
}

@inproceedings{leo_federatedarchitectureapproach_2014,
  title = {A Federated Architecture Approach for {{Internet}} of {{Things}} Security},
  booktitle = {2014 {{Euro Med Telco Conference}} ({{EMTC}})},
  author = {Leo, Marco and Battisti, Federica and Carli, Marco and Neri, Alessandro},
  date = {2014-11},
  pages = {1--5},
  publisher = {IEEE},
  doi = {10.1109/EMTC.2014.6996632},
  url = {http://ieeexplore.ieee.org/document/6996632/},
  abstract = {Internet of Things (IoT) refers to the capability to connect, communicate and remotely manage a large number of networked, automated devices via the Internet. IoT is becoming as part of daily life and aims to extend pervasive communication and networking anytime, anywhere with any device. In this context security requirements and architectures must be properly formulated, implemented in order to enforce the security policies during their life-cycle. This paper provides a survey and analysis of security in the area of IoT introducing an approach addressed to overcome the conventional security solutions and deploy a federated architecture for dynamic prevention, detection, diagnosis, isolation, and countermeasures against cyber attacks. Based on the analysis of the most common web services, the paper defines the security needs proposing a federated model to design an architecture for secure exchange of services in IoT paradigm.},
  isbn = {978-88-87237-20-7}
}

@article{li_BlockchainBasedDecentralizedFederated_2021,
  title = {A {{Blockchain-Based Decentralized Federated Learning Framework}} with {{Committee Consensus}}},
  author = {Li, Yuzheng and Chen, Chuan and Liu, Nan and Huang, Huawei and Zheng, Zibin and Yan, Qiang},
  date = {2021-01},
  journaltitle = {IEEE Network},
  shortjournal = {IEEE Network},
  volume = {35},
  number = {1},
  pages = {234--241},
  issn = {0890-8044, 1558-156X},
  doi = {10.1109/MNET.011.2000263},
  url = {https://ieeexplore.ieee.org/document/9293091/},
  urldate = {2023-09-11},
  abstract = {Federated learning has been widely studied and applied to various scenarios, such as financial credit, medical identification, and so on. Under these settings, federated learning protects users from exposing their private data, while cooperatively training a shared machine learning algorithm model (i.e., the global model) for a variety of realworld applications. The only data exchanged is the gradient of the model or the updated model (i.e., the local model update). However, the security of federated learning is increasingly being questioned, due to the malicious clients or central servers' constant attack on the global model or user privacy data. To address these security issues, we propose a decentralized federated learning framework based on blockchain, that is, a Block-chain-based Federated Learning framework with Committee consensus (BFLC). Without a centralized server, the framework uses blockchain for the global model storage and the local model update exchange. To enable the proposed BFLC, we also devise an innovative committee consensus mechanism, which can effectively reduce the amount of consensus computing and reduce malicious attacks. We then discuss the scalability of BFLC, including theoretical security, storage optimization, and incentives. Finally, based on a FISCO blockchain system, we perform experiments using an AlexNet model on several frameworks with a real-world dataset FEMNIST. The experimental results demonstrate the effectiveness and security of the BFLC framework.}
}

@article{li_BlockchainEmpoweredFederated_2022,
  title = {Blockchain {{Empowered Federated Learning}} for {{Distributed Network Security Behaviour Knowledge Base}} in {{6G}}},
  author = {Li, Kun and Zhou, Huachun and Tu, Zhe and Liu, Feiyang and Zhang, Hongke},
  date = {2022-04-21},
  journaltitle = {Security and Communication Networks},
  volume = {2022},
  pages = {e4233238},
  publisher = {Hindawi},
  issn = {1939-0114},
  doi = {10.1155/2022/4233238},
  url = {https://www.hindawi.com/journals/scn/2022/4233238/},
  urldate = {2024-04-12},
  abstract = {The malicious flow originating from massive access devices in 6G network will increase sharply. In order to effectively reduce malicious flow, we hope to establish a new framework for coordination of security monitoring and malicious behaviour control in 6G network. Federated learning provides data and privacy protection for the distributed network security behaviour knowledge base. However, since the equipment of its participants needs to upload the original data to the central server for model training, this may lead to data leakage in the knowledge base. Therefore, in this article, we first use the knowledge graph to describe network security behaviours, then build a universal network security malicious behaviour knowledge base, and discuss its application scenarios. Then, we propose a blockchain empowered federated learning (BeFL) for distributed network security malicious behaviour knowledge base architecture to ensure the security of knowledge transmission. Finally, we deployed the designed distributed knowledge base in the prototype system and compared it with the other two baseline methods to verify the performance. Relevant results show that our method outperforms other methods in terms of user identification, flow detection, and attack source tracing.},
  langid = {english}
}

@article{li_DeepFedFederatedDeep_2020,
  title = {{{DeepFed}}: {{Federated Deep Learning}} for {{Intrusion Detection}} in {{Industrial Cyber-Physical Systems}}},
  author = {Li, Beibei and Wu, Yuhao and Song, Jiarui and Lu, Rongxing and Li, Tao and Zhao, Liang},
  date = {2020},
  journaltitle = {IEEE Transactions on Industrial Informatics},
  volume = {3203},
  number = {c},
  pages = {1--1},
  issn = {1551-3203},
  doi = {10.1109/TII.2020.3023430},
  url = {https://ieeexplore.ieee.org/document/9195012/},
  abstract = {The rapid convergence of legacy industrial infrastructures with intelligent networking and computing technologies (e.g., 5G, software defined networking, and artificial intelligence), have dramatically increased the attack surface of industrial cyber-physical systems (CPSs). However, withstanding cyber threats to such large-scale, complex, and heterogeneous industrial CPSs has been extremely challenging, due to the insufficiency of high-quality attack examples. In this paper, we propose a novel federated deep learning scheme, named DeepFed, to detect cyber threats against softwarized industrial CPSs. Specifically, we first design a new deep learning based intrusion detection model for industrial CPSs, by making use of a convolutional neur},
  isbn = {2013018112007},
  keywords = {survey-fids}
}

@online{li_DifferentiallyPrivateVertical_2022,
  title = {Differentially {{Private Vertical Federated Clustering}}},
  author = {Li, Zitao and Wang, Tianhao and Li, Ninghui},
  date = {2022-08-02},
  eprint = {2208.01700},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2208.01700},
  urldate = {2022-08-16},
  abstract = {In many applications, multiple parties have private data regarding the same set of users but on disjoint sets of attributes, and a server wants to leverage the data to train a model. To enable model learning while protecting the privacy of the data subjects, we need vertical federated learning (VFL) techniques, where the data parties share only information for training the model, instead of the private data. However, it is challenging to ensure that the shared information maintains privacy while learning accurate models. To the best of our knowledge, the algorithm proposed in this paper is the first practical solution for differentially private vertical federated {$k$}-means clustering, where the server can obtain a set of global centers with a provable differential privacy guarantee. Our algorithm assumes an untrusted central server that aggregates differentially private local centers and membership encodings from local data parties. It builds a weighted grid as the synopsis of the global dataset based on the received information. Final centers are generated by running any {$k$}-means algorithm on the weighted grid. Our approach for grid weight estimation uses a novel, light-weight, and differentially private set intersection cardinality estimation algorithm based on the Flajolet-Martin sketch. To improve the estimation accuracy in the setting with more than two data parties, we further propose a refined version of the weights estimation algorithm and a parameter tuning strategy to reduce the final {$k$}-means utility to be close to that in the central private setting. We provide theoretical utility analysis and experimental evaluation results for the cluster centers computed by our algorithm and show that our approach performs better both theoretically and empirically than the two baselines based on existing techniques.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@article{li_DistributedNetworkIntrusion_2020,
  title = {Distributed {{Network Intrusion Detection System}} in {{Satellite-Terrestrial Integrated Networks Using Federated Learning}}},
  author = {Li, Kun and Zhou, Huachun and Tu, Zhe and Wang, Weilin and Zhang, Hongke},
  date = {2020},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {8},
  pages = {214852--214865},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3041641},
  url = {https://ieeexplore.ieee.org/document/9274426/},
  urldate = {2021-10-25},
  abstract = {The existing satellite-terrestrial integrated networks (STINs) suffer from security and privacy concerns due to the limited resources, poor attack resistance and high privacy requirements of satellite networks. Network Intrusion Detection System (NIDS) is intended to provide a high level of protection for modern network environments, but how to implement distributed NIDS on STINs has not been widely discussed. At the same time, satellite networks have always lacked real and effective security data sets as references. To solve these problems, we propose a distributed NIDS using Federal Learning (FL) in STIN to properly allocate resources in each domain to analyze and block malicious traffic, especially distributed denial-of-service (DDoS) attacks. Specifically, we first design a typical STIN topology, on the basis of which we collect and design security data sets adapted to satellite and terrestrial networks in STIN, respectively. To address the problem of poor attack resistance of satellite networks, we propose a satellite network topology optimization algorithm to reduce the difficulty in tracing malicious packets due to frequent link switching. In order to solve the problem of limited resources and high privacy requirements of satellite networks, we propose an algorithm for FL adaptation to STIN, and build a distributed NIDS using FL in STIN. Finally, we deploy the designed distributed NIDS in a prototype system and evaluate our proposed distributed NIDS with a large number of simulations of randomly generated malicious traffic. Related results demonstrate that the performance of our approach is better than traditional deep learning and intrusion detection methods in terms of malicious traffic recognition rate, packet loss rate, and CPU utilization.},
  langid = {english},
  keywords = {survey-fids}
}

@article{li_EfficientFederatedLearning_2023a,
  title = {An {{Efficient Federated Learning System}} for {{Network Intrusion Detection}}},
  author = {Li, Jianbin and Tong, Xin and Liu, Jinwei and Cheng, Long},
  date = {2023-06},
  journaltitle = {IEEE Systems Journal},
  volume = {17},
  number = {2},
  pages = {2455--2464},
  issn = {1937-9234},
  doi = {10.1109/JSYST.2023.3236995},
  url = {https://ieeexplore.ieee.org/abstract/document/10032055},
  urldate = {2024-04-12},
  abstract = {Network intrusion detection is used to detect unauthorized activities on a digital network, with which the cybersecurity teams of organizations can then kick-start prevention protocols to protect the security of their networks and data. In real-life scenarios, due to the lack of high-quality attack instance data, building an in-depth network intrusion detection system (NIDS) is always challenging for a single enterprise, in terms of handling complex network security threats. To remedy the problem, this article proposes an efficient intrusion detection system called dynamic weighted aggregation federated learning (DAFL) based on federated learning. Specifically, DAFL has used the full advantages of federated learning for data privacy preservation. Moreover, compared to a conventional federated-learning based intrusion detection system, our scheme has implemented dynamic filtering and weighting strategies for local models. In this way, DAFL can perform better in detecting network intrusions with less communication overhead. We give the detailed designs of DAFL, and our experimental results demonstrate that DAFL can achieve excellent detection performance with a low network communication overhead, with data privacy preserved.},
  eventtitle = {{{IEEE Systems Journal}}},
  keywords = {Computational modeling,Data models,Data privacy,deep learning,dynamic weighted aggregation,federated learning,Federated learning,network intrusion detection,Network intrusion detection,Servers,Training}
}

@thesis{li_EnhancingFederatedLearning_,
  title = {Enhancing {{Federated Learning Robustness}} and {{Fairness}} in {{Non-IID Scenarios}}},
  author = {Li, Yanli},
  langid = {english}
}

@inproceedings{li_EPPSEfficientPrivacyPreserving_2019,
  title = {{{EPPS}}: {{Efficient Privacy-Preserving Scheme}} in {{Distributed Deep Learning}}},
  shorttitle = {{{EPPS}}},
  booktitle = {2019 {{IEEE Global Communications Conference}} ({{GLOBECOM}})},
  author = {Li, Yiran and Li, Hongwei and Xu, Guowen and Liu, Sen and Lu, Rongxing},
  date = {2019-12},
  pages = {1--6},
  publisher = {IEEE},
  location = {Waikoloa, HI, USA},
  doi = {10.1109/GLOBECOM38437.2019.9013395},
  url = {https://ieeexplore.ieee.org/document/9013395/},
  urldate = {2021-05-18},
  abstract = {As a promising training model with Neural Network, distributed deep learning has been widely applied in various scenarios, where clients and the cloud server work together only by sharing local gradients and global parameters. However, research has shown that the adversary can still reconstruct the users' private information even if little information is leaked. To address this problem, several approaches of privacy-preserving distributed training have been exploited with existing mature technologies, such as Differential Privacy, Secure Multi-party Computation and Homomorphic Encryption. However, stateof-the-art results are still defective in security, functionality and efficiency. In this paper, we propose an Efficient PrivacyPreserving Scheme (EPPS) for distributed deep learning. We claim that our solution achieves the best performance tradeoff between security, efficiency and functionality. Specifically, we adopt the threshold Paillier encryption as the underlying structure to construct our secure training model. Hence, the confidentiality of honest users' of local gradients can be guaranteed, even the cloud server colluding with multiple users. In addition, since users are often accidentally offline due to either network environment or equipment damage, our EPPS can also support users exiting at any phases of the entire work process. Further more, we conducted extensive experiments on real-world data to demonstrate the preferable performance of our proposed scheme. Index Terms---Privacy-Preserving, Distributed Deep Learning, Multiple Keys.},
  eventtitle = {{{GLOBECOM}} 2019 - 2019 {{IEEE Global Communications Conference}}},
  isbn = {978-1-72810-962-6},
  langid = {english}
}

@article{li_FederatedAnomalyDetection_2022,
  title = {Federated {{Anomaly Detection}} on {{System Logs}} for the {{Internet}} of {{Things}}: {{A Customizable}} and {{Communication-Efficient Approach}}},
  shorttitle = {Federated {{Anomaly Detection}} on {{System Logs}} for the {{Internet}} of {{Things}}},
  author = {Li, Beibei and Ma, Shang and Deng, Ruilong and Choo, Kim-Kwang Raymond and Yang, Jin},
  date = {2022},
  journaltitle = {IEEE Transactions on Network and Service Management},
  shortjournal = {IEEE Trans. Netw. Serv. Manage.},
  pages = {1--1},
  issn = {1932-4537, 2373-7379},
  doi = {10.1109/TNSM.2022.3152620},
  url = {https://ieeexplore.ieee.org/document/9716881/},
  urldate = {2022-02-25},
  abstract = {Runtime log-based anomaly detection is one of several key building blocks in ensuring system security, as well as post-incident forensic investigations. However, existing logbased anomaly detection approaches that are implemented on large-scale Internet of Things (IoT) systems generally upload the local data from the edge devices to a centralized (cloud) server for processing and analysis. Such a workflow incurs significant communication and computation overheads, with potential privacy implications. Hence, in this paper, we propose a customizable and communication-efficient federated anomaly detection scheme (hereafter referred to as FedLog), designed to facilitate the identification of abnormal log patterns in large-scale IoT systems. Specifically, we first craft a Temporal Convolutional Network-Attention Mechanism-based Convolutional Neural Network (TCN-ACNN) model, to effectively extract fine-grained features from system logs. Second, we develop a new federated learning framework to support IoT devices in establishing a comprehensive anomaly detection model in a collaborative and privacy-preserving manner. Third, a lottery ticket hypothesis based masking strategy is designed to achieve customizable and communication-efficient federated learning in handling nonIndependent and Identically Distributed (non-IID) log datasets. We then evaluate the performance of our proposed scheme with those of DeepLog (published in CCS, 2017) and Loganomaly (published in IJCAI, 2019) in both centralized learning and federated learning settings, using two publicly available and widely used real-world datasets (i.e., HDFS and BGL). The findings demonstrate the utility of the proposed FedLog scheme, in terms of log-based anomaly detection.},
  langid = {english}
}

@online{li_FederatedLearningNonIID_2021,
  title = {Federated {{Learning}} on {{Non-IID Data Silos}}: {{An Experimental Study}}},
  shorttitle = {Federated {{Learning}} on {{Non-IID Data Silos}}},
  author = {Li, Qinbin and Diao, Yiqun and Chen, Quan and He, Bingsheng},
  date = {2021-10-28},
  eprint = {2102.02079},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2102.02079},
  urldate = {2023-09-12},
  abstract = {Due to the increasing privacy concerns and data regulations, training data have been increasingly fragmented, forming distributed databases of multiple ``data silos'' (e.g., within different organizations and countries). To develop effective machine learning services, there is a must to exploit data from such distributed databases without exchanging the raw data. Recently, federated learning (FL) has been a solution with growing interests, which enables multiple parties to collaboratively train a machine learning model without exchanging their local data. A key and common challenge on distributed databases is the heterogeneity of the data distribution among the parties. The data of different parties are usually non-independently and identically distributed (i.e., non-IID). There have been many FL algorithms to address the learning effectiveness under non-IID data settings. However, there lacks an experimental study on systematically understanding their advantages and disadvantages, as previous studies have very rigid data partitioning strategies among parties, which are hardly representative and thorough. In this paper, to help researchers better understand and study the non-IID data setting in federated learning, we propose comprehensive data partitioning strategies to cover the typical non-IID data cases. Moreover, we conduct extensive experiments to evaluate state-ofthe-art FL algorithms. We find that non-IID does bring significant challenges in learning accuracy of FL algorithms, and none of the existing state-of-the-art FL algorithms outperforms others in all cases. Our experiments provide insights for future studies of addressing the challenges in ``data silos''.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Machine Learning}
}

@article{li_Federatedlearningworkloadaware_2022,
  title = {Federated Learning with Workload-Aware Client Scheduling in Heterogeneous Systems},
  author = {Li, Li and Liu, Duo and Duan, Moming and Zhang, Yu and Ren, Ao and Chen, Xianzhang and Tan, Yujuan and Wang, Chengliang},
  date = {2022-08-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2022.07.030},
  url = {https://www.sciencedirect.com/science/article/pii/S0893608022002957},
  urldate = {2022-08-16},
  abstract = {Federated Learning (FL) is a novel distributed machine learning, which allows thousands of edge devices to train models locally without uploading data to the central server. Since devices in real federated settings are resource-constrained, FL encounters systems heterogeneity, which causes considerable stragglers and incurs significant accuracy degradation. To tackle the challenges of systems heterogeneity and improve the robustness of the global model, we propose a novel adaptive federated framework in this paper. Specifically, we propose FedSAE that leverages the workload completion history of clients to adaptively predict the affordable training workload for each device. Consequently, FedSAE can significantly reduce stragglers in highly heterogeneous systems. We incorporate Active Learning into FedSAE to dynamically schedule participants. The server evaluates the devices' training value based on their training loss in each round, and larger-value clients are selected with a higher probability. As a result, the model convergence is accelerated. Furthermore, we propose q-FedSAE that combines FedSAE and q-FFL to improve global fairness in highly heterogeneous systems. The evaluations conducted in a highly heterogeneous system demonstrate that both FedSAE and q-FedSAE converge faster than FedAvg. In particular, FedSAE outperforms FedAvg across multiple federated datasets --- FedSAE improves testing accuracy by 22.19\% and reduces stragglers by 90.69\% on average. Moreover, holding the same accuracy as FedSAE, q-FedSAE allows for more robust convergence and fairer model performance than q-FedAvg, FedSAE.},
  langid = {english},
  keywords = {Distributed machine learning,Federated learning,Neural Networks}
}

@unpublished{li_FederatedOptimizationHeterogeneous_2020,
  title = {Federated {{Optimization}} in {{Heterogeneous Networks}}},
  shorttitle = {Fedprox},
  author = {Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  date = {2020-04-21},
  eprint = {1812.06127},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1812.06127},
  urldate = {2021-09-20},
  abstract = {Federated Learning is a distributed learning paradigm with two key challenges that differentiate it from traditional distributed optimization: (1) significant variability in terms of the systems characteristics on each device in the network (systems heterogeneity), and (2) non-identically distributed data across the network (statistical heterogeneity). In this work, we introduce a framework, FedProx, to tackle heterogeneity in federated networks. FedProx can be viewed as a generalization and re-parametrization of FedAvg, the current state-of-the-art method for federated learning. While this re-parameterization makes only minor modifications to the method itself, these modifications have important ramifications both in theory and in practice. Theoretically, we provide convergence guarantees for our framework when learning over data from non-identical distributions (statistical heterogeneity), and while adhering to device-level systems constraints by allowing each participating device to perform a variable amount of work (systems heterogeneity). Practically, we demonstrate that FedProx allows for more robust convergence than FedAvg across a suite of realistic federated datasets. In particular, in highly heterogeneous settings, FedProx demonstrates significantly more stable and accurate convergence behavior relative to FedAvg---improving absolute test accuracy by 22\% on average.},
  langid = {english},
  keywords = {\_read,â›” No DOI found,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@unpublished{li_FedMDHeterogenousFederated_2019,
  title = {{{FedMD}}: {{Heterogenous Federated Learning}} via {{Model Distillation}}},
  shorttitle = {{{FedMD}}},
  author = {Li, Daliang and Wang, Junpu},
  date = {2019-10-08},
  eprint = {1910.03581},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1910.03581},
  urldate = {2022-02-25},
  abstract = {Federated learning enables the creation of a powerful centralized model without compromising the data privacy of multiple participants. While successful, it does not incorporate the case where each participant independently designs its own model. Due to intellectual property concerns and heterogeneous nature of tasks and data, this is a widespread requirement in applications of federated learning to areas such as health care and AI as a service. In this work, we use transfer learning and knowledge distillation to develop a universal framework that enables federated learning when each agent owns not only their private data, but also uniquely designed models. We test our framework on the MNIST/FEMNIST dataset and the CIFAR10/CIFAR100 dataset and observe fast improvement across all participating models. With 10 distinct participants, the final test accuracy of each model on average receives a 20\% gain on top of what's possible without collaboration and is only a few percent lower than the performance each model would have obtained if all private datasets were pooled and made directly available for all participants.},
  langid = {english},
  keywords = {â›” No DOI found,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{li_FSLfederatedsequential_2023,
  title = {{{FSL}}: Federated Sequential Learning-Based Cyberattack Detection for {{Industrial Internet}} of {{Things}}},
  shorttitle = {{{FSL}}},
  author = {Li, Fangyu and Lin, Junnuo and Han, Honggui},
  date = {2023-03-17},
  journaltitle = {Industrial Artificial Intelligence},
  shortjournal = {Industrial Artificial Intelligence},
  volume = {1},
  number = {1},
  pages = {4},
  issn = {2731-667X},
  doi = {10.1007/s44244-023-00006-2},
  url = {https://doi.org/10.1007/s44244-023-00006-2},
  urldate = {2024-04-12},
  abstract = {Industrial Internet of Things (IIoT) brings revolutionary technical supports to modern industries. However, today's IIoT still faces the challenges of modeling varying time-series in common data isolation while considering data security. To accurately characterize industrial dynamics, we propose a possible solution based on federated sequence learning (FSL) with cyber attack detection capabilities. Under a federated framework, FSL constructs a collaborative global model without violating local data integrity. Taking advantages of the locally sequential modeling, FSL captures the intrinsic industrial time-series responses. Furthermore, data heterogeneity among distributed clients is also considered, which is important to maintenance a robust but sensitive attack detection. Experiments on classic distributed datasets demonstrate that FSL is capable to accurately model data heterogeneity caused by data isolation and dynamics of time-series. Real IIoT attack detection experiments using a distributed testbed show that our FSL provides better detection performances for industrial time-series sensory data compared to existing methods. Therefore, the proposed attack detection approach FSL is promising in real IIoT scenarios in terms of feasibility, robustness and accuracy.},
  langid = {english},
  keywords = {Cyberattack detection,Federated learning,IIoT,Sequential modeling}
}

@inproceedings{li_HBMDFLHeterogeneousFederated_2022,
  title = {{{HBMD-FL}}: {{Heterogeneous Federated Learning Algorithm Based}} on~{{Blockchain}} and~{{Model Distillation}}},
  shorttitle = {{{HBMD-FL}}},
  booktitle = {Emerging {{Information Security}} and {{Applications}}},
  author = {Li, Ye and Zhang, Jiale and Zhu, Junwu and Li, Wenjuan},
  editor = {Chen, Jiageng and He, Debiao and Lu, Rongxing},
  date = {2022},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {145--159},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-23098-1_9},
  abstract = {Federated learning is a distributed machine learning framework that allows participants to keep their privacy data locally. Traditional federated learning coordinates participants collaboratively train a powerful global model. However, this process has several problems: it cannot meet the heterogeneous model's requirements, and it cannot resist poisoning attacks and single-point-of-failure. In order to resolve these issues, we proposed a heterogeneous federated learning algorithm based on blockchain and model distillation. The problem of fully heterogeneous models that are hard to aggregate in the central server can be solved by leveraging model distillation technology. Moreover, blockchain replaces the central server in federated learning to solve the single-point-of-failure problem. The validation algorithm is combined with cross-validation, which helps federated learning to resist poison attacks. The extensive experimental results demonstrate that HBMD-FL can resist poisoning attacks while losing less than 3\$\$\textbackslash\%\$\$of model accuracy, and the communication consumption significantly outperformed the comparison algorithm.},
  isbn = {978-3-031-23098-1},
  langid = {english},
  keywords = {Blockchain,Federated learning,Heterogeneous,Model distillation}
}

@article{li_InspectingRunningProcess_2021,
  title = {Inspecting the {{Running Process}} of {{Horizontal Federated Learning}} via {{Visual Analytics}}},
  author = {Li, Quan and Wei, Xiguang and Lin, Huanbin and Liu, Yang and Chen, Tianjian and Ma, Xiaojuan},
  date = {2021},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  shortjournal = {IEEE Trans. Visual. Comput. Graphics},
  pages = {1--1},
  issn = {1077-2626, 1941-0506, 2160-9306},
  doi = {10.1109/TVCG.2021.3074010},
  url = {https://ieeexplore.ieee.org/document/9408377/},
  urldate = {2021-09-21},
  abstract = {As a decentralized training approach, horizontal federated learning (HFL) enables distributed clients to collaboratively learn a machine learning model while keeping personal/private information on local devices. Despite the enhanced performance and efficiency of HFL over local training, clues for inspecting the behaviors of the participating clients and the federated model are usually lacking due to the privacy-preserving nature of HFL. Consequently, the users can only conduct a shallow-level analysis of potential abnormal behaviors and have limited means to assess the contributions of individual clients and implement the necessary intervention. Visualization techniques have been introduced to facilitate the HFL process inspection, usually by providing model metrics and evaluation results as a dashboard representation. Although the existing visualization methods allow a simple examination of the HFL model performance, they cannot support the intensive exploration of the HFL process. In this study, strictly following the HFL privacy-preserving protocol, we design an exploratory visual analytics system for the HFL process termed HFLens, which supports comparative visual interpretation at the overview, communication round, and client instance levels. Specifically, the proposed system facilitates the investigation of the overall process involving all clients, the correlation analysis of clients' information in one or different communication round(s), the identification of potential anomalies, and the contribution assessment of each HFL client. Two case studies confirm the efficacy of our system. Experts' feedback suggests that our approach indeed helps in understanding and diagnosing the HFL process better.},
  langid = {english}
}

@inproceedings{li_LocalModelUpdate_2021,
  title = {Local {{Model Update}} for {{Blockchain Enabled Federated Learning}}: {{Approach}} and {{Analysis}}},
  shorttitle = {Local {{Model Update}} for {{Blockchain Enabled Federated Learning}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Blockchain}} ({{Blockchain}})},
  author = {Li, Zhidu and Zhou, Yujie and Wu, Dapeng and Wang, Ruyan},
  date = {2021-12},
  pages = {113--121},
  publisher = {IEEE},
  location = {Melbourne, Australia},
  doi = {10/gpbg4x},
  url = {https://ieeexplore.ieee.org/document/9680546/},
  urldate = {2022-01-31},
  abstract = {Federated learning (FL) has been considered as a promising distributed learning tool in massive data mining for different local devices. Addressing in the trust risk of centralized model aggregation and the challenge of data heterogeneity in traditional FL, this paper proposes an enhancement FL approach in a blockchain network. By analyzing the shortcakes of the classic FL that is widely used in the blockchain enabled FL networks, we propose a novel local parameter update approach, where the information of the last-round global model is utilized to reduce the local performance drift caused by data heterogeneity. The convergence of the proposed FL approach is then proved and the convergence rate is revealed to be linear to the training time. Finally, extensive experiments are carried out with a public dataset to validate the effectiveness of the proposed approach with comparisons of two classic baseline approaches.},
  eventtitle = {2021 {{IEEE International Conference}} on {{Blockchain}} ({{Blockchain}})},
  isbn = {978-1-66541-760-0},
  langid = {english}
}

@article{li_MultiTentacleFederatedLearning_2022,
  title = {Multi-{{Tentacle Federated Learning}} over {{Software-Defined Industrial Internet}} of {{Things Against Adaptive Poisoning Attacks}}},
  author = {Li, Gaolei and Wu, Jun and Li, Shenghong and Yang, Wu and Li, Changlian},
  date = {2022},
  journaltitle = {IEEE Transactions on Industrial Informatics},
  pages = {1--1},
  issn = {1941-0050},
  doi = {10.1109/TII.2022.3173996},
  abstract = {Software-defined industrial Internet of things (SD-IIoT) exploits federated learning to process the sensitive data at edges, while adaptive poisoning attacks threat the security of SD-IIoT. To address this problem, this paper proposes a multi-tentacle federated learning (MTFL) framework, which is essential to guarantee the trustness of training data in SD-IIoT. In MTFL, participants with similar learning tasks are assigned to the same tentacle group. To identify adaptive poisoning attacks, a tentacle distribution-based efficient poisoning attack detection (TD-EPAD) algorithm is presented. And also, to minimize the impact of adaptive poisoning data, a stochastic tentacle data exchanging (STDE) protocol is also proposed. Simultaneously, to protect the tentacle's privacy in STDE, all exchanged data will be processed by differential privacy technology. A MTFL prototype system is implemented, which provides extensive ablation experiments and comparison experiments, demonstrating that the accuracy of the global model under attack scenario can be improved with 40\%.},
  eventtitle = {{{IEEE Transactions}} on {{Industrial Informatics}}},
  keywords = {Adaptation models,Collaborative work,Data models,Differential Privacy,Industrial Internet of Things,Informatics,Multi-Tentacle Federated Learning,Poisoning Attacks,Protocols,Software-Defined Industrial Internet of Things (SD-IIoT),Training}
}

@inproceedings{li_SamplelevelDataSelection_2021,
  title = {Sample-Level {{Data Selection}} for {{Federated Learning}}},
  booktitle = {{{IEEE INFOCOM}} 2021 - {{IEEE Conference}} on {{Computer Communications}}},
  author = {Li, Anran and Zhang, Lan and Tan, Juntao and Qin, Yaxuan and Wang, Junhao and Li, Xiang-Yang},
  date = {2021-05},
  pages = {1--10},
  issn = {2641-9874},
  doi = {10.1109/INFOCOM42981.2021.9488723},
  url = {https://ieeexplore.ieee.org/abstract/document/9488723},
  urldate = {2024-03-27},
  abstract = {Federated learning (FL) enables participants to collaboratively construct a global machine learning model without sharing their local training data to the remote server. In FL systems, the selection of training samples has a significant impact on model performances, e.g., selecting participants whose datasets have erroneous samples, skewed categorical distributions, and low content diversity would result in low accuracy and unstable models. In this work, we aim to solve the exigent optimization problem that selects a collection of high-quality training samples for a given FL task under a monetary budget in a privacy-preserving way, which is extremely challenging without visibility to participants' local data and training process. We provide a systematic analysis of important data related factors affecting the model performance and propose a holistic design to privately and efficiently select high-quality data samples considering all these factors. We verify the merits of our proposed solution with extensive experiments on a real AIoT system with 50 clients, including 20 edge computers, 20 laptops, and 10 desktops. The experimental results validates that our solution achieves accurate and efficient selection of high-quality data samples, and consequently an FL model with a faster convergence speed and higher accuracy than that achieved by existing solutions.},
  eventtitle = {{{IEEE INFOCOM}} 2021 - {{IEEE Conference}} on {{Computer Communications}}},
  keywords = {Collaborative work,Computational modeling,Computers,Data privacy,Systematics,Training,Training data}
}

@article{li_SurveyingTrustBasedCollaborative_2022,
  title = {Surveying {{Trust-Based Collaborative Intrusion Detection}}: {{State-of-the-Art}}, {{Challenges}} and {{Future Directions}}},
  shorttitle = {Surveying {{Trust-Based Collaborative Intrusion Detection}}},
  author = {Li, Wenjuan and Meng, Weizhi and Kwok, Lam For},
  date = {2022},
  journaltitle = {IEEE Communications Surveys \& Tutorials},
  volume = {24},
  number = {1},
  pages = {280--305},
  issn = {1553-877X},
  doi = {10.1109/COMST.2021.3139052},
  url = {https://ieeexplore.ieee.org/document/9663537},
  urldate = {2024-06-22},
  abstract = {Owing to the swift growth in cyber attacks, intrusion detection systems (IDSs) have become a necessity to help safeguard personal and organizational assets. However, with the increasing size of computer networks, it becomes difficult for a stand-alone IDS to identify sophisticated and advanced threats, such as DDoS attack, due to the lack of contextual information and knowledge regarding the deployed environments. To tackle this issue, distributed and collaborative IDSs (DIDSs and CIDSs) are developed, which enable a set of IDS nodes to operate in a collaborative way through exchanging required information. In this survey, we first summarize the state-of-the-art for traditional DIDSs according to the collaboration topology, e.g., centralized, decentralized, and distributed, and discuss major external and internal threats. Because of the distributed nature and various threats, trust is often enforced among various IDS nodes. We then summarize the relevant research on trust-based DIDSs/CIDSs in a chronological order. Also, we highlight challenges and future directions in this field. The main purpose of this survey is to stimulate more research efforts in developing robust and practical trust-based collaborative intrusion detection.},
  eventtitle = {{{IEEE Communications Surveys}} \& {{Tutorials}}},
  keywords = {+survey,challenges and future directions,Collaboration,Collaborative intrusion detection,Detectors,distributed network,Engines,insider attack,Intrusion detection,Prototypes,review and survey,Security,trust computation and management,Tutorials}
}

@article{li_Transferlearningbased_2021,
  title = {Transfer Learning Based Intrusion Detection Scheme for {{Internet}} of Vehicles},
  author = {Li, Xinghua and Hu, Zhongyuan and Xu, Mengfan and Wang, Yunwei and Ma, Jianfeng},
  date = {2021-02},
  journaltitle = {Information Sciences},
  shortjournal = {Information Sciences},
  volume = {547},
  pages = {119--135},
  issn = {00200255},
  doi = {10.1016/j.ins.2020.05.130},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0020025520305569},
  urldate = {2021-10-04},
  abstract = {As a new type of network, the types of attack in the Internet of Vehicles (IoV) are constantly emerging and changing. Consequently, the machine learning based intrusion detection model has to update to cope with new attacks. However, existing machine learning based IoV intrusion detection schemes require large amounts of labeled data to complete model updates. For new attacks, the IoV cloud is also difficult to identify in time, which requires a lot of labor and time cost in IoV. To solve above issue, this paper employs transfer learning and proposes two model update schemes based on whether the IoV cloud can timely provide a small amount of labeled data for a new attack. The first one is the cloud-assisted update scheme where the IoV cloud can provide a small amount of data. And the second one is the local update scheme where the IoV cloud cannot provide any labeled data timely. In this paper, the local update scheme obtains pseudo label of the unlabeled data in new attacks via pre-classifies and uses the pseudo-labeled data for multiple rounds of transfer learning. Then the vehicle can complete the update without obtaining any labeled data through the IoV cloud. The experimental results show that compared with the existing method, our two schemes have improved the detection accuracy by at least 23\%.},
  langid = {english},
  keywords = {\_read}
}

@inproceedings{lian_DecentralizedFederatedLearning_2022,
  title = {Decentralized {{Federated Learning}} for {{Internet}} of {{Things Anomaly Detection}}},
  booktitle = {Proceedings of the 2022 {{ACM}} on {{Asia Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Lian, Zhuotao and Su, Chunhua},
  date = {2022-05-30},
  series = {{{ASIA CCS}} '22},
  pages = {1249--1251},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3488932.3527285},
  url = {https://dl.acm.org/doi/10.1145/3488932.3527285},
  urldate = {2024-04-12},
  abstract = {With the improvement of computing power and the development of network technology, Internet of Things (IoT) devices are widely used in many industries. But it also faces various security threats. Anomaly detection is a commonly used method, but traditional methods face shortcomings such as low accuracy. Therefore, in this paper, we introduce a decentralized federated learning method for anomaly detection, using neural networks to improve accuracy and take advantage of the characteristics of federated learning to protect local data security. The decentralized algorithm avoids the drawbacks of traditional federated learning such as the single point of failure. Finally, we conduct simulation experiments on the IoT23 dataset, which verify the performance of our system.},
  isbn = {978-1-4503-9140-5},
  keywords = {anomaly detection,decentralized system,federated learning,internet of things}
}

@article{liang_ImprovedDistributedPrincipal_2014,
  title = {Improved {{Distributed Principal Component Analysis}}},
  author = {Liang, Yingyu and Balcan, Maria-Florina and Kanchanapally, Vandana and Woodruff, David P.},
  date = {2014-08-25},
  journaltitle = {ArXiv},
  url = {https://www.semanticscholar.org/paper/525f6256d85d08dc3383d3c80030aa4b5bb12990},
  urldate = {2024-04-02},
  abstract = {We study the distributed computing setting in which there are multiple servers, each holding a set of points, who wish to compute functions on the union of their point sets. A key task in this setting is Principal Component Analysis (PCA), in which the servers would like to compute a low dimensional subspace capturing as much of the variance of the union of their point sets as possible. Given a procedure for approximate PCA, one can use it to approximately solve problems such as k-means clustering and low rank approximation. The essential properties of an approximate distributed PCA algorithm are its communication cost and computational efficiency for a given desired accuracy in downstream applications. We give new algorithms and analyses for distributed PCA which lead to improved communication and computational costs for k-means clustering and related problems. Our empirical study on real world data shows a speedup of orders of magnitude, preserving communication with only a negligible degradation in solution quality. Some of these techniques we develop, such as a general transformation from a constant success probability subspace embedding to a high success probability subspace embedding with a dimension and sparsity independent of the success probability, may be of independent interest.}
}

@article{liang_IntrusionDetectionMethod_2023,
  title = {An {{Intrusion Detection Method}} for {{Advanced Metering Infrastructure System Based}} on {{Federated Learning}}},
  author = {Liang, Haolan and Liu, Dongqi and Zeng, Xiangjun and Ye, Chunxiao},
  date = {2023-05},
  journaltitle = {Journal of Modern Power Systems and Clean Energy},
  volume = {11},
  number = {3},
  pages = {927--937},
  issn = {2196-5420},
  doi = {10.35833/MPCE.2021.000279},
  url = {https://ieeexplore.ieee.org/document/9808312},
  urldate = {2024-04-12},
  abstract = {An advanced metering infrastructure (AMI) system plays a key role in the smart grid (SG), but it is vulnerable to cyberattacks. Current detection methods for AMI cyberattacks mainly focus on the data center or a distributed independent node. On one hand, it is difficult to train an excellent detection intrusion model on a self-learning independent node. On the other hand, large amounts of data are shared over the network and uploaded to a central node for training. These processes may compromise data privacy, cause communication delay, and incur high communication costs. With these limitations, we propose an intrusion detection method for AMI system based on federated learning (FL). The intrusion detection system is deployed in the data concentrators for training, and only its model parameters are communicated to the data center. Furthermore, the data center distributes the learning to each data concentrator through aggregation and weight assignments for collaborative learning. An optimized deep neural network (DNN) is exploited for this proposed method, and extensive experiments based on the NSL-KDD dataset are carried out. From the results, this proposed method improves detection performance and reduces computation costs, communication delays, and communication overheads while guaranteeing data privacy.},
  eventtitle = {Journal of {{Modern Power Systems}} and {{Clean Energy}}},
  keywords = {advanced metering infrastructure (AMI) system,Behavioral sciences,Data centers,data concentrator,Data models,Federated learning (FL),intrusion detection,Intrusion detection,Smart meters,Wide area networks,WiMAX}
}

@inproceedings{lightbody_HostBasedIntrusionDetection_2022,
  title = {Host-{{Based Intrusion Detection System}} for {{IoT}} Using {{Convolutional Neural Networks}}},
  booktitle = {2022 33rd {{Irish Signals}} and {{Systems Conference}} ({{ISSC}})},
  author = {Lightbody, Dominic and Ngo, Duc-Minh and Temko, Andriy and Murphy, Colin and Popovici, Emanuel},
  date = {2022-06},
  pages = {1--7},
  issn = {2688-1454},
  doi = {10.1109/ISSC55427.2022.9826188},
  abstract = {This paper proposes and analyses a lightweight Convolutional Neural Network (CNN) based anomaly detection framework for Internet of Things (IoT) devices. IoT security has become a massive concern in recent years. IoT devices form the backbone of much of the critical infrastructure we have today. From power stations to biomedical devices, there is the potential of heavy financial damage and loss of human life if they become compromised. As IoT adoption accelerates, the amount of cyberattacks on IoT devices increases substantially. Due to the resource constrained nature of IoT devices, no security solution addresses all concerns in the IoT field. By training models based on normal power consumption behaviour, a wide range of anomalies can be detected in the power time series data of the IoT device. The methodology proposed in this paper is generic in nature, making it applicable to every IoT device on the market. The work in this paper is implemented at the edge, on an ultra-low-power microcontroller.},
  eventtitle = {2022 33rd {{Irish Signals}} and {{Systems Conference}} ({{ISSC}})},
  keywords = {anomaly detection,CNN,Convolutional neural networks,HIDS,IDS,Internet of Things,Intrusion detection,IoT,low-power,machine learning,Power demand,Security,sustainable security,Time series analysis,Training}
}

@article{lin_FedEVCPFederatedLearningBased_2023,
  title = {{{FedEVCP}}: {{Federated Learning-Based Anomalies Detection}} for {{Electric Vehicle Charging Pile}}},
  shorttitle = {{{FedEVCP}}},
  author = {Lin, Zhaoliang and Li, Jinguo},
  date = {2023-08-07},
  journaltitle = {The Computer Journal},
  shortjournal = {The Computer Journal},
  pages = {bxad078},
  issn = {0010-4620},
  doi = {10.1093/comjnl/bxad078},
  url = {https://doi.org/10.1093/comjnl/bxad078},
  urldate = {2024-04-12},
  abstract = {Vehicle-to-Grid (V2G) is a technology that enables electric vehicles to use smart charging methods to harness low-cost and renewable energy when it is available, and obtain income by feeding energy back into the grid. With the rise of V2G technology, the use of electric vehicles has begun to increase dramatically, which relies on the reliable Electric Vehicle Charging Pile (EVCP). However, most EVCPs are online and networked, introducing many potential network threats, such as Electricity Theft, Identity Theft and False Data Injection etc. Prior work has mostly focused on machine learning, which is not able to effectively capture the relationships and structures in network traffic, making it difficult to deal with the propagation and infection of the novel network attacks. Moreover, most neural network models collect and transfer data from EVCPs to the central server for training, which makes the central server attractive to attackers. It poses a serious threat to user privacy. To address these issues, propose an anomaly detection model that incorporates Federated Learning and Deep Autoencoder, which can increase the amount and diversity of data used to train deep learning models without compromising privacy. The proposed model forms a layer-by-layer unsupervised representation learning algorithm by autoencoder stacking, while batch normalization of hidden layers accelerates the convergence of the model to avoid overfitting and local optima, and introduces an attention mechanism to enhance key features of sequences composed of data vectors to improve the accuracy rate. To prevent the risk of user privacy leakage on the central server, EVCP is allowed to retain local data for model training and send model parameters to the central server for constructing new global models. Experimental results show that the proposed scheme achieves improved detection accuracy with superior performance than other similar models.}
}

@article{lin_Multidatasourcemachinelearning_2022,
  title = {Multi-Datasource Machine Learning in Intrusion Detection: {{Packet}} Flows, System Logs and Host Statistics},
  shorttitle = {Multi-Datasource Machine Learning in Intrusion Detection},
  author = {Lin, Ying-Dar and Wang, Ze-Yu and Lin, Po-Ching and Nguyen, Van-Linh and Hwang, Ren-Hung and Lai, Yuan-Cheng},
  date = {2022-08-01},
  journaltitle = {Journal of Information Security and Applications},
  shortjournal = {Journal of Information Security and Applications},
  volume = {68},
  pages = {103248},
  issn = {2214-2126},
  doi = {10.1016/j.jisa.2022.103248},
  url = {https://www.sciencedirect.com/science/article/pii/S2214212622001168},
  urldate = {2022-08-11},
  abstract = {This work compares the performance of different combinations of data sources for intrusion detection in depth. To learn and distinguish between normal and malicious behavior, we use machine learning algorithms and train three typical models on three kinds of datasets: system logs, packet flows and host statistics. Unlike other studies, our study captures and monitors the behavior from multiple data sources in order to catch security attacks. Our aim is to figure out how to build the most effective dataset for machine learning with a combination of multiple sources. However, since there are no such datasets which have been generated from multiple sources for given attacks, we show how to build and generate a dataset with three data sources. We then compare the F1 score of the detection by applying machine learning algorithms for various combinations of the data sources. Our evaluation results show that the dataset of host statistics results in better performance (0.91) than traffic flows (0.63) and system logs (0.44) because it has the highest average F1-score in the three stages of attacks, while the other datasets may have poor F1-scores in some of the stages, particularly in the stage of impact. However, in the initial access stage of attacks, the dataset of logs performs the best (0.94), and the packet flows are suitable for detecting network DoS attacks (0.82). Furthermore, running this detection with all three data sources results in minor overheads of at most 2.1\% CPU utilization. Finally, we analyze the important features of each model, such as the number of logs generated by apache-access, in.telnetd and postfix in the dataset of logs, SrcBytes and TotBytes in the dataset of flows, and MINFLT, VSTEXT and RSIZE in the dataset of statistics.},
  langid = {english},
  keywords = {Feature engineering,Host statistics,Intrusion detection,Machine learning,System log,Traffic flow}
}

@article{lin_PrivacyEnhancedIntrusionDetection_2022,
  title = {Privacy-{{Enhanced Intrusion Detection}} and {{Defense}} for {{Cyber-Physical Systems}}: {{A Deep Reinforcement Learning Approach}}},
  shorttitle = {Privacy-{{Enhanced Intrusion Detection}} and {{Defense}} for {{Cyber-Physical Systems}}},
  author = {Lin, Qingyuan and Ming, Rui and Zhang, Kailing and Luo, Haibo},
  editor = {Wu, Yulei},
  date = {2022-10-10},
  journaltitle = {Security and Communication Networks},
  shortjournal = {Security and Communication Networks},
  volume = {2022},
  pages = {1--9},
  issn = {1939-0122, 1939-0114},
  doi = {10.1155/2022/4996427},
  url = {https://www.hindawi.com/journals/scn/2022/4996427/},
  urldate = {2022-10-18},
  abstract = {Cyber-physical systems (CPSs) will play an important role in future real-world applications through the deep integration of computing, communication, and control technologies. CPSs are increasingly deployed in critical infrastructure, industry, and homes to achieve a smart grid, smart transportation, and smart healthcare and to bring many benefits to citizens, businesses, and governments. However, the openness and complexity brought by network and wireless communication technology, as well as the intelligence and dynamic of network intrusions make CPS more vulnerable to network intrusions and bring more serious threats to human life, enterprise productivity, and national security. Therefore, intrusion detection and defense in CPS have attracted considerable attention and have become a fundamental aspect of CPS security. However, a new challenging problem arises: how to improve the efficiency and accuracy of intrusion detection while protecting user privacy during the intrusion detection process. To address this challenge, we propose a deep reinforcement learning-based privacy-enhanced intrusion detection and defense mechanism (PIDD) for CPS. The PIDD is composed of three modules: privacy-enhanced topology graphs generation module, graph convolutional networks-based user evaluation module, and the deep reinforcement learning-based intruder identification and handling module. The experimental results show that the proposed PIDD achieves excellent performance in intrusion detection accuracy, intrusion defense percentage, and privacy protection.},
  langid = {english}
}

@article{lin_SurveyInternetThings_2017,
  title = {A {{Survey}} on {{Internet}} of {{Things}}: {{Architecture}}, {{Enabling Technologies}}, {{Security}} and {{Privacy}}, and {{Applications}}},
  author = {Lin, Jie and Yu, Wei and Zhang, Nan and Yang, Xinyu and Zhang, Hanlin and Zhao, Wei},
  date = {2017-10},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {4},
  number = {5},
  pages = {1125--1142},
  publisher = {IEEE},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2017.2683200},
  url = {https://ieeexplore.ieee.org/document/7879243/},
  abstract = {Fog/edge computing has been proposed to be integrated with Internet of Things (IoT) to enable computing services devices deployed at network edge, aiming to improve the user's experience and resilience of the services in case of fail- ures. With the advantage of distributed architecture and close to end-users, fog/edge computing can provide faster response and greateome-imt-cer quality of service for IoT applications. Thus, fog/edge computing-based IoT becomes future infrastructure on IoT devel- opment. To develop fog/edge computing-based IoT infrastructure, the architecture, enabling techniques, and issues related to IoT should be investigated first, and then the integration of fog/edge computing and IoT should be explored. To this end, this paper conducts a comprehensive overview of IoT with respect to system architecture, enabling technologies, security and privacy issues, and present the integration of fog/edge computing and IoT, and applications. Particularly, this paper first explores the relation- ship between cyber-physical systems and IoT, both of which play important roles in realizing an intelligent cyber-physical world. Then, existing architectures, enabling technologies, and security and privacy issues in IoT are presented to enhance the under- standing of the state of the art IoT development. To investigate the fog/edge computing-based IoT, this paper also investigate the rela- tionship between IoT and fog/edge computing, and discuss issues in fog/edge computing-based IoT. Finally, several applications, including the smart grid, smart transportation, and smart cities, are presented to demonstrate how fog/edge computing-based IoT to be implemented in real-world applications.},
  isbn = {978-1-5386-1442-6}
}

@article{lingzizhu_TICPSTrustworthyCollaborative_InReview,
  title = {{{TICPS}}: {{A Trustworthy Collaborative Intrusion Detection Framework}} for {{Industrial Cyber}}--{{Physical Systems}}},
  author = {{Lingzi Zhu} and {Bo Zhao} and {Weidong Li} and {Yixuan Wang} and {Yang An}},
  year = {In Review},
  abstract = {The networking of industrial cyber-physical systems (CPSs) brings more security threats, which highlights the significance of intrusion detection frameworks. However, the data of industrial CPSs have the problem of islanding and high sensitivity. As a distributed machine learning technique, the federate learning (FL) framework alleviates this situation by allowing detection models to be constructed collaboratively with multiple agents while protecting data privacy. However, existing FL-based intrusion detection methods perform ineffectively on the poisoning attacks launched by malicious agents. The poisoning attacks can manipulate the local data set to send malicious updates to the server, thus corrupting the intrusion detection model. To address these issues, we design TICPS, a collaborative intrusion detection framework based on a trustworthy model update strategy to detect cyber threats from industrial CPSs. The framework utilizes FL to allow multiple industrial CPSs to jointly construct a comprehensive intrusion detection model. In addition, we evaluate the trustworthiness of each industrial agent by similarity tests between local model updates and a trustworthy root model update. By implementing secure model aggregation updates, the models can perform effective intrusion detection even under poisoning attacks. Extensive experiments on real industrial CPSs datasets demonstrate the effectiveness of our framework in detecting various types of cyber threats to industrial CPSs. In particular, when the proportion of malicious agents reaches 90\% under three typical poisoning attacks, it can still achieve 94\% accuracy of intrusion detection.},
  keywords = {\_done,\_unpublished}
}

@article{liu_AsynchronousFederatedLearning_2023,
  title = {An {{Asynchronous Federated Learning Arbitration Model}} for {{Low-Rate DDoS Attack Detection}}},
  author = {Liu, Zengguang and Guo, Cuiyun and Liu, Deyong and Yin, Xiaochun},
  date = {2023},
  journaltitle = {IEEE Access},
  volume = {11},
  pages = {18448--18460},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3247512},
  url = {https://ieeexplore.ieee.org/document/10049569},
  urldate = {2024-04-12},
  abstract = {Low-rate Distributed Denial of Service (LDDoS) attacks have been one of the most notorious network security threats, which use periodic slight multi-variate time series pulse flows to degrade network quality. Limited by the poor data in a single client, a powerful and satisfactory LDDoS attack detection model is hard to be trained. Federated Learning (FL) is a promising paradigm offering joint learning through multiple clients. We propose an asynchronous federated learning arbitration framework based on bidirectional LSTM (bi-LSTM) and attention mechanism (AsyncFL-bLAM). In the AsyncFL-bLAM, the leader node election algorithm is proposed for constructing the framework of asynchronous federated learning. The proposed bLAM model composed of feature extracter and arbitrator takes on the responsibility of LDDoS detection locally. Furthermore, the novel AsyncFL framework helps to upload and aggregate the bLAM models' parameters asynchronously between leader node and client nodes. Experimental results show that the AsyncFL-bLAM outperforms the state-of-the-art models in accuracy, and reduces the overall communication rounds.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Arbitration mechanism,asynchronous federated learning,Data models,deep learning,Electronic mail,Feature extraction,Federated learning,Internet of Things,IP networks,low-rate distributed denial-of-service,Training}
}

@article{liu_BlockchainFederatedLearning_2021,
  title = {Blockchain and {{Federated Learning}} for {{Collaborative Intrusion Detection}} in {{Vehicular Edge Computing}}},
  author = {Liu, Hong and Zhang, Shuaipeng and Zhang, Pengfei and Zhou, Xinqiang and Shao, Xuebin and Pu, Geguang and Zhang, Yan},
  date = {2021-06},
  journaltitle = {IEEE Transactions on Vehicular Technology},
  shortjournal = {IEEE Trans. Veh. Technol.},
  volume = {70},
  number = {6},
  pages = {6073--6084},
  issn = {0018-9545, 1939-9359},
  doi = {10.1109/TVT.2021.3076780},
  url = {https://ieeexplore.ieee.org/document/9420262/},
  urldate = {2021-10-04},
  abstract = {The vehicular networks constructed by interconnected vehicles and transportation infrastructure are vulnerable to cyber-intrusions due to the expanded use of software and the introduction of wireless interfaces. Intrusion detection systems (IDSs) can be customized efficiently in response to this increased attack surface. There has been significant progress in detecting malicious attack traffic using machine learning approaches. However, existing IDSs require network devices with powerful computing capabilities to continuously train and update complex network models, which reduces the efficiency and defense capability of intrusion detection systems due to limited resources and untimely model updates. This work proposes a cooperative intrusion detection mechanism that offloads the training model to distributed edge devices (e.g., connected vehicles and roadside units (RSUs). Distributed federated-based approach reduces resource utilization of the central server while assuring security and privacy. To ensure the security of the aggregation model, blockchain is used for the storage and sharing of the training models. This work analyzes common attacks and shows that the proposed scheme achieves cooperative privacy-preservation for vehicles while reducing communication overhead and computation cost.},
  langid = {english},
  keywords = {survey-fids}
}

@inproceedings{liu_ClientEdgeCloudHierarchicalFederated_2020,
  title = {Client-{{Edge-Cloud Hierarchical Federated Learning}}},
  booktitle = {{{ICC}} 2020 - 2020 {{IEEE International Conference}} on {{Communications}} ({{ICC}})},
  author = {Liu, Lumin and Zhang, Jun and Song, S.H. and Letaief, Khaled B.},
  date = {2020-06},
  pages = {1--6},
  issn = {1938-1883},
  doi = {10.1109/ICC40277.2020.9148862},
  url = {https://ieeexplore.ieee.org/document/9148862},
  urldate = {2024-06-23},
  abstract = {Federated Learning is a collaborative machine learning framework to train a deep learning model without accessing clients' private data. Previous works assume one central parameter server either at the cloud or at the edge. The cloud server can access more data but with excessive communication overhead and long latency, while the edge server enjoys more efficient communications with the clients. To combine their advantages, we propose a client-edge-cloud hierarchical Federated Learning system, supported with a HierFAVG algorithm that allows multiple edge servers to perform partial model aggregation. In this way, the model can be trained faster and better communication-computation trade-offs can be achieved. Convergence analysis is provided for HierFAVG and the effects of key parameters are also investigated, which lead to qualitative design guidelines. Empirical experiments verify the analysis and demonstrate the benefits of this hierarchical architecture in different data distribution scenarios. Particularly, it is shown that by introducing the intermediate edge servers, the model training time and the energy consumption of the end devices can be simultaneously reduced compared to cloud-based Federated Learning.},
  eventtitle = {{{ICC}} 2020 - 2020 {{IEEE International Conference}} on {{Communications}} ({{ICC}})},
  keywords = {Cloud computing,Computational modeling,Convergence,Data models,Edge Learning,Federated Learning,Machine learning,Mobile Edge Computing,Servers,Training}
}

@article{liu_DelayEnergyEfficientAsynchronous_2024,
  title = {Delay and {{Energy-Efficient Asynchronous Federated Learning}} for {{Intrusion Detection}} in {{Heterogeneous Industrial Internet}} of {{Things}}},
  author = {Liu, Shumei and Yu, Yao and Zong, Yue and Yeoh, Phee Lep and Guo, Lei and Vucetic, Branka and Duong, Trung Q. and Li, Yonghui},
  date = {2024-04},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {11},
  number = {8},
  pages = {14739--14754},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2023.3344457},
  url = {https://ieeexplore.ieee.org/abstract/document/10365696},
  urldate = {2024-04-12},
  abstract = {Federated learning (FL) is a promising solution to overcome data island and privacy issues in intrusion detection systems (IDSs) for the Industrial Internet of Things (IIoT). However, the heterogeneity of various IIoT devices poses formidable challenges to FL-based intrusion detection, especially the training cost relating to delay and energy consumption. In this article, we propose a delay and energy-efficient asynchronous FL (AFL) framework for intrusion detection (DEAFL-ID) in heterogeneous IIoT. Specifically, we address the shortcomings of low efficiency and high energy consumption in existing FL-based solutions involving all idle IIoT devices. To do so, we formulate an AFL-based optimal device selection problem which aims to select high-quality training devices in advance by exploring the device advantages in detection accuracy, delay reduction, and energy saving. Subsequently, a deep Q-network (DQN)-based learning algorithm is developed to quickly solve the above high-dimensional problem. In addition, to further improve the detection performance, we build a hybrid sampling-assisted convolutional neural network (CNN)-based IDS model, which can eliminate the imbalance of IIoT data and enable the selected devices to fully extract data features. Through simulations, we demonstrate that DEAFL-ID achieves a significant improvement in training cost and detection performance compared with existing IDS schemes.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {Asynchronous federated learning (AFL),Data models,delay and energy consumption,Delays,heterogeneous Industrial Internet of Things (IIoT) devices,IIoT,Industrial Internet of Things,intrusion detection,Intrusion detection,Performance evaluation,Servers,Training}
}

@inproceedings{liu_ErrorPrevalenceNIDS_2022,
  title = {Error {{Prevalence}} in {{NIDS}} Datasets: {{A Case Study}} on {{CIC-IDS-2017}} and {{CSE-CIC-IDS-2018}}},
  shorttitle = {Error {{Prevalence}} in {{NIDS}} Datasets},
  booktitle = {2022 {{IEEE Conference}} on {{Communications}} and {{Network Security}} ({{CNS}})},
  author = {Liu, Lisa and Engelen, Gints and Lynar, Timothy and Essam, Daryl and Joosen, Wouter},
  date = {2022-10},
  pages = {254--262},
  doi = {10.1109/CNS56114.2022.9947235},
  abstract = {Benchmark datasets are heavily depended upon by the research community to validate theoretical findings and track progression in the state-of-the-art. NIDS dataset creation presents numerous challenges on account of the volume, heterogeneity, and complexity of network traffic, making the process labor intensive, and thus, prone to error. This paper provides a critical review of CIC-IDS-2017 and CIC-CSE-IDS-2018, datasets which have seen extensive usage in the NIDS literature, and are currently considered primary benchmarking datasets for NIDS. We report a large number of previously undocumented errors throughout the dataset creation lifecycle, including in attack orchestration, feature generation, documentation, and labeling. The errors destabilize the results and challenge the findings of numerous publications that have relied on it as a benchmark. We demonstrate the implications of these errors through several experiments. We provide comprehensive documentation to summarize the discovery of these issues, as well as a fully-recreated dataset, with labeling logic that has been reverse-engineered, corrected, and made publicly available for the first time. We demonstrate the implications of dataset errors through a series of experiments. The findings serve to remind the research community of common pitfalls with dataset creation processes, and of the need to be vigilant when adopting new datasets. Lastly, we strongly recommend the release of labeling logic for any dataset released, to ensure full transparency.},
  eventtitle = {2022 {{IEEE Conference}} on {{Communications}} and {{Network Security}} ({{CNS}})},
  keywords = {Benchmark testing,CIC-IDS-2017,Complexity theory,CSE-CIC-IDS-2018,datasets,Documentation,Labeling,Network intrusion,network intrusion detection,Network security,Telecommunication traffic}
}

@inproceedings{liu_FederatedLearningAnomaly_2022,
  title = {Federated {{Learning}} with {{Anomaly Client Detection}} and {{Decentralized Parameter Aggregation}}},
  booktitle = {2022 52nd {{Annual IEEE}}/{{IFIP International Conference}} on {{Dependable Systems}} and {{Networks Workshops}} ({{DSN-W}})},
  author = {Liu, Shu and Shang, Yanlei},
  date = {2022-06},
  pages = {37--43},
  issn = {2325-6664},
  doi = {10.1109/DSN-W54100.2022.00016},
  abstract = {Federated learning is a framework for machine learning that is dedicated to data privacy protection. In federated learning, system cannot fully control the behavior of clients which can be faulty. These behaviors include sharing arbitrary faulty gradients and delaying the process of sharing due to Byzantine attacks or clients' own software and hardware failures. In federated learning, the parameter server may also be faulty during gradient collection and aggregation, mainly including gradient-based training data inference and model parameter faulty update. The above problems may lead to reduced accuracy of federated learning model training, leakage of client privacy, etc. Existing research enhances the robustness of federated learning by exploiting the decentralization and immutability of Blockchain. For untrusted clients, most research is based on Byzantine fault tolerance to defend against clients indiscriminately, and may cause model accuracy reduction. In addition, most of the research focus on unencrypted gradients, and there is insufficient research on dealing with client anomalies in the case of gradient encryption. For untrusted parameter servers, existing research has problems in energy overhead and scalability. Aiming at the problems above, this paper studies the robustness of federated learning, and proposes a blockchain-based federated learning parameter update architecture PUS-FL. Through experiments simulating distributed machine learning on neural networks, we demonstrate that the anomaly detection algorithm of PUS-FL outperforms conventional gradient filters including geometric median, Multi-Krum and trimmed mean. In addition, our experiments also verify that the scalability-enhanced parameter aggregation consensus algorithm proposed in this paper(SE-PBFT) improves consensus scalability by reducing communication complexity.},
  eventtitle = {2022 52nd {{Annual IEEE}}/{{IFIP International Conference}} on {{Dependable Systems}} and {{Networks Workshops}} ({{DSN-W}})},
  keywords = {Blockchain,Byzantine Attack,Collaborative work,Consensus Algorithm,Fault tolerant systems,Federated learning,Inference algorithms,Machine learning,Privacy,Robustness,Scalability,Trusted Computing}
}

@inproceedings{liu_FederatedLearningAnomaly_2022a,
  title = {Federated {{Learning}} with {{Anomaly Client Detection}} and {{Decentralized Parameter Aggregation}}},
  booktitle = {2022 52nd {{Annual IEEE}}/{{IFIP International Conference}} on {{Dependable Systems}} and {{Networks Workshops}} ({{DSN-W}})},
  author = {Liu, Shu and Shang, Yanlei},
  date = {2022-06},
  pages = {37--43},
  issn = {2325-6664},
  doi = {10.1109/DSN-W54100.2022.00016},
  abstract = {Federated learning is a framework for machine learning that is dedicated to data privacy protection. In federated learning, system cannot fully control the behavior of clients which can be faulty. These behaviors include sharing arbitrary faulty gradients and delaying the process of sharing due to Byzantine attacks or clients' own software and hardware failures. In federated learning, the parameter server may also be faulty during gradient collection and aggregation, mainly including gradient-based training data inference and model parameter faulty update. The above problems may lead to reduced accuracy of federated learning model training, leakage of client privacy, etc. Existing research enhances the robustness of federated learning by exploiting the decentralization and immutability of Blockchain. For untrusted clients, most research is based on Byzantine fault tolerance to defend against clients indiscriminately, and may cause model accuracy reduction. In addition, most of the research focus on unencrypted gradients, and there is insufficient research on dealing with client anomalies in the case of gradient encryption. For untrusted parameter servers, existing research has problems in energy overhead and scalability. Aiming at the problems above, this paper studies the robustness of federated learning, and proposes a blockchain-based federated learning parameter update architecture PUS-FL. Through experiments simulating distributed machine learning on neural networks, we demonstrate that the anomaly detection algorithm of PUS-FL outperforms conventional gradient filters including geometric median, Multi-Krum and trimmed mean. In addition, our experiments also verify that the scalability-enhanced parameter aggregation consensus algorithm proposed in this paper(SE-PBFT) improves consensus scalability by reducing communication complexity.},
  eventtitle = {2022 52nd {{Annual IEEE}}/{{IFIP International Conference}} on {{Dependable Systems}} and {{Networks Workshops}} ({{DSN-W}})},
  keywords = {Blockchain,Byzantine Attack,Collaborative work,Consensus Algorithm,Fault tolerant systems,Federated learning,Inference algorithms,Machine learning,Privacy,Robustness,Scalability,Trusted Computing}
}

@inproceedings{liu_FederatedLearningBasedIntrusion_2023,
  title = {Federated {{Learning-Based Intrusion Detection}} on~{{Non-IID Data}}},
  booktitle = {Algorithms and {{Architectures}} for {{Parallel Processing}}},
  author = {Liu, Yongfei and Wu, Guangjun and Zhang, Wenyuan and Li, Jun},
  editor = {Meng, Weizhi and Lu, Rongxing and Min, Geyong and Vaidya, Jaideep},
  date = {2023},
  pages = {313--329},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-22677-9_17},
  abstract = {Intrusion detection is an effective means to deal with network attacks. Currently, the commonly used detection methods are based on machine learning. However, traditional machine learning-based methods are centralized architectures that require uploading data to cloud servers, which face serious latency and data security issues. Federated learning (FL) can collaboratively train a machine learning model with good performance while the data is kept locally on the client, which can effectively make up for the shortcomings of the centralized architecture. Most of the current research on using FL methods in machine learning-based intrusion detection ideally consider the data to be independent and identically distributed (IID), which doesn't conform to real scenarios. In the real world, due to the different environment of the client, the types of attacks contained in the data owned by each client may be different. Therefore, we study the effects of various non-independent and identically distribution (non-IID) settings on FL in detail and give specific partitioning methods. In addition, we also propose a FL data rebalancing method based on auxiliary classifier generative adversarial networks (ACGAN), which is experimentally validated on the UNSW-NB15 dataset. Experiments show that the proposed data augmentation method can well improve the impact of non-IID data on FL.},
  isbn = {978-3-031-22677-9},
  langid = {english}
}

@article{liu_HierarchicalFederatedLearning_2022,
  title = {Hierarchical {{Federated Learning}} with {{Quantization}}: {{Convergence Analysis}} and {{System Design}}},
  shorttitle = {Hierarchical {{Federated Learning}} with {{Quantization}}},
  author = {Liu, Lumin and Zhang, Jun and Song, Shenghui and Letaief, Khaled B.},
  date = {2022},
  journaltitle = {IEEE Transactions on Wireless Communications},
  pages = {1--1},
  issn = {1558-2248},
  doi = {10.1109/TWC.2022.3190512},
  abstract = {Federated learning (FL) is a powerful distributed machine learning framework where a server aggregates models trained by different clients without accessing their private data. Hierarchical FL, with a client-edge-cloud aggregation hierarchy, can effectively leverage both the cloud server's access to many clients' data and the edge servers' closeness to the clients to achieve a high communication efficiency. Neural network quantization can further reduce the communication overhead during model uploading. To fully exploit the advantages of hierarchical FL, an accurate convergence analysis with respect to the key system parameters is needed. Unfortunately, existing analysis is loose and does not consider model quantization. In this paper, we derive a tighter convergence bound for hierarchical FL with quantization. The convergence result leads to practical guidelines for important design problems such as the client-edge aggregation and edge-client association strategies. Based on the obtained analytical results, we optimize the two aggregation intervals and show that the client-edge aggregation interval should slowly decay while the edge-cloud aggregation interval needs to adapt to the ratio of the client-edge and edge-cloud propagation delay. Simulation results shall verify the design guidelines and demonstrate the effectiveness of the proposed aggregation strategy.},
  eventtitle = {{{IEEE Transactions}} on {{Wireless Communications}}},
  keywords = {Convergence,Convergence Analysis,Edge Learning,Federated Learning,Guidelines,Optimization,Quantization (signal),Servers,System analysis and design,Training}
}

@article{liu_IntrusionDetectionMaritime_2022,
  title = {Intrusion {{Detection}} for {{Maritime Transportation Systems With Batch Federated Aggregation}}},
  author = {Liu, Wentao and Xu, Xiaolong and Wu, Lianxiang and Qi, Lianyong and Jolfaei, Alireza and Ding, Weiping and Khosravi, Mohammad R.},
  date = {2022},
  journaltitle = {IEEE Transactions on Intelligent Transportation Systems},
  pages = {1--12},
  issn = {1558-0016},
  doi = {10.1109/TITS.2022.3181436},
  abstract = {As a fast-growing and promising technology, Internet of Things (IoT) significantly promotes the informationization and intelligentization of Maritime Transportation System (MTS). The massive data collected during the voyage is usually disposed of with the assistance of cloud or edge computing, which imposes serious cyber security threats. For multifarious cyber-attacks, Intrusion Detection System (IDS) is one of the efficient mechanisms to prevent IoT devices from network intrusion. However, most of the methods based on deep learning train their models in a centralized manner, which needs uploading all data to the central server for training, increasing the risk of privacy disclosure. In this paper, we consider the characteristics of IoT-based MTS and propose a CNN-MLP based model for intrusion detection which is trained through Federated Learning, named FedBatch. Federated Learning keeps the model training local and only updates the global model through the exchange of model parameters, preserving the privacy of local data on vessels. First, the characteristics of the communication between different vessels are discussed to model the federated learning process during the voyage. Then, the lightweight local model constructed by Convolutional Neural Network (CNN) and Multi-Layer Perception (MLP) is designed to save on computing and storage overhead. Moreover, to mitigate the straggler problem during the federated learning in MTS, we proposed an adaptive aggregation method, named Batch Federated Aggregation, which suppresses the oscillations of model parameters during federated learning. Finally, the simulation results on the NSL-KDD dataset demonstrate the effectiveness and efficiency of FedBatch.},
  eventtitle = {{{IEEE Transactions}} on {{Intelligent Transportation Systems}}},
  keywords = {Collaborative work,Convolutional neural networks,Data models,federated learning,Internet of Things,Intrusion detection,IoT,maritime transportation systems,privacy preservation,Servers,Training}
}

@article{liu_MachineLearningDeep_2019,
  title = {Machine {{Learning}} and {{Deep Learning Methods}} for {{Intrusion Detection Systems}}: {{A Survey}}},
  shorttitle = {Machine {{Learning}} and {{Deep Learning Methods}} for {{Intrusion Detection Systems}}},
  author = {Liu, Hongyu and Lang, Bo},
  date = {2019-10-17},
  journaltitle = {Applied Sciences},
  shortjournal = {Applied Sciences},
  volume = {9},
  number = {20},
  pages = {4396},
  issn = {2076-3417},
  doi = {10.3390/app9204396},
  url = {https://www.mdpi.com/2076-3417/9/20/4396},
  urldate = {2022-03-11},
  abstract = {Networks play important roles in modern life, and cyber security has become a vital research area. An intrusion detection system (IDS) which is an important cyber security technique, monitors the state of software and hardware running in the network. Despite decades of development, existing IDSs still face challenges in improving the detection accuracy, reducing the false alarm rate and detecting unknown attacks. To solve the above problems, many researchers have focused on developing IDSs that capitalize on machine learning methods. Machine learning methods can automatically discover the essential differences between normal data and abnormal data with high accuracy. In addition, machine learning methods have strong generalizability, so they are also able to detect unknown attacks. Deep learning is a branch of machine learning, whose performance is remarkable and has become a research hotspot. This survey proposes a taxonomy of IDS that takes data objects as the main dimension to classify and summarize machine learning-based and deep learning-based IDS literature. We believe that this type of taxonomy framework is fit for cyber security researchers. The survey first clarifies the concept and taxonomy of IDSs. Then, the machine learning algorithms frequently used in IDSs, metrics, and benchmark datasets are introduced. Next, combined with the representative literature, we take the proposed taxonomic system as a baseline and explain how to solve key IDS issues with machine learning and deep learning techniques. Finally, challenges and future developments are discussed by reviewing recent representative studies.},
  langid = {english},
  keywords = {+survey}
}

@unpublished{liu_PrivacyPreservingAggregationFederated_2022,
  title = {Privacy-{{Preserving Aggregation}} in {{Federated Learning}}: {{A Survey}}},
  shorttitle = {Privacy-{{Preserving Aggregation}} in {{Federated Learning}}},
  author = {Liu, Ziyao and Guo, Jiale and Yang, Wenzhuo and Fan, Jiani and Lam, Kwok-Yan and Zhao, Jun},
  date = {2022-07-13},
  eprint = {2203.17005},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2203.17005},
  urldate = {2023-04-03},
  abstract = {Over the recent years, with the increasing adoption of Federated Learning (FL) algorithms and growing concerns over personal data privacy, Privacy-Preserving Federated Learning (PPFL) has attracted tremendous attention from both academia and industry. Practical PPFL typically allows multiple participants to individually train their machine learning models, which are then aggregated to construct a global model in a privacy-preserving manner. As such, Privacy-Preserving Aggregation (PPAgg) as the key protocol in PPFL has received substantial research interest. This survey aims to fill the gap between a large number of studies on PPFL, where PPAgg is adopted to provide a privacy guarantee, and the lack of a comprehensive survey on the PPAgg protocols applied in FL systems. In this survey, we review the PPAgg protocols proposed to address privacy and security issues in FL systems. The focus is placed on the construction of PPAgg protocols with an extensive analysis of the advantages and disadvantages of these selected PPAgg protocols and solutions. Additionally, we discuss the open-source FL frameworks that support PPAgg. Finally, we highlight important challenges and future research directions for applying PPAgg to FL systems and the combination of PPAgg with other technologies for further security improvement.},
  langid = {english},
  keywords = {Computer Science - Cryptography and Security}
}

@inproceedings{liu_ThreelayerSecurityAssurance_2022,
  title = {A {{Three-layer Security Assurance Model}} for a {{Decentralized Federated Learning System}}},
  booktitle = {2022 31st {{Wireless}} and {{Optical Communications Conference}} ({{WOCC}})},
  author = {Liu, Jinyu and Wang, Ziyang and Yang, Qing and Wu, Sissi Xiaoxiao},
  date = {2022-08},
  pages = {85--90},
  issn = {2379-1276},
  doi = {10.1109/WOCC55104.2022.9880591},
  url = {https://ieeexplore.ieee.org/abstract/document/9880591},
  urldate = {2024-04-12},
  abstract = {We focus on the security issues of decentralized federated learning systems for the core requirements of secure environments and trusted computing for applications such as medical big data, distributed cognitive learning, and autonomous driving. We propose a three-layer security assurance model that aims to ensure secure trusted computing in decentralized networks. Therein, the first-layer security model realizes the authentication of trusted users through blockchain technology to ensure the safe access of legitimate users to the greatest extent; the second-layer security model utilizes the trusted execution environment (TEE) technology to realize the privacy protection and trusted computing of each local user; the last layer of security model adopts a set of detection and location algorithms for defending the internal attackers, in case the first two layers of models fail. Our experimental results show that the proposed three-layer security model can effectively defend against external and internal attacks in the network, thereby promoting secure and trusted computing in distributed federated learning networks.},
  eventtitle = {2022 31st {{Wireless}} and {{Optical Communications Conference}} ({{WOCC}})},
  keywords = {blockchain,Collaborative work,Computational modeling,Decentralized federated learning,insider attacker,Privacy,Resists,security assurance,Simulation,Trusted computing,Trusted Execution Environment (TEE),Wireless communication}
}

@article{lo_SystematicLiteratureReview_2021,
  title = {A {{Systematic Literature Review}} on {{Federated Machine Learning}}: {{From A Software Engineering Perspective}}},
  shorttitle = {A {{Systematic Literature Review}} on {{Federated Machine Learning}}},
  author = {Lo, Sin Kit and Lu, Qinghua and Wang, Chen and Paik, Hye-Young and Zhu, Liming},
  date = {2021-06},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {54},
  number = {5},
  eprint = {2007.11354},
  eprinttype = {arXiv},
  pages = {1--39},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3450288},
  url = {http://arxiv.org/abs/2007.11354},
  urldate = {2021-10-04},
  abstract = {Federated learning is an emerging machine learning paradigm where clients train models locally and formulate a global model based on the local model updates. To identify the state-of-the-art in federated learning and explore how to develop federated learning systems, we perform a systematic literature review from a software engineering perspective, based on 231 primary studies. Our data synthesis covers the lifecycle of federated learning system development that includes background understanding, requirement analysis, architecture design, implementation, and evaluation. We highlight and summarise the findings from the results, and identify future trends to encourage researchers to advance their current work.},
  langid = {english},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},\_read,+survey,Computer Science - Machine Learning,Computer Science - Software Engineering}
}

@article{lu_Defensebackdoorattack_2022,
  title = {Defense against Backdoor Attack in Federated Learning},
  author = {Lu, Shiwei and Li, Ruihu and Liu, Wenbin and Chen, Xuan},
  date = {2022-06},
  journaltitle = {Computers \& Security},
  shortjournal = {Computers \& Security},
  pages = {102819},
  issn = {01674048},
  doi = {10.1016/j.cose.2022.102819},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167404822002139},
  urldate = {2022-07-04},
  abstract = {As a new distributed machine learning framework, Federated Learning (FL) effectively solves the problems of data silo and privacy protection in the field of artificial intelligence. However, for its independent devices, heterogeneous data and unbalanced data distribution, it is more vulnerable to adversarial attack, especially backdoor attack. In this paper, we investigate typical backdoor attacks in FL, containing model replacement attack and adaptive backdoor attack. Based on attack initiating round, we divide backdoor attack into convergence-round attack and early-round attack. In addition, we respectively design a defense scheme with model pre-aggregation and similarity measurement to detect and remove backdoor model under convergence-round attack and a defense scheme with backdoor neuron activation to remove backdoor under early-round attack. Experiments and performance analysis show that compared to benchmark schemes, our defense scheme with similarity measurement obtains the highest backdoor detection accuracy under model replacement attack (25\% increase) and adaptive backdoor attack (67\% increase) at the convergence round. Moreover, detection effect is the most stable. Compared to defense of participant-level differential privacy and adversarial training, our defense scheme with backdoor neuron activation can rapidly remove malicious effects of backdoor without reducing the main task accuracy under early-round attack. Thus, the robustness of FL can be improved greatly with our defense schemes. We make our key codes public at Github https://github.com/lsw3130104597/Backdoor\_detection.},
  langid = {english}
}

@inproceedings{lubben_AdvancesMLBasedAnomaly_2021,
  title = {Advances in {{ML-Based Anomaly Detection}} for the {{IoT}}},
  booktitle = {2021 5th {{Cyber Security}} in {{Networking Conference}} ({{CSNet}})},
  author = {Lubben, Christian and Pahl, Marc-Oliver},
  date = {2021-10-12},
  pages = {18--22},
  publisher = {IEEE},
  location = {Abu Dhabi, United Arab Emirates},
  doi = {10/gpbg2d},
  url = {https://ieeexplore.ieee.org/document/9614280/},
  urldate = {2022-01-31},
  abstract = {The Internet of Things drives many activities in our modern world. Through its heterogeneity and connectivity to the Internet, it provides an attractive and big attack surface. Anomaly detection is a central tool for making IoT systems more secure. Since 2017, machine learning is successfully used for anomaly detection. This work gives an overview on the evolution of using machine learning for anomaly detection including the most active research groups, and the most attractive venues. In addition, it discusses the advantages and disadvantages of the available methods based on their use in literature.},
  eventtitle = {2021 5th {{Cyber Security}} in {{Networking Conference}} ({{CSNet}})},
  isbn = {978-1-66540-722-9},
  langid = {english}
}

@inproceedings{lubben_DistributedDeviceSpecificAnomaly_2023,
  title = {Distributed {{Device-Specific Anomaly Detection}} for {{Resource-Constrained Devices}}},
  booktitle = {{{NOMS}} 2023-2023 {{IEEE}}/{{IFIP Network Operations}} and {{Management Symposium}}},
  author = {L\"ubben, Christian and Pahl, Marc-Oliver},
  date = {2023-05-08},
  pages = {1--3},
  publisher = {IEEE},
  location = {Miami, FL, USA},
  doi = {10.1109/NOMS56928.2023.10154372},
  url = {https://ieeexplore.ieee.org/document/10154372/},
  urldate = {2023-10-09},
  abstract = {The Internet of Things (IoT) requires security mechanisms that account for heterogeneous devices and resource constraints. Current Anomaly Detection (AD) approaches typically apply centralized data processing. This lacks scalability as well as privacy, bandwidth consumption, latency, and availability. The combination of device-specific AD models and distributed edge computing provides a solution to these challenges. It allows the creation of simplified, lightweight AD models that run on constrained hardware. The hands-on environment described allows interactive exploration of the impact of model simplification. This includes live evaluation of performance metrics and processing latency on a constrained device.},
  eventtitle = {{{NOMS}} 2023-2023 {{IEEE}}/{{IFIP Network Operations}} and {{Management Symposium}}},
  isbn = {978-1-66547-716-1},
  langid = {english}
}

@thesis{ludinard_Caracterisationlocalefautes_2014,
  type = {Informatique},
  title = {Caract\'erisation locale de fautes dans les syst\`emes large \'echelle},
  author = {Ludinard, Romaric},
  date = {2014},
  institution = {Universit\'e Rennes 1},
  abstract = {Internet est un r\'eseau de r\'eseaux permettant la mise en \oe uvre de divers services consomm\'es par les utilisateurs. Malheureusement, chacun des \'el\'ements pr\'esents dans le r\'eseau ou impliqu\'es dans ces services peut potentiellement exhiber des d\'efaillances. Une d\'efaillance peut \^etre per\c  cue par un nombre variable d'utilisateurs suivant la localisation dans le syst\`eme de la source de celle-ci. Cette th\`ese propose un ensemble de contributions visant \`a d\'eterminer du point de vue d'un utilisateur percevant une d\'efaillance, si celle-ci est per\c cue par un faible nombre d'utilisateurs (d\'efaillance isol\'ee) ou \`a l'inverse par un tr\`es grand nombre d'utilisateurs (d\'efaillance massive). Nous formalisons dans un premier temps les d\'efaillances par leur impact sur la perception des services consomm\'es par les utilisateurs. Nous montrons ainsi qu'il est impossible, du point de vue d'un utilisateur, de d\'eterminer de mani\`ere certaine si une d\'efaillance per\c cue est isol\'ee ou massive. Cependant, il possible de d\'eterminer de mani\`ere certaine pour chaque utilisateur, s'il a per\c cu une d\'efaillance isol\'ee, massive, ou s'il est impossible de le d\'eterminer. Cette caract\'erisation est optimale et totalement parallelisable. Dans un second temps, nous proposons une architecture pour la caract\'erisation de fautes. Les entit\'es du syst\`eme s'organisent au sein d'une structure \`a deux niveaux permettant de regrouper ensemble les entit\'es ayant des perceptions similaires et ainsi mener \`a bien l'approche propos\'ee. Enfin, une analyse probabiliste de la r\'esistance au dynamisme et aux comportements malveillants du second niveau de cette architecture compl\`ete ce document.},
  langid = {french},
  keywords = {â›” No DOI found}
}

@book{ludwig_FederatedLearning_2022,
  title = {Federated {{Learning}}},
  author = {Ludwig, Heiko and Baracaldo, Nathalie},
  date = {2022},
  url = {https://link.springer.com/book/10.1007/978-3-030-96896-0},
  urldate = {2022-08-11},
  abstract = {This book presents an in-depth summary of the most important issues and approaches to Federated Learning (FL) for researchers and practitioners.},
  langid = {english}
}

@inproceedings{lundberg_UnifiedApproachInterpreting_2017,
  title = {A {{Unified Approach}} to {{Interpreting Model Predictions}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Lundberg, Scott M and Lee, Su-In},
  date = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html},
  urldate = {2023-03-11},
  abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
  keywords = {â›” No DOI found}
}

@inproceedings{luo_CostEffectiveFederatedLearning_2021,
  title = {Cost-{{Effective Federated Learning Design}}},
  booktitle = {{{IEEE INFOCOM}} 2021 - {{IEEE Conference}} on {{Computer Communications}}},
  author = {Luo, Bing and Li, Xiang and Wang, Shiqiang and Huang, Jianwei and Tassiulas, Leandros},
  date = {2021-05-10},
  pages = {1--10},
  publisher = {IEEE},
  location = {Vancouver, BC, Canada},
  doi = {10.1109/INFOCOM42981.2021.9488679},
  url = {https://ieeexplore.ieee.org/document/9488679/},
  urldate = {2022-05-25},
  abstract = {Federated learning (FL) is a distributed learning paradigm that enables a large number of devices to collaboratively learn a model without sharing their raw data. Despite its practical efficiency and effectiveness, the iterative on-device learning process incurs a considerable cost in terms of learning time and energy consumption, which depends crucially on the number of selected clients and the number of local iterations in each training round. In this paper, we analyze how to design adaptive FL that optimally chooses these essential control variables to minimize the total cost while ensuring convergence. Theoretically, we analytically establish the relationship between the total cost and the control variables with the convergence upper bound. To efficiently solve the cost minimization problem, we develop a low-cost sampling-based algorithm to learn the convergence related unknown parameters. We derive important solution properties that effectively identify the design principles for different metric preferences. Practically, we evaluate our theoretical results both in a simulated environment and on a hardware prototype. Experimental evidence verifies our derived properties and demonstrates that our proposed solution achieves near-optimal performance for various datasets, different machine learning models, and heterogeneous system settings.},
  eventtitle = {{{IEEE INFOCOM}} 2021 - {{IEEE Conference}} on {{Computer Communications}}},
  isbn = {978-1-66540-325-2},
  langid = {english}
}

@article{lv_MisbehaviorDetectionVehicular_2022,
  title = {Misbehavior {{Detection}} in {{Vehicular Ad Hoc Networks Based}} on {{Privacy-Preserving Federated Learning}} and {{Blockchain}}},
  author = {Lv, Pin and Xie, Linyan and Xu, Jia and Wu, Xu and Li, Taoshen},
  date = {2022-12},
  journaltitle = {IEEE Transactions on Network and Service Management},
  volume = {19},
  number = {4},
  pages = {3936--3948},
  issn = {1932-4537},
  doi = {10.1109/TNSM.2022.3220779},
  url = {https://ieeexplore.ieee.org/abstract/document/9944011},
  urldate = {2024-04-12},
  abstract = {As an irreversible trend, connected vehicles have become increasingly more popular. They depend on the generation and sharing of data between vehicles to improve safety and efficiency of the transportation system. Due to the open feature of the vehicular ad hoc network (VANET), it is possible for dishonest and misbehaving vehicles to disrupt traffic by transmitting false information. In recent years, misbehavior detection systems have been developed to detect the malicious behaviour, and machine learning methods have been employed to make the detection more accurately. However, existing misbehavior detection systems typically require a single entity (e.g., a central server) for centralized data collection and training. Model updates are restricted due to data privacy and high overhead of data communication, which reduces the defensive capability of misbehavior detection systems. In this paper, we propose a blockchain-based federated learning scheme to detect misbehavior, which is trained collaboratively by coordinating multiple distributed edge devices while ensuring data security and privacy. In addition, to further protect the privacy of the model on the blockchain, differential privacy with the Gaussian mechanism is leveraged to provide strict privacy protection. Common data falsification attacks are studied in this paper. The experimental results show that our proposed scheme is feasible and effective, and demonstrate that our scheme achieves satisfied accuracy and efficiency.},
  eventtitle = {{{IEEE Transactions}} on {{Network}} and {{Service Management}}},
  keywords = {blockchain,Blockchains,Data models,differential privacy,federated learning,Federated learning,misbehavior detection,Security,Servers,Training,Vehicular ad hoc networks,Vehicular network}
}

@article{lyu_ThreatsFederatedLearning_2020,
  title = {Threats to {{Federated Learning}}: {{A Survey}}},
  author = {Lyu, Lingjuan and Yu, Han and Yang, Qiang},
  date = {2020-03-04},
  journaltitle = {arXiv},
  url = {http://arxiv.org/abs/2003.02133},
  abstract = {With the emergence of data silos and popular privacy awareness, the traditional centralized approach of training artificial intelligence (AI) models is facing strong challenges. Federated learning (FL) has recently emerged as a promising solution under this new reality. Existing FL protocol design has been shown to exhibit vulnerabilities which can be exploited by adversaries both within and without the system to compromise data privacy. It is thus of paramount importance to make FL system designers to be aware of the implications of future FL algorithm design on privacy-preservation. Currently, there is no survey on this topic. In this paper, we bridge this important gap in FL literature. By providing a concise introduction to the concept of FL, and a unique taxonomy covering threat models and two major attacks on FL: 1) poisoning attacks and 2) inference attacks, this paper provides an accessible review of this important topic. We highlight the intuitions, key techniques as well as fundamental assumptions adopted by various attacks, and discuss promising future research directions towards more robust privacy preservation in FL.},
  keywords = {â›” No DOI found}
}

@article{ma_ApplyingFederatedLearning_2022,
  title = {Applying {{Federated Learning}} in {{Software-Defined Networks}}: {{A Survey}}},
  shorttitle = {Applying {{Federated Learning}} in {{Software-Defined Networks}}},
  author = {Ma, Xiaohang and Liao, Lingxia and Li, Zhi and Lai, Roy Xiaorong and Zhang, Miao},
  date = {2022-01-20},
  journaltitle = {Symmetry},
  shortjournal = {Symmetry},
  volume = {14},
  number = {2},
  pages = {195},
  issn = {2073-8994},
  doi = {10/gpbg4s},
  url = {https://www.mdpi.com/2073-8994/14/2/195},
  urldate = {2022-01-31},
  abstract = {Federated learning (FL) is a type of distributed machine learning approacs that trains global models through the collaboration of participants. It protects data privacy as participants only contribute local models instead of sharing private local data. However, the performance of FL highly relies on the number of participants and their contributions. When applying FL over conventional computer networks, attracting more participants, encouraging participants to contribute more local resources, and enabling efficient and effective collaboration among participants become very challenging. As software-defined networks (SDNs) enable open and flexible networking architecture with separate control and data planes, SDNs provide standardized protocols and specifications to enable fine-grained collaborations among devices. Applying FL approaches over SDNs can take use such advantages to address challenges. A SDN control plane can have multiple controllers organized in layers; the controllers in the lower layer can be placed in the network edge to deal with the asymmetries in the attached switches and hosts, and the controller in the upper layer can supervise the whole network centrally and globally. Applying FL in SDNs with a layered-distributed control plane may be able to protect the data privacy of each participant while improving collaboration among participants to produce higher-quality models over asymmetric networks. Accordingly, this paper aims to make a comprehensive survey on the related mechanisms and solutions that enable FL in SDNs. It highlights three major challenges, an incentive mechanism, privacy and security, and model aggregation, which affect the quality and quantity of participants, the security and privacy in model transferring, and the performance of the global model, respectively. The state of the art in mechanisms and solutions that can be applied to address such challenges in the current literature are categorized based on the challenges they face, followed by suggestions of future research directions. To the best of our knowledge, this work is the first effort in surveying the state of the art in combining FL with SDNs.},
  langid = {english},
  keywords = {+survey}
}

@article{ma_ShieldFLMitigatingModel_2022,
  title = {{{ShieldFL}}: {{Mitigating Model Poisoning Attacks}} in {{Privacy-Preserving Federated Learning}}},
  shorttitle = {{{ShieldFL}}},
  author = {Ma, Zhuoran and Ma, Jianfeng and Miao, Yinbin and Li, Yingjiu and Deng, Robert H.},
  date = {2022},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  shortjournal = {IEEE Trans.Inform.Forensic Secur.},
  volume = {17},
  pages = {1639--1654},
  issn = {1556-6013, 1556-6021},
  doi = {10.1109/TIFS.2022.3169918},
  url = {https://ieeexplore.ieee.org/document/9762272/},
  urldate = {2022-07-05},
  abstract = {Privacy-Preserving Federated Learning (PPFL) is an emerging secure distributed learning paradigm that aggregates user-trained local gradients into a federated model through a cryptographic protocol. Unfortunately, PPFL is vulnerable to model poisoning attacks launched by a Byzantine adversary, who crafts malicious local gradients to harm the accuracy of the federated model. To resist model poisoning attacks, existing defense strategies focus on identifying suspicious local gradients over plaintexts. However, the Byzantine adversary submits encrypted poisonous gradients to circumvent existing defense strategies in PPFL, resulting in encrypted model poisoning. To address the issue, in this paper we design a privacy-preserving defense strategy using two-trapdoor homomorphic encryption (referred to as ShieldFL), which can resist encrypted model poisoning without compromising privacy in PPFL. Specially, we first present the secure cosine similarity method aiming to measure the distance between two encrypted gradients. Then, we propose the Byzantine-tolerance aggregation using cosine similarity, which can achieve robustness for both Independently Identically Distribution (IID) and non-IID data. Extensive evaluations on three benchmark datasets (i.e., MNIST, KDDCup99, and Amazon) show that ShieldFL outperforms existing defense strategies. Especially, ShieldFL can achieve 30\%-80\% accuracy improvement to defend two state-of-the-art model poisoning attacks in both non-IID and IID settings.},
  langid = {english}
}

@inproceedings{madala_FederatedLearningApproach_2022a,
  title = {Federated {{Learning Approach}} for {{Tracking Malicious Activities}} in {{Cyber-Physical Systems}}},
  booktitle = {2022 {{International Conference}} on {{Edge Computing}} and {{Applications}} ({{ICECAA}})},
  author = {Madala, Chandu Jagan Sekhar and Yadav, G. Hemanth Kumar and Sivakumar, S. and Nithya, R. and M, Manjunatha K and Deivakani, M.},
  date = {2022-10},
  pages = {494--499},
  doi = {10.1109/ICECAA55415.2022.9936285},
  url = {https://ieeexplore.ieee.org/abstract/document/9936285},
  urldate = {2024-04-12},
  abstract = {The fast rise of the Internet and advanced technologies causes an increase in network traffic, making network infrastructure increasingly complicated and varied. Mobile phones, wearable gadgets, and driverless cars are all instances of dispersed networks that create massive amounts of data every day. The processing capability of these devices has also increased steadily, necessitating the need to transport data, store data locally, and direct network calculations to edge devices. Intrusion detection systems are essential in guaranteeing the safety and confidentiality of such equipment. Deep Learning (DL) combined Intrusion Detection Systems (IDS) have gained prominence due to their excellent categorization accuracy. However, the requirement to store and communicate data to a centralized server may jeopardize privacy and security concerns. Federated learning (FL), on the other hand, fits in nicely as private information decentralized learning approach that does not transport data but instead trains algorithms locally and sends the parameters to a centralized server. This work targets to offer an extensive overview of the FL in intrusion detection systems.},
  eventtitle = {2022 {{International Conference}} on {{Edge Computing}} and {{Applications}} ({{ICECAA}})},
  keywords = {Computational modeling,confidentiality,Federated learning,intrusion,Intrusion detection,learning,network evaluation,Target tracking,Telecommunication traffic,Training,Training data}
}

@inproceedings{magdy_AnonymousblockchainBased_2020,
  title = {Anonymous Blockchain {{Based Routing For Moving-target Defense Across Federated Clouds}}},
  booktitle = {2020 {{IEEE}} 21st {{International Conference}} on {{High Performance Switching}} and {{Routing}} ({{HPSR}})},
  author = {Magdy, Yousra and Kashkoush, Mona S. and Azab, Mohamed and Rizk, Mohamed R. M.},
  date = {2020-05},
  pages = {1--7},
  issn = {2325-5609},
  doi = {10.1109/HPSR48589.2020.9098983},
  abstract = {Cloud federation is the evolution of modern cloud computing. It provides better resource-sharing, perfect resource-utilization, and load-balancing. However, the heterogeneity of security policies and configurations between cloud service providers makes it hard for users to totally trust them. Further, the severe impact of modern cloud attacks such as cross-side channels on federated environments is a major roadblock against such evolution. Securing users' capsules (Virtual Machines and containers) against cross-side channel attacks is considered as a big challenge to cloud service providers. Moving-target Defense (MtD) by live capsule migration was introduced as an effective mechanism to overcome such challenge. However, researchers noted that even with MtD, migrated capsules can still be tracked via routing information. In this paper, we propose a novel Blockchain-based routing mechanism to enable trace-resistant Moving-target Defence (BMtD) to enable anonymous live cross-cloud migrations of running capsules in federated cloud environments. Exploiting the Vulnerable, Exposed, Attacked, Recovered (VEAR) model, simulation results demonstrated the effectiveness of BMtD in minimizing viral attack dispersion.},
  eventtitle = {2020 {{IEEE}} 21st {{International Conference}} on {{High Performance Switching}} and {{Routing}} ({{HPSR}})},
  keywords = {Blockchain,Cloud computing,Cloud Federation,Containers,IP networks,Light Linux Virtualization,Moving target defense,Public key,Routing}
}

@article{magnani_EnhancingNetworkIntrusion_,
  title = {Enhancing {{Network Intrusion Detection}}: {{An Online Methodology}} for {{Performance Analysis}}},
  author = {Magnani, Simone and Doriguzzi-Corin, Roberto and Siracusa, Domenico},
  abstract = {Machine learning models have been extensively proposed for classifying network flows as benign or malicious, either in-network or at the endpoints of the infrastructure. Typically, the performance of such models is assessed by evaluating the trained model against a portion of the available dataset. However, in a production scenario, these models are fed by a monitoring stage that collects information from flows and provides inputs to a filtering stage that eventually blocks malicious traffic. To the best of our knowledge, no work has analysed the entire pipeline, focusing on its performance in terms of both inputs (i.e., the information collected from each flow) and outputs (i.e., the system's ability to prevent an attack from reaching the application layer).},
  langid = {english},
  keywords = {\_read\_urgently,â›” No DOI found}
}

@article{mahmoodi_AutonomousFederatedLearning_2023,
  title = {Autonomous {{Federated Learning}} for {{Distributed Intrusion Detection Systems}} in {{Public Networks}}},
  author = {Mahmoodi, Alireza Bakhshi Zadi and Sheikhi, Saeid and Peltonen, Ella and Kostakos, Panos},
  date = {2023},
  journaltitle = {IEEE Access},
  volume = {11},
  pages = {121325--121339},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3327922},
  url = {https://ieeexplore.ieee.org/document/10296918},
  urldate = {2024-04-12},
  abstract = {The rapid integration of IoT, cloud, and edge computing has resulted in highly interconnected networks, emphasizing the need for advanced Intrusion Detection Systems (IDS) to maintain security. Successful AI-based IDS relies on high-quality data for model training. Even though a vast array of datasets from controlled settings are accessible, many fall short as they are outdated and lack the representative data of network traffic dynamics typically seen in public networks. This paper aims to advance understanding in designing testbed architectures for defense mechanisms within public networks. At its core, this research introduces a unique testbed utilizing the connectivity of panOULU Municipal public network in the city of Oulu, Finland. This experimental setup examines AI-driven security across the public network. It utilizes edge-to-cloud infrastructures, incorporating Software-Defined Networking (SDN) and Network Function Virtualization (NFV) via the VMware vSphere platform. During the training phase, a script distinguishes incoming packets as either benign or malicious based on well-defined local parameters and simulated attack scenarios. This labeled data is then utilized for training machine learning models within the Federated Learning framework, FED-ML. Subsequently, these models are evaluated on previously unseen data. The entire procedure, from traffic gathering to model training, operates without human involvement. The evaluation dataset and testbed configuration we have made publicly available through this research can deepen our understanding of the challenges in safeguarding public networks, especially those that blend various technologies in diverse environments.},
  eventtitle = {{{IEEE Access}}},
  keywords = {cybersecurity,data engineering,Data models,distributed computing,federated learning,Internet of Things,Intrusion detection,Network security,Protocols,Security,stream processing,Telecommunication traffic,Training}
}

@inproceedings{mai_ContentCentricControlPlane_2019a,
  title = {Towards {{Content-Centric Control Plane Supporting Efficient Anomaly Detection Functions}}},
  booktitle = {2019 15th {{International Conference}} on {{Network}} and {{Service Management}} ({{CNSM}})},
  author = {Mai, Hoang Long and Doyen, Guillaume and Mallouli, Wissam and family=Oca, given=Edgardo Montes, prefix=de, useprefix=true and Festor, Olivier},
  date = {2019-10},
  pages = {1--9},
  issn = {2165-963X},
  doi = {10.23919/CNSM46954.2019.9012668},
  abstract = {Anomaly detection remains a challenging task due to both the ever more complex functions that need to be executed and the evolution of current networking devices which induces limitation of computational resources such as the Internet of Things (IoT). Furthermore, results of anomaly function computations can be repeated gradually over time or executed in neighboring nodes, thus leading to a waste of such limited computing resources in constrained nodes. To tackle these issues, the content-centric paradigm enhanced with computing features offers a promising solution to reduce the computation resources and finally improve the scalability of anomaly detection functions. In this paper, we propose a first step toward a content-oriented control plane which enables the distribution of the processing and the sharing of results of anomaly detection functions in the network. We present the way we leverage NFN to support Bayesian Network inference to detect anomalies in network traffic. The relevance and performance of our proposed approach are demonstrated by considering the Content Poisoning Attack (CPA) through numerous experiment data.},
  eventtitle = {2019 15th {{International Conference}} on {{Network}} and {{Service Management}} ({{CNSM}})},
  keywords = {Anomaly detection,Bayes methods,Bayesian Network,Computer architecture,Distributed anomaly detection,Inference algorithms,Internet of Things,Named Function Networking,Random variables,Security}
}

@inproceedings{majeed_FLchainFederatedLearning_2019,
  title = {{{FLchain}}: {{Federated Learning}} via {{MEC-enabled Blockchain Network}}},
  booktitle = {2019 20th {{Asia-Pacific Network Operations}} and {{Management Symposium}} ({{APNOMS}})},
  author = {Majeed, Umer and Hong, Choong Seon},
  date = {2019-09},
  pages = {1--4},
  publisher = {IEEE},
  doi = {10.23919/APNOMS.2019.8892848},
  url = {https://ieeexplore.ieee.org/document/8892848/},
  abstract = {In this paper, we propose blockchain network based architecture called 'FLchain' for enhancing security of Federated Learning (FL). We leverage the concept of channels for learning multiple global models on FLchain. Local model parameters for each global iteration are stored as a block on the channel-specific ledger. We introduce the notion of 'the global model state trie' which is stored and updated on the blockchain network based on the aggregation of local model updates collected from mobile devices. Qualitative evaluation shows that FLchain is more robust than traditional FL schemes as it ensures provenance and maintains auditable aspects of FL model in an immutable manner.},
  isbn = {978-4-88552-320-5}
}

@inproceedings{manhaeve_DeepProbLogNeuralProbabilistic_2018,
  title = {{{DeepProbLog}}: {{Neural Probabilistic Logic Programming}}},
  shorttitle = {{{DeepProbLog}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Manhaeve, Robin and Dumancic, Sebastijan and Kimmig, Angelika and Demeester, Thomas and De Raedt, Luc},
  date = {2018},
  volume = {31},
  publisher = {Curran Associates, Inc.},
  url = {https://papers.nips.cc/paper/2018/hash/dc5d637ed5e62c36ecb73b654b05ba2a-Abstract.html},
  urldate = {2024-07-01},
  abstract = {We introduce DeepProbLog, a probabilistic logic programming language that incorporates deep learning by means of neural predicates. We show how existing inference and learning techniques can be adapted for the new language. Our experiments demonstrate that DeepProbLog supports (i) both symbolic and subsymbolic representations and inference, (ii) program induction, (iii) probabilistic (logic) programming, and (iv) (deep) learning from examples. To the best of our knowledge, this work is the first to propose a framework where general-purpose neural networks and expressive probabilistic-logical modeling and reasoning are integrated in a way that exploits the full expressiveness and strengths of both worlds and can be trained end-to-end based on examples.}
}

@article{manhaeve_Neuralprobabilisticlogic_2021,
  title = {Neural Probabilistic Logic Programming in {{DeepProbLog}}},
  author = {Manhaeve, Robin and Duman\v ci\'c, Sebastijan and Kimmig, Angelika and Demeester, Thomas and De Raedt, Luc},
  date = {2021-09-01},
  journaltitle = {Artificial Intelligence},
  shortjournal = {Artificial Intelligence},
  volume = {298},
  pages = {103504},
  issn = {0004-3702},
  doi = {10.1016/j.artint.2021.103504},
  url = {https://www.sciencedirect.com/science/article/pii/S0004370221000552},
  urldate = {2024-07-01},
  abstract = {We introduce DeepProbLog, a neural probabilistic logic programming language that incorporates deep learning by means of neural predicates. We show how existing inference and learning techniques of the underlying probabilistic logic programming language ProbLog can be adapted for the new language. We theoretically and experimentally demonstrate that DeepProbLog supports (i) both symbolic and subsymbolic representations and inference, (ii) program induction, (iii) probabilistic (logic) programming, and (iv) (deep) learning from examples. To the best of our knowledge, this work is the first to propose a framework where general-purpose neural networks and expressive probabilistic-logical modeling and reasoning are integrated in a way that exploits the full expressiveness and strengths of both worlds and can be trained end-to-end based on examples.},
  keywords = {Learning and reasoning,Logic,Neural networks,Neuro-symbolic integration,Probabilistic logic programming,Probability}
}

@inproceedings{manyadza_FLfinderDetectingUnknown_2022,
  title = {{{FL-finder}}: {{Detecting Unknown Network Anomaly}} in {{Federated Learning}}},
  shorttitle = {{{FL-finder}}},
  booktitle = {2022 5th {{International Conference}} on {{Artificial Intelligence}} and {{Big Data}} ({{ICAIBD}})},
  author = {Manyadza, Tinashe Justice and Du, Haizhou and Wang, Shiwei and Yang, Wenbin and Chen, Cheng and Tian, Fei},
  date = {2022-05},
  pages = {593--597},
  doi = {10.1109/ICAIBD55127.2022.9820480},
  abstract = {The emergence of federated learning has ensured data and privacy security in deep learning models while enabling models to train more efficiently. However, the transmission of network parameters in federated learning may be subject to attacks by unknown anomalies. In this paper, we attempted to detect unknown anomalies in transmitted parameters in federated learning. We designed and implemented F1-finder, an unknown network anomaly detection framework in federated learning, which detects anomalies based on incremental learning. It retains the unknown anomalies to its prior knowledge base using the network updater, and adopts an online mode that reports new anomalies in a real-time. Extensive experimental results show that our model increased the average accuracy of unknown anomaly detection by 10.4\% and the average F1-Score improved to 19\%.},
  eventtitle = {2022 5th {{International Conference}} on {{Artificial Intelligence}} and {{Big Data}} ({{ICAIBD}})},
  keywords = {Collaborative work,Data models,Detectors,Energy consumption,Federated Learning,Incremental learning,Knowledge based systems,Learning (artificial intelligence),Prior Knowledge,Real-time systems,Unknown Anomaly Detection}
}

@inproceedings{manyadza_FLfinderDetectingUnknown_2022a,
  title = {{{FL-finder}}: {{Detecting Unknown Network Anomaly}} in {{Federated Learning}}},
  shorttitle = {{{FL-finder}}},
  booktitle = {2022 5th {{International Conference}} on {{Artificial Intelligence}} and {{Big Data}} ({{ICAIBD}})},
  author = {Manyadza, Tinashe Justice and Du, Haizhou and Wang, Shiwei and Yang, Wenbin and Chen, Cheng and Tian, Fei},
  date = {2022-05},
  pages = {593--597},
  doi = {10.1109/ICAIBD55127.2022.9820480},
  abstract = {The emergence of federated learning has ensured data and privacy security in deep learning models while enabling models to train more efficiently. However, the transmission of network parameters in federated learning may be subject to attacks by unknown anomalies. In this paper, we attempted to detect unknown anomalies in transmitted parameters in federated learning. We designed and implemented F1-finder, an unknown network anomaly detection framework in federated learning, which detects anomalies based on incremental learning. It retains the unknown anomalies to its prior knowledge base using the network updater, and adopts an online mode that reports new anomalies in a real-time. Extensive experimental results show that our model increased the average accuracy of unknown anomaly detection by 10.4\% and the average F1-Score improved to 19\%.},
  eventtitle = {2022 5th {{International Conference}} on {{Artificial Intelligence}} and {{Big Data}} ({{ICAIBD}})},
  keywords = {Collaborative work,Data models,Detectors,Energy consumption,Federated Learning,Incremental learning,Knowledge based systems,Learning (artificial intelligence),Prior Knowledge,Real-time systems,Unknown Anomaly Detection}
}

@inproceedings{manyadza_FLfinderDetectingUnknown_2022b,
  title = {{{FL-finder}}: {{Detecting Unknown Network Anomaly}} in {{Federated Learning}}},
  shorttitle = {{{FL-finder}}},
  booktitle = {2022 5th {{International Conference}} on {{Artificial Intelligence}} and {{Big Data}} ({{ICAIBD}})},
  author = {Manyadza, Tinashe Justice and Du, Haizhou and Wang, Shiwei and Yang, Wenbin and Chen, Cheng and Tian, Fei},
  date = {2022-05},
  pages = {593--597},
  doi = {10.1109/ICAIBD55127.2022.9820480},
  url = {https://ieeexplore.ieee.org/abstract/document/9820480},
  urldate = {2024-04-12},
  abstract = {The emergence of federated learning has ensured data and privacy security in deep learning models while enabling models to train more efficiently. However, the transmission of network parameters in federated learning may be subject to attacks by unknown anomalies. In this paper, we attempted to detect unknown anomalies in transmitted parameters in federated learning. We designed and implemented F1-finder, an unknown network anomaly detection framework in federated learning, which detects anomalies based on incremental learning. It retains the unknown anomalies to its prior knowledge base using the network updater, and adopts an online mode that reports new anomalies in a real-time. Extensive experimental results show that our model increased the average accuracy of unknown anomaly detection by 10.4\% and the average F1-Score improved to 19\%.},
  eventtitle = {2022 5th {{International Conference}} on {{Artificial Intelligence}} and {{Big Data}} ({{ICAIBD}})},
  keywords = {Collaborative work,Data models,Detectors,Energy consumption,Federated Learning,Incremental learning,Knowledge based systems,Learning (artificial intelligence),Prior Knowledge,Real-time systems,Unknown Anomaly Detection}
}

@inproceedings{mao_RomoaRobustModel_2021,
  title = {Romoa: {{Robust Model Aggregation}} for the {{Resistance}} of {{Federated Learning}} to {{Model Poisoning Attacks}}},
  shorttitle = {Romoa},
  booktitle = {Computer {{Security}} -- {{ESORICS}} 2021},
  author = {Mao, Yunlong and Yuan, Xinyu and Zhao, Xinyang and Zhong, Sheng},
  editor = {Bertino, Elisa and Shulman, Haya and Waidner, Michael},
  date = {2021},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {476--496},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-88418-5_23},
  abstract = {Training a deep neural network requires substantial data and intensive computing resources. Unaffordable price holds back many potential applications of deep learning. Besides, it is risky to gather user's private data for training centrally. Then federated learning appears as a promising solution to having users learned jointly while keeping training data local. However, security issues keep coming up in federated learning applications. One of the most threatening attacks is the model poisoning attack which can manipulate the inference result of a jointly learned model. Some recent studies show that elaborate model poisoning approaches can even breach the existing Byzantine-robust federated learning solutions. Hence, it is critical to discuss alternative solutions to secure federated learning. In this paper, we propose to protect federated learning against model poisoning attacks by introducing a robust model aggregation solution named Romoa. Unlike previous studies, Romoa can deal with targeted and untargeted poisoning attacks with a unified approach. Moreover, Romoa achieves more precise attack detection and better fairness for federated learning participants by constructing a new similarity measurement. We conclude that through a comprehensive evaluation of standard datasets, Romoa can provide a satisfying defense effect against model poisoning attacks, including those attacks breaching Byzantine-robust federated learning solutions.},
  isbn = {978-3-030-88418-5},
  langid = {english},
  keywords = {Federated learning,Model poisoning attack,Robust model aggregation}
}

@article{marchal_AuDIAutonomousIoT_2019,
  title = {{{AuDI}}: {{Toward Autonomous IoT Device-Type Identification Using Periodic Communication}}},
  shorttitle = {{{AuDI}}},
  author = {Marchal, Samuel and Miettinen, Markus and Nguyen, Thien Duc and Sadeghi, Ahmad-Reza and Asokan, N.},
  date = {2019-06},
  journaltitle = {IEEE Journal on Selected Areas in Communications},
  shortjournal = {IEEE J. Select. Areas Commun.},
  volume = {37},
  number = {6},
  pages = {1402--1412},
  issn = {0733-8716, 1558-0008},
  doi = {10.1109/JSAC.2019.2904364},
  url = {https://ieeexplore.ieee.org/document/8664655/},
  urldate = {2021-06-04},
  abstract = {IoT devices are being widely deployed. But the huge variance among them in the level of security and requirements for network resources makes it unfeasible to manage IoT networks using a common generic policy. One solution to this challenge is to define policies for classes of devices based on device type. In this paper, we present AUDI, a system for quickly and effectively identifying the type of a device in an IoT network by analyzing their network communications. AUDI models the periodic communication traffic of IoT devices using an unsupervised learning method to perform identification. In contrast to prior work, AUDI operates autonomously after initial setup, learning, without human intervention nor labeled data, to identify previously unseen device types. AUDI can identify the type of a device in any mode of operation or stage of lifecycle of the device. Via systematic experiments using 33 off-the-shelf IoT devices, we show that AUDI is effective (98.2\% accuracy).},
  langid = {english}
}

@inproceedings{marfo_NetworkAnomalyDetection_2022,
  title = {Network {{Anomaly Detection Using Federated Learning}}},
  booktitle = {{{MILCOM}} 2022 - 2022 {{IEEE Military Communications Conference}} ({{MILCOM}})},
  author = {Marfo, William and Tosh, Deepak K. and Moore, Shirley V.},
  date = {2022-11},
  pages = {484--489},
  issn = {2155-7586},
  doi = {10.1109/MILCOM55135.2022.10017793},
  url = {https://ieeexplore.ieee.org/abstract/document/10017793},
  urldate = {2024-04-12},
  abstract = {Due to the veracity and heterogeneity in network traffic, detecting anomalous events is challenging. The computational load on global servers is a significant challenge in terms of efficiency, accuracy, and scalability. Our primary motivation is to introduce a robust and scalable framework that enables efficient network anomaly detection. We address the issue of scalability and efficiency for network anomaly detection by leveraging federated learning, in which multiple participants train a global model jointly. Unlike centralized training architectures, federated learning does not require participants to upload their training data to the server, preventing attackers from exploiting the training data. Moreover, most prior works have focused on traditional centralized machine learning, making federated machine learning under-explored in network anomaly detection. Therefore, we propose a deep neural network framework that could work on low to mid-end devices detecting network anomalies while checking if a request from a specific IP address is malicious or not. Compared to multiple traditional centralized machine learning models, the deep neural federated model reduces training time overhead. The proposed method performs better than baseline machine learning techniques on the UNSW-NB15 data set as measured by experiments conducted with an accuracy of 97.21\% and a faster computation time.},
  eventtitle = {{{MILCOM}} 2022 - 2022 {{IEEE Military Communications Conference}} ({{MILCOM}})},
  keywords = {Anomaly Detection,Artificial Intelligence,Computational modeling,Deep Learning,Federated learning,Federated Learning,Machine Learning,Networks,Performance evaluation,Scalability,Security Attacks,Telecommunication traffic,Training,Training data}
}

@article{marmolcampos_Misbehaviordetectionintelligent_2024,
  title = {Misbehavior Detection in Intelligent Transportation Systems Based on Federated Learning},
  author = {M\'armol Campos, Enrique and Hernandez-Ramos, Jos\'e L. and Gonz\'alez Vidal, Aurora and Baldini, Gianmarco and Skarmeta, Antonio},
  date = {2024-04-01},
  journaltitle = {Internet of Things},
  shortjournal = {Internet of Things},
  volume = {25},
  pages = {101127},
  issn = {2542-6605},
  doi = {10.1016/j.iot.2024.101127},
  url = {https://www.sciencedirect.com/science/article/pii/S2542660524000696},
  urldate = {2024-04-12},
  abstract = {Misbehavior detection represents a key security approach in vehicular scenarios to identify attacks that cannot be detected by traditional cryptographic mechanisms. In this context, the application of Machine Learning (ML) techniques has been widely considered to identify increasingly sophisticated misbehavior attacks. However, most of the proposed approaches are based on centralized settings, which could pose privacy issues, as well as an increased latency leading to severe consequences in the vehicular environment where real-time and scalability requirements are challenging. To address this issue, we propose a collaborative learning approach based on Federated Learning (FL) for vehicles' misbehavior detection. We use the reference misbehavior dataset VeReMi, which is re-balanced by applying the SMOTE-Tomek technique. We carry out a thorough evaluation considering different balancing settings and number of nodes. The evaluation results overcome recent state-of-the-art approaches, with an overall accuracy of 93\% using an optimized multilayer perceptron (MLP) for multiclass classification.},
  keywords = {Federated learning,Intelligent transportation systems,Misbehavior detection}
}

@article{martins_HostbasedIDSreview_2022,
  title = {Host-Based {{IDS}}: {{A}} Review and Open Issues of an Anomaly Detection System in {{IoT}}},
  shorttitle = {Host-Based {{IDS}}},
  author = {Martins, In\^es and Resende, Jo\~ao S. and Sousa, Patr\'icia R. and Silva, Sim\~ao and Antunes, Lu\'is and Gama, Jo\~ao},
  date = {2022-08},
  journaltitle = {Future Generation Computer Systems},
  shortjournal = {Future Generation Computer Systems},
  volume = {133},
  pages = {95--113},
  issn = {0167739X},
  doi = {10.1016/j.future.2022.03.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X22000760},
  urldate = {2022-03-23},
  abstract = {The Internet of Things (IoT) envisions a smart environment powered by connectivity and heterogeneity where ensuring reliable services and communications across multiple industries, from financial fields to healthcare and fault detection systems, is a top priority. In such fields, data is being collected and broadcast at high speed on a continuous and real-time scale, including IoT in the streaming processing paradigm. Intrusion Detection Systems (IDS) rely on manually defined security policies and signatures that fail to design a real-time solution or prevent zero-day attacks. Therefore, anomaly detection appears as a prominent solution capable of recognizing patterns, learning from experience, and detecting abnormal behavior. However, most approaches do not fit the urged requirements, often evaluated on deprecated datasets not representative of the working environment. As a result, our contributions address an overview of cybersecurity threats in IoT, important recommendations for a real-time IDS, and a real-time dataset setting to evaluate a security system covering multiple cyber threats. The dataset used to evaluate current host-based IDS approaches is publicly available and can be used as a benchmark by the community.},
  langid = {english},
  keywords = {\_read,+survey}
}

@article{maseer_BenchmarkingMachineLearning_2021,
  title = {Benchmarking of {{Machine Learning}} for {{Anomaly Based Intrusion Detection Systems}} in the {{CICIDS2017 Dataset}}},
  author = {Maseer, Ziadoon Kamil and Yusof, Robiah and Bahaman, Nazrulazhar and Mostafa, Salama A. and Foozy, Cik Feresa Mohd},
  date = {2021},
  journaltitle = {IEEE Access},
  volume = {9},
  pages = {22351--22370},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2021.3056614},
  abstract = {An intrusion detection system (IDS) is an important protection instrument for detecting complex network attacks. Various machine learning (ML) or deep learning (DL) algorithms have been proposed for implementing anomaly-based IDS (AIDS). Our review of the AIDS literature identifies some issues in related work, including the randomness of the selected algorithms, parameters, and testing criteria, the application of old datasets, or shallow analyses and validation of the results. This paper comprehensively reviews previous studies on AIDS by using a set of criteria with different datasets and types of attacks to set benchmarking outcomes that can reveal the suitable AIDS algorithms, parameters, and testing criteria. Specifically, this paper applies 10 popular supervised and unsupervised ML algorithms for identifying effective and efficient ML-AIDS of networks and computers. These supervised ML algorithms include the artificial neural network (ANN), decision tree (DT), k-nearest neighbor (k-NN), naive Bayes (NB), random forest (RF), support vector machine (SVM), and convolutional neural network (CNN) algorithms, whereas the unsupervised ML algorithms include the expectation-maximization (EM), k-means, and self-organizing maps (SOM) algorithms. Several models of these algorithms are introduced, and the turning and training parameters of each algorithm are examined to achieve an optimal classifier evaluation. Unlike previous studies, this study evaluates the performance of AIDS by measuring the true positive and negative rates, accuracy, precision, recall, and F-Score of 31 ML-AIDS models. The training and testing time for ML-AIDS models are also considered in measuring their performance efficiency given that time complexity is an important factor in AIDSs. The ML-AIDS models are tested by using a recent and highly unbalanced multiclass CICIDS2017 dataset that involves real-world network attacks. In general, the k-NN-AIDS, DT-AIDS, and NB-AIDS models obtain the best results and show a greater capability in detecting web attacks compared with other models that demonstrate irregular and inferior results.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Benchmark testing,Classification algorithms,Cyberattacks,Feature extraction,intrusion detection system,machine learning,Radio frequency,Self-organizing feature maps,supervised and unsupervised learning,Support vector machines,Training}
}

@inproceedings{mathur_SWaTwatertreatment_2016,
  title = {{{SWaT}}: A Water Treatment Testbed for Research and Training on {{ICS}} Security},
  shorttitle = {{{SWaT}}},
  booktitle = {2016 {{International Workshop}} on {{Cyber-physical Systems}} for {{Smart Water Networks}} ({{CySWater}})},
  author = {Mathur, Aditya P. and Tippenhauer, Nils Ole},
  date = {2016-04-11},
  pages = {31--36},
  publisher = {IEEE},
  location = {Vienna, Austria},
  doi = {10.1109/CySWater.2016.7469060},
  url = {http://ieeexplore.ieee.org/document/7469060/},
  urldate = {2021-05-19},
  abstract = {This paper presents the SWaT testbed, a modern industrial control system (ICS) for security research and training. SWaT is currently in use to (a) understand the impact of cyber and physical attacks on a water treatment system, (b) assess the effectiveness of attack detection algorithms, (c) assess the effectiveness of defense mechanisms when the system is under attack, and (d) understand the cascading effects of failures in one ICS on another dependent ICS. SWaT consists of a 6-stage water treatment process, each stage is autonomously controlled by a local PLC. The local fieldbus communications between sensors, actuators, and PLCs is realized through alternative wired and wireless channels. While the experience with the testbed indicates its value in conducting research in an active and realistic environment, it also points to design limitations that make it difficult for system identification and attack detection in some experiments.},
  eventtitle = {2016 {{International Workshop}} on {{Cyber-physical Systems}} for {{Smart Water Networks}} ({{CySWater}})},
  isbn = {978-1-5090-1161-2},
  langid = {english}
}

@inproceedings{mbow_AdvancesAdversarialAttacks_2022,
  title = {Advances in~{{Adversarial Attacks}} and~{{Defenses}} in~{{Intrusion Detection System}}: {{A Survey}}},
  shorttitle = {Advances in~{{Adversarial Attacks}} and~{{Defenses}} in~{{Intrusion Detection System}}},
  booktitle = {Science of {{Cyber Security}} - {{SciSec}} 2022 {{Workshops}}},
  author = {Mbow, Mariama and Sakurai, Kouichi and Koide, Hiroshi},
  editor = {Su, Chunhua and Sakurai, Kouichi},
  date = {2022},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {196--212},
  publisher = {Springer Nature},
  location = {Singapore},
  doi = {10.1007/978-981-19-7769-5_15},
  abstract = {Machine learning is one of the predominant methods used in computer science and has been widely and successfully applied in many areas such as computer vision, pattern recognition, natural language processing, cyber security etc. In cyber security, the application of machine learning algorithms for network intrusion detection system (NIDS) has seen promising results for anomaly detection mostly with the adoption of deep learning and is still growing. However, machine learning algorithms are vulnerable to adversarial attacks resulting in significant performance degradation. Adversarial attacks are security threats that aim to deceive the learning algorithm by manipulating its predictions, and Adversarial machine learning is a research area that studies both the generation and defense of such attacks. Researchers have extensively worked on the adversarial machine learning in computer vision but not many works in Intrusion detection system. However, failure in this critical Intrusion detection area could compromise the security of an entire system, and need much attention. This paper provides a review of the advancement in adversarial machine learning based intrusion detection and explores the various defense techniques applied against. Finally discuss their limitations for future research direction in this emerging area.},
  isbn = {978-981-19776-9-5},
  langid = {english},
  keywords = {Adversarial attack,Cyber security,Deep learning,Evasion attack,Intrusion detection,Machine learning,Poisoning attack}
}

@inproceedings{mcmahan_Communicationefficientlearningdeep_2017,
  title = {Communication-Efficient Learning of Deep Networks from Decentralized Data},
  booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
  author = {McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and family=Arcas, given=Blaise Aguera, prefix=y, useprefix=false},
  editor = {Singh, Aarti and Zhu, Jerry},
  date = {2017-04-20/2017-04-22},
  series = {Proceedings of Machine Learning Research},
  volume = {54},
  pages = {1273--1282},
  publisher = {PMLR},
  url = {https://proceedings.mlr.press/v54/mcmahan17a.html},
  abstract = {Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches. We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning. We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10-100x as compared to synchronized stochastic gradient descent.}
}

@inproceedings{medina_BRITEapproachuniversal_2001,
  title = {{{BRITE}}: An Approach to Universal Topology Generation},
  shorttitle = {{{BRITE}}},
  booktitle = {{{MASCOTS}} 2001, {{Proceedings Ninth International Symposium}} on {{Modeling}}, {{Analysis}} and {{Simulation}} of {{Computer}} and {{Telecommunication Systems}}},
  author = {Medina, A. and Lakhina, A. and Matta, I. and Byers, J.},
  date = {2001-08},
  pages = {346--353},
  issn = {1526-7639},
  doi = {10.1109/MASCOT.2001.948886},
  abstract = {Effective engineering of the Internet is predicated upon a detailed understanding of issues such as the large-scale structure of its underlying physical topology, the manner in which it evolves over time, and the way in which its constituent components contribute to its overall function. Unfortunately, developing a deep understanding of these issues has proven to be a challenging task, since it in turn involves solving difficult problems such as mapping the actual topology, characterizing it, and developing models that capture its emergent behavior. Consequently, even though there are a number of topology models, it is an open question as to how representative the generated topologies they generate are of the actual Internet. Our goal is to produce a topology generation framework which improves the state of the art and is based on the design principles of representativeness, inclusiveness, and interoperability. Representativeness leads to synthetic topologies that accurately reflect many aspects of the actual Internet topology (e.g. hierarchical structure, node degree distribution, etc.). Inclusiveness combines the strengths of as many generation models as possible in a single generation tool. Interoperability provides interfaces to widely-used simulation applications such as ns and SSF and visualization tools like otter. We call such a tool a universal topology generator.},
  eventtitle = {{{MASCOTS}} 2001, {{Proceedings Ninth International Symposium}} on {{Modeling}}, {{Analysis}} and {{Simulation}} of {{Computer}} and {{Telecommunication Systems}}},
  keywords = {Bandwidth,Character generation,Computer science,Engineering profession,Internet,IP networks,Large-scale systems,Network topology,Protocols,Visualization}
}

@article{medina_originpowerlaws_2000,
  title = {On the Origin of Power Laws in {{Internet}} Topologies},
  author = {Medina, Alberto and Matta, Ibrahim and Byers, John},
  date = {2000-04-01},
  journaltitle = {ACM SIGCOMM Computer Communication Review},
  shortjournal = {SIGCOMM Comput. Commun. Rev.},
  volume = {30},
  number = {2},
  pages = {18--28},
  issn = {0146-4833},
  doi = {10.1145/505680.505683},
  url = {https://doi.org/10.1145/505680.505683},
  urldate = {2023-02-08},
  abstract = {Recent empirical studies [6] have shown that Internet topologies exhibit power laws of the form y = x {$\alpha$} for the following relationships: (P1) outdegree of node (domain or router) versus rank; (P2) number of nodes versus outdegree; (P3) number of node pairs within a neighborhood versus neighborhood size (in hops); and (P4) eigenvalues of the adjacency matrix versus rank. However, causes for the appearance of such power laws have not been convincingly given. In this paper, we examine four factors in the formation of Internet topologies. These factors are (F1) preferential connectivity of a new node to existing nodes; (F2) incremental growth of the network; (F3) distribution of nodes in space; and (F4) locality of edge connections. In synthetically generated network topologies, we study the relevance of each factor in causing the aforementioned power laws as well as other properties, namely diameter, average path length and clustering coefficient. Different kinds of network topologies are generated: (T1) topologies generated using our parametrized generator, we call BRITE; (T2) random topologies generated using the well-known Waxman model [12]; (T3) Transit-Stub topologies generated using GT-ITM tool [3]; and (T4) regular grid topologies. We observe that some generated topologies may not obey power laws P1 and P2. Thus, the existence of these power laws can be used to validate the accuracy of a given tool in generating representative Internet topologies. Power laws P3 and P4 were observed in nearly all considered topologies, but different topologies showed different values of the power exponent {$\alpha$}. Thus, while the presence of power laws P3 and P4 do not give strong evidence for the representativeness of a generated topology, the value of {$\alpha$} in P3 and P4 can be used as a litmus test for the representativeness of a generated topology. We also find that factors F1 and F2 are the key contributors in our study which provide the resemblance of our generated topologies to that of the Internet.}
}

@article{meidan_NBaIoTNetworkbasedDetection_2018,
  title = {N-{{BaIoT}}: {{Network-based Detection}} of {{IoT Botnet Attacks Using Deep Autoencoders}}},
  shorttitle = {N-{{BaIoT}}},
  author = {Meidan, Yair and Bohadana, Michael and Mathov, Yael and Mirsky, Yisroel and Breitenbacher, Dominik and Shabtai, Asaf and Elovici, Yuval},
  date = {2018-07},
  journaltitle = {IEEE Pervasive Computing},
  shortjournal = {IEEE Pervasive Comput.},
  volume = {17},
  number = {3},
  eprint = {1805.03409},
  eprinttype = {arXiv},
  pages = {12--22},
  issn = {1536-1268, 1558-2590},
  doi = {10.1109/MPRV.2018.03367731},
  url = {http://arxiv.org/abs/1805.03409},
  urldate = {2021-10-23},
  abstract = {The proliferation of IoT devices which can be more easily compromised than desktop computers has led to an increase in the occurrence of IoT-based botnet attacks. In order to mitigate this new threat there is a need to develop new methods for detecting attacks launched from compromised IoT devices and differentiate between hour and millisecond long IoT-based attacks. In this paper we propose and empirically evaluate a novel network-based anomaly detection method which extracts behavior snapshots of the network and uses deep autoencoders to detect anomalous network traffic emanating from compromised IoT devices. To evaluate our method, we infected nine commercial IoT devices in our lab with two of the most widely known IoT-based botnets, Mirai and BASHLITE. Our evaluation results demonstrated our proposed method's ability to accurately and instantly detect the attacks as they were being launched from the compromised IoT devices which were part of a botnet.},
  langid = {english},
  keywords = {68U35,Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@article{meng_CollaborativeSecuritySurvey_2015,
  title = {Collaborative {{Security}}: {{A Survey}} and {{Taxonomy}}},
  shorttitle = {Collaborative {{Security}}},
  author = {Meng, Guozhu and Liu, Yang and Zhang, Jie and Pokluda, Alexander and Boutaba, Raouf},
  date = {2015-07-22},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {48},
  number = {1},
  pages = {1:1--1:42},
  issn = {0360-0300},
  doi = {10.1145/2785733},
  url = {https://doi.org/10.1145/2785733},
  urldate = {2024-06-22},
  abstract = {Security is oftentimes centrally managed. An alternative trend of using collaboration in order to improve security has gained momentum over the past few years. Collaborative security is an abstract concept that applies to a wide variety of systems and has been used to solve security issues inherent in distributed environments. Thus far, collaboration has been used in many domains such as intrusion detection, spam filtering, botnet resistance, and vulnerability detection. In this survey, we focus on different mechanisms of collaboration and defense in collaborative security. We systematically investigate numerous use cases of collaborative security by covering six types of security systems. Aspects of these systems are thoroughly studied, including their technologies, standards, frameworks, strengths and weaknesses. We then present a comprehensive study with respect to their analysis target, timeliness of analysis, architecture, network infrastructure, initiative, shared information and interoperability. We highlight five important topics in collaborative security, and identify challenges and possible directions for future research. Our work contributes the following to the existing research on collaborative security with the goal of helping to make collaborative security systems more resilient and efficient. This study (1) clarifies the scope of collaborative security, (2) identifies the essential components of collaborative security, (3) analyzes the multiple mechanisms of collaborative security, and (4) identifies challenges in the design of collaborative security.},
  keywords = {+survey,Collaborative security,information sharing,intrusion detection,malware,privacy,spam,taxonomy,trust}
}

@article{meng_WhenIntrusionDetection_2018,
  title = {When {{Intrusion Detection Meets Blockchain Technology}}: {{A Review}}},
  author = {Meng, Weizhi and Tischhauser, Elmar Wolfgang and Wang, Qingju and Wang, Yu and Han, Jinguang},
  date = {2018},
  journaltitle = {IEEE Access},
  volume = {6},
  pages = {10179--10188},
  publisher = {IEEE},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2018.2799854},
  url = {http://ieeexplore.ieee.org/document/8274922/},
  abstract = {With the purpose of identifying cyber threats and possible incidents, intrusion detection systems (IDSs) are widely deployed in various computer networks. In order to enhance the detection capability of a single IDS, collaborative intrusion detection networks (or collaborative IDSs) have been developed, which allow IDS nodes to exchange data with each other. However, data and trust management still remain two challenges for current detection architectures, which may degrade the effectiveness of such detection systems. In recent years, blockchain technology has shown its adaptability in many fields, such as supply chain management, international payment, interbanking, and so on. As blockchain can protect the integrity of data storage and ensure process transparency, it has a potential to be applied to intrusion detection domain. Motivated by this, this paper provides a review regarding the intersection of IDSs and blockchains. In particular, we introduce the background of intrusion detection and blockchain, discuss the applicability of blockchain to intrusion detection, and identify open challenges in this direction.}
}

@inproceedings{merzouk_Parameterizingpoisoningattacks_2023,
  title = {Parameterizing Poisoning Attacks in Federated Learning-Based Intrusion Detection},
  booktitle = {Proceedings of the 18th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Merzouk, Mohamed Amine and Cuppens, Fr\'ed\'eric and Boulahia-Cuppens, Nora and Yaich, Reda},
  date = {2023-08-29},
  series = {{{ARES}} '23},
  pages = {1--8},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3600160.3605090},
  url = {https://dl.acm.org/doi/10.1145/3600160.3605090},
  urldate = {2024-01-29},
  abstract = {Federated learning is a promising research direction in network intrusion detection. It enables collaborative training of machine learning models without revealing sensitive data. However, the lack of transparency in federated learning creates a security threat. Since the server cannot ensure the clients' reliability by analyzing their data, malicious clients have the opportunity to insert a backdoor in the model and activate it to evade detection. To maximize their chances of success, adversaries must fine-tune the attack parameters. Here we evaluate the impact of four attack parameters on the effectiveness, stealthiness, consistency, and timing of data poisoning attacks. Our results show that each parameter is decisive for the success of poisoning attacks, provided they are carefully adjusted to avoid damaging the model's accuracy or the data's consistency. Our findings serve as guidelines for the security evaluation of federated learning systems and insights for defense strategies. Our experiments are carried out on the UNSW-NB15 dataset, and their implementation is available in a public code repository.},
  isbn = {9798400707728},
  keywords = {adversarial attack,backdoor,data poisoning,federated learning,intrusion detection,obsidian}
}

@inproceedings{merzouk_Parameterizingpoisoningattacks_2023a,
  title = {Parameterizing Poisoning Attacks in Federated Learning-Based Intrusion Detection},
  booktitle = {Proceedings of the 18th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Merzouk, Mohamed Amine and Cuppens, Fr\'ed\'eric and Boulahia-Cuppens, Nora and Yaich, Reda},
  date = {2023-08-29},
  series = {{{ARES}} '23},
  pages = {1--8},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3600160.3605090},
  url = {https://dl.acm.org/doi/10.1145/3600160.3605090},
  urldate = {2024-04-12},
  abstract = {Federated learning is a promising research direction in network intrusion detection. It enables collaborative training of machine learning models without revealing sensitive data. However, the lack of transparency in federated learning creates a security threat. Since the server cannot ensure the clients' reliability by analyzing their data, malicious clients have the opportunity to insert a backdoor in the model and activate it to evade detection. To maximize their chances of success, adversaries must fine-tune the attack parameters. Here we evaluate the impact of four attack parameters on the effectiveness, stealthiness, consistency, and timing of data poisoning attacks. Our results show that each parameter is decisive for the success of poisoning attacks, provided they are carefully adjusted to avoid damaging the model's accuracy or the data's consistency. Our findings serve as guidelines for the security evaluation of federated learning systems and insights for defense strategies. Our experiments are carried out on the UNSW-NB15 dataset, and their implementation is available in a public code repository.},
  isbn = {9798400707728},
  keywords = {adversarial attack,backdoor,data poisoning,federated learning,intrusion detection}
}

@article{miao_PrivacyPreservingByzantineRobustFederated_2022,
  title = {Privacy-{{Preserving Byzantine-Robust Federated Learning}} via {{Blockchain Systems}}},
  author = {Miao, Yinbin and Liu, Ziteng and Li, Hongwei and Choo, Kim-Kwang Raymond and Deng, Robert H.},
  date = {2022},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  pages = {1--1},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2022.3196274},
  abstract = {Federated learning enables clients to train a machine learning model jointly without sharing their local data. However, due to the centrality of federated learning framework and the untrustworthiness of clients, traditional federated learning solutions are vulnerable to poisoning attacks from malicious clients and servers. In this paper, we aim to mitigate the impact of the central server and malicious clients by designing a Privacy-preserving Byzantine-robust Federated Learning (PBFL) scheme based on blockchain. Specifically, we use cosine similarity to judge the malicious gradients uploaded by malicious clients. Then, we adopt fully homomorphic encryption to provide secure aggregation. Finally, we use blockchain system to facilitate transparent processes and implementation of regulations. Our formal analysis proves that our scheme achieves convergence and provides privacy protection. Our extensive experiments on different datasets demonstrate that our scheme is robust and efficient. Even if the root dataset is small, our scheme can achieve the same efficiency as FedSGD.},
  eventtitle = {{{IEEE Transactions}} on {{Information Forensics}} and {{Security}}},
  keywords = {blockchain,Blockchain,Blockchains,Collaborative work,Computational modeling,Federated learning,Federated Learning,fully homomorphic encryption,Fully Homomorphic Encryption,poisoning attacks,Poisoning Attacks,Privacy,Resists,Servers,Training}
}

@article{miao_PrivacyPreservingByzantineRobustFederated_2022a,
  title = {Privacy-{{Preserving Byzantine-Robust Federated Learning}} via {{Blockchain Systems}}},
  author = {Miao, Yinbin and Liu, Ziteng and Li, Hongwei and Choo, Kim-Kwang Raymond and Deng, Robert H.},
  date = {2022},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  volume = {17},
  pages = {2848--2861},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2022.3196274},
  abstract = {Federated learning enables clients to train a machine learning model jointly without sharing their local data. However, due to the centrality of federated learning framework and the untrustworthiness of clients, traditional federated learning solutions are vulnerable to poisoning attacks from malicious clients and servers. In this paper, we aim to mitigate the impact of the central server and malicious clients by designing a Privacy-preserving Byzantine-robust Federated Learning (PBFL) scheme based on blockchain. Specifically, we use cosine similarity to judge the malicious gradients uploaded by malicious clients. Then, we adopt fully homomorphic encryption to provide secure aggregation. Finally, we use blockchain system to facilitate transparent processes and implementation of regulations. Our formal analysis proves that our scheme achieves convergence and provides privacy protection. Our extensive experiments on different datasets demonstrate that our scheme is robust and efficient. Even if the root dataset is small, our scheme can achieve the same efficiency as FedSGD.},
  eventtitle = {{{IEEE Transactions}} on {{Information Forensics}} and {{Security}}},
  keywords = {blockchain,Blockchains,Collaborative work,Computational modeling,Federated learning,fully homomorphic encryption,poisoning attacks,Privacy,Resists,Servers,Training}
}

@article{michel_Metricscommunitydynamics_[review],
  title = {Metrics for Community Dynamics Applied to Unsupervised Attacks Detection},
  author = {Michel, Julien and Parrend, Pierre},
  year = {[review]},
  abstract = {Attack detection in big networks has become a necessity. Yet, with the ever changing threat landscape and massive amount of data to handle, network intrusion detection systems (NIDS) end up being obsolete. Different machine-learning-based solutions have been developed to answer the detection problem for data with evolving statistical distributions. However, no approach has proved to be both scalable and robust to passing time. In this paper, we propose a scalable and unsupervised approach to detect behavioral patterns without prior knowledge on the nature of attacks. For this purpose, we define novel metrics for graph community dynamics and use them as feature with unsupervised detection algorithm on the UGR'16 dataset. The proposed approach improves existing detection algorithms by 285,56\% in precision and 222,82\% in recall when compared to usual feature extraction (FE) using isolation forest.},
  langid = {english},
  keywords = {\_done,\_unpublished,â›” No DOI found}
}

@article{milenkoski_EvaluatingComputerIntrusion_2015,
  title = {Evaluating {{Computer Intrusion Detection Systems}}: {{A Survey}} of {{Common Practices}}},
  shorttitle = {Evaluating {{Computer Intrusion Detection Systems}}},
  author = {Milenkoski, Aleksandar and Vieira, Marco and Kounev, Samuel and Avritzer, Alberto and Payne, Bryan D.},
  date = {2015-09-29},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {48},
  number = {1},
  pages = {12:1--12:41},
  issn = {0360-0300},
  doi = {10.1145/2808691},
  url = {https://doi.org/10.1145/2808691},
  urldate = {2023-03-04},
  abstract = {The evaluation of computer intrusion detection systems (which we refer to as intrusion detection systems) is an active research area. In this article, we survey and systematize common practices in the area of evaluation of such systems. For this purpose, we define a design space structured into three parts: workload, metrics, and measurement methodology. We then provide an overview of the common practices in evaluation of intrusion detection systems by surveying evaluation approaches and methods related to each part of the design space. Finally, we discuss open issues and challenges focusing on evaluation methodologies for novel intrusion detection systems.},
  keywords = {Computer intrusion detection systems,measurement methodology,metrics,workload generation}
}

@article{minh_explainablebydesignensemblelearning_[review],
  title = {An Explainable-by-Design Ensemble Learning System to Detect Unknown Network Attacks},
  author = {Minh, Celine and Vermeulen, Kevin and Lefebvre, Cedric and Owezarski, Philippe and Ritchie, William},
  year = {[review]},
  abstract = {Machine learning is a promising technology for network intrusion detection systems. There is a wide variety of machine learning algorithms whose results seem complementary, but determining which result is true is difficult because models lack explainability. Our system intends to reconstruct attack patterns from a set of unsupervised learning models' outputs, and show them to security analysts. Therefore, we introduce an explainable-by-design system to detect network attacks, and evaluated its accuracy on the CSE-CIC-IDS2018 dataset [1].},
  langid = {english},
  keywords = {\_done,\_unpublished,â›” No DOI found}
}

@online{mirai_tracker,
  title = {Mirai {{Tracker}}},
  author = {{Anonym}},
  date = {2019},
  url = {https://mirai.security.gives/},
  urldate = {2021-03-12},
  keywords = {pinned}
}

@inproceedings{mirzaee_CHFLCollaborativeHierarchical_2022,
  title = {{{CHFL}}: {{A Collaborative Hierarchical Federated Intrusion Detection System}} for {{Vehicular Networks}}},
  shorttitle = {{{CHFL}}},
  booktitle = {2022 {{IEEE Symposium}} on {{Computers}} and {{Communications}} ({{ISCC}})},
  author = {Mirzaee, Parya Haji and Shojafar, Mohammad and Cruickshank, Haitham and Tafazolli, Rahim},
  date = {2022-06},
  pages = {1--7},
  issn = {2642-7389},
  doi = {10.1109/ISCC55528.2022.9913013},
  url = {https://ieeexplore.ieee.org/document/9913013},
  urldate = {2024-06-11},
  abstract = {Wireless interfaces, remote control schemes, and increased autonomy have raised the attacks surface of vehicular networks. As powerful monitoring entities, intrusion detection systems (IDS) must be updated and customised to respond to emerging networks' requirements. As server-based monitoring schemes were prone to significant privacy concerns, new privacy constrained learning methods such as federated learning (FL) have received considerable attention in designing IDS. However, to alleviate the efficiency and enhance the scalability of the original FL, this paper proposes a novel collaborative hierarchical federated IDS, named CHFL for the vehicular network. In the CHFL model, a group of vehicles assisted by vehicle-to-everything (V2X) communication technologies can exchange intrusion detection information collaboratively in a private format. Each group nominates a leader, and the leading vehicle serves as the intermediate in the second level detection system of the hierarchical federated model. The leader communicates directly with the server to transmit and receive model updates of its nearby end vehicles. By reducing the number of direct communications to the server, our proposed system reduces network uplink traffic and queuing-processing latency. In addition, CHFL improved the prediction loss and the accuracy of the whole system. We are achieving an accuracy of 99.10\% compared with 97.01 \% accuracy of the original FL.},
  eventtitle = {2022 {{IEEE Symposium}} on {{Computers}} and {{Communications}} ({{ISCC}})},
  keywords = {Collaboration,Collaborative Learning,Federated Learning (FL),Intrusion detection,Intrusion Detection System (IDS),Machine Learning (ML),Privacy,Scalability,Servers,Uplink,Vehicular Networks,Wireless communication}
}

@article{mirzaee_FIDSFederatedIntrusion_2021,
  title = {{{FIDS}}: {{A Federated Intrusion Detection System}} for {{5G Smart Metering Network}}},
  author = {Mirzaee, Parya Haji and Shojafar, Mohammad and Pooranian, Zahra and Asef, Pedram and Cruickshank, Haitham and Tafazolli, Rahim},
  date = {2021},
  pages = {8},
  abstract = {In a critical infrastructure such as Smart Grid (SG), providing security of the system and privacy of consumers are significant challenges to be considered. The SG developers adopt Machine Learning (ML) algorithms within the Intrusion Detection System (IDS) to monitor traffic data and network performance. This visibility safeguards the SG from possible intrusions or attacks that may trigger the system. However, it requires access to residents' consumption information which is a severe threat to their privacy. In this paper, we present a novel method to detect abnormalities on a large scale SG while preserving the privacy of users. We design a Federated IDS (FIDS) architecture using Federated Learning (FL) in a 5G environment for the SG metering network. In this way, we design Federated Deep Neural Network (FDNN) model that protects customers' information and provides supervisory management for the whole energy distribution network. Simulation results for a real-time dataset demonstrate the reasonable improvement of the proposed FDNN model compared with the state-of-the-art algorithms. The FDNN achieves approximately 99.5\% accuracy, 99.5\% precision/recall, and 99.5\% f1-score when comparing with classification algorithms.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@online{mo_PPFLPrivacypreservingFederated_2021,
  title = {{{PPFL}}: {{Privacy-preserving Federated Learning}} with {{Trusted Execution Environments}}},
  shorttitle = {{{PPFL}}},
  author = {Mo, Fan and Haddadi, Hamed and Katevas, Kleomenis and Marin, Eduard and Perino, Diego and Kourtellis, Nicolas},
  date = {2021-06-28},
  eprint = {2104.14380},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2104.14380},
  urldate = {2023-04-03},
  abstract = {We propose and implement a Privacy-preserving Federated Learning ({$PPF$} {$L$}) framework for mobile systems to limit privacy leakages in federated learning. Leveraging the widespread presence of Trusted Execution Environments (TEEs) in high-end and mobile devices, we utilize TEEs on clients for local training, and on servers for secure aggregation, so that model/gradient updates are hidden from adversaries. Challenged by the limited memory size of current TEEs, we leverage greedy layer-wise training to train each model's layer inside the trusted area until its convergence. The performance evaluation of our implementation shows that {$PPF$} {$L$} can significantly improve privacy while incurring small system overheads at the client-side. In particular, {$PPF$} {$L$} can successfully defend the trained model against data reconstruction, property inference, and membership inference attacks. Furthermore, it can achieve comparable model utility with fewer communication rounds (0.54\texttimes ) and a similar amount of network traffic (1.002\texttimes ) compared to the standard federated learning of a complete model. This is achieved while only introducing up to {$\sim$}15\% CPU time, {$\sim$}18\% memory usage, and {$\sim$}21\% energy consumption overhead in {$PPF$} {$L$}'s client-side.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@article{mohanta_SurveyIoTsecurity_2020,
  title = {Survey on {{IoT}} Security: {{Challenges}} and Solution Using Machine Learning, Artificial Intelligence and Blockchain Technology},
  author = {Mohanta, Bhabendu Kumar and Jena, Debasish and Satapathy, Utkalika and Patnaik, Srikanta},
  date = {2020-09},
  journaltitle = {Internet of Things},
  volume = {11},
  pages = {100227},
  publisher = {Elsevier B.V.},
  issn = {25426605},
  doi = {10.1016/j.iot.2020.100227},
  url = {https://doi.org/10.1016/j.iot.2020.100227},
  abstract = {Internet of Things (IoT) is one of the most rapidly used technologies in the last decade in various applications. The smart things are connected in wireless or wired for communication, processing, computing, and monitoring different real-time scenarios. The things are heterogeneous and have low memory, less processing power. The implementation of the IoT system comes with security and privacy challenges because traditional based existing security protocols do not suitable for IoT devices. In this survey, the authors initially described an overview of the IoT technology and the area of its application. The primary security issue CIA (confidentially, Integrity, Availability) and layer-wise issues are identified. Then the authors systematically study the three primary technology Machine learning(ML), Artificial intelligence(AI), and Blockchain for addressing the security issue in IoT. In the end, an analysis of this survey, security issues solved by the ML, AI, and Blockchain with research challenges are mention.}
}

@article{mohanty_efficientLightweightintegrated_2020,
  title = {An Efficient {{Lightweight}} Integrated {{Blockchain}} ({{ELIB}}) Model for {{IoT}} Security and Privacy},
  author = {Mohanty, Sachi Nandan and Ramya, K.C. and Rani, S. Sheeba and Gupta, Deepak and Shankar, K. and Lakshmanaprabu, S.K. and Khanna, Ashish},
  date = {2020-01},
  journaltitle = {Future Generation Computer Systems},
  volume = {102},
  pages = {1027--1037},
  publisher = {Elsevier B.V.},
  issn = {0167739X},
  doi = {10.1016/j.future.2019.09.050},
  url = {https://doi.org/10.1016/j.future.2019.09.050},
  abstract = {Presently, BlockChain (BC) gained significant interest because of its undeniable nature and related advantages of security and privacy, BC has the power to resolve the limitations of Internet of Things (IoT) such as data protection and privacy. At the same time, BC has high computation complexity, restricted scalability, high bandwidth overhead and latency that is unsuitable to IoT. In this paper, efficient Lightweight integrated Blockchain (ELIB) model is developed to meet necessitates of IoT. The presented model is deployed in a smart home environment as an important illustration to verify its applicability in various IoT scenarios. The resource constrained resources in a smart home takes the advantages from a centralized manager which generates shared keys to transmit data, process every incoming and outgoing requests. The presented ELIB model generates an overlay network where highly equipped resources can merges to a public BC which verifies dedicated security and privacy. A set of three optimizations are carried out in the presented ELIB model include lightweight consensus algorithm, certificateless (CC) cryptography and Distributed Throughput Management (DTM) scheme. A detailed simulation takes place under different scenarios in terms of processing time, energy usage and overhead. The ELIB attains a total of 50\% saving in processing time on comparing to baseline method with the minimum energy consumption of 0.07mJ. The obtained experimental outcome indicated that the ELIB shows maximum performance under several evaluation parameters.}
}

@inproceedings{mokry_EfficientPrivacyPreservingCollaborative_2021,
  title = {Efficient and {{Privacy-Preserving Collaborative Intrusion Detection Using Additive Secret Sharing}} and {{Differential Privacy}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  author = {Mokry, Laylon and Slife, Paul and Bishop, Patrick and Quiroz, Jose and Guzzi, Cooper and Chen, Zhiyuan and Crainiceanu, Adina and Needham, Don},
  date = {2021-12-15},
  pages = {3324--3333},
  publisher = {IEEE},
  location = {Orlando, FL, USA},
  doi = {10.1109/BigData52589.2021.9671428},
  url = {https://ieeexplore.ieee.org/document/9671428/},
  urldate = {2022-01-31},
  abstract = {Intrusion Detection Systems are commonly used by organizations to monitor network traffic and detect attacks or suspicious behaviours. However, many attacks occur across organizations and are often difficult to detect using any single IDS. Collaborative Intrusion Detection Systems could lead to more accurate prediction and detection of cyber threats as well as a reduction of security administrators' workload as similar threats from different places can be merged. However, most organizations are unwilling to disclose sensitive information about their internal network topology and traffic, lending these systems unusable. Existing solutions using homomorphic encryption and secure multi-party computation are often expensive. In this paper, we propose efficient and privacy preserving techniques to correlate alerts generated at different organizations. We propose skP rototypes, a distributed clustering algorithm for horizontally partitioned mixed data using additive secret sharing. This algorithm can be used to create a privacy preserving, collaborative intrusion detection system. We also propose dpkP rototypes which uses differential privacy on categorical attributes and is more efficient than skP rototypes for categorical attributes with many distinct values. Theoretical and experimental results validate the effectiveness of our algorithms.},
  eventtitle = {2021 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  isbn = {978-1-66543-902-2},
  langid = {english}
}

@online{mondal_FlateeFederatedLearning_2021,
  title = {Flatee: {{Federated Learning Across Trusted Execution Environments}}},
  shorttitle = {Flatee},
  author = {Mondal, Arup and More, Yash and Rooparaghunath, Ruthu Hulikal and Gupta, Debayan},
  date = {2021-11-12},
  eprint = {2111.06867},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2111.06867},
  urldate = {2023-04-03},
  abstract = {Federated learning allows us to distributively train a machine learning model where multiple parties share local model parameters without sharing private data. However, parameter exchange may still leak information. Several approaches have been proposed to overcome this, based on multi-party computation, fully homomorphic encryption, etc.; many of these protocols are slow and impractical for real-world use as they involve a large number of cryptographic operations. In this paper, we propose the use of Trusted Execution Environments (TEE), which provide a platform for isolated execution of code and handling of data, for this purpose. We describe Flatee, an efficient privacy-preserving federated learning framework across TEEs, which considerably reduces training and communication time. Our framework can handle malicious parties (we do not natively solve adversarial data poisoning, though we describe a preliminary approach to handle this).},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security}
}

@incollection{morris_IndustrialControlSystem_2014,
  title = {Industrial {{Control System Traffic Data Sets}} for {{Intrusion Detection Research}}},
  booktitle = {Progress in {{Pattern Recognition}}, {{Image Analysis}}, {{Computer Vision}}, and {{Applications}}},
  author = {Morris, Thomas and Gao, Wei},
  editor = {Bayro-Corrochano, Eduardo and Hancock, Edwin},
  date = {2014},
  volume = {8827},
  pages = {65--78},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-662-45355-1_5},
  url = {http://link.springer.com/10.1007/978-3-662-45355-1_5},
  urldate = {2021-06-10},
  abstract = {Supervisory control and data acquisition (SCADA) systems monitor and control physical processes associated with the critical infrastructure. Weaknesses in the application layer protocols, however, leave SCADA networks vulnerable to attack. In response, cyber security researchers have developed myriad intrusion detection systems. Researchers primarily rely on unique threat models and the corresponding network traffic data sets to train and validate their intrusion detection systems. This leads to a situation in which researchers cannot independently verify the results, cannot compare the effectiveness of different instruction detection systems, and cannot adequately validate the ability of intrusion detection systems to detect various classes of attacks. Indeed, a common data set is needed that can be used by researchers to compare intrusion detection approaches and implementations. This paper describes four data sets, which include network traffic, process control and process measurement features from a set of 28 attacks against two laboratory-scale industrial control systems that use the MODBUS application layer protocol. The data sets, which are freely available, enable effective comparisons of intrusion detection solutions for SCADA systems.},
  isbn = {978-3-319-12567-1 978-3-319-12568-8},
  langid = {english}
}

@inproceedings{mothukuri_CloudFLZeroTouchFederated_2022,
  title = {{{CloudFL}}: {{A Zero-Touch Federated Learning Framework}} for {{Privacy-aware Sensor Cloud}}},
  shorttitle = {{{CloudFL}}},
  booktitle = {Proceedings of the 17th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Mothukuri, Viraaji and Parizi, Reza M. and Pouriyeh, Seyedamin and Mashhadi, Afra},
  date = {2022-08-23},
  series = {{{ARES}} '22},
  pages = {1--8},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3538969.3543783},
  url = {https://doi.org/10.1145/3538969.3543783},
  urldate = {2022-08-23},
  abstract = {Intelligent sensing solutions bridge the gap between the physical world and the cyber-physical systems by digitizing the sensor data collected from sensor devices. Sensor cloud networks provide physical and virtual sensing device resources and enable uninterrupted intelligent solutions to end-users. Thanks to advancements in machine learning algorithms and big data, the automation of mundane tasks with artificial intelligence is becoming a reliable smart option. However, existing approaches based on centralized Machine Learning (ML) on sensor cloud networks fail to ensure data privacy. Moreover, centralized ML works with the pre-requisite to transfer the entire training dataset from end devices to a central server. To address this, we propose a Quantized Federated Learning (FL) based approach, called CloudFL, to ensure data privacy on end devices in a sensor cloud network. Our framework enables a personalized version of FL implementation and enhances privacy and security with cryptosystem tools to obfuscate the information of the FL process from unauthorized access. Furthermore, microservices of our approach provide software as a service implementation of FL with instances of cloud servers that require zero-touch on local data for training.},
  isbn = {978-1-4503-9670-7},
  keywords = {Decentralized machine learning,Federated Learning,Privacy,Quantization,Security.,Sensor cloud}
}

@article{mothukuri_FederatedLearningbasedAnomaly_2021,
  title = {Federated {{Learning-based Anomaly Detection}} for {{IoT Security Attacks}}},
  author = {Mothukuri, Viraaji and Khare, Prachi and Parizi, Reza M. and Pouriyeh, Seyedamin and Dehghantanha, Ali and Srivastava, Gautam},
  date = {2021},
  journaltitle = {IEEE Internet of Things Journal},
  pages = {1--1},
  issn = {2327-4662},
  doi = {10/gmhhmw},
  abstract = {The Internet of Things (IoT) is made up of billions of physical devices connected to the Internet via networks that perform tasks independently with less human intervention. Such brilliant automation of mundane tasks requires a considerable amount of user data in digital format, which in turn makes IoT networks an open-source of Personally Identifiable Information data for malicious attackers to steal, manipulate and perform nefarious activities. Huge interest has developed over the past years in applying machine learning (ML)-assisted approaches in the IoT security space. However, the assumption in many current works is that big training data is widely available and transferable to the main server because data is born at the edge and is generated continuously by IoT devices. This is to say that classic ML works on the legacy set of entire data located on a central server, which makes it the least preferred option for domains with privacy concerns on user data. To address this issue, we propose federated learning (FL)-based anomaly detection approach to proactively recognize intrusion in IoT networks using decentralized on-device data. Our approach uses federated training rounds on Gated Recurrent Units (GRUs) models and keeps the data intact on local IoT devices by sharing only the learned weights with the central server of the FL. Also, the approach's ensembler part aggregates the updates from multiple sources to optimize the global ML model's accuracy. Our experimental results demonstrate that our approach outperforms the classic/centralized machine learning (non-FL) versions in securing the privacy of user data and provides an optimal accuracy rate in attack detection.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {\_read,Anomaly detection,Computer architecture,Data models,Federated Learning,Gated Recurrent Units.,Internet of Things,Logic gates,Recurrent neural networks,Security,Servers,Training}
}

@article{mothukuri_surveysecurityprivacy_2021,
  title = {A Survey on Security and Privacy of Federated Learning},
  author = {Mothukuri, Viraaji and Parizi, Reza M. and Pouriyeh, Seyedamin and Huang, Yan and Dehghantanha, Ali and Srivastava, Gautam},
  date = {2021-02},
  journaltitle = {Future Generation Computer Systems},
  volume = {115},
  pages = {619--640},
  publisher = {Elsevier B.V.},
  issn = {0167739X},
  doi = {10.1016/j.future.2020.10.007},
  url = {https://doi.org/10.1016/j.future.2020.10.007},
  abstract = {Federated learning (FL) is a new breed of Artificial Intelligence (AI) that builds upon decentralized data and training that brings learning to the edge or directly on-device. FL is a new research area often referred to as a new dawn in AI, is in its infancy, and has not yet gained much trust in the community, mainly because of its (unknown) security and privacy implications. To advance the state of the research in this area and to realize extensive utilization of the FL approach and its mass adoption, its security and privacy concerns must be first identified, evaluated, and documented. FL is preferred in use-cases where security and privacy are the key concerns and having a clear view and understanding of risk factors enable an implementer/adopter of FL to successfully build a secure environment and gives researchers a clear vision on possible research areas. This paper aims to provide a comprehensive study concerning FL's security and privacy aspects that can help bridge the gap between the current state of federated AI and a future in which mass adoption is possible. We present an illustrative description of approaches and various implementation styles with an examination of the current challenges in FL and establish a detailed review of security and privacy concerns that need to be considered in a thorough and clear context. Findings from our study suggest that overall there are fewer privacy-specific threats associated with FL compared to security threats. The most specific security threats currently are communication bottlenecks, poisoning, and backdoor attacks while inference-based attacks are the most critical to the privacy of FL. We conclude the paper with much needed future research directions to make FL adaptable in realistic scenarios.}
}

@article{moustafa_DFSatDeepFederated_2022,
  title = {{{DFSat}}: {{Deep Federated Learning}} for {{Identifying Cyber Threats}} in {{IoT-based Satellite Networks}}},
  shorttitle = {{{DFSat}}},
  author = {Moustafa, Nour and Khan, Izhar Ahmed and Hassanin, Mohammed and Ormrod, David and Pi, Dechang and Razzak, Imran and Slay, Jill},
  date = {2022},
  journaltitle = {IEEE Transactions on Industrial Informatics},
  pages = {1--8},
  issn = {1941-0050},
  doi = {10.1109/TII.2022.3214652},
  url = {https://ieeexplore.ieee.org/abstract/document/9925589},
  urldate = {2024-04-12},
  abstract = {The integration of satellite systems with smart computing and networking technologies, such as the Internet of Things (IoT), has intensely augmented sophisticated cyberattacks against satellite environments. Resisting cyber threats to complex and large-scale satellite configurations has been enormously challenging, owing to the deficiency of high-quality samples of attack data collected from distributed satellite networks. This study proposes a novel federated learning-based deep learning framework for intrusion detection, named DFSat, to identify cyberattacks from IoT-integrated satellite networks. We develop a distributed deep learning-enabled attack detection method using a recurrent neural network. We then build a federated learning architecture which, utilizes several IoT-integrated satellite networks to preserve the privacy and security of DFSat's parameters throughout the learning process. Extensive experiments have been conducted using communication rounds on an IoT-based network dataset to validate the efficiency of DFSat. The results revealed that the proposed framework significantly distinguishes complex cyberattacks, outperforming recent state-of-the-art intrusion detection techniques, validating its usefulness as a viable deployment framework in IoT-integrated satellite networks.},
  eventtitle = {{{IEEE Transactions}} on {{Industrial Informatics}}},
  keywords = {Computer architecture,Cyber security,Earth,Federated learning,Internet of Things,Internet of Things (IoT),Intrusion detection,Intrusion Detection,Low earth orbit satellites,Satellite Systems,Satellites,Security,Smart Enterprise Systems}
}

@inproceedings{moustafa_FederatedTON_IoTWindows_2020,
  title = {Federated {{TON}}\_{{IoT Windows Datasets}} for {{Evaluating AI-Based Security Applications}}},
  booktitle = {2020 {{IEEE}} 19th {{International Conference}} on {{Trust}}, {{Security}} and {{Privacy}} in {{Computing}} and {{Communications}} ({{TrustCom}})},
  author = {Moustafa, Nour and Keshky, Marwa and Debiez, Essam and Janicke, Helge},
  date = {2020-12},
  pages = {848--855},
  issn = {2324-9013},
  doi = {10.1109/TrustCom50675.2020.00114},
  abstract = {Existing cyber security solutions have been basically developed using knowledge-based models that often cannot trigger new cyber-attack families. With the boom of Artificial Intelligence (AI), especially Deep Learning (DL) algorithms, those security solutions have been plugged-in with AI models to discover, trace, mitigate or respond to incidents of new security events. The algorithms demand a large number of heterogeneous data sources to train and validate new security systems. This paper presents the description of new datasets, the so-called ToN\_IoT, which involve federated data sources collected from Telemetry datasets of IoT services, Operating system datasets of Windows and Linux, and datasets of Network traffic. The paper introduces the testbed and description of TON\_IoT datasets for Windows operating systems. The testbed was implemented in three layers: edge, fog and cloud. The edge layer involves IoT and network devices, the fog layer contains virtual machines and gateways, and the cloud layer involves cloud services, such as data analytics, linked to the other two layers. These layers were dynamically managed using the platforms of software-Defined Network (SDN) and Network-Function Virtualization (NFV) using the VMware NSX and vCloud NFV platform. The Windows datasets were collected from audit traces of memories, processors, networks, processes and hard disks. The datasets would be used to evaluate various AI-based cyber security solutions, including intrusion detection, threat intelligence and hunting, privacy preservation and digital forensics. This is because the datasets have a wide range of recent normal and attack features and observations, as well as authentic ground truth events. The datasets can be publicly accessed from this link [1].},
  eventtitle = {2020 {{IEEE}} 19th {{International Conference}} on {{Trust}}, {{Security}} and {{Privacy}} in {{Computing}} and {{Communications}} ({{TrustCom}})},
  keywords = {{Federated datasets, AI-based security applications, testbed, Windows operating systems, intrusion detection},Cloud computing,Computer crime,Data privacy,Internet of Things,Operating systems,Security,Virtual machining}
}

@article{moustafa_newdistributedarchitecture_2021,
  title = {A New Distributed Architecture for Evaluating {{AI-based}} Security Systems at the Edge: {{Network TON}}\_{{IoT}} Datasets},
  shorttitle = {A New Distributed Architecture for Evaluating {{AI-based}} Security Systems at the Edge},
  author = {Moustafa, Nour},
  date = {2021-09-01},
  journaltitle = {Sustainable Cities and Society},
  shortjournal = {Sustainable Cities and Society},
  volume = {72},
  pages = {102994},
  issn = {2210-6707},
  doi = {10.1016/j.scs.2021.102994},
  url = {https://www.sciencedirect.com/science/article/pii/S2210670721002808},
  urldate = {2024-06-21},
  abstract = {While there has been a significant interest in understanding the cyber threat landscape of Internet of Things (IoT) networks, and the design of Artificial Intelligence (AI)-based security approaches, there is a lack of distributed architecture led to generating heterogeneous datasets that contain the actual behaviors of real-world IoT networks and complex cyber threat scenarios to evaluate the credibility of the new systems. This paper presents a novel testbed architecture of IoT network which can be used to evaluate Artificial Intelligence (AI)-based security applications. The platform NSX vCloud NFV was employed to facilitate the execution of Software-Defined Network (SDN), Network Function Virtualization (NFV) and Service Orchestration (SO) to offer dynamic testbed networks, which allow the interaction of edge, fog and cloud tiers. While deploying the architecture, real-world normal and attack scenarios are executed to collect labeled datasets. The generated datasets are named `TON\_IoT', as they comprise heterogeneous data sources collected from telemetry datasets of IoT services, Windows and Linux-based datasets, and datasets of network traffic. The TON\_IoT network dataset is validated using four machine learning-based intrusion detection algorithms of Gradient Boosting Machine, Random Forest, Naive Bayes, and Deep Neural Networks, revealing a high performance of detection accuracy using the set of training and testing. A comparative summary of the TON\_IoT network dataset and other competing network datasets demonstrates its diverse legitimate and anomalous patterns that can be used to better validate new AI-based security solutions. The architecture and datasets can be publicly accessed from TON\_IOT Datasets (2020).},
  keywords = {Cybersecurity applications,Edge,Machine learning,Network datasets,Network Function Virtualization (NFV),Service Orchestration (SO),Smart cities,Software-Defined Network (SDN)}
}

@article{moustafa_NewThreatIntelligence_2018,
  title = {A {{New Threat Intelligence Scheme}} for {{Safeguarding Industry}} 4.0 {{Systems}}},
  author = {Moustafa, Nour and Adi, Erwin and Turnbull, Benjamin and Hu, Jiankun},
  date = {2018},
  journaltitle = {IEEE Access},
  volume = {6},
  pages = {32910--32924},
  publisher = {IEEE},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2018.2844794},
  url = {https://ieeexplore.ieee.org/document/8374422/},
  abstract = {Industry 4.0 represents the fourth phase of industry and manufacturing revolution, unique in that it provides Internet-connected smart systems, including automated factories, organizations, development on demand, and 'just-in-time' development. Industry 4.0 includes the integration of cyber-physical systems (CPSs), Internet of Things (IoT), cloud and fog computing paradigms for developing smart systems, smart homes, and smart cities. Given Industry 4.0 is comprised sensor fields, actuators, fog and cloud processing paradigms, and network systems, designing a secure architecture faces two major challenges: handling heterogeneous sources at scale and maintaining security over a large, disparate, data-driven system that interacts with the physical environment. This paper addresses these challenges by proposing a new threat intelligence scheme that models the dynamic interactions of industry 4.0 components including physical and network systems. The scheme consists of two components: a smart management module and a threat intelligence module. The smart data management module handles heterogeneous data sources, one of the foundational requirements for interacting with an Industry 4.0 system. This includes data to and from sensors, actuators, in addition to other forms of network traffic. The proposed threat intelligence technique is designed based on beta mixture-hidden Markov models (MHMMs) for discovering anomalous activities against both physical and network systems. The scheme is evaluated on two well-known datasets: the CPS dataset of sensors and actuators and the UNSW-NB15 dataset of network traffic. The results reveal that the proposed technique outperforms five peer mechanisms, suggesting its effectiveness as a viable deployment methodology in real-Industry 4.0 systems.}
}

@inproceedings{moustafa_UNSWNB15comprehensivedata_2015,
  title = {{{UNSW-NB15}}: A Comprehensive Data Set for Network Intrusion Detection Systems ({{UNSW-NB15}} Network Data Set)},
  shorttitle = {{{UNSW-NB15}}},
  booktitle = {2015 {{Military Communications}} and {{Information Systems Conference}} ({{MilCIS}})},
  author = {Moustafa, Nour and Slay, Jill},
  date = {2015-11},
  pages = {1--6},
  doi = {10.1109/MilCIS.2015.7348942},
  url = {https://ieeexplore.ieee.org/abstract/document/7348942},
  urldate = {2023-10-09},
  abstract = {One of the major research challenges in this field is the unavailability of a comprehensive network based data set which can reflect modern network traffic scenarios, vast varieties of low footprint intrusions and depth structured information about the network traffic. Evaluating network intrusion detection systems research efforts, KDD98, KDDCUP99 and NSLKDD benchmark data sets were generated a decade ago. However, numerous current studies showed that for the current network threat environment, these data sets do not inclusively reflect network traffic and modern low footprint attacks. Countering the unavailability of network benchmark data set challenges, this paper examines a UNSW-NB15 data set creation. This data set has a hybrid of the real modern normal and the contemporary synthesized attack activities of the network traffic. Existing and novel methods are utilised to generate the features of the UNSWNB15 data set. This data set is available for research purposes and can be accessed from the link.},
  eventtitle = {2015 {{Military Communications}} and {{Information Systems Conference}} ({{MilCIS}})}
}

@inproceedings{mtibaa_ComputeCentricNetworkingEdge_2020,
  title = {Compute-{{Centric Networking At The Edge}}: {{An Autonomous Driving Use-Case}}},
  shorttitle = {Compute-{{Centric Networking At The Edge}}},
  booktitle = {2020 {{Global Information Infrastructure}} and {{Networking Symposium}} ({{GIIS}})},
  author = {Mtibaa, Abderrahmen},
  date = {2020-10},
  pages = {1--6},
  issn = {2150-329X},
  doi = {10.1109/GIIS50753.2020.9248493},
  abstract = {This paper highlights the benefits of information-centric networking (ICN) and its named data networking (NDN) architecture for future edge computing applications in a multi-tenant multi-stakeholder ecosystem. We consider an exemplary scenario of autonomous driving to discuss open issues for efficient and timely distributed compute-centric networking. We discuss what NDN has to offer for efficient and resilient edge computing, and what needs to be done to augment NDN to move from an information-centric architecture to a compute-centric architecture. Based on the autonomous driving scenario, we identify security, naming, networking challenges, and discuss the different options to tackle these challenges and propose potential solutions.},
  eventtitle = {2020 {{Global Information Infrastructure}} and {{Networking Symposium}} ({{GIIS}})},
  keywords = {Autonomous vehicles,Computer architecture,Edge computing,Information-centric networking,Resilience,Security,Synchronization}
}

@misc{MUD_rfc,
  title = {Manufacturer Usage Description Specification},
  author = {Lear, Eliot and Droms, Ralph and Romascanu, Dan},
  date = {2019-03},
  series = {Request for Comments},
  number = {8520},
  doi = {10.17487/RFC8520},
  url = {https://rfc-editor.org/rfc/rfc8520.txt},
  abstract = {This memo specifies a component-based architecture for Manufacturer Usage Descriptions (MUDs). The goal of MUD is to provide a means for end devices to signal to the network what sort of access and network functionality they require to properly function. The initial focus is on access control. Later work can delve into other aspects. This memo specifies two YANG modules, IPv4 and IPv6 DHCP options, a Link Layer Discovery Protocol (LLDP) TLV, a URL, an X.509 certificate extension, and a means to sign and verify the descriptions.},
  howpublished = {RFC 8520},
  organization = {RFC Editor},
  pagetotal = {60},
  keywords = {pinned}
}

@article{mun_InternetTrafficClassification_2020,
  title = {Internet {{Traffic Classification}} with {{Federated Learning}}},
  author = {Mun, Hyunsu and Lee, Youngseok},
  date = {2020-12-28},
  journaltitle = {Electronics},
  shortjournal = {Electronics},
  volume = {10},
  number = {1},
  pages = {27},
  issn = {2079-9292},
  doi = {10/gmhhmv},
  url = {https://www.mdpi.com/2079-9292/10/1/27},
  urldate = {2022-02-08},
  abstract = {As Internet traffic classification is a typical problem for ISPs or mobile carriers, there have been a lot of studies based on statistical packet header information, deep packet inspection, or machine learning. Due to recent advances in end-to-end encryption and dynamic port policies, machine or deep learning has been an essential key to improve the accuracy of packet classification. In addition, ISPs or mobile carriers should carefully deal with the privacy issue while collecting user packets for accounting or security. The recent development of distributed machine learning, called federated learning, collaboratively carries out machine learning jobs on the clients without uploading data to a central server. Although federated learning provides an on-device learning framework towards user privacy protection, its feasibility and performance of Internet traffic classification have not been fully examined. In this paper, we propose a federated-learning traffic classification protocol (FLIC), which can achieve an accuracy comparable to centralized deep learning for Internet application identification without privacy leakage. FLIC can classify new applications on-the-fly when a participant joins in learning with a new application, which has not been done in previous works. By implementing the prototype of FLIC clients and a server with TensorFlow, the clients gather packets, perform the on-device training job and exchange the training results with the FLIC server. In addition, we demonstrate that federated learning-based packet classification achieves an accuracy of 88\% under non-independent and identically distributed (non-IID) traffic across clients. When a new application that can be classified dynamically as a client participates in learning was added, an accuracy of 92\% was achieved.},
  langid = {english}
}

@inproceedings{murdoch_AnonymityvsTrust_2015,
  title = {Anonymity vs. {{Trust}} in {{Cyber-Security Collaboration}}},
  booktitle = {Proceedings of the 2nd {{ACM Workshop}} on {{Information Sharing}} and {{Collaborative Security}}},
  author = {Murdoch, Stuart and Leaver, Nick},
  date = {2015-10-12},
  pages = {27--29},
  publisher = {ACM},
  location = {New York, NY, USA},
  doi = {10.1145/2808128.2808134},
  url = {https://dl.acm.org/doi/10.1145/2808128.2808134},
  abstract = {With the growing threat from overseas and domestic cyber attacks inter-organization cyber-security information sharing is an essential contributor to helping governments and industry to protect and defend their critical network infrastructure from attack. Encouraging collaboration directly impacts the defensive capabilities of all organizations involved in any cyber-information sharing community. A barrier to successful collaboration is the conflicting needs of collaborators to be able to both protect the source of their information for sensitivity, legal, or public relations reasons, but also to validate and trust the information shared with them. This paper uses as an example the UK government's Cyber- Security Information Sharing Partnership (CiSP), an online collaboration environment created by Surevine for sharing and collaborating on cyber-security information across UK industry and government. We discuss the organization and operating principles of the collaboration environment, how the community is structured, and the barriers to participation caused by the conflict between the need for anonymity versus the need to trust the information shared.},
  isbn = {978-1-4503-3822-6}
}

@inproceedings{muros_Cooperativegametheory_2016,
  title = {Cooperative Game Theory Tools to Detect Critical Nodes in Distributed Control Systems},
  booktitle = {2016 {{European Control Conference}} ({{ECC}})},
  author = {Muros, F. J. and Algaba, E. and Maestre, J. M. and Camacho, E. F.},
  date = {2016-06},
  number = {1},
  pages = {190--195},
  publisher = {IEEE},
  doi = {10.1109/ECC.2016.7810285},
  url = {http://ieeexplore.ieee.org/document/7810285/},
  abstract = {In this work, we deal with the identification of critical nodes in distributed control systems by means of game theoretical tools. This detection is addressed taking into consideration different factors such as the control performance under different topologies, the communication costs, and the centrality of the nodes in the network under study. In this sense, a generalization of the solution concept known as position value is considered to obtain a payoff for each node. A method that captures relevant information of the nodes using probability density functions of their payoffs is given and tested through an academic example.},
  isbn = {978-1-5090-2591-6}
}

@incollection{myneni_DAPT2020Constructing_2020,
  title = {{{DAPT}} 2020 - {{Constructing}} a {{Benchmark Dataset}} for {{Advanced Persistent Threats}}},
  booktitle = {Deployable {{Machine Learning}} for {{Security Defense}}},
  author = {Myneni, Sowmya and Chowdhary, Ankur and Sabur, Abdulhakim and Sengupta, Sailik and Agrawal, Garima and Huang, Dijiang and Kang, Myong},
  editor = {Wang, Gang and Ciptadi, Arridhana and Ahmadzadeh, Ali},
  date = {2020},
  volume = {1271},
  pages = {138--163},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-59621-7_8},
  url = {https://link.springer.com/10.1007/978-3-030-59621-7_8},
  urldate = {2022-06-24},
  abstract = {Machine learning is being embraced by information security researchers and organizations alike for its potential in detecting attacks that an organization faces, specifically attacks that go undetected by traditional signature-based intrusion detection systems. Along with the ability to process large amounts of data, machine learning brings the potential to detect contextual and collective anomalies, an essential attribute of an ideal threat detection system. Datasets play a vital role in developing machine learning models that are capable of detecting complex and sophisticated threats like Advanced Persistent Threats (APT). However, there is currently no APT-dataset that can be used for modeling and detecting APT attacks. Characterized by the sophistication involved and the determined nature of the APT attackers, these threats are not only difficult to detect but also to model. Generic intrusion datasets have three key limitations - (1) They capture attack traffic at the external endpoints, limiting their usefulness in the context of APTs which comprise of attack vectors within the internal network as well (2) The difference between normal and anomalous behavior is quiet distinguishable in these datasets and thus fails to represent the sophisticated attackers' of APT attacks (3) The data imbalance in existing datasets do not reflect the real-world settings rendering themselves as a benchmark for supervised models and falling short of semi-supervised learning. To address these concerns, in this paper, we propose a dataset DAPT 2020 which consists of attacks that are part of Advanced Persistent Threats (APT). These attacks (1) are hard to distinguish from normal traffic flows but investigate the raw feature space and (2) comprise of traffic on both public-to-private interface and the internal (private) network. Due to the existence of severe class imbalance, we benchmark DAPT 2020 dataset on semi-supervised models and show that they perform poorly trying to detect attack traffic in the various stages of an APT.},
  isbn = {978-3-030-59620-0 978-3-030-59621-7},
  langid = {english}
}

@article{naeem_Cachefogcomputing_2022,
  title = {Cache in Fog Computing Design, Concepts, Contributions, and Security Issues in Machine Learning Prospective},
  author = {Naeem, Muhammad Ali and Zikria, Yousaf Bin and Ali, Rashid and Tariq, Usman and Meng, Yahui and Bashir, Ali Kashif},
  date = {2022-08-12},
  journaltitle = {Digital Communications and Networks},
  shortjournal = {Digital Communications and Networks},
  issn = {2352-8648},
  doi = {10.1016/j.dcan.2022.08.004},
  url = {https://www.sciencedirect.com/science/article/pii/S2352864822001651},
  urldate = {2022-08-16},
  abstract = {The massive growth of diversified smart devices and continuous data generation poses a challenge to communication architectures. To deal with this problem, communication networks consider fog computing as one of promising technologies that can improve overall communication performance. It brings on-demand services proximate to the end devices and delivers the requested data in a short time. Fog computing faces several issues such as latency, bandwidth, and link utilization due to limited resources and the high processing demands of end devices. To this end, fog caching plays an imperative role in addressing data dissemination issues. This study provides a comprehensive discussion of fog computing, Internet of Things (IoTs) and the critical issues related to data security and dissemination in fog computing. Moreover, we determine the fog-based caching schemes and contribute to deal with the existing issues of fog computing. Besides, this paper presents a number of caching schemes with their contributions, benefits, and challenges to overcome the problems and limitations of fog computing. We also identify machine learning-based approaches for cache security and management in fog computing, as well as several prospective future research directions in caching, fog computing, and machine learning.},
  langid = {english},
  keywords = {Caching,Cloud computing,Fog computing,Internet of things,Latency}
}

@article{naeem_FederatedLearningEmpoweredSemiSupervisedActive_2023,
  title = {Federated-{{Learning-Empowered Semi-Supervised Active Learning Framework}} for {{Intrusion Detection}} in {{ZSM}}},
  author = {Naeem, Faisal and Ali, Mansoor and Kaddoum, Georges},
  date = {2023-02},
  journaltitle = {IEEE Communications Magazine},
  volume = {61},
  number = {2},
  pages = {88--94},
  issn = {1558-1896},
  doi = {10.1109/MCOM.001.2200533},
  url = {https://ieeexplore.ieee.org/abstract/document/10047851},
  urldate = {2024-04-12},
  abstract = {Exponential growth of novel radical applications and services in sixth-generation (6G) networks is expected to increase the complexity of managing existing network infrastructures. In this context, the zero touch network and service management (ZSM) paradigm, which leverages AI, SDN, and NFV techniques, is seen as a promising solution to automatically manage and orchestrate network resources. However, due to the closed-loop operation and automated end-to-end framework in a distributed 6G network, the ZSM architecture, along with its potential benefits, is exposed to various security threats. A recently proposed solution to address privacy concerns is federated learning (FL), whereby distributed training is performed, and the aggregated model parameters, instead of clients' raw data, are forwarded to the global server. However, most of the existing FL and semi-supervised learning (SSL) models for intrusion detection are based on the assumption that fully labeled data are always available at the server and client sides, which is not practical due to the high labeling costs and privacy constraints in the 6G network. In this article, we propose a novel FL-empowered semi-supervised active learning (FL-SSAL) security orchestration framework for the Label-at-Client scenario where, along with unlabeled samples, clients have a small portion of labeled data. The entropy-based active learning selects the most informative samples for data annotation and leverages the unlabeled data using a semi-supervised approach. The results of our experimental evaluations performed on the private, not independent and identically distributed (non-IID) dataset demonstrate that FL-SSAL achieves higher intrusion detection accuracy and has less communication overhead than baseline schemes with less labeled data.},
  eventtitle = {{{IEEE Communications Magazine}}},
  keywords = {6G mobile communication,Annotations,Costs,Data privacy,Distributed databases,Intrusion detection,Training}
}

@online{nardi_AnomalyDetectionUnsupervised_2022,
  title = {Anomaly {{Detection}} through {{Unsupervised Federated Learning}}},
  author = {Nardi, Mirko and Valerio, Lorenzo and Passarella, Andrea},
  date = {2022-09-09},
  eprint = {2209.04184},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2209.04184},
  urldate = {2022-09-29},
  abstract = {Federated learning (FL) is proving to be one of the most promising paradigms for leveraging distributed resources, enabling a set of clients to collaboratively train a machine learning model while keeping the data decentralized. The explosive growth of interest in the topic has led to rapid advancements in several core aspects like communication efficiency, handling non-IID data, privacy, and security capabilities. However, the majority of FL works only deal with supervised tasks, assuming that clients' training sets are labeled. To leverage the enormous unlabeled data on distributed edge devices, in this paper, we aim to extend the FL paradigm to unsupervised tasks by addressing the problem of anomaly detection in decentralized settings. In particular, we propose a novel method in which, through a preprocessing phase, clients are grouped into communities, each having similar majority (i.e., inlier) patterns. Subsequently, each community of clients trains the same anomaly detection model (i.e., autoencoders) in a federated fashion. The resulting model is then shared and used to detect anomalies within the clients of the same community that joined the corresponding federated process. Experiments show that our method is robust, and it can detect communities consistent with the ideal partitioning in which groups of clients having the same inlier patterns are known. Furthermore, the performance is significantly better than those in which clients train models exclusively on local data and comparable with federated models of ideal communities' partition.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning}
}

@inproceedings{naseri_CerberusExploringFederated_2022,
  title = {Cerberus: {{Exploring Federated Prediction}} of {{Security Events}}},
  shorttitle = {Cerberus},
  booktitle = {Proceedings of the 2022 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Naseri, Mohammad and Han, Yufei and Mariconti, Enrico and Shen, Yun and Stringhini, Gianluca and De Cristofaro, Emiliano},
  date = {2022-11-07},
  series = {{{CCS}} '22},
  pages = {2337--2351},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3548606.3560580},
  url = {https://doi.org/10.1145/3548606.3560580},
  urldate = {2023-11-20},
  abstract = {Modern defenses against cyberattacks increasingly rely on proactive approaches, e.g., to predict the adversary's next actions based on past events. Building accurate prediction models requires knowledge from many organizations; alas, this entails disclosing sensitive information, such as network structures, security postures, and policies, which might often be undesirable or outright impossible. In this paper, we explore the feasibility of using Federated Learning (FL) to predict future security events. To this end, we introduce Cerberus, a system enabling collaborative training of Recurrent Neural Network (RNN) models for participating organizations. The intuition is that FL could potentially offer a middle-ground between the non-private approach where the training data is pooled at a central server and the low-utility alternative of only training local models. We instantiate Cerberus on a dataset obtained from a major security company's intrusion prevention product and evaluate it vis-\`a-vis utility, robustness, and privacy, as well as how participants contribute to and benefit from the system. Overall, our work sheds light on both the positive aspects and the challenges of using FL for this task and paves the way for deploying federated approaches to predictive security.},
  isbn = {978-1-4503-9450-5},
  keywords = {federated learning,predictive security,privacy,robustness}
}

@inproceedings{natarajan_LearningNoisyLabels_2013,
  title = {Learning with {{Noisy Labels}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Natarajan, Nagarajan and Dhillon, Inderjit S and Ravikumar, Pradeep K and Tewari, Ambuj},
  date = {2013},
  volume = {26},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2013/hash/3871bd64012152bfb53fdf04b401193f-Abstract.html},
  urldate = {2024-03-28},
  abstract = {In this paper, we theoretically study the problem of binary classification in the presence of random classification noise --- the learner, instead of seeing the true labels, sees labels that have independently been flipped with some small probability. Moreover, random label noise is \textbackslash emph\{class-conditional\} --- the flip probability depends on the class. We provide two approaches to suitably modify any given surrogate loss function. First, we provide a simple unbiased estimator of any loss, and obtain performance bounds for empirical risk minimization in the presence of iid data with noisy labels. If the loss function satisfies a simple symmetry condition, we show that the method leads to an efficient algorithm for empirical minimization. Second, by leveraging a reduction of risk minimization under noisy labels to classification with weighted 0-1 loss, we suggest the use of a simple weighted surrogate loss, for which we are able to obtain strong empirical risk bounds. This approach has a very remarkable consequence --- methods used in practice such as biased SVM and weighted logistic regression are provably noise-tolerant. On a synthetic non-separable dataset, our methods achieve over 88\textbackslash\% accuracy even when 40\textbackslash\% of the labels are corrupted, and are competitive with respect to recently proposed methods for dealing with label noise in several benchmark datasets.}
}

@report{nationalinstituteofstandardsandtechnology_NISTCybersecurityFramework_2024,
  title = {The {{NIST Cybersecurity Framework}} ({{CSF}}) 2.0},
  author = {{National Institute of Standards and Technology}},
  date = {2024-02-26},
  number = {NIST CSWP 29},
  pages = {NIST CSWP 29},
  institution = {{National Institute of Standards and Technology}},
  location = {Gaithersburg, MD},
  doi = {10.6028/NIST.CSWP.29},
  url = {https://nvlpubs.nist.gov/nistpubs/CSWP/NIST.CSWP.29.pdf},
  urldate = {2024-05-23},
  abstract = {The NIST Cybersecurity Framework (CSF) 2.0 provides guidance to industry, government agencies, and other organizations to manage cybersecurity risks. It offers a taxonomy of highlevel cybersecurity outcomes that can be used by any organization --- regardless of its size, sector, or maturity --- to better understand, assess, prioritize, and communicate its cybersecurity efforts. The CSF does not prescribe how outcomes should be achieved. Rather, it links to online resources that provide additional guidance on practices and controls that could be used to achieve those outcomes. This document describes CSF 2.0, its components, and some of the many ways that it can be used.},
  langid = {english}
}

@article{navas_MTDWhereArt_2020,
  title = {{{MTD}}, {{Where Art Thou}}? {{A Systematic Review}} of {{Moving Target Defense Techniques}} for {{IoT}}},
  author = {Navas, Renzo E. and Cuppens, Frederic and Cuppens, Nora Boulahia and Toutain, Laurent and Papadopoulos, Georgios Z.},
  date = {2020},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {V},
  number = {c},
  pages = {1--1},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2020.3040358},
  url = {https://ieeexplore.ieee.org/document/9270287/},
  abstract = {Context: Internet of Things (IoT) systems are increasingly deployed in the real world, but their security lags behind the state of the art of non-IoT systems. Moving Target Defense (MTD) is a cyberdefense paradigm, successfully implemented in conventional systems, that could improve IoT security. Objective: Identify and synthesize existing MTD techniques for IoT and validate the feasibility of MTD as a cybersecurity paradigm suitable for IoT systems. Method: We use a systematic literature review method to search and analyze existing MTD for IoT techniques up to July 2020. We evaluated the existing techniques in terms of security foundations and real-world deployability using the evidence they provide. We define and use entropy-related metrics to categorize them. This is the first MTD survey to use Shannon\&\#x2019;s entropy metric empirically. Results: Thirty-two distinct MTD for IoT techniques exist: 54\% are Network-layer-based, 50\% present strong evidence about their real-world deployment, and 64\% have weak security foundations. Conclusion: MTD for IoT is a feasible cyberdefense approach. A variety of proposals exist, with evidence about their implementation and evaluation. Nevertheless, the MTD for IoT state of the art is still immature: the security foundations of most existing proposals are weak. Novel techniques should prioritize providing convincing security foundations and real-world deployment evidence.}
}

@article{naz_EnsemblelearningbasedIDS_2022,
  title = {Ensemble Learning-Based {{IDS}} for Sensors Telemetry Data in {{IoT}} Networks},
  author = {Naz, Naila and Khan, Muazzam A and Alsuhibany, Suliman A. and Diyan, Muhammad and Tan, Zhiyuan and Khan, Muhammad Almas and Ahmad, Jawad},
  date = {2022},
  journaltitle = {Mathematical Biosciences and Engineering},
  shortjournal = {MBE},
  volume = {19},
  number = {10},
  pages = {10550--10580},
  issn = {1551-0018},
  doi = {10.3934/mbe.2022493},
  url = {http://www.aimspress.com/article/doi/10.3934/mbe.2022493},
  urldate = {2022-08-11},
  abstract = {The Internet of Things (IoT) is a paradigm that connects a range of physical smart devices to provide ubiquitous services to individuals and automate their daily tasks. IoT devices collect data from the surrounding environment and communicate with other devices using different communication protocols such as CoAP, MQTT, DDS, etc. Study shows that these protocols are vulnerable to attack and prove a significant threat to IoT telemetry data. Within a network, IoT devices are interdependent, and the behaviour of one device depends on the data coming from another device. An intruder exploits vulnerabilities of a device's interdependent feature and can alter the telemetry data to indirectly control the behaviour of other dependent devices in a network. Therefore, securing IoT devices have become a significant concern in IoT networks. The research community often proposes intrusion Detection Systems (IDS) using different techniques. One of the most adopted techniques is machine learning (ML) based intrusion detection. This study suggests a stacking-based ensemble model makes IoT devices more intelligent for detecting unusual behaviour in IoT networks. The TON-IoT (2020) dataset is used to assess the effectiveness of the proposed model. The proposed model achieves significant improvements in accuracy and other evaluation measures in binary and multi-class classification scenarios for most of the sensors compared to traditional ML algorithms and other ensemble techniques.},
  langid = {english}
}

@article{neshenko_DemystifyingIoTSecurity_2019,
  title = {Demystifying {{IoT Security}}: {{An Exhaustive Survey}} on {{IoT Vulnerabilities}} and a {{First Empirical Look}} on {{Internet-Scale IoT Exploitations}}},
  author = {Neshenko, Nataliia and Bou-Harb, Elias and Crichigno, Jorge and Kaddoum, Georges and Ghani, Nasir},
  date = {2019},
  journaltitle = {IEEE Communications Surveys \& Tutorials},
  volume = {21},
  number = {3},
  pages = {2702--2733},
  publisher = {IEEE},
  issn = {1553-877X},
  doi = {10.1109/COMST.2019.2910750},
  url = {https://ieeexplore.ieee.org/document/8688434/},
  abstract = {The security issue impacting the Internet-of-Things (IoT) paradigm has recently attracted significant attention from the research community. To this end, several surveys were put forward addressing various IoT-centric topics, including intrusion detection systems, threat modeling, and emerging technologies. In contrast, in this paper, we exclusively focus on the ever-evolving IoT vulnerabilities. In this context, we initially provide a comprehensive classification of state-of-the-art surveys, which address various dimensions of the IoT paradigm. This aims at facilitating IoT research endeavors by amalgamating, comparing, and contrasting dispersed research contributions. Subsequently, we provide a unique taxonomy, which sheds the light on IoT vulnerabilities, their attack vectors, impacts on numerous security objectives, attacks which exploit such vulnerabilities, corresponding remediation methodologies and currently offered operational cyber security capabilities to infer and monitor such weaknesses. This aims at providing the reader with a multidimensional research perspective related to IoT vulnerabilities, including their technical details and consequences, which is postulated to be leveraged for remediation objectives. Additionally, motivated by the lack of empirical (and malicious) data related to the IoT paradigm, this paper also presents a first look on Internet-scale IoT exploitations by drawing upon more than 1.2 GB of macroscopic, passive measurements' data. This aims at practically highlighting the severity of the IoT problem, while providing operational situational awareness capabilities, which undoubtedly would aid in the mitigation task, at large. Insightful findings, inferences and outcomes in addition to open challenges and research problems are also disclosed in this paper, which we hope would pave the way for future research endeavors addressing theoretical and empirical aspects related to the imperative topic of IoT security.},
  keywords = {+survey}
}

@inproceedings{neto_CollaborativeDDoSDetection_2022,
  title = {Collaborative {{DDoS Detection}} in {{Distributed Multi-Tenant IoT}} Using {{Federated Learning}}},
  booktitle = {2022 19th {{Annual International Conference}} on {{Privacy}}, {{Security}} \& {{Trust}} ({{PST}})},
  author = {Neto, Euclides Carlos Pinto and Dadkhah, Sajjad and Ghorbani, Ali A.},
  date = {2022-08},
  pages = {1--10},
  doi = {10.1109/PST55820.2022.9851984},
  url = {https://ieeexplore.ieee.org/document/9851984},
  urldate = {2024-04-12},
  abstract = {Nowadays, the Internet of Things (IoT) has attracted much attention from the industry, and new initiatives are expected to be developed in the next decade. IoT is establishing a globally connected sensor network in which many devices are connected to the Internet generating large amounts of data. Conversely, many challenges need to be overcome to enable efficient and secure IoT applications (e.g., interoperability, security, standards, and server technologies). Furthermore, edge computing presents a paramount role in the diverse range of IoT applications. In this sense, processing sensitive data for different tenants (e.g., e-health and smart cities applications) requires transactions to be protected and isolated from different flows. Thereupon, different tenants can be targeted by Distributed Denial of Service (DDoS) attacks. However, attacks performed against a tenant remain unknown to others, preventing the improvement of detection and mitigation capabilities for DDoS attacks. The main obstacle in this collaboration relies on maintaining privacy in a multi-tenant environment while sharing the characteristics of attacks faced in the past. In this paper, we propose a collaborative DDoS detection and classification approach for distributed multi-tenant IoT environments using Federated Learning. This approach enables multiples tenants to collaboratively enhance their DDoS detection and classification capabilities across all edge nodes while maintaining their privacy. To accomplish this, tenants train deep learning instances on locally scaled traffic data and share the model parameters with other tenants. This strategy enables safer IoT operations and can be adopted in different applications. The experiments performed on a simulated environment considered the CICD-DoS2019 dataset and showed that the proposed approach can classify different DDoS attacks types with over 84.2\% accuracy. The results demonstrate that collaborative DDoS detection enhances tenant protection compared to single detection.},
  eventtitle = {2022 19th {{Annual International Conference}} on {{Privacy}}, {{Security}} \& {{Trust}} ({{PST}})},
  keywords = {Collaboration,Collaborative work,Deep Learning,Denial-of-service attack,Distributed Denial of Service (DDoS),Federated Learning,Industries,Internet of Things,Internet of Things (IoT),Privacy,Security,Servers}
}

@inproceedings{neto_FedSAAcceleratingIntrusion_2022,
  title = {{{FedSA}}: {{Accelerating Intrusion Detection}} in {{Collaborative Environments}} with {{Federated Simulated Annealing}}},
  booktitle = {2022 {{IEEE}} 8th {{International Conference}} on {{Network Softwarization}} ({{NetSoft}})},
  author = {Neto, Helio N. Cunha and Dusparic, Ivana and Mattos, Diogo M. F. and Fernandes, Natalia C.},
  date = {2022},
  publisher = {IEEE},
  location = {Milan, Italy},
  abstract = {Fast identification of new network attack patterns is crucial for improving network security. Nevertheless, identifying an ongoing attack in a heterogeneous network is a non-trivial task. Federated learning emerges as a solution to collaborative training for an Intrusion Detection System (IDS). The federated learning-based IDS trains a global model using local machine learning models provided by federated participants without sharing local data. However, optimization challenges are intrinsic to federated learning. This paper proposes the Federated Simulated Annealing (FedSA) metaheuristic to select the hyperparameters and a subset of participants for each aggregation round in federated learning. FedSA optimizes hyperparameters linked to the global model convergence. The proposal reduces aggregation rounds and speeds up convergence. Thus, FedSA accelerates learning extraction from local models, requiring fewer IDS updates. The proposal assessment shows that the FedSA global model converges in less than ten communication rounds. The proposal requires up to 50\% fewer aggregation rounds to achieve approximately 97\% accuracy in attack detection than the conventional aggregation approach.},
  eventtitle = {2022 {{IEEE}} 8th {{International Conference}} on {{Network Softwarization}} ({{NetSoft}})},
  langid = {english},
  keywords = {â›” No DOI found}
}

@inproceedings{neto_FedSAAcceleratingIntrusion_2022a,
  title = {{{FedSA}}: {{Accelerating Intrusion Detection}} in {{Collaborative Environments}} with {{Federated Simulated Annealing}}},
  shorttitle = {{{FedSA}}},
  booktitle = {2022 {{IEEE}} 8th {{International Conference}} on {{Network Softwarization}} ({{NetSoft}})},
  author = {Neto, Helio N. Cunha and Dusparic, Ivana and Mattos, Diogo M. F. and Fernande, Natalia C.},
  date = {2022-06},
  pages = {420--428},
  issn = {2693-9789},
  doi = {10.1109/NetSoft54395.2022.9844024},
  url = {https://ieeexplore.ieee.org/document/9844024},
  urldate = {2024-04-12},
  abstract = {Fast identification of new network attack patterns is crucial for improving network security. Nevertheless, identifying an ongoing attack in a heterogeneous network is a non-trivial task. Federated learning emerges as a solution to collaborative training for an Intrusion Detection System (IDS). The federated learning-based IDS trains a global model using local machine learning models provided by federated participants without sharing local data. However, optimization challenges are intrinsic to federated learning. This paper proposes the Federated Simulated Annealing (FedSA) metaheuristic to select the hyperparameters and a subset of participants for each aggregation round in federated learning. FedSA optimizes hyperparameters linked to the global model convergence. The proposal reduces aggregation rounds and speeds up convergence. Thus, FedSA accelerates learning extraction from local models, requiring fewer IDS updates. The proposal assessment shows that the FedSA global model converges in less than ten communication rounds. The proposal requires up to 50\% fewer aggregation rounds to achieve approximately 97\% accuracy in attack detection than the conventional aggregation approach.},
  eventtitle = {2022 {{IEEE}} 8th {{International Conference}} on {{Network Softwarization}} ({{NetSoft}})},
  keywords = {Collaboration,Collaborative work,Data models,Intrusion detection,Simulated annealing,Training,Training data}
}

@article{neto_SurveySecuringFederated_2023,
  title = {A {{Survey}} on {{Securing Federated Learning}}: {{Analysis}} of {{Applications}}, {{Attacks}}, {{Challenges}}, and {{Trends}}},
  shorttitle = {A {{Survey}} on {{Securing Federated Learning}}},
  author = {Neto, Helio N. Cunha and Hribar, Jernej and Dusparic, Ivana and Mattos, Diogo Menezes Ferrazani and Fernandes, Natalia C.},
  date = {2023},
  journaltitle = {IEEE Access},
  volume = {11},
  pages = {41928--41953},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3269980},
  url = {https://ieeexplore.ieee.org/document/10107622},
  urldate = {2024-04-12},
  abstract = {The growth of data generation capabilities, facilitated by advancements in communication and computation technologies, as well as the rise of the Internet of Things (IoT), results in vast amounts of data that significantly enhance the performance of machine learning models. However, collecting all necessary data to train accurate models is often unfeasible due to privacy laws. Federated Learning (FL) evolved as a collaborative machine learning approach for training models without sharing private data. Unfortunately, several in-design vulnerabilities have been exposed, allowing attackers to infer private data of participants and negatively impacting the performance of the federated model. In light of these challenges and to encourage the development of FL solutions, this paper provides a comprehensive analysis of secure FL proposals that both protect user privacy and enhance the performance of the model. We performed a systematic review using predefined criteria to screen and extract data from multiple electronic databases, resulting in a final set of studies for analysis. Through the systematic review methodology, the paper groups the security vulnerabilities of FL into model performance and data privacy attacks. It also presents an analysis and comparison of potential mitigation strategies against these attacks. Additionally, the paper conducts a security analysis of state-of-the-art FL applications and proposals based on the vulnerabilities addressed. Finally, the paper outlines the main applications of secure FL and lists future research challenges. The survey highlights the crucial role of security strategies in ensuring the protection of user privacy and model performance in the context of future FL applications.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Cloud computing,Collaboration,collaborative learning,Computational modeling,Data models,Edge computing,Federated learning,information security,Information security,machine learning,Machine learning,multiaccess edge computing,Security}
}

@article{ng_ReputationAwareHedonicCoalition_2022,
  title = {Reputation-{{Aware Hedonic Coalition Formation}} for {{Efficient Serverless Hierarchical Federated Learning}}},
  author = {Ng, Jer Shyuan and Lim, Wei Yang Bryan and Xiong, Zehui and Cao, Xianbin and Jin, Jiangming and Niyato, Dusit and Leung, Cyril and Miao, Chunyan},
  date = {2022-11},
  journaltitle = {IEEE Transactions on Parallel and Distributed Systems},
  volume = {33},
  number = {11},
  pages = {2675--2686},
  issn = {1558-2183},
  doi = {10.1109/TPDS.2021.3139039},
  abstract = {Amid growing concerns on data privacy, Federated Learning (FL) has emerged as a promising privacy preserving distributed machine learning paradigm. Given that the FL network is expected to be implemented at scale, several studies have proposed system architectures towards improving the network scalability and efficiency. Specifically, the Hierarchical FL (HFL) network utilizes cluster heads, e.g., base stations, for the intermediate aggregation and relay of model parameters. Serverless FL is also proposed recently, in which the data owners, i.e., workers, exchange the local model parameters among a neighborhood of workers. This decentralized approach reduces the risk of a single point of failure but inevitably incurs significant communication overheads. To achieve the best of both worlds, we propose the Serverless Hierarchical Federated Learning (SHFL) framework in this article. The SHFL framework adopts a two-layer system architecture. In the lower layer, the FL workers are grouped into clusters under cluster heads. In the upper layer, the cluster heads exchange the intermediate parameters with their one-hop neighbors without the aid of a central server. To improve the sustainable efficiency of the FL system while taking into account the incentive design for workers' marginal contributions in the system, we propose the reputation-aware hedonic coalition formation game in this article. Specifically, the workers are rewarded for their marginal contribution to the cluster, whereas the reputation opinions of each cluster head is updated in a decentralized manner, thereby deterring malicious behaviors by the cluster head. This improves the performance of the network since cluster heads with higher reputation scores are more reliable in relaying the intermediate model parameters. The simulation results show that our proposed hedonic coalition formation algorithm converges to a Nash-stable partition and improves the network efficiency.},
  eventtitle = {{{IEEE Transactions}} on {{Parallel}} and {{Distributed Systems}}},
  keywords = {Base stations,Collaborative work,Computational modeling,Costs,decentralized edge intelligence,Federated learning,hedonic coalition formation,Magnetic heads,serverless federated learning,Servers,Training}
}

@inproceedings{nguyen_CARSDynamicCyberattack_2021,
  title = {{{CARS}}: {{Dynamic Cyber-attack Reaction}} in {{SDN-based Networks}} with {{Q-learning}}},
  shorttitle = {{{CARS}}},
  booktitle = {2021 {{International Conference}} on {{Advanced Technologies}} for {{Communications}} ({{ATC}})},
  author = {Nguyen, Hai Hoang and Nguyen, Tri Gia and Hoang, Dinh Thai and Le, Duc Tran and Phan, Trung V.},
  date = {2021-10},
  pages = {156--161},
  issn = {2162-1039},
  doi = {10.1109/ATC52653.2021.9598233},
  abstract = {In this paper, we propose a dynamic cyber-attack reaction system based on Q-learning, namely CARS, to effectively defeat cyber-attacks in Software-Defined Networks (SDN). In particular, we first examine a cyber-attack reaction system that operates at the SDN control plane. Then, we propose a dynamic cyber-attack reaction solution to maximize the attack defense performance while minimizing the negative influence on benign traffic forwarding in the data plane. Next, we model the cyber-attack reaction system based on a Markov decision process (MDP) and formulate its optimization problem. Afterward, we develop a Q-learning based cyber-attack reaction control algorithm to solve the optimization problem, obtaining the optimal cyber-attack reaction policy. As our case study on denial-of-service (DoS) attacks, the obtained results verify that CARS can effectively prevent malicious packets from reaching the victim server in all DoS attacks, i.e., approximately 80\% of abnormal packets are dropped. In addition, by implementing the optimal cyber-attack reaction policy, CARS can significantly reduce the ratio of QoS (Quality-of-Service) violated traffic flows compared to two existing solutions, i.e., GATE (by approx. 66\%) and GTAC-IRS (by approx. 75\%).},
  eventtitle = {2021 {{International Conference}} on {{Advanced Technologies}} for {{Communications}} ({{ATC}})},
  keywords = {Approximation algorithms,Automobiles,Cyber-attack Reaction System,Denial-of-service attack,Denial-of-Service attacks and Software-Defined Networking,Heuristic algorithms,Logic gates,Markov processes,Q-learning,Quality of service}
}

@inproceedings{nguyen_DIoTFederatedSelflearning_2019,
  title = {{{D\"IoT}}: {{A Federated Self-learning Anomaly Detection System}} for {{IoT}}},
  booktitle = {2019 {{IEEE}} 39th {{International Conference}} on {{Distributed Computing Systems}} ({{ICDCS}})},
  author = {Nguyen, Thien Duc and Marchal, Samuel and Miettinen, Markus and Fereidooni, Hossein and Asokan, N. and Sadeghi, Ahmad-Reza},
  date = {2019-07},
  volume = {2019-July},
  pages = {756--767},
  publisher = {IEEE},
  doi = {10.1109/ICDCS.2019.00080},
  url = {https://ieeexplore.ieee.org/document/8884802/},
  abstract = {IoT devices are increasingly deployed in daily life. Many of these devices are, however, vulnerable due to insecure design, implementation, and configuration. As a result, many networks already have vulnerable IoT devices that are easy to compromise. This has led to a new category of malware specifically targeting IoT devices. However, existing intrusion detection techniques are not effective in detecting compromised IoT devices given the massive scale of the problem in terms of the number of different types of devices and manufacturers involved. In this paper, we present D\"IoT, an autonomous self-learning distributed system for detecting compromised IoT devices. D\"IoT builds effectively on device-type-specific communication profiles without human intervention nor labeled data that are subsequently used to detect anomalous deviations in devices' communication behavior, potentially caused by malicious adversaries. D\"IoT utilizes a federated learning approach for aggregating behavior profiles efficiently. To the best of our knowledge, it is the first system to employ a federated learning approach to anomaly-detection-based intrusion detection. Consequently, D\"IoT can cope with emerging new and unknown attacks. We systematically and extensively evaluated more than 30 off-the-shelf IoT devices over a long term and show that D\"IoT is highly effective (95.6\% detection rate) and fast (257 ms) at detecting devices compromised by, for instance, the infamous Mirai malware. D\"IoT reported no false alarms when evaluated in a real-world smart home deployment setting.},
  isbn = {978-1-72812-519-0},
  keywords = {survey-fids}
}

@article{nguyen_FastConvergentFederatedLearning_2021,
  title = {Fast-{{Convergent Federated Learning}}},
  author = {Nguyen, Hung T. and Sehwag, Vikash and Hosseinalipour, Seyyedali and Brinton, Christopher G. and Chiang, Mung and Vincent Poor, H.},
  date = {2021-01},
  journaltitle = {IEEE Journal on Selected Areas in Communications},
  shortjournal = {IEEE J. Select. Areas Commun.},
  volume = {39},
  number = {1},
  pages = {201--218},
  issn = {0733-8716, 1558-0008},
  doi = {10.1109/JSAC.2020.3036952},
  url = {https://ieeexplore.ieee.org/document/9252927/},
  urldate = {2022-05-25},
  abstract = {Federated learning has emerged recently as a promising solution for distributing machine learning tasks through modern networks of mobile devices. Recent studies have obtained lower bounds on the expected decrease in model loss that is achieved through each round of federated learning. However, convergence generally requires a large number of communication rounds, which induces delay in model training and is costly in terms of network resources. In this paper, we propose a fast-convergent federated learning algorithm, called FOLB, which performs intelligent sampling of devices in each round of model training to optimize the expected convergence speed. We first theoretically characterize a lower bound on improvement that can be obtained in each round if devices are selected according to the expected improvement their local models will provide to the current global model. Then, we show that FOLB obtains this bound through uniform sampling by weighting device updates according to their gradient information. FOLB is able to handle both communication and computation heterogeneity of devices by adapting the aggregations according to estimates of device's capabilities of contributing to the updates. We evaluate FOLB in comparison with existing federated learning algorithms and experimentally show its improvement in trained model accuracy, convergence speed, and/or model stability across various machine learning tasks and datasets.},
  langid = {english}
}

@article{nguyen_FederatedLearningSmart_2022,
  title = {Federated {{Learning}} for {{Smart Healthcare}}: {{A Survey}}},
  shorttitle = {Federated {{Learning}} for {{Smart Healthcare}}},
  author = {Nguyen, Dinh C. and Pham, Quoc-Viet and Pathirana, Pubudu N. and Ding, Ming and Seneviratne, Aruna and Lin, Zihuai and Dobre, Octavia and Hwang, Won-Joo},
  date = {2022-02-03},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {55},
  number = {3},
  pages = {60:1--60:37},
  issn = {0360-0300},
  doi = {10.1145/3501296},
  url = {https://doi.org/10.1145/3501296},
  urldate = {2023-03-11},
  abstract = {Recent advances in communication technologies and the Internet-of-Medical-Things (IOMT) have transformed smart healthcare enabled by artificial intelligence (AI). Traditionally, AI techniques require centralized data collection and processing that may be infeasible in realistic healthcare scenarios due to the high scalability of modern healthcare networks and growing data privacy concerns. Federated Learning (FL), as an emerging distributed collaborative AI paradigm, is particularly attractive for smart healthcare, by coordinating multiple clients (e.g., hospitals) to perform AI training without sharing raw data. Accordingly, we provide a comprehensive survey on the use of FL in smart healthcare. First, we present the recent advances in FL, the motivations, and the requirements of using FL in smart healthcare. The recent FL designs for smart healthcare are then discussed, ranging from resource-aware FL, secure and privacy-aware FL to incentive FL and personalized FL. Subsequently, we provide a state-of-the-art review on the emerging applications of FL in key healthcare domains, including health data management, remote health monitoring, medical imaging, and COVID-19 detection. Several recent FL-based smart healthcare projects are analyzed, and the key lessons learned from the survey are also highlighted. Finally, we discuss interesting research challenges and possible directions for future FL research in smart healthcare.},
  keywords = {Federated learning,privacy,smart healthcare}
}

@inproceedings{nguyen_FLAMETamingBackdoors_2022,
  title = {{{FLAME}}: {{Taming Backdoors}} in {{Federated Learning}}},
  shorttitle = {{{FLAME}}},
  author = {Nguyen, Thien Duc and Rieger, Phillip and Chen, Huili and Yalame, Hossein and M\"ollering, Helen and Fereidooni, Hossein and Marchal, Samuel and Miettinen, Markus and Mirhoseini, Azalia and Zeitouni, Shaza and Koushanfar, Farinaz and Sadeghi, Ahmad-Reza and Schneider, Thomas},
  date = {2022},
  pages = {1415--1432},
  url = {https://www.usenix.org/conference/usenixsecurity22/presentation/nguyen},
  urldate = {2024-03-06},
  eventtitle = {31st {{USENIX Security Symposium}} ({{USENIX Security}} 22)},
  isbn = {978-1-939133-31-1},
  langid = {english}
}

@unpublished{nguyen_FLGUARDSecurePrivate_2021,
  title = {{{FLGUARD}}: {{Secure}} and {{Private Federated Learning}}},
  shorttitle = {{{FLGUARD}}},
  author = {Nguyen, Thien Duc and Rieger, Phillip and Yalame, Hossein and M\"ollering, Helen and Fereidooni, Hossein and Marchal, Samuel and Miettinen, Markus and Mirhoseini, Azalia and Sadeghi, Ahmad-Reza and Schneider, Thomas and Zeitouni, Shaza},
  date = {2021-01-21},
  eprint = {2101.02281},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2101.02281},
  urldate = {2021-05-18},
  abstract = {Recently, a number of backdoor attacks against Federated Learning (FL) have been proposed. In such attacks, an adversary injects poisoned model updates into the federated model aggregation process with the goal of manipulating the aggregated model to provide false predictions on specific adversary-chosen inputs. A number of defenses have been proposed but none of them can effectively protect the FL process also against so-called multi-backdoor attacks in which multiple different backdoors are injected by the adversary simultaneously without severely impacting the benign performance of the aggregated model. To overcome this challenge, we introduce FLGUARD, a poisoning defense framework that is able to defend FL against state-ofthe-art backdoor attacks while simultaneously maintaining the benign performance of the aggregated model. Moreover, FL is also vulnerable to inference attacks, in which a malicious aggregator can infer information about clients' training data from their model updates. To thwart such attacks, we augment FLGUARD with state-of-the-art secure computation techniques that securely evaluate the FLGUARD algorithm. We provide formal argumentation for the effectiveness of our FLGUARD and extensively evaluate it against known backdoor attacks on several datasets and applications (including image classification, word prediction, and IoT intrusion detection) demonstrating that FLGUARD can entirely remove backdoors with a negligible effect on accuracy. We also show that private FLGUARD achieves practical runtimes.},
  langid = {english},
  keywords = {\_processed,â›” No DOI found}
}

@inproceedings{nguyen_PoisoningAttacksFederated_2020b,
  title = {Poisoning {{Attacks}} on {{Federated Learning-based IoT Intrusion Detection System}}},
  booktitle = {Proceedings 2020 {{Workshop}} on {{Decentralized IoT Systems}} and {{Security}}},
  author = {Nguyen, Thien Duc and Rieger, Phillip and Miettinen, Markus and Sadeghi, Ahmad-Reza},
  date = {2020},
  publisher = {Internet Society},
  location = {San Diego, CA},
  doi = {10.14722/diss.2020.23003},
  url = {https://www.ndss-symposium.org/wp-content/uploads/2020/04/diss2020-23003-paper.pdf},
  urldate = {2024-01-29},
  abstract = {Federated Learning (FL) is an appealing method for applying machine learning to large scale systems due to the privacy and efficiency advantages that its training mechanism provides. One important field for FL deployment is emerging IoT applications. In particular, FL has been recently used for IoT intrusion detection systems where clients, e.g., a home security gateway, monitors traffic data generated by IoT devices in its network, trains a local intrusion detection model, and send this model to a central entity, the aggregator, who then computes a global model (using the models of all gateways) that is distributed back to clients. This approach protects the privacy of users as it does not require local clients to share their potentially private IoT data with any other parties, and it is in general more efficient than a centralized system. However, FL schemes have been subject to poising attacks, in particular to backdoor attacks.},
  eventtitle = {Workshop on {{Decentralized IoT Systems}} and {{Security}}},
  isbn = {978-1-891562-64-8},
  langid = {english}
}

@article{nguyen_RealguardLightweightNetwork_2022,
  title = {Realguard: {{A Lightweight Network Intrusion Detection System}} for {{IoT Gateways}}},
  shorttitle = {Realguard},
  author = {Nguyen, Xuan-Ha and Nguyen, Xuan-Duong and Huynh, Hoang-Hai and Le, Kim-Hung},
  date = {2022-01-07},
  journaltitle = {Sensors},
  shortjournal = {Sensors},
  volume = {22},
  number = {2},
  pages = {432},
  issn = {1424-8220},
  doi = {10/gpbg37},
  url = {https://www.mdpi.com/1424-8220/22/2/432},
  urldate = {2022-01-31},
  abstract = {Cyber security has become increasingly challenging due to the proliferation of the Internet of things (IoT), where a massive number of tiny, smart devices push trillion bytes of data to the Internet. However, these devices possess various security flaws resulting from the lack of defense mechanisms and hardware security support, therefore making them vulnerable to cyber attacks. In addition, IoT gateways provide very limited security features to detect such threats, especially the absence of intrusion detection methods powered by deep learning. Indeed, deep learning models require high computational power that exceeds the capacity of these gateways. In this paper, we introduce Realguard, an DNN-based network intrusion detection system (NIDS) directly operated on local gateways to protect IoT devices within the network. The superiority of our proposal is that it can accurately detect multiple cyber attacks in real time with a small computational footprint. This is achieved by a lightweight feature extraction mechanism and an efficient attack detection model powered by deep neural networks. Our evaluations on practical datasets indicate that Realguard could detect ten types of attacks (e.g., port scan, Botnet, and FTP-Patator) in real time with an average accuracy of 99.57\%, whereas the best of our competitors is 98.85\%. Furthermore, our proposal effectively operates on resource-constraint gateways (Raspberry PI) at a high packet processing rate reported about 10.600 packets per second.},
  langid = {english}
}

@legislation{NIS_directive,
  title = {Directive ({{EU}}) 2016/1148 of 6 {{July}} 2016 Concerning Measures for a High Common Level of Security of Network and Information Systems across the {{Union}}},
  namea = {{European Parliament} and {Council of the European Union}},
  nameatype = {collaborator},
  date = {2016},
  url = {https://eur-lex.europa.eu/eli/dir/2016/1148/oj},
  abstract = {It proposes a wide-ranging set of measures to boost the level of security of network and information systems (cybersecurity*) to secure services vital to the EU economy and society. It aims to ensure that EU countries are well-prepared and are ready to handle and respond to cyberattacks through: the designation of competent authorities, the set-up of computer-security incident response teams (CSIRTs), and the adoption of national cybersecurity strategies. It also establishes EU-level cooperation both at strategic and technical level. Lastly, it introduces the obligation on essential-services providers and digital service providers to take the appropriate security measures and to notify the relevant national authorities about serious incidents.},
  keywords = {pinned}
}

@legislation{NIS2,
  title = {Directive ({{EU}}) 2022/2555 of the {{European Parliament}} and of the {{Council}} of 14 {{December}} 2022 on Measures for a High Common Level of Cybersecurity across the {{Union}}, Amending {{Regulation}} ({{EU}}) {{No}} 910/2014 and {{Directive}} ({{EU}}) 2018/1972, and Repealing {{Directive}} ({{EU}}) 2016/1148 ({{NIS}} 2 {{Directive}})},
  namea = {{European Parliament} and {Council of the European Union}},
  nameatype = {collaborator},
  date = {2022-12-14},
  number = {PE/32/2022/REV/2},
  url = {https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32022L2555},
  urldate = {2024-05-26}
}

@online{noble_DifferentiallyPrivateFederated_2022,
  title = {Differentially {{Private Federated Learning}} on {{Heterogeneous Data}}},
  author = {Noble, Maxence and Bellet, Aur\'elien and Dieuleveut, Aymeric},
  date = {2022-02-22},
  eprint = {2111.09278},
  eprinttype = {arXiv},
  eprintclass = {cs, math, stat},
  url = {http://arxiv.org/abs/2111.09278},
  urldate = {2022-07-05},
  abstract = {Federated Learning (FL) is a paradigm for large-scale distributed learning which faces two key challenges: (i) training efficiently from highly heterogeneous user data, and (ii) protecting the privacy of participating users. In this work, we propose a novel FL approach (DP-SCAFFOLD) to tackle these two challenges together by incorporating Differential Privacy (DP) constraints into the popular SCAFFOLD algorithm. We focus on the challenging setting where users communicate with a ``honest-but-curious'' server without any trusted intermediary, which requires to ensure privacy not only towards a third party observing the final model but also towards the server itself. Using advanced results from DP theory and optimization, we establish the convergence of our algorithm for convex and non-convex objectives. Our paper clearly highlights the trade-off between utility and privacy and demonstrates the superiority of DP-SCAFFOLD over the state-ofthe-art algorithm DP-FedAvg when the number of local updates and the level of heterogeneity grows. Our numerical results confirm our analysis and show that DP-SCAFFOLD provides significant gains in practice.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Mathematics - Statistics Theory}
}

@article{novikova_FederatedLearningIntrusion_2022,
  title = {Federated {{Learning}} for {{Intrusion Detection}} in the {{Critical Infrastructures}}: {{Vertically Partitioned Data Use Case}}},
  shorttitle = {Federated {{Learning}} for {{Intrusion Detection}} in the {{Critical Infrastructures}}},
  author = {Novikova, Evgenia and Doynikova, Elena and Golubev, Sergey},
  date = {2022-03-23},
  journaltitle = {Algorithms},
  shortjournal = {Algorithms},
  volume = {15},
  number = {4},
  pages = {104},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1999-4893},
  doi = {10.3390/a15040104},
  url = {https://www.mdpi.com/1999-4893/15/4/104},
  urldate = {2022-07-05},
  abstract = {One of the challenges in the Internet of Things systems is the security of the critical data, for example, data used for intrusion detection. The paper research construction of an intrusion detection system that ensures the confidentiality of critical data at a given level of intrusion detection accuracy. For this goal, federated learning is used to train an intrusion detection model. Federated learning is a computational model for distributed machine learning that allows different collaborating entities to train one global model without sharing data. This paper considers the case when entities have data that are different in attributes. Authors believe that it is a common situation for the critical systems constructed using Internet of Things (IoT) technology, when industrial objects are monitored by different sets of sensors. To evaluate the applicability of the federated learning for this case, the authors developed an approach and an architecture of the intrusion detection system for vertically partitioned data that consider the principles of federated learning and conducted the series of experiments. To model vertically partitioned data, the authors used the Secure Water Treatment (SWaT) data set that describes the functioning of the water treatment facility. The conducted experiments demonstrate that the accuracy of the intrusion detection model trained using federated learning is compared with the accuracy of the intrusion detection model trained using the centralized machine learning model. However, the computational efficiency of the learning and inference process is currently extremely low. It is explained by the application of homomorphic encryption for input data protection from different data owners or data sources. This defines the necessity to elaborate techniques for generating attributes that could model horizontally partitioned data even for the cases when the collaborating entities share datasets that differ in their attributes.},
  issue = {4},
  langid = {english},
  keywords = {confidential data,critical infrastructures,federated learning,gradient boosting decision trees,homomorphic encryption,intrusion detection,vertically partitioned data}
}

@online{novoa-paradela_FastDeepAutoencoder_2022,
  title = {Fast {{Deep Autoencoder}} for {{Federated}} Learning},
  author = {Novoa-Paradela, David and Romero-Fontenla, Oscar and Guijarro-Berdi\~nas, Bertha},
  date = {2022-06-13},
  eprint = {2206.05136},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2206.05136},
  urldate = {2022-07-05},
  abstract = {This paper presents a novel, fast and privacy preserving implementation of deep autoencoders. DAEF (Deep Autoencoder for Federated learning), unlike traditional neural networks, trains a deep autoencoder network in a non-iterative way, which drastically reduces its training time. Its training can be carried out in a distributed way (several partitions of the dataset in parallel) and incrementally (aggregation of partial models), and due to its mathematical formulation, the data that is exchanged does not endanger the privacy of the users. This makes DAEF a valid method for edge computing and federated learning scenarios. The method has been evaluated and compared to traditional (iterative) deep autoencoders using seven real anomaly detection datasets, and their performance have been shown to be similar despite DAEF's faster training.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning}
}

@inproceedings{nuding_DataPoisoningSequential_2022,
  title = {Data {{Poisoning}} in {{Sequential}} and {{Parallel Federated Learning}}},
  booktitle = {Proceedings of the 2022 {{ACM}} on {{International Workshop}} on {{Security}} and {{Privacy Analytics}}},
  author = {Nuding, Florian and Mayer, Rudolf},
  date = {2022-04-18},
  pages = {24--34},
  publisher = {ACM},
  location = {Baltimore MD USA},
  doi = {10.1145/3510548.3519372},
  url = {https://dl.acm.org/doi/10.1145/3510548.3519372},
  urldate = {2022-07-05},
  abstract = {Federated Machine Learning has recently become a prominent approach to leverage data that is distributed across different clients, without the need to centralize data. Models are trained locally, and only model parameters are shared and aggregated into a global model. Federated learning can increase privacy of sensitive data, as the data itself is never shared, and benefit from the distributed setting by utilizing computational resources of the clients.},
  eventtitle = {{{CODASPY}} '22: {{Twelveth ACM Conference}} on {{Data}} and {{Application Security}} and {{Privacy}}},
  isbn = {978-1-4503-9230-3},
  langid = {english}
}

@inproceedings{oh_federatedbinarizedneural_2022,
  title = {A Federated Binarized Neural Network Model for Constrained Devices in {{IoT}} Healthcare Services},
  booktitle = {2022 {{International Conference}} on {{Artificial Intelligence}} in {{Information}} and {{Communication}} ({{ICAIIC}})},
  author = {Oh, Hyeontaek and Yu, Jongmin and Kim, Nakyoung and Kim, Dongyeong and Lee, Jangwon and Yang, Jinhong},
  date = {2022-02-21},
  pages = {241--245},
  publisher = {IEEE},
  location = {Jeju Island, Korea, Republic of},
  doi = {10.1109/ICAIIC54071.2022.9722649},
  url = {https://ieeexplore.ieee.org/document/9722649/},
  urldate = {2022-03-04},
  abstract = {In IoT healthcare environment, the devices are not sufficiently powerful for operating recent deep learning models, and data collected by the devices are usually decentralized. Moreover, data are unavailable to share between devices because of information security issues. Therefore, a concept of federated learning has emerged to overcome data sharing issues, and a concept of binarized neural network has emerged to generate lightweight deep learning models. This paper proposes a federated binarized neural network model to derive a reliable healthcare system in this circumstance. This paper shows an overview of considered system model with constrained IoT healthcare devices. In addition, this paper shows illustrations of implementing the proposed federated learning model with the proposed binarized MLP networks by utilizing an open-source library. The experiment results show that the binarized MLP network shows comparable performances compared to the fullprecision MLP network while the binarized MLP requires about 10-times less model size for training.},
  eventtitle = {2022 {{International Conference}} on {{Artificial Intelligence}} in {{Information}} and {{Communication}} ({{ICAIIC}})},
  isbn = {978-1-66545-818-4},
  langid = {english}
}

@online{ongun_CELESTFederatedLearning_2022,
  title = {{{CELEST}}: {{Federated Learning}} for {{Globally Coordinated Threat Detection}}},
  shorttitle = {{{CELEST}}},
  author = {Ongun, Talha and Boboila, Simona and Oprea, Alina and Eliassi-Rad, Tina and Hiser, Jason and Davidson, Jack},
  date = {2022-05-23},
  eprint = {2205.11459},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2205.11459},
  urldate = {2022-07-05},
  abstract = {The cyber-threat landscape has evolved tremendously in recent years, with new threat variants emerging daily, and large-scale coordinated campaigns becoming more prevalent. In this study, we propose CELEST (CollaborativE LEarning for Scalable Threat detection), a federated machine learning framework for global threat detection over HTTP, which is one of the most commonly used protocols for malware dissemination and communication. CELEST leverages federated learning in order to collaboratively train a global model across multiple clients who keep their data locally, thus providing increased privacy and confidentiality assurances. Through a novel active learning component integrated with the federated learning technique, our system continuously discovers and learns the behavior of new, evolving, and globally-coordinated cyber threats. We show that CELEST is able to expose attacks that are largely invisible to individual organizations. For instance, in one challenging attack scenario with data exfiltration malware, the global model achieves a three-fold increase in Precision-Recall AUC compared to the local model. We deploy CELEST on two university networks and show that it is able to detect the malicious HTTP communication with high precision and low false positive rates. Furthermore, during its deployment, CELEST detected a set of previously unknown 42 malicious URLs and 20 malicious domains in one day, which were confirmed to be malicious by VirusTotal.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {\_read\_urgently,Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@article{onyema_DesignIntrusionDetection_2022,
  title = {Design of {{Intrusion Detection System}} Based on {{Cyborg}} Intelligence for Security of {{Cloud Network Traffic}} of {{Smart Cities}}},
  author = {Onyema, Edeh Michael and Dalal, Surjeet and Romero, Carlos Andr\'es Tavera and Seth, Bijeta and Young, Praise and Wajid, Mohd Anas},
  date = {2022-12},
  journaltitle = {Journal of Cloud Computing},
  shortjournal = {J Cloud Comp},
  volume = {11},
  number = {1},
  pages = {1--20},
  publisher = {SpringerOpen},
  issn = {2192-113X},
  doi = {10.1186/s13677-022-00305-6},
  url = {https://journalofcloudcomputing.springeropen.com/articles/10.1186/s13677-022-00305-6},
  urldate = {2022-08-18},
  abstract = {The Internet of things (IoT) is an important technology that is highly beneficial in establishing smart items, connections and cities. However, there are worries regarding security and privacy vulnerabilities in IoT in which some emerge from numerous sources, including cyberattacks, unsecured networks, data, connections or communication. This paper provides an ensemble intrusion strategy based on Cyborg Intelligence (machine learning and biological intelligence) framework to boost security of IoT enabled networks utilized for network traffic of smart cities. To do this, multiple algorithms such Random Forest, Bayesian network (BN), C5.0, CART and Artificial Neural Network were investigated to determine their usefulness in identifying threats and attacks-botnets in IoT networks based on cyborg intelligence using the KDDcup99 dataset. The results reveal that the AdaBoost ensemble learning based on Cyborg Intelligence Intrusion Detection framework facilitates dissimilar network characteristics with the capacity to swiftly identify different botnet assaults efficiently. The suggested framework has obtained good accuracy, detection rate and a decreased false positive rate in comparison to other standard methodologies. The conclusion of this study would be a valuable complement to the efforts toward protecting IoT-powered networks and the accomplishment of safer smart cities.},
  issue = {1},
  langid = {english}
}

@book{oppliger_SSLTLStheory_2016,
  title = {{{SSL}} and {{TLS}}: Theory and Practice},
  shorttitle = {{{SSL}} and {{TLS}}},
  author = {Oppliger, Rolf},
  date = {2016},
  series = {Artech {{House}} Information Security and Privacy Series},
  edition = {Second edition},
  publisher = {Artech House},
  location = {Boston},
  isbn = {978-1-60807-998-8},
  langid = {english},
  pagetotal = {278},
  keywords = {Computer networks,Security measures},
  annotation = {OCLC: ocn951909923}
}

@article{oseni_ExplainableDeepLearning_2022,
  title = {An {{Explainable Deep Learning Framework}} for {{Resilient Intrusion Detection}} in {{IoT-Enabled Transportation Networks}}},
  author = {Oseni, Ayodeji and Moustafa, Nour and Creech, Gideon and Sohrabi, Nasrin and Strelzoff, Andrew and Tari, Zahir and Linkov, Igor},
  date = {2022},
  journaltitle = {IEEE Transactions on Intelligent Transportation Systems},
  pages = {1--15},
  issn = {1558-0016},
  doi = {10.1109/TITS.2022.3188671},
  abstract = {The security of safety-critical IoT systems, such as the Internet of Vehicles (IoV), has a great interest, focusing on using Intrusion Detection Systems (IDS) to recognise cyber-attacks in IoT networks. Deep learning methods are commonly used for the anomaly detection engines of many IDSs because of their ability to learn from heterogeneous data. However, while this type of machine learning model produces high false-positive rates and the reasons behind its predictions are not easily understood, even by experts. The ability to understand or comprehend the reasoning behind the decision of an IDS to block a particular packet helps cybersecurity experts validate the system's effectiveness and develop more cyber-resilient systems. This paper proposes an explainable deep learning-based intrusion detection framework that helps improve the transparency and resiliency of DL-based IDS in IoT networks. The framework employs a SHapley Additive exPlanations (SHAP) mechanism to interpret decisions made by deep learning-based IDS to experts who rely on the decisions to ensure IoT networks' security and design more cyber-resilient systems. The proposed framework was validated using the ToN\_IoT dataset and compared with other compelling techniques. The experimental results have revealed the high performance of the proposed framework with a 99.15\% accuracy and a 98.83\% F1 score, illustrating its capability to protect IoV networks against sophisticated cyber-attacks.},
  eventtitle = {{{IEEE Transactions}} on {{Intelligent Transportation Systems}}},
  keywords = {Computer architecture,deep learning,Deep learning,Explainable AI,Internet of Things,Internet of Vehicles (IoV),Intrusion detection,IoT,network intrusion detection,Protocols,Safety,security,Security}
}

@article{otoum_FeasibilitySplitLearning_2023,
  title = {On the {{Feasibility}} of {{Split Learning}}, {{Transfer Learning}} and {{Federated Learning}} for {{Preserving Security}} in {{ITS Systems}}},
  author = {Otoum, Safa and Guizani, Nadra and Mouftah, Hussein},
  date = {2023-07},
  journaltitle = {IEEE Transactions on Intelligent Transportation Systems},
  volume = {24},
  number = {7},
  pages = {7462--7470},
  issn = {1558-0016},
  doi = {10.1109/TITS.2022.3159092},
  url = {https://ieeexplore.ieee.org/abstract/document/9756883},
  urldate = {2024-04-12},
  abstract = {Due to the absence of distinct boundaries, wireless networks are vulnerable to a variety of intrusions. As the number of intruders has increased, the risks on critical infrastructures monitored by networked systems have also increased. Protecting shared information using effective and robust Intrusion Detection Systems (IDSs) remains a critical issue, especially with the growing implementation of vehicular networks. Building an IDS that detects threats efficiently with maximum accuracy and detection is a challenging undertaking. Machine Learning (ML) mechanisms have been successfully adopted in IDSs to detect a variety of network intruders. Split learning is considered one of the main developments in creating efficient ML approaches. In utilizing the Split Learning approach, an IDS is successful in performing at higher accuracy, and detection rate as well as a higher classification performance (Precision, Recall). In this work, a Split Learning-based IDS ( SplitLearn ) for Intelligent Transportation System (ITS) infrastructures has been proposed to address the potential security concerns. The proposed model has been evaluated and compared against other models (i.e., Federated Learning ( FedLearn ) and Transfer Learning ( TransLearn )-based solutions). With the highest accuracy and detection rates, the proposed model ( SplitLearn ) outperforms FedLearn and TransLearn by 2 to 5 \% respectively. We also see a decrease in power consumption when utilizing SplitLearn versus FedLearn .},
  eventtitle = {{{IEEE Transactions}} on {{Intelligent Transportation Systems}}},
  keywords = {Collaborative work,Federated learning,Industrial Internet of Things,Internet of Things (IoT),Medical services,Monitoring,Security,split learning,Task analysis,transfer learning,Transfer learning}
}

@inproceedings{otoum_FederatedTransferLearningBased_2021,
  title = {Federated {{Transfer Learning-Based IDS}} for the {{Internet}} of {{Medical Things}} ({{IoMT}})},
  booktitle = {2021 {{IEEE Globecom Workshops}} ({{GC Wkshps}})},
  author = {Otoum, Yazan and Wan, Yue and Nayak, Amiya},
  date = {2021-12},
  pages = {1--6},
  publisher = {IEEE},
  location = {Madrid, Spain},
  doi = {10/gpbg4z},
  url = {https://ieeexplore.ieee.org/document/9682118/},
  urldate = {2022-01-31},
  abstract = {The Internet of Medical Things (IoMT) is a set of medical devices and applications that connect to healthcare systems through the Internet. Those devices are equipped with communication technologies that allow them to communicate with each other and the Internet. Reliance on the IoMT is increasing with the increase in epidemics and chronic diseases such as COVID-19 and diabetes; with the increase in the number of IoMT users and the need for electronic data sharing and virtual services, cyberattacks in the healthcare sector for accessing confidential patient data has been increasing in the recent years. The healthcare applications and their infrastructures have special requirements for handling sensitive users' data and the need for high availability. Therefore, securing healthcare applications and data has attracted special attention from both industry and researchers. In this paper, we propose a Federated Transfer Learning-based Intrusion Detection System (IDS) to secure the patient's healthcare-connected devices. The model uses Deep Neural Network (DNN) algorithm for training the network and transferring the knowledge from the connected edge models to build an aggregated global model and customizing it for each one of the connected edge devices without exposing data privacy. CICIDS2017 dataset has been used to evaluate the performance in terms of accuracy, detection rate, and average training time. In addition to preserving data privacy of edge devices and achieving better performance, our comparison indicates that the proposed model can be generalized better and learns incrementally compared to other baseline ML/DL algorithms used in the traditional centralized learning schemes.},
  eventtitle = {2021 {{IEEE Globecom Workshops}} ({{GC Wkshps}})},
  isbn = {978-1-66542-390-8},
  langid = {english}
}

@inproceedings{otoum_FederatedTransferLearningBased_2021a,
  title = {Federated {{Transfer Learning-Based IDS}} for the {{Internet}} of {{Medical Things}} ({{IoMT}})},
  booktitle = {2021 {{IEEE Globecom Workshops}} ({{GC Wkshps}})},
  author = {Otoum, Yazan and Wan, Yue and Nayak, Amiya},
  date = {2021-12},
  pages = {1--6},
  doi = {10.1109/GCWkshps52748.2021.9682118},
  url = {https://ieeexplore.ieee.org/abstract/document/9682118},
  urldate = {2024-04-12},
  abstract = {The Internet of Medical Things (IoMT) is a set of medical devices and applications that connect to healthcare systems through the Internet. Those devices are equipped with communication technologies that allow them to communicate with each other and the Internet. Reliance on the IoMT is increasing with the increase in epidemics and chronic diseases such as COVID-19 and diabetes; with the increase in the number of IoMT users and the need for electronic data sharing and virtual services, cyberattacks in the healthcare sector for accessing confidential patient data has been increasing in the recent years. The healthcare applications and their infrastructures have special requirements for handling sensitive users' data and the need for high availability. Therefore, securing healthcare applications and data has attracted special attention from both industry and researchers. In this paper, we propose a Federated Transfer Learning-based Intrusion Detection System (IDS) to secure the patient's healthcare-connected devices. The model uses Deep Neural Network (DNN) algorithm for training the network and transferring the knowledge from the connected edge models to build an aggregated global model and customizing it for each one of the connected edge devices without exposing data privacy. CICIDS2017 dataset has been used to evaluate the performance in terms of accuracy, detection rate, and average training time. In addition to preserving data privacy of edge devices and achieving better performance, our comparison indicates that the proposed model can be generalized better and learns incrementally compared to other baseline ML/DL algorithms used in the traditional centralized learning schemes.},
  eventtitle = {2021 {{IEEE Globecom Workshops}} ({{GC Wkshps}})},
  keywords = {Data privacy,Deep learning,Federated Learning (FL),Image edge detection,Internet of Medical Things (IoMT),Intrusion Detection System (IDS),Medical devices,Neural networks,Performance evaluation,Training,Transfer Learning (TL)}
}

@article{otoum_FederatedTransferLearningEmpowered_2022,
  title = {Federated and {{Transfer Learning-Empowered Intrusion Detection}} for {{IoT Applications}}},
  author = {Otoum, Yazan and Chamola, Vinay and Nayak, Amiya},
  date = {2022-09},
  journaltitle = {IEEE Internet of Things Magazine},
  volume = {5},
  number = {3},
  pages = {50--54},
  issn = {2576-3199},
  doi = {10.1109/IOTM.001.2200048},
  url = {https://ieeexplore.ieee.org/abstract/document/9945849},
  urldate = {2024-04-12},
  abstract = {The Internet of Things (IoT) can be described as a considerable number of sensors and physical devices connected to different applications, supported with networking technologies to communicate with other devices and the Internet. With the growing number of IoT users, emerging services, and the need for high availability and data exchange, cyberattacks on those applications have increased in recent years. Therefore, securing IoT applications has allured particular consideration from the industry and research fields. This article illustrates and comprehensively analyzes the effectiveness of using FL/TL trending techniques used with different Machine Learning (ML) and Deep Learning (DL) algorithms to drive the Intrusion Detection Systems (IDS) to secure the IoT applications. The Internet of Medical Things (IoMT) is considered in this article as a use case in which we have demonstrated that using federated and transfer learning can improve model performance, increase learning process speed, reduce the amount of data needed to be trained, and preserve the user's data privacy compared with the traditional learning approaches.},
  eventtitle = {{{IEEE Internet}} of {{Things Magazine}}},
  keywords = {Federated learning,Internet of Things,Intrusion detection,Learning systems,Machine learning algorithms,Transfer learning}
}

@article{ouyang_ClusterFLClusteringbasedFederated_2022,
  title = {{{ClusterFL}}: {{A Clustering-based Federated Learning System}} for {{Human Activity Recognition}}},
  shorttitle = {{{ClusterFL}}},
  author = {Ouyang, Xiaomin and Xie, Zhiyuan and Zhou, Jiayu and Xing, Guoliang and Huang, Jianwei},
  date = {2022-12-08},
  journaltitle = {ACM Transactions on Sensor Networks},
  shortjournal = {ACM Trans. Sen. Netw.},
  volume = {19},
  number = {1},
  pages = {17:1--17:32},
  issn = {1550-4859},
  doi = {10.1145/3554980},
  url = {https://dl.acm.org/doi/10.1145/3554980},
  urldate = {2024-01-12},
  abstract = {Federated Learning (FL) has recently received significant interest, thanks to its capability of protecting data privacy. However, existing FL paradigms yield unsatisfactory performance for a wide class of human activity recognition (HAR) applications, since they are oblivious to the intrinsic relationship between data of different users. We propose ClusterFL, a clustering-based federated learning system that can provide high model accuracy and low communication overhead for HAR applications. ClusterFL features a novel clustered multi-task federated learning framework that minimizes the empirical training loss of multiple learned models while automatically capturing the intrinsic clustering relationship among the nodes. We theoretically prove the convergence of proposed FL framework for non-convex and strongly convex models and provide the guidance on selection of hyper-parameters for achieving such convergence. Based on the learned cluster relationship, ClusterFL can efficiently drop the nodes that converge slower or have little correlations with others in each cluster, significantly speeding up the convergence while maintaining the accuracy performance. We evaluate the performance of ClusterFL on an NVIDIA edge testbed using four new HAR datasets collected from 145 users. The results show that ClusterFL outperforms several state-of-the-art FL paradigms in terms of overall accuracy and can save more than 50\% communication overhead.},
  keywords = {Activity recognition,clustering,federated learning,multi-task learning}
}

@inproceedings{ouyang_ClusterFLsimilarityawarefederated_2021,
  title = {{{ClusterFL}}: A Similarity-Aware Federated Learning System for Human Activity Recognition},
  shorttitle = {{{ClusterFL}}},
  booktitle = {Proceedings of the 19th {{Annual International Conference}} on {{Mobile Systems}}, {{Applications}}, and {{Services}}},
  author = {Ouyang, Xiaomin and Xie, Zhiyuan and Zhou, Jiayu and Huang, Jianwei and Xing, Guoliang},
  date = {2021-06-24},
  pages = {54--66},
  publisher = {ACM},
  location = {Virtual Event Wisconsin},
  doi = {10.1145/3458864.3467681},
  url = {https://dl.acm.org/doi/10.1145/3458864.3467681},
  urldate = {2023-02-02},
  abstract = {Federated Learning (FL) has recently received significant interests thanks to its capability of protecting data privacy. However, existing FL paradigms yield unsatisfactory performance for a wide class of human activity recognition (HAR) applications since they are oblivious to the intrinsic relationship between data of different users. We propose ClusterFL, a similarity-aware federated learning system that can provide high model accuracy and low communication overhead for HAR applications. ClusterFL features a novel clustered multi-task federated learning framework that maximizes the training accuracy of multiple learned models while automatically capturing the intrinsic clustering relationship among the data of different nodes. Based on the learned cluster relationship, ClusterFL can efficiently drop out the nodes that converge slower or have little correlation with other nodes in each cluster, significantly speeding up the convergence while maintaining the accuracy performance. We evaluate the performance of ClusterFL on an NVIDIA edge testbed using four new HAR datasets collected from total 145 users. The results show that, ClusterFL outperforms several state-of-the-art FL paradigms in terms of overall accuracy, and save more than 50\% communication overhead at the expense of negligible accuracy degradation.},
  eventtitle = {{{MobiSys}} '21: {{The}} 19th {{Annual International Conference}} on {{Mobile Systems}}, {{Applications}}, and {{Services}}},
  isbn = {978-1-4503-8443-8},
  langid = {english}
}

@article{ozkara_PersonalizedPCAFederated_2023,
  title = {Personalized {{PCA}} for {{Federated Heterogeneous Data}}},
  author = {Ozkara, Kaan and Huang, Bruce and Diggavi, Suhas},
  date = {2023-06-25},
  journaltitle = {2023 IEEE International Symposium on Information Theory (ISIT)},
  pages = {168--173},
  publisher = {IEEE},
  location = {Taipei, Taiwan},
  doi = {10.1109/ISIT54713.2023.10206971},
  url = {https://ieeexplore.ieee.org/document/10206971/},
  urldate = {2024-04-02},
  abstract = {As the high dimensional data generation/storage shifts from data centers to millions of edge devices, PCA algorithms also need to adapt to federated systems to reveal insights about the distributed data. One of the prominent challenges in Federated Learning (FL) is that each edge device has a limited number of samples, and therefore collaboration among clients is necessary for learning tasks. Another challenge is heterogeneous distribution of data across devices, which necessitates careful design of algorithms that enable collaboration of devices with different data distributions. While many such federated supervised learning algorithms were proposed in recent years, heterogeneity for unsupervised FL algorithms (such as PCA) has received less attention. In this work, our goal is to enable collaborations of heterogeneous clients in learning personalized Principal Components (PCs). To this end, we develop a hierarchical Bayesian framework for discovering individual PCs; and inspired by this, we formulate an optimization problem related to maximum likelihood estimation of the PCs. To solve the optimization problem, we propose an alternating Stiefel gradient descent algorithm. Analytically, we prove the convergence result for our proposed algorithm; and empirically, we show that our method outperforms local and global estimation of PCs in various heterogeneous settings in terms of the reconstruction error.},
  eventtitle = {2023 {{IEEE International Symposium}} on {{Information Theory}} ({{ISIT}})},
  isbn = {9781665475549}
}

@inproceedings{ozkara_PersonalizedPCAFederated_2023a,
  title = {Personalized {{PCA}} for {{Federated Heterogeneous Data}}},
  booktitle = {2023 {{IEEE International Symposium}} on {{Information Theory}} ({{ISIT}})},
  author = {Ozkara, Kaan and Huang, Bruce and Diggavi, Suhas},
  date = {2023-06-25},
  pages = {168--173},
  publisher = {IEEE},
  location = {Taipei, Taiwan},
  doi = {10.1109/ISIT54713.2023.10206971},
  url = {https://ieeexplore.ieee.org/document/10206971/},
  urldate = {2024-04-02},
  abstract = {As the high dimensional data generation/storage shifts from data centers to millions of edge devices, PCA algorithms also need to adapt to federated systems to reveal insights about the distributed data. One of the prominent challenges in Federated Learning (FL) is that each edge device has a limited number of samples, and therefore collaboration among clients is necessary for learning tasks. Another challenge is heterogeneous distribution of data across devices, which necessitates careful design of algorithms that enable collaboration of devices with different data distributions. While many such federated supervised learning algorithms were proposed in recent years, heterogeneity for unsupervised FL algorithms (such as PCA) has received less attention. In this work, our goal is to enable collaborations of heterogeneous clients in learning personalized Principal Components (PCs). To this end, we develop a hierarchical Bayesian framework for discovering individual PCs; and inspired by this, we formulate an optimization problem related to maximum likelihood estimation of the PCs. To solve the optimization problem, we propose an alternating Stiefel gradient descent algorithm. Analytically, we prove the convergence result for our proposed algorithm; and empirically, we show that our method outperforms local and global estimation of PCs in various heterogeneous settings in terms of the reconstruction error.},
  eventtitle = {2023 {{IEEE International Symposium}} on {{Information Theory}} ({{ISIT}})},
  isbn = {978-1-66547-554-9},
  langid = {english}
}

@article{pa_IoTPOTNovelHoneypot_2016,
  title = {{{IoTPOT}}: {{A Novel Honeypot}} for {{Revealing Current IoT Threats}}},
  author = {Pa, Yin Minn Pa and Suzuki, Shogo and Yoshioka, Katsunari and Matsumoto, Tsutomu and Kasama, Takahiro and Rossow, Christian},
  date = {2016},
  journaltitle = {Journal of Information Processing},
  volume = {24},
  number = {3},
  pages = {522--533},
  issn = {1882-6652},
  doi = {10.2197/ipsjjip.24.522},
  url = {https://www.jstage.jst.go.jp/article/ipsjjip/24/3/24_522/_article},
  abstract = {We analyze the increasing threats against IoT devices. We show that Telnet-based attacks that target IoT devices have rocketed since 2014. Based on this observation, we propose an IoT honeypot and sandbox, which attracts and analyzes Telnet-based attacks against various IoT devices running on different CPU architectures such as ARM, MIPS, and PPC. By analyzing the observation results of our honeypot and captured malware samples, we show that there are currently at least 5 distinct DDoS malware families targeting Telnet-enabled IoT devices and one of the families has quickly evolved to target more devices with as many as 9 different CPU architectures.}
}

@article{pahl_AllEyesYou_2018,
  title = {All {{Eyes}} on {{You}}: {{Distributed Multi-Dimensional IoT Microservice Anomaly Detection}}},
  author = {Pahl, Marc-Oliver and Aubet, Francois Xavier},
  date = {2018},
  journaltitle = {14th International Conference on Network and Service Management, CNSM 2018, 1st Workshop on Segment Routing and Service Function Chaining},
  shortjournal = {CNSM},
  pages = {72--80},
  abstract = {The Internet of Things (IoT) is a Distributed System of cooperating Microservices ({$\mu$} Ss). IoT services manage devices that monitor and control their environments. The interaction of the IoT with the physical environment creates strong security, privacy, and safety implications. It makes providing adequate security for IoT {$\mu$} Ss essential. However, the complexity of IoT services makes detecting anomalous behavior difficult.We present a machine-learning based approach for modeling IoT service behavior by only observing inter-service communication. Our algorithm continuously learns {$\mu$}S models on distributed IoT nodes within an IoT site. Combining the learned models within and in-between IoT sites converges our {$\mu$}S models within short time. Sharing the resulting stable models among compute nodes enables good anomaly detection.As one application, firewalling IoT {$\mu$} Ss becomes possible. Combining our autonomous {$\mu$}S modeling with firewalling enables retrofitting security to existing IoT installations. We enable retrofitting access control to existing non-secure IoT installations.Our proposed approach is resource efficient, matching the requirements of the IoT. To evaluate the quality of our proposed algorithm, we show its behavior for a set of common IoT attacks. We evaluate how domain knowledge enables us to decorrelate events on a node, and how adding context features improves the detection rate.},
  isbn = {9783903176140},
  keywords = {â›” No DOI found,survey-fids}
}

@inproceedings{pahl_AllEyesYou_2018a,
  title = {All {{Eyes}} on {{You}}: {{Distributed Multi-Dimensional IoT Microservice Anomaly Detection}}},
  shorttitle = {All {{Eyes}} on {{You}}},
  booktitle = {2018 14th {{International Conference}} on {{Network}} and {{Service Management}} ({{CNSM}})},
  author = {Pahl, Marc-Oliver and Aubet, Fran\c cois-Xavier},
  date = {2018-11},
  pages = {72--80},
  issn = {2165-963X},
  url = {https://ieeexplore.ieee.org/abstract/document/8584985},
  urldate = {2024-04-12},
  abstract = {The Internet of Things (IoT) is a Distributed System of cooperating Microservices ({$\mu$}Ss). IoT services manage devices that monitor and control their environments. The interaction of the IoT with the physical environment creates strong security, privacy, and safety implications. It makes providing adequate security for IoT {$\mu$}Ss essential. However, the complexity of IoT services makes detecting anomalous behavior difficult. We present a machine-learning based approach for modeling IoT service behavior by only observing inter-service communication. Our algorithm continuously learns {$\mu$}S models on distributed IoT nodes within an IoT site. Combining the learned models within and in-between IoT sites converges our {$\mu$}S models within short time. Sharing the resulting stable models among compute nodes enables good anomaly detection. As one application, firewalling IoT {$\mu$}Ss becomes possible. Combining our autonomous {$\mu$}S modeling with firewalling enables retrofitting security to existing IoT installations. We enable retrofitting access control to existing non-secure IoT installations. Our proposed approach is resource efficient, matching the requirements of the IoT. To evaluate the quality of our proposed algorithm, we show its behavior for a set of common IoT attacks. We evaluate how domain knowledge enables us to decorrelate events on a node, and how adding context features improves the detection rate.},
  eventtitle = {2018 14th {{International Conference}} on {{Network}} and {{Service Management}} ({{CNSM}})},
  isbn = {978-3-903176-14-0},
  keywords = {Adaptation models,anomaly detection,Biological system modeling,Computational modeling,Internet of Things,IoT,machine learning,Middleware,modeling,Monitoring,security,Security,survey-fids}
}

@inproceedings{pahl_Distributedsmartspace_2016,
  title = {Distributed Smart Space Orchestration},
  booktitle = {Network Operations and Management Symposium 2016 ({{NOMS}} 2016) - Dissertation Digest},
  author = {Pahl, Marc-Oliver and Carle, Georg and Klinker, Gudrun},
  date = {2016-05},
  abstract = {Many networked devices that can interface their physical environments are available off-the-shelf or can be built in 2016. A comprehensive management of those Smart Devices is required to unlock the existing potential. However, the amount and heterogeneity of the devices make their management difficult. A suitable abstraction is missing. This paper identifies requirements on managing Smart Devices from diverse research fields, assesses relevant existing work, proposes a new management middleware design, and evaluates it quantitatively and qualitatively. The presented novel middleware architecture could become an enabler for a software maker culture.},
  webpdf = {http://www.pahl.de/download/publications/NOMS2016\textsubscript{D}istributed\textsubscript{S}mart\textsubscript{S}pace\textsubscript{O}rchestration\textsubscript{P}ahl.pdf}
}

@article{pahl_MixedInteractionCriticalInfrastructure_2020,
  title = {A {{Mixed-Interaction Critical Infrastructure Honeypot}}},
  author = {Pahl, Marc-Oliver and Kabil, Alexandre and Bourget, Edwin and Gay, Matthieu and Brun, Paul-emmanuel},
  date = {2020},
  journaltitle = {European Cyber Week (ECW), C\&ESAR Conferences},
  abstract = {Operational Technology (OT) plays an essential role in modern societies. It is pivotal for applications such as water or power supply, healthcare, or transportation. At the same time, OT is often connected to the Internet for enabling remote-control and collaboration. Its societal impact makes OT an attractive attack target. Its connectivity to the Internet significantly increases the attack probability. For protecting against attacks, it is important to identify and study them. Honeypots enable such studies. However, realistic honeypots are difficult and expensive to setup. They are also inflexible as their setting is typically static. In collaboration with Airbus Cybersecurity, the chaire Cy- ber CNI currently develops a mixed-interaction honeypot for critical infrastructures. The targeted setup combines physical and virtualized elements that can flexibly be reconfigured. This allows running diverse settings distributed in time or space. The virtualized part allows scaling the experiments. The goal of the Cyber CNI honeypot is enabling the closer study of Information and Operational Technology (IT \& OT).},
  keywords = {â›” No DOI found}
}

@incollection{paillier_PublicKeyCryptosystemsBased_1999,
  title = {Public-{{Key Cryptosystems Based}} on {{Composite Degree Residuosity Classes}}},
  booktitle = {Advances in {{Cryptology}} --- {{EUROCRYPT}} '99},
  author = {Paillier, Pascal},
  editor = {Stern, Jacques},
  date = {1999},
  volume = {1592},
  pages = {223--238},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/3-540-48910-X_16},
  url = {http://link.springer.com/10.1007/3-540-48910-X_16},
  urldate = {2021-07-05},
  abstract = {This paper investigates a novel computational problem, namely the Composite Residuosity Class Problem, and its applications to public-key cryptography. We propose a new trapdoor mechanism and derive from this technique three encryption schemes : a trapdoor permutation and two homomorphic probabilistic encryption schemes computationally comparable to RSA. Our cryptosystems, based on usual modular arithmetics, are provably secure under appropriate assumptions in the standard model.},
  isbn = {978-3-540-65889-4},
  langid = {english}
}

@article{pala_InformationSharingCybersecurity_2019,
  title = {Information {{Sharing}} in {{Cybersecurity}}: {{A Review}}},
  author = {Pala, Ali and Zhuang, Jun},
  date = {2019-09},
  journaltitle = {Decision Analysis},
  volume = {16},
  number = {3},
  pages = {172--196},
  issn = {1545-8490},
  doi = {10.1287/deca.2018.0387},
  url = {http://pubsonline.informs.org/doi/10.1287/deca.2018.0387},
  abstract = {In this survey, we review the cybersecurity information-sharing literature, categorizing the identified papers based on their main focus and methodological approaches implemented to the cybersecurity information-sharing problem. We constitute our research framework on the major considerations of firms, governments, citizens, and adversaries. This includes actors involved, types of information to be shared, current legal baseline, information-sharing organizations/policies/architectures, benefits of sharing, and concerns/costs/barriers of sharing. We observe that both qualitative and quantitative approaches are implemented in the literature. In general, quantitative approaches have been dedicated to discuss the challenges and barriers of public/private collaboration in information sharing, such as privacy and liability, and to propose secure and effective sharing mechanisms. On the other hand, quantitative approaches have been more interested in developing models that balance cybersecurity investment and information sharing as well as provide effective incentive mechanisms. This review summarizes the academic efforts in cybersecurity information sharing by analyzing 82 identified papers with their methodological approaches. The papers using game-theoretical models are dominant in the literature as we spend more time summarizing those efforts. We conclude the review by providing potential research gaps and future research directions.}
}

@inproceedings{panagoda_ApplicationFederatedLearning_2022,
  title = {Application of {{Federated Learning}} in {{Health Care Sector}} for {{Malware Detection}} and {{Mitigation Using Software Defined Networking Approach}}},
  booktitle = {2022 2nd {{Asian Conference}} on {{Innovation}} in {{Technology}} ({{ASIANCON}})},
  author = {Panagoda, Dinelka and Malinda, Chathura and Wijetunga, Chamod and Rupasinghe, Lakmal and Bandara, Bathiya and Liyanapathirana, Chethana},
  date = {2022-08},
  pages = {1--6},
  doi = {10.1109/ASIANCON55314.2022.9909488},
  url = {https://ieeexplore.ieee.org/abstract/document/9909488},
  urldate = {2024-04-12},
  abstract = {This research takes us forward with the concepts of Federated Learning and SDN to introduce an efficient malware detection technique and provide a mitigation mechanism to give birth to a resilient and automated healthcare sector network system by also adding the feature of extended privacy preservation. Due to the daily transformation of new malware attacks on hospital ICEs, the healthcare industry is at an undefinable peak of never knowing its continuity direction. The state of blindness by the array of indispensable opportunities that new medical device inventions and their connected coordination offer daily, a factor that should be focused driven is not yet entirely understood by most healthcare operators and patients. This solution has the involvement of four clients in the form of hospital networks to build up the federated learning experimentation architectural structure with different geographical participation to reach the most reasonable accuracy rate with privacy preservation. While the logistic regression with cross-entropy conveys the detection, SDN comes in handy in the second half of the research to stack up the initial development phases of the system with malware mitigation based on policy implementation. The overall evaluation sums up with a system that proves the accuracy with the added privacy. It is no longer needed to continue with traditional centralized systems that offer almost everything but not privacy.},
  eventtitle = {2022 2nd {{Asian Conference}} on {{Innovation}} in {{Technology}} ({{ASIANCON}})},
  keywords = {Collaboration,decentralized learning,Feature extraction,Federated learning,Federated Learning,Hospitals,Integrated Clinical Environment,Malware,malware detection,malware mitigation,privacy,Privacy,Software Defined Network,Technological innovation}
}

@inproceedings{panchal_SecurityIssuesIIoT_2018,
  title = {Security {{Issues}} in {{IIoT}}: {{A Comprehensive Survey}} of {{Attacks}} on {{IIoT}} and {{Its Countermeasures}}},
  booktitle = {2018 {{IEEE Global Conference}} on {{Wireless Computing}} and {{Networking}} ({{GCWCN}})},
  author = {Panchal, Abhijeet C. and Khadse, Vijay M. and Mahalle, Parikshit N.},
  date = {2018-11},
  pages = {124--130},
  publisher = {IEEE},
  doi = {10.1109/GCWCN.2018.8668630},
  url = {https://ieeexplore.ieee.org/document/8668630/},
  abstract = {Industrial Internet of Things (IIoT) applications connect machines, sensors and actuators in high-stake manufacturing industries. Industrial systems are using the potential of IoT to reduce the unnecessary operational cost and increase the usability and reliability of the industrial assets to achieve more profits. However, such smart Industries need connectivity and interoperability to enhance performance which makes them susceptible to various attacks. Recent attacks on Cyber-physical systems raise a strong security concern as such attacks causes a huge property loss and may also lead to life threatening situations. In this paper we discuss the potential security threats to the Industries adapting to IIoT and study the various attacks that are possible on the components in the layered IIoT architecture and some of the preventive measures. Finally, we propose IIoT attack taxonomy which would help in mitigating the risks of the attacks.},
  isbn = {978-1-5386-5201-5}
}

@inproceedings{panda_DistributedLedgerTechnology_2020,
  title = {Distributed {{Ledger Technology}} for {{Securing IoT}}},
  booktitle = {2020 11th {{International Conference}} on {{Computing}}, {{Communication}} and {{Networking Technologies}} ({{ICCCNT}})},
  author = {Panda, Soumyashree S. and Mohanta, Bhabendu Kumar and Dey, Meenu Rani and Satapathy, Utkalika and Jena, Debasish},
  date = {2020-07},
  pages = {1--6},
  publisher = {IEEE},
  doi = {10.1109/ICCCNT49239.2020.9225333},
  url = {https://ieeexplore.ieee.org/document/9225333/},
  abstract = {Computing and communication are getting increasingly ubiquitous with the inclusion of sophisticated devices like electric vehicles, smart phones and other house hold appliances. Due to the constant evolution in Internet of Things (IoT), the process of collaboration of these devices at a mass scale in order to provide improved and better services to the society. Traditional mechanisms which are used to sustain privacy and security become incapable from achieving the same for IoT systems having distributed or decentralized topology. Distributed Ledger Technologies (DLT), an emerging digital technology, consists of different kinds of decentralized data structures to ensure immutability by linking blocks using cryptographic measures. DLT has the ability to ensure privacy, security and distributed or decentralized computations with adhering to the constraints of IoT nodes. This study is motivated due to the lack of an in-depth analysis on how the characteristics of DLT can be exploited to secure IoT systems. So, an in depth overview of DLT along with some of the existing solutions to meet security requirements of IoT systems employing DLT have been provided in this paper. With respect to integrating DLT with IoT, this article also highlights the different challenges.},
  isbn = {978-1-72816-851-7}
}

@article{pappas_IPLSFrameworkDecentralized_2021,
  title = {{{IPLS}}: {{A Framework}} for {{Decentralized Federated Learning}}},
  shorttitle = {{{IPLS}}},
  author = {Pappas, Christodoulos and Chatzopoulos, Dimitris and Lalis, Spyros and Vavalis, Manolis},
  date = {2021-06-21},
  journaltitle = {2021 IFIP Networking Conference (IFIP Networking)},
  pages = {1--6},
  publisher = {IEEE},
  location = {Espoo and Helsinki, Finland},
  doi = {10.23919/IFIPNetworking52078.2021.9472790},
  url = {https://ieeexplore.ieee.org/document/9472790/},
  urldate = {2023-09-11},
  abstract = {The proliferation of resourceful mobile devices that store rich, multidimensional and privacy-sensitive user data motivate federated learning, a paradigm that enables mobile devices to produce a machine-learning model without sharing their data. However, the majority of the existing federated frameworks follow a centralized approach. In this work, we introduce IPLS, a fully decentralized federated learning framework that is partially based on the interplanetary file system (IPFS). By using IPLS and connecting into the corresponding private IPFS network, any party can initiate the training process of a machine-learning model or join an ongoing training process that has been started by another party. IPLS scales with the number of participants, is robust against intermittent connectivity and dynamic participant departures/arrivals, requires minimal resources and guarantees that the accuracy of the trained model quickly converges to that of a centralized federated learning framework with a negligible accuracy drop of less than 1â€°.},
  eventtitle = {2021 {{IFIP Networking Conference}} ({{IFIP Networking}})},
  isbn = {9783903176393}
}

@inproceedings{park_DesignDevelopmentServerClient_2022,
  title = {Design and {{Development}} of {{Server-Client Cooperation Framework}} for {{Federated Learning}}},
  booktitle = {2022 {{Thirteenth International Conference}} on {{Ubiquitous}} and {{Future Networks}} ({{ICUFN}})},
  author = {Park, Jongbin and Woo Kum, Seung},
  date = {2022-07},
  pages = {271--273},
  issn = {2165-8536},
  doi = {10.1109/ICUFN55119.2022.9829693},
  abstract = {Federated learning is a machine learning technique that enables distributed training without explicitly data sharing between multiple heterogeneous devices. In this paper, we propose and develop a practical federated learning framework to effectively support model deployment, aggregation, and client device monitoring. The proposed approach is designed as a micro-architecture service using container-related technologies such as Docker, Kubernetes, and Prometheus.},
  eventtitle = {2022 {{Thirteenth International Conference}} on {{Ubiquitous}} and {{Future Networks}} ({{ICUFN}})},
  keywords = {\_read\_urgently,Collaborative work,Computational modeling,Computer architecture,Distributed databases,Edge Computing,Federated Learning Framework,Load management,Machine learning,Micro Service Architecture,Training}
}

@incollection{parker_NewFrameworkInformation_2015,
  title = {Toward a {{New Framework}} for {{Information Security}}?},
  booktitle = {Computer {{Security Handbook}}},
  author = {Parker, Donn B.},
  date = {2015-09-12},
  pages = {3.1-3.23},
  publisher = {John Wiley \& Sons, Inc.},
  location = {Hoboken, NJ, USA},
  doi = {10.1002/9781118851678.ch3},
  url = {http://doi.wiley.com/10.1002/9781118851678.ch3}
}

@inproceedings{parra_Interpretablefederatedtransformer_2022,
  title = {Interpretable Federated Transformer Log Learning for Cloud Threat Forensics},
  author = {Parra, Gonzalo and Selvera, Luis and Khoury, Joseph and Irizarry, Hector and Bou-Harb, Elias and Rad, Paul},
  date = {2022-01}
}

@inproceedings{patel_DetectionIntrusionsusing_2022,
  title = {Detection of {{Intrusions}} Using {{Support Vector Machines}} and {{Deep Neural Networks}}},
  booktitle = {2022 10th {{International Conference}} on {{Reliability}}, {{Infocom Technologies}} and {{Optimization}} ({{Trends}} and {{Future Directions}}) ({{ICRITO}})},
  author = {Patel, N D and Mehtre, B M and Wankar, Rajeev},
  date = {2022-10},
  pages = {1--5},
  doi = {10.1109/ICRITO56286.2022.9964756},
  abstract = {An Intrusion detection system (IDS) plays a role in network intrusion detection through network data analysis, and high detection accuracy, precision, and recall are required to detect intrusions. Also, various techniques such as expert systems, data mining, and state transition analysis are used for network data analysis. The paper compares the detection effects of the two IDS methods using data mining. The first technique is a support vector machine (SVM), a machine learning algorithm; the second is a deep neural network (DNN), one of the artificial neural network models. The accuracy, precision, and recall were calculated and compared using NSL-KDD training and validation data, which is widely used in intrusion detection to compare the detection effects of the two techniques. DNN shows slightly higher accuracy than the SVM model. The risk of recognizing an actual intrusion as normal data is much greater than the risk of considering normal data as an intrusion, so DNN proves to be much more effective in intrusion detection than SVM.},
  eventtitle = {2022 10th {{International Conference}} on {{Reliability}}, {{Infocom Technologies}} and {{Optimization}} ({{Trends}} and {{Future Directions}}) ({{ICRITO}})},
  keywords = {Advanced Persistent Threat (APT),Data analysis,Deep learning,Deep Neural Network (DNN),Intrusion detection,Intrusion Detection System (IDS),Machine Learning,Market research,Network intrusion detection,NSL-KDD,Support Vector Machine (SVM),Support vector machines,Training}
}

@book{pearl_CausalInferenceStatistics_2016,
  title = {Causal {{Inference}} in {{Statistics}}: A {{Primer}}},
  shorttitle = {Causal Inference in Statistics},
  author = {Pearl, Judea and Glymour, Madelyn and Jewell, Nicholas P.},
  date = {2016},
  publisher = {Wiley},
  location = {Chichester, West Sussex},
  isbn = {978-1-119-18684-7},
  langid = {english},
  pagetotal = {136},
  keywords = {Causation,Mathematical statistics,Probabilities}
}

@article{pei_KnowledgeTransferBasedSemiSupervised_2023,
  title = {A {{Knowledge Transfer-Based Semi-Supervised Federated Learning}} for {{IoT Malware Detection}}},
  author = {Pei, Xinjun and Deng, Xiaoheng and Tian, Shengwei and Zhang, Lan and Xue, Kaiping},
  date = {2023-05},
  journaltitle = {IEEE Transactions on Dependable and Secure Computing},
  volume = {20},
  number = {3},
  pages = {2127--2143},
  issn = {1941-0018},
  doi = {10.1109/TDSC.2022.3173664},
  url = {https://ieeexplore.ieee.org/abstract/document/9772293},
  urldate = {2024-04-12},
  abstract = {As the demand for Internet of Things (IoT) technologies continues to grow, IoT devices have been viable targets for malware infections. Although deep learning-based malware detection has achieved great success, the detection models are usually trained based on the collected user records, thereby leading to significant privacy risks. One promising solution is to leverage federated learning (FL) to enable distributed on-device training without centralizing the private user records. However, it is non-trivial for IoT users to label these records, where the quality and the trustworthiness of data labeling are hard to guarantee. To address the above issues, this paper develops a semi-supervised federated IoT malware detection framework based on knowledge transfer technologies, named by FedMalDE. Specifically, FedMalDE explores the underlying correlation between labeled and unlabeled records to infer labels towards unlabeled samples by the knowledge transfer mechanism. Moreover, a specially designed subgraph aggregated capsule network (SACN) is used to efficiently capture varied malicious behaviors. The extensive experiments conducted on real-world data demonstrate the effectiveness of FedMalDE in detecting IoT malware and its sufficient privacy and robustness guarantee.},
  eventtitle = {{{IEEE Transactions}} on {{Dependable}} and {{Secure Computing}}},
  keywords = {capsule network,Capsule Network,Collaborative work,Feature extraction,federated learning,Federated Learning,Malware,Malware detection,Malware Detection,Privacy,privacy-preserving,Privacy-Preserving,Security,Semantics,semi-supervised learning,Semi-Supervised Learning,Training}
}

@article{pei_Personalizedfederatedlearning_2022,
  title = {Personalized Federated Learning Framework for Network Traffic Anomaly Detection},
  author = {Pei, Jiaming and Zhong, Kaiyang and Jan, Mian Ahmad and Li, Jinhai},
  date = {2022-05},
  journaltitle = {Computer Networks},
  shortjournal = {Computer Networks},
  volume = {209},
  pages = {108906},
  issn = {13891286},
  doi = {10.1016/j.comnet.2022.108906},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1389128622001001},
  urldate = {2022-04-01},
  abstract = {With the widespread use of real-time sensors in various fields, such as IoT systems, it is important to improve the performance of most network traffic anomaly detection methods, which have low accuracy and high false alarm rates. However, there are two key challenges to address. In this study, we proposed a personalized federated anomaly detection framework for network traffic anomaly detection, in which data are aggregated under the premise of privacy protection and relatively personalized models are constructed by fine-tuning. Subsequently, a network traffic anomaly detection method based on the self-coding of long- and short-term memory networks was proposed. Real network traffic was tested to analyze the effects of the model structure and external noise on the detection performance, and the experimental results verified the correctness of the proposed method. Compared with other data-reconstruction-based detection methods, the proposed method has higher detection accuracy and better detection performance.},
  langid = {english},
  keywords = {RETRACTED}
}

@article{pejo_QualityInferenceFederated_2023,
  title = {Quality {{Inference}} in {{Federated Learning With Secure Aggregation}}},
  author = {Pej\'o, Bal\'azs and Bicz\'ok, Gergely},
  date = {2023-10},
  journaltitle = {IEEE Transactions on Big Data},
  volume = {9},
  number = {5},
  pages = {1430--1437},
  issn = {2332-7790},
  doi = {10.1109/TBDATA.2023.3280406},
  url = {https://ieeexplore.ieee.org/abstract/document/10138056},
  urldate = {2024-03-27},
  abstract = {Federated learning algorithms are developed both for efficiency reasons and to ensure the privacy and confidentiality of personal and business data, respectively. Despite no data being shared explicitly, recent studies showed that the mechanism could still leak sensitive information. Hence, secure aggregation is utilized in many real-world scenarios to prevent attribution to specific participants. In this paper, we focus on the quality (i.e., the ratio of correct labels) of individual training datasets and show that such quality information could be inferred and attributed to specific participants even when secure aggregation is applied. Specifically, through a series of image recognition experiments, we infer the relative quality ordering of participants. Moreover, we apply the inferred quality information to stabilize training performance, measure the individual contribution of participants, and detect misbehavior.},
  eventtitle = {{{IEEE Transactions}} on {{Big Data}}},
  keywords = {Big Data,Computational modeling,contribution score,Correlation,Data integrity,Data models,federated learning,misbehavior detection,Quality inference,secure aggregation,Task analysis,Training}
}

@inproceedings{peregrina_MetadataManagementSystem_2022,
  title = {Towards a~{{Metadata Management System}} for~{{Provenance}}, {{Reproducibility}} and~{{Accountability}} in~{{Federated Machine Learning}}},
  booktitle = {Advances in {{Service-Oriented}} and {{Cloud Computing}}},
  author = {Peregrina, Jos\'e A. and Ortiz, Guadalupe and Zirpins, Christian},
  editor = {Zirpins, Christian and Ortiz, Guadalupe and Nochta, Zoltan and Waldhorst, Oliver and Soldani, Jacopo and Villari, Massimo and Tamburri, Damian},
  date = {2022},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {5--18},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-23298-5_1},
  abstract = {The application of Data Governance (DG) to Federated Machine Learning (FML) could provide a way to produce better Machine Learning models. Nevertheless, such an application is still almost nonexistent in literature. Within a proposal for applying DG to FML, we first present an approach of metadata for FML, to provide accountability and assist with the continuous improvement of models in the federation. Our proposal includes a metadata model for tracing the operations of participants and collecting all information regarding the definition of goals and configuration of FML training processes. Additionally, we present the outline of a metadata management system as part of a broader DG architecture. Finally, we show some use cases of metadata management.},
  isbn = {978-3-031-23298-5},
  langid = {english},
  keywords = {Data Governance,Federated Machine Learning,Metadata}
}

@inproceedings{peri_DeepkNNDefense_2020,
  title = {Deep K-{{NN Defense Against Clean-Label Data Poisoning Attacks}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2020 {{Workshops}}},
  author = {Peri, Neehar and Gupta, Neal and Huang, W. Ronny and Fowl, Liam and Zhu, Chen and Feizi, Soheil and Goldstein, Tom and Dickerson, John P.},
  editor = {Bartoli, Adrien and Fusiello, Andrea},
  date = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {55--70},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-66415-2_4},
  abstract = {Targeted clean-label data poisoning is a type of adversarial attack on machine learning systems in which an adversary injects a few correctly-labeled, minimally-perturbed samples into the training data, causing a model to misclassify a particular test sample during inference. Although defenses have been proposed for general poisoning attacks, no reliable defense for clean-label attacks has been demonstrated, despite the attacks' effectiveness and realistic applications. In this work, we propose a simple, yet highly-effective Deep k-NN defense against both feature collision and convex polytope clean-label attacks on the CIFAR-10 dataset. We demonstrate that our proposed strategy is able to detect over 99\% of poisoned examples in both attacks and remove them without compromising model performance. Additionally, through ablation studies, we discover simple guidelines for selecting the value of k as well as for implementing the Deep k-NN defense on real-world datasets with class imbalance. Our proposed defense shows that current clean-label poisoning attack strategies can be annulled, and serves as a strong yet simple-to-implement baseline defense to test future clean-label poisoning attacks. Our code is available on GitHub.},
  isbn = {978-3-030-66415-2},
  langid = {english},
  keywords = {Adversarial attacks,Clean label poisoning,Deep k-NN,Machine learning}
}

@thesis{perrin_Specificationobjetspartages_2016,
  title = {Sp\'ecification Des Objets Partag\'es Dans Les Syst\`emes R\'epartis Sans-Attente},
  author = {Perrin, Matthieu},
  date = {2016},
  pages = {1 vol. (203 p.)},
  url = {http://www.theses.fr/2016NANT2103}
}

@article{petrakopoulos_DDoSDetectionusing_,
  title = {{{DDoS Detection}} Using {{Trust-Aware Federated Learning}} for {{Heterogeneous Collaborators}}},
  author = {Petrakopoulos, Vasilis},
  langid = {english},
  keywords = {â›” No DOI found}
}

@article{phan_DeepAirDeepReinforcement_2022,
  title = {{{DeepAir}}: {{Deep Reinforcement Learning}} for {{Adaptive Intrusion Response}} in {{Software-Defined Networks}}},
  shorttitle = {{{DeepAir}}},
  author = {Phan, Trung V. and Bauschert, Thomas},
  date = {2022},
  journaltitle = {IEEE Transactions on Network and Service Management},
  shortjournal = {IEEE Trans. Netw. Serv. Manage.},
  pages = {1--1},
  issn = {1932-4537, 2373-7379},
  doi = {10.1109/TNSM.2022.3158468},
  url = {https://ieeexplore.ieee.org/document/9732448/},
  urldate = {2022-03-23},
  abstract = {In this paper, we propose an adaptive intrusion response solution based on deep reinforcement learning, namely DeepAir, to effectively defend against cyber-attacks in SoftwareDefined Networks (SDN). Specifically, we first study an intrusion response system (IRS) that operates at the SDN control plane. Next, we propose a dynamic intrusion response solution to maximize the attack defense performance while minimizing the negative impact on benign traffic forwarding and the policy deployment cost in the SDN data plane. Then, we model the intrusion response system based on a Markov decision process (MDP) approach and formulate the related optimization problem. Afterward, we develop a Double Deep Q-Network based intrusion response control algorithm to assist the intrusion response system to quickly obtain the optimal intrusion response policy. In our case study, we consider denial-of-service (DoS) attacks---the performance evaluation results demonstrate that DeepAir can effectively prevent malicious packets from arriving at the victim in all considered DoS attack scenarios, i.e., approximately 85\% of attack packets are dropped. Moreover, by applying the optimal intrusion response policy, DeepAir can significantly reduce the ratio of Quality-of-Service violated traffic flows compared to a Qlearning based approach (by 70\%), and to two existing solutions, i.e., GATE (by 75\%) and GTAC-IRS (by 80\%), respectively.},
  langid = {english},
  keywords = {\_read}
}

@inproceedings{phan_FEARFederatedCyberAttack_2022,
  title = {{{FEAR}}: {{Federated Cyber-Attack Reaction}} in {{Distributed Software-Defined Networks}} with {{Deep Q-Network}}},
  shorttitle = {{{FEAR}}},
  booktitle = {2022 {{Wireless Telecommunications Symposium}} ({{WTS}})},
  author = {Phan, Trung V. and Gia Nguyen, Tri},
  date = {2022-04},
  pages = {1--7},
  issn = {2690-8336},
  doi = {10.1109/WTS53620.2022.9768169},
  abstract = {In this paper, we propose a FEderated cyber-Attack Reaction (FEAR) system using Deep Q-Network algorithm for distributed software-defined networks. In our recent study [1], we propose a Q-learning based cyber-attack reaction control system, called CARS, for a single SDN. However, for real network deployments that are usually distributed over the Internet, the CARS suffers from two main shortcomings, i.e., a slow-convergence rate of Q-learning algorithm and the scalability issue. Therefore, in this paper, we first develop a Deep Q-Network (DQN) based cyber-attack reaction control algorithm to assist the control agent in obtaining the optimal policy quickly. Next, we propose a federated DQN based cyber-attack reaction control system, which eliminates the scalability problem and improves the learning performance of the DQN algorithm in a distributed manner. As our case study on denial-of-service (DoS) attacks, the obtained results show that the FEAR can effectively protect the victim from malicious packets, i.e., approximately 90\% of attack packets are discarded. Furthermore, by deploying the optimal cyber-attack reaction policy, the FEAR can reduce the ratio of QoS (Quality-of-Service) violated traffic flows compared to the CARS (by approx. 44\%) and the GATE (by approx. 63\%).},
  eventtitle = {2022 {{Wireless Telecommunications Symposium}} ({{WTS}})},
  keywords = {and Software-Defined Networks,Control systems,Cyber-Attack Reaction,Deep Q-learning,Denial-of-service attack,DoS Attacks,Federated Learning,Logic gates,Q-learning,Quality of service,Scalability,Wireless communication}
}

@article{pontes_NewMethodFlowBased_2021,
  title = {A {{New Method}} for {{Flow-Based Network Intrusion Detection Using}} the {{Inverse Potts Model}}},
  author = {Pontes, Camila F. T. and family=Souza, given=Manuela M. C., prefix=de, useprefix=true and Gondim, Jo\~ao J. C. and Bishop, Matt and Marotta, Marcelo Antonio},
  date = {2021-06},
  journaltitle = {IEEE Transactions on Network and Service Management},
  volume = {18},
  number = {2},
  pages = {1125--1136},
  issn = {1932-4537},
  doi = {10.1109/TNSM.2021.3075503},
  abstract = {Network Intrusion Detection Systems (NIDS) play an important role as tools for identifying potential network threats. In the context of ever-increasing traffic volume on computer networks, flow-based NIDS arise as good solutions for real-time traffic classification. In recent years, different flow-based classifiers have been proposed using Machine Learning (ML) algorithms. Nevertheless, classical ML-based classifiers have some limitations. For instance, they require large amounts of labeled data for training, which might be difficult to obtain. Additionally, most ML-based classifiers are not capable of domain adaptation, i.e., after being trained on an specific data distribution, they are not general enough to be applied to other related data distributions. And, finally, many of the models inferred by these algorithms are black boxes, which do not provide explainable results. To overcome these limitations, we propose a new algorithm, called Energy-based Flow Classifier (EFC). This anomaly-based classifier uses inverse statistics to infer a statistical model based on labeled benign examples. We show that EFC is capable of accurately performing binary flow classification and is more adaptable to different data distributions than classical ML-based classifiers. Given the positive results obtained on three different datasets (CIDDS-001, CICIDS17 and CICDDoS19), we consider EFC to be a promising algorithm to perform robust flow-based traffic classification.},
  eventtitle = {{{IEEE Transactions}} on {{Network}} and {{Service Management}}},
  keywords = {Adaptation models,anomaly-based network intrusion detection,Data models,domain adaptation,energy-based flow classifier,Flow-based network intrusion detection,inverse Potts model,Machine learning algorithms,network flow classification,Network intrusion detection,network intrusion detection systems,Real-time systems,Security,Training}
}

@inproceedings{popoola_FederatedDeepLearning_2021,
  title = {Federated {{Deep Learning}} for {{Collaborative Intrusion Detection}} in {{Heterogeneous Networks}}},
  booktitle = {2021 {{IEEE}} 94th {{Vehicular Technology Conference}} ({{VTC2021-Fall}})},
  author = {Popoola, Segun I. and Gui, Guan and Adebisi, Bamidele and Hammoudeh, Mohammad and Gacanin, Haris},
  date = {2021-09},
  pages = {1--6},
  issn = {2577-2465},
  doi = {10.1109/VTC2021-Fall52928.2021.9625505},
  abstract = {In this paper, we propose Federated Deep Learning (FDL) for intrusion detection in heterogeneous networks. Local Deep Neural Network (DNN) models are used to learn the hierarchical representations of the private network traffic data in multiple edge nodes. A dedicated central server receives the parameters of the local DNN models from the edge nodes, and it aggregates them to produce an FDL model using the Fed+ fusion algorithm. Simulation results show that the FDL model achieved an accuracy of 99.27 \textpm{} 0.79\%, a precision of 97.03 \textpm{} 4.22\%, a recall of 98.06 \textpm{} 1.72\%, an F1 score of 97.50 \textpm{} 2.55\%, and a False Positive Rate (FPR) of 2.40 \textpm{} 2.47\%. The classification performance and the generalisation ability of the FDL model are better than those of the local DNN models. The Fed+ algorithm outperformed two state-of-the-art fusion algorithms, namely federated averaging (FedAvg) and Coordinate Median (CM). Therefore, the DNN-Fed+ model is preferable for intrusion detection in heterogeneous wireless networks.},
  eventtitle = {2021 {{IEEE}} 94th {{Vehicular Technology Conference}} ({{VTC2021-Fall}})},
  keywords = {deep learning,Deep learning,federated learning,Heterogeneous networks,heterogeneous wireless networks,Image edge detection,intrusion detection,Intrusion detection,Simulation,smart city,Telecommunication traffic,Wireless networks}
}

@article{popoola_FederatedDeepLearning_2021a,
  title = {Federated {{Deep Learning}} for {{Zero-Day Botnet Attack Detection}} in {{IoT Edge Devices}}},
  author = {Popoola, Segun I. and Ande, Ruth and Adebisi, Bamidele and Gui, Guan and Hammoudeh, Mohammad and Jogunola, Olamide},
  date = {2021},
  journaltitle = {IEEE Internet of Things Journal},
  shortjournal = {IEEE Internet Things J.},
  pages = {1--1},
  issn = {2327-4662, 2372-2541},
  doi = {10.1109/JIOT.2021.3100755},
  url = {https://ieeexplore.ieee.org/document/9499122/},
  urldate = {2021-10-01},
  abstract = {Deep Learning (DL) has been widely proposed for botnet attack detection in Internet of Things (IoT) networks. However, the traditional Centralized DL (CDL) method cannot be used to detect previously unknown (zero-day) botnet attack without breaching the data privacy rights of the users. In this paper, we propose Federated Deep Learning (FDL) method for zero-day botnet attack detection to avoid data privacy leakage in IoT edge devices. In this method, an optimal Deep Neural Network (DNN) architecture is employed for network traffic classification. A model parameter server remotely coordinates the independent training of the DNN models in multiple IoT edge devices, while Federated Averaging (FedAvg) algorithm is used to aggregate local model updates. A global DNN model is produced after a number of communication rounds between the model parameter server and the IoT edge devices. Zero-day botnet attack scenarios in IoT edge devices is simulated with the BotIoT and N-BaIoT data sets. Experiment results show that FDL model: (a) detects zero-day botnet attacks with high classification performance; (b) guarantees data privacy and security; (c) has low communication overhead (d) requires low memory space for the storage of training data; and (e) has low network latency. Therefore, FDL method outperformed CDL, Localized DL, and Distributed DL methods in this application scenario.},
  langid = {english},
  keywords = {survey-fids}
}

@article{popoola_FederatedDeepLearning_2023,
  title = {Federated {{Deep Learning}} for {{Intrusion Detection}} in {{Consumer-Centric Internet}} of {{Things}}},
  author = {Popoola, Segun I. and Imoize, Agbotiname L. and Hammoudeh, Mohammad and Adebisi, Bamidele and Jogunola, Olamide and Aibinu, Abiodun M.},
  date = {2023},
  journaltitle = {IEEE Transactions on Consumer Electronics},
  pages = {1--1},
  issn = {1558-4127},
  doi = {10.1109/TCE.2023.3347170},
  url = {https://ieeexplore.ieee.org/abstract/document/10373897},
  urldate = {2024-04-12},
  abstract = {Consumer-centric Internet of Things (CIoT) will play a pivotal role in the fifth industrial revolution (Industry 5.0) but it exhibits vulnerabilities that can render it susceptible to various cyberattacks. Recent studies have explored the potential of Federated Learning (FL) for privacy-preserving intrusion detection in IoT. However, the development of the FL models relied on unrealistic and irrelevant network traffic data, while also exhibiting limitations in terms of covered attack types and classification scenarios. In this paper, we develop Federated Deep Learning (FDL) models using three recent and highly relevant datasets, covering a wide range of attack types as well as binary and multi-class classification scenarios. Our findings demonstrate that the FDL models not only achieve high classification performance, comparable to traditional Centralized Deep Learning (CDL) models, in terms of accuracy (99.60\textpm 0.46\%), precision (92.50\textpm 8.40\%), recall (95.42\textpm 6.24\%), and F1 score (93.51\textpm 7.76\%) but also exhibit superior computational efficiency compared to their CDL counterparts. The FDL approach reduces the training time by 30.52-75.87\%. These classification performance and computational efficiency were achieved through multiple rounds of distributed local training in FDL. Therefore, the proposed FDL framework presents a robust security solution for designing and deploying a resilient CIoT.},
  eventtitle = {{{IEEE Transactions}} on {{Consumer Electronics}}},
  keywords = {Computational modeling,cyber security,deep learning,Deep learning,Federated learning,industrial internet of things,Industrial Internet of Things,Industries,intrusion detection,Intrusion detection,Protocols,Training}
}

@report{popoola_OptimizingDeepLearning_2022,
  type = {preprint},
  title = {Optimizing {{Deep Learning Model Hyperparameters}} for {{Botnet Attack Detection}} in {{IoT Networks}}},
  author = {Popoola, Segun and Adebisi, Bamidele and Gui, Guan and Hammoudeh, Mohammad and Gacanin, Haris and Dancey, Darren},
  date = {2022-04-08},
  doi = {10.36227/techrxiv.19501885.v1},
  url = {https://www.techrxiv.org/articles/preprint/Optimizing_Deep_Learning_Model_Hyperparameters_for_Botnet_Attack_Detection_in_IoT_Networks/19501885/1},
  urldate = {2022-04-14},
  abstract = {Deep Learning (DL) models can be trained to automatically learn the underlying features of the traffic patterns in IoT networks to detect complex botnet attacks. However, the performance of a neural network model largely depends on the set of hyperparameters that is used for the model development. In this paper, an algorithm is proposed to determine the optimal set of hyperparameters (the numbers of hidden layers and hidden units, the learning rate, the optimiser, the activation function, the batch size, and the number of epochs) for efficient DLbased botnet detection in IoT networks. The DL models employ a Deep Neural Network (DNN) architecture for binary and multi-class classification. DNN-based botnet detection models are developed and experiments are performed with the BotIoT and N-BaIoT datasets to validate the effectiveness of the hyperparameter optimisation method. Experiment results showed that the proposed method produced DNN models that achieved high botnet attack detection rates, low false alarm rates, and near real-time computation speed.},
  langid = {english}
}

@article{pourahmadi_SpottingAnomaliesEdge_2022,
  title = {Spotting {{Anomalies}} at the {{Edge}}: {{Outlier Exposure-based Cross-silo Federated Learning}} for {{DDoS Detection}}},
  shorttitle = {Spotting {{Anomalies}} at the {{Edge}}},
  author = {Pourahmadi, Vahid and Alameddine, Hyame Assem and Salahuddin, Mohammad A. and Boutaba, Raouf},
  date = {2022},
  journaltitle = {IEEE Transactions on Dependable and Secure Computing},
  pages = {1--14},
  issn = {1941-0018},
  doi = {10.1109/TDSC.2022.3224896},
  abstract = {Distributed Denial-of-Service (DDoS) attacks are expected to continue plaguing service availability in emerging networks which rely on distributed edge clouds to offer critical, latency-sensitive applications. However, edge servers increase the network attack surface, which is exacerbated with the massive number of connected Internet of Things (IoT) devices that can be weaponized to launch DDoS attacks. Therefore, it is crucial to detect DDoS attacks early, i.e., at the network edge. In this paper, we empower the network edge with intelligent DDoS detection by learning from similarities between different data and DDoS attacks available across the edge servers. To this end, we develop a novel Outlier Exposure (OE)-enabled cross-silo Federated Learning framework, namely FedOE. FedOE enables distributed training of OE-based ML models using a limited number of labeled outliers (i.e., attack flows) experienced at edge servers. We propose a novel OE-based Autoencoder (oAE) that can better discriminate anomalies in comparison to the widely adopted traditional Autoencoder, using a tailored, OE-based loss function. We evaluate oAE in FedOE and demonstrate its ability to generalize to zero-day attacks, with just 50 labeled attack flows per edge server. The results show that oAE achieves a high F1-score for most DDoS attacks, outclassing its non-OE counterpart.},
  eventtitle = {{{IEEE Transactions}} on {{Dependable}} and {{Secure Computing}}},
  keywords = {anomaly detection,Anomaly detection,Computer crime,Data models,DDoS detection,Denial-of-service attack,Edge intelligence,federated learning,Image edge detection,outlier exposure,Servers,Training}
}

@article{pourahmadi_SpottingAnomaliesEdge_2023a,
  title = {Spotting {{Anomalies}} at the {{Edge}}: {{Outlier Exposure-Based Cross-Silo Federated Learning}} for {{DDoS Detection}}},
  shorttitle = {Spotting {{Anomalies}} at the {{Edge}}},
  author = {Pourahmadi, Vahid and Alameddine, Hyame Assem and Salahuddin, Mohammad Ali and Boutaba, Raouf},
  date = {2023-09},
  journaltitle = {IEEE Transactions on Dependable and Secure Computing},
  volume = {20},
  number = {5},
  pages = {4002--4015},
  issn = {1941-0018},
  doi = {10.1109/TDSC.2022.3224896},
  url = {https://ieeexplore.ieee.org/document/9964111},
  urldate = {2024-04-12},
  abstract = {Distributed Denial-of-Service (DDoS) attacks are expected to continue plaguing service availability in emerging networks which rely on distributed edge clouds to offer critical, latency-sensitive applications. However, edge servers increase the network attack surface, which is exacerbated with the massive number of connected Internet of Things (IoT) devices that can be weaponized to launch DDoS attacks. Therefore, it is crucial to detect DDoS attacks early, i.e., at the network edge. In this paper, we empower the network edge with intelligent DDoS detection by learning from similarities between different data and DDoS attacks available across the edge servers. To this end, we develop a novel Outlier Exposure (OE)-enabled cross-silo Federated Learning framework, namely FedOE. FedOE enables distributed training of OE-based ML models using a limited number of labeled outliers (i.e., attack flows) experienced at edge servers. We propose a novel OE-based Autoencoder (oAE) that can better discriminate anomalies in comparison to the widely adopted traditional Autoencoder, using a tailored, OE-based loss function. We evaluate oAE in FedOE and demonstrate its ability to generalize to zero-day attacks, with just 50 labeled attack flows per edge server. The results show that oAE achieves a high F1-score for most DDoS attacks, outclassing its non-OE counterpart.},
  eventtitle = {{{IEEE Transactions}} on {{Dependable}} and {{Secure Computing}}},
  keywords = {anomaly detection,Anomaly detection,Computer crime,Data models,DDoS detection,Denial-of-service attack,Edge intelligence,federated learning,Image edge detection,outlier exposure,Servers,Training}
}

@online{prasad_ReconcilingSecurityCommunication_2022,
  title = {Reconciling {{Security}} and {{Communication Efficiency}} in {{Federated Learning}}},
  author = {Prasad, Karthik and Ghosh, Sayan and Cormode, Graham and Mironov, Ilya and Yousefpour, Ashkan and Stock, Pierre},
  date = {2022-07-26},
  eprint = {2207.12779},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2207.12779},
  urldate = {2022-08-18},
  abstract = {Cross-device Federated Learning is an increasingly popular machine learning setting to train a model by leveraging a large population of client devices with high privacy and security guarantees. However, communication efficiency remains a major bottleneck when scaling federated learning to production environments, particularly due to bandwidth constraints during uplink communication. In this paper, we formalize and address the problem of compressing client-to-server model updates under the Secure Aggregation primitive, a core component of Federated Learning pipelines that allows the server to aggregate the client updates without accessing them individually. In particular, we adapt standard scalar quantization and pruning methods to Secure Aggregation and propose Secure Indexing, a variant of Secure Aggregation that supports quantization for extreme compression. We establish state-of-the-art results on LEAF benchmarks in a secure Federated Learning setup with up to 40\texttimes{} compression in uplink communication with no meaningful loss in utility compared to uncompressed baselines.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
}

@article{preuveneers_ChainedAnomalyDetection_2018,
  title = {Chained {{Anomaly Detection Models}} for {{Federated Learning}}: {{An Intrusion Detection Case Study}}},
  shorttitle = {Chained {{Anomaly Detection Models}} for {{Federated Learning}}},
  author = {Preuveneers, Davy and Rimmer, Vera and Tsingenopoulos, Ilias and Spooren, Jan and Joosen, Wouter and Ilie-Zudor, Elisabeth},
  date = {2018-12-18},
  journaltitle = {Applied Sciences},
  shortjournal = {Applied Sciences},
  volume = {8},
  number = {12},
  pages = {2663},
  issn = {2076-3417},
  doi = {10.3390/app8122663},
  url = {http://www.mdpi.com/2076-3417/8/12/2663},
  urldate = {2021-06-07},
  abstract = {The adoption of machine learning and deep learning is on the rise in the cybersecurity domain where these AI methods help strengthen traditional system monitoring and threat detection solutions. However, adversaries too are becoming more effective in concealing malicious behavior amongst large amounts of benign behavior data. To address the increasing time-to-detection of these stealthy attacks, interconnected and federated learning systems can improve the detection of malicious behavior by joining forces and pooling together monitoring data. The major challenge that we address in this work is that in a federated learning setup, an adversary has many more opportunities to poison one of the local machine learning models with malicious training samples, thereby influencing the outcome of the federated learning and evading detection. We present a solution where contributing parties in federated learning can be held accountable and have their model updates audited. We describe a permissioned blockchain-based federated learning method where incremental updates to an anomaly detection machine learning model are chained together on the distributed ledger. By integrating federated learning with blockchain technology, our solution supports the auditing of machine learning models without the necessity to centralize the training data. Experiments with a realistic intrusion detection use case and an autoencoder for anomaly detection illustrate that the increased complexity caused by blockchain technology has a limited performance impact on the federated learning, varying between 5 and 15\%, while providing full transparency over the distributed training process of the neural network. Furthermore, our blockchain-based federated learning solution can be generalized and applied to more sophisticated neural network architectures and other use cases.},
  langid = {english}
}

@inproceedings{putra_DecentralisedTrustworthyCollaborative_2021,
  title = {Decentralised {{Trustworthy Collaborative Intrusion Detection System}} for {{IoT}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Blockchain}} ({{Blockchain}})},
  author = {Putra, Guntur Dharma and Dedeoglu, Volkan and Pathak, Abhinav and Kanhere, Salil S. and Jurdak, Raja},
  date = {2021-12},
  pages = {306--313},
  doi = {10.1109/Blockchain53845.2021.00048},
  abstract = {Intrusion Detection Systems (IDS) have been the industry standard for securing IoT networks against known attacks. To increase the capability of an IDS, researchers proposed the concept of blockchain-based Collaborative-IDS (CIDS), wherein blockchain acts as a decentralised platform allowing collaboration between CIDS nodes to share intrusion related information, such as intrusion alarms and detection rules. However, proposals in blockchain-based CIDS overlook the importance of continuous evaluation of the trustworthiness of each node and generally work based on the assumption that the nodes are always honest. In this paper, we propose a decentralised CIDS that emphasises the importance of building trust between CIDS nodes. In our proposed solution, each CIDS node exchanges detection rules to help other nodes detect new types of intrusion. Our architecture offloads the trust computation to the blockchain and utilises a decentralised storage to host the shared trustworthy detection rules, ensuring scalability. Our implementation in a lab-scale testbed shows that the our solution is feasible and performs within the expected benchmarks of the Ethereum platform.},
  eventtitle = {2021 {{IEEE International Conference}} on {{Blockchain}} ({{Blockchain}})},
  keywords = {Benchmark testing,blockchain,Blockchains,Collaboration,collaborative,Computer architecture,Economics,Intrusion detection,intrusion detection system,IoT,scalability,Scalability,trust management}
}

@article{putra_TrustReputationManagement_,
  title = {Trust and {{Reputation Management}} for {{Blockchain-enabled IoT}}},
  author = {Putra, Guntur Dharma and Malik, Sidra and Dedeoglu, Volkan and Kanhere, Salil S and Jurdak, Raja},
  abstract = {In recent years, there has been an increasing interest in incorporating blockchain for the Internet of Things (IoT) to address the inherent issues of IoT, such as single point of failure and data silos. However, blockchain alone cannot ascertain the authenticity and veracity of the data coming from IoT devices. The append-only nature of blockchain exacerbates this issue, as it would not be possible to alter the data once recorded onchain. Trust and Reputation Management (TRM) is an effective approach to overcome the aforementioned trust issues. However, designing TRM frameworks for blockchain-enabled IoT applications is a non-trivial task, as each application has its unique trust challenges with their unique features and requirements. In this paper, we present our experiences in designing TRM framework for various blockchain-enabled IoT applications to provide insights and highlight open research challenges for future opportunities.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@report{qi_DifferentiallyPrivateKnowledge_2022,
  type = {preprint},
  title = {Differentially {{Private Knowledge Transfer}} for {{Federated Learning}}},
  author = {Qi, Tao and Wu, Fangzhao and Wu, Chuhan and Huang, Yongfeng and Xie, Xing},
  date = {2022-05-26},
  institution = {In Review},
  doi = {10.21203/rs.3.rs-1571398/v1},
  url = {https://www.researchsquare.com/article/rs-1571398/v1},
  urldate = {2022-07-05},
  abstract = {Abstract           Extracting useful knowledge from big data is important for machine learning. When data is privacy-sensitive and cannot be directly collected, federated learning is a promising option that extracts knowledge from decentralized data by learning and exchanging model parameters, rather than raw data. However, model parameters may encode not only non-private knowledge but also private information of local data, thereby transferring knowledge via model parameters is not privacy-secure. Here, we present a novel knowledge transfer method named PrivateKT, which uses actively selected small public data to transfer high-quality knowledge in federated learning with privacy guarantees. We verify PrivateKT on three different datasets, and results show that PrivateKT can maximally reduce 84\% of the performance gap between centralized learning and existing federated learning methods under strict differential privacy restrictions. PrivateKT provides a potential direction to effective and privacy-preserving knowledge transfer in machine intelligent systems.},
  langid = {english}
}

@article{qi_FedBKDHeterogenousFederated_2022,
  title = {{{FedBKD}}: {{Heterogenous Federated Learning Via Bidirectional Knowledge Distillation}} for {{Modulation Classification}} in {{IoT-Edge System}}},
  shorttitle = {{{FedBKD}}},
  author = {Qi, Peihan and Zhou, Xiaoyu and Ding, Yuanlei and Zhang, Zhengyu and Zheng, Shilian and Li, Zan},
  date = {2022},
  journaltitle = {IEEE Journal of Selected Topics in Signal Processing},
  pages = {1--16},
  issn = {1941-0484},
  doi = {10.1109/JSTSP.2022.3224597},
  abstract = {Benefit from the rapid evolution of artificial intelligence and wireless communication technology, diverse Internet of Things (IoT) devices with edge computing ability have widely penetrated every aspect of daily human life. However, the deviations of private datasets and the heterogeneity of local models caused by the difference in device composition and application scenarios have hampering the aggregation of global recognition model in modulation classification task, thus constraining the classification performance of intelligent IoT-edge devices severely. To address this problem, we propose a heterogenous Federated learning framework based on Bidirectional Knowledge Distillation (FedBKD) for IoT system, which integrates knowledge distillation into the local model upload (client-to-cloud) and global model download (cloud-to-client) steps of federated learning. The client-to-cloud distillation is regarded as a process of multi-teacher knowledge distillation and the global network is regarded as a student network that unifies the heterogeneous knowledge from multiple local teacher networks. A public dataset is generated by conditional variational autoencoder (CVAE) and stored in the cloud server for supporting the obtaining of heterogeneous knowledge without sharing the private data of IoT devices. The cloud-to-client distillation is single-teacher-multiple-students process, which distills the knowledge from the single global model back to multiple heterogeneous local networks and partial knowledge distillation is used in this process. We implement our FedBKD method in the modulation classification task and the simulation results have proven the effectiveness of our proposed method.},
  eventtitle = {{{IEEE Journal}} of {{Selected Topics}} in {{Signal Processing}}},
  keywords = {Adaptation models,conditional variational autoencoder,Data models,federated learning,Federated learning,Internet of Things,IoT,knowledge distillation,Knowledge engineering,model heterogeneity,Modulation,Training}
}

@inproceedings{qin_FederatedLearningBasedNetwork_2021,
  title = {Federated {{Learning-Based Network Intrusion Detection}} with a {{Feature Selection Approach}}},
  booktitle = {2021 {{International Conference}} on {{Electrical}}, {{Communication}}, and {{Computer Engineering}} ({{ICECCE}})},
  author = {Qin, Yang and Kondo, Masaaki},
  date = {2021-06-12},
  pages = {1--6},
  publisher = {IEEE},
  location = {Kuala Lumpur, Malaysia},
  doi = {10.1109/ICECCE52056.2021.9514222},
  url = {https://ieeexplore.ieee.org/document/9514222/},
  urldate = {2021-10-04},
  abstract = {With the increase and diversity of network attacks, machine learning has shown its efficiency in realizing intrusion detection. Federated Learning (FL) has been proposed as a new distributed machine learning approach, which collaboratively trains a prediction model by aggregating local models of users without sharing their privacy-sensitive data. Recently, the approach is applied to optimize intrusion detection for resourced-constrained environments. However, since the attacks are becoming more sophisticated and targeted, there is also a growing need to enhance detection models according to the characteristics of attack type; meanwhile, choosing effective feature sets from the network traffic characteristics is considered one of the most important technologies in data analysis. In this paper, we first proposed a federated learning-based intrusion detection system with feature selection technology. Firstly, a greedy algorithm is suggested to select features that achieve better intrusion detection accuracy regarding different attack categories. Afterward, multiple global models are generated by the server in federated learning, according to the decided features of edge devices. For evaluating the effectiveness of the proposed approach, simulation experiments based on the latest on-device neural network for anomaly detection are conducted over the NSL-KDD dataset. Experimental results demonstrate greatly improved accuracy of our method.},
  eventtitle = {2021 {{International Conference}} on {{Electrical}}, {{Communication}}, and {{Computer Engineering}} ({{ICECCE}})},
  isbn = {978-1-66543-897-1},
  langid = {english},
  keywords = {survey-fids}
}

@article{qin_LineSpeedScalableIntrusion_2020,
  title = {Line-{{Speed}} and {{Scalable Intrusion Detection}} at the {{Network Edge}} via {{Federated Learning}}},
  author = {Qin, Qiaofeng and Poularakis, Konstantinos and Leung, Kin K and Tassiulas, Leandros},
  date = {2020-06},
  pages = {9},
  abstract = {Intrusion detection through classifying incoming packets is a crucial functionality at the network edge, requiring accuracy, efficiency and scalability at the same time, introducing a great challenge. On the one hand, traditional table-based switch functions have limited capacity to identify complicated network attack behaviors. On the other hand, machine learning based methods providing high accuracy are widely used for packet classification, but they typically require packets to be forwarded to an extra host and therefore increase the network latency. To overcome these limitations, in this paper we propose an architecture with programmable data plane switches. We show that Binarized Neural Networks (BNNs) can be implemented as switch functions at the network edge classifying incoming packets at the line speed of the switches. To train BNNs in a scalable manner, we adopt a federated learning approach that keeps the communication overheads of training small even for scenarios involving many edge network domains. We next develop a prototype using the P4 language and perform evaluations. The results demonstrate that a multi-fold improvement in latency and communication overheads can be achieved compared to state-ofthe-art learning architectures.},
  langid = {english},
  keywords = {â›” No DOI found,survey-fids}
}

@inproceedings{qin_LineSpeedScalableIntrusion_2020a,
  title = {Line-{{Speed}} and {{Scalable Intrusion Detection}} at the {{Network Edge}} via {{Federated Learning}}},
  booktitle = {2020 {{IFIP Networking Conference}} ({{Networking}})},
  author = {Qin, Qiaofeng and Poularakis, Konstantinos and Leung, Kin K. and Tassiulas, Leandros},
  date = {2020-06},
  pages = {352--360},
  url = {https://ieeexplore.ieee.org/document/9142704},
  urldate = {2024-04-12},
  abstract = {Intrusion detection through classifying incoming packets is a crucial functionality at the network edge, requiring accuracy, efficiency and scalability at the same time, introducing a great challenge. On the one hand, traditional table-based switch functions have limited capacity to identify complicated network attack behaviors. On the other hand, machine learning based methods providing high accuracy are widely used for packet classification, but they typically require packets to be forwarded to an extra host and therefore increase the network latency. To overcome these limitations, in this paper we propose an architecture with programmable data plane switches. We show that Binarized Neural Networks (BNNs) can be implemented as switch functions at the network edge classifying incoming packets at the line speed of the switches. To train BNNs in a scalable manner, we adopt a federated learning approach that keeps the communication overheads of training small even for scenarios involving many edge network domains. We next develop a prototype using the P4 language and perform evaluations. The results demonstrate that a multi-fold improvement in latency and communication overheads can be achieved compared to state-of the-art learning architectures.},
  eventtitle = {2020 {{IFIP Networking Conference}} ({{Networking}})},
  keywords = {Logic gates,Neural networks,Security,Servers,survey-fids,Switches,Training}
}

@inproceedings{qureshi_PerformanceImpactPoisoning_2021,
  title = {On the {{Performance Impact}} of {{Poisoning Attacks}} on {{Load Forecasting}} in {{Federated Learning}}},
  booktitle = {Adjunct {{Proceedings}} of the 2021 {{ACM International Joint Conference}} on {{Pervasive}} and {{Ubiquitous Computing}} and {{Proceedings}} of the 2021 {{ACM International Symposium}} on {{Wearable Computers}}},
  author = {Qureshi, Naik Bakht Sania and Kim, Dong-Hoon and Lee, Jiwoo and Lee, Eun-Kyu},
  date = {2021-09-24},
  series = {{{UbiComp}}/{{ISWC}} '21 {{Adjunct}}},
  pages = {64--66},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3460418.3479285},
  url = {https://dl.acm.org/doi/10.1145/3460418.3479285},
  urldate = {2023-11-02},
  abstract = {This article examines a poisoning attack on federated learning. While recent studies are actively exploring this topic in classification models of learning such as image recognition, there are few studies that address the topic in regression models. In particular, this research investigates the impacts of poisoning attacks on the performance of load forecasting, which has hardly studied yet in academia. This research implements two poisoning attacks on a federated learning setting and runs experiments to enumerate their impacts on prediction accuracy of load forecasting. With initial results, we plan to bring a couple of research questions for open discussion to audience.},
  isbn = {978-1-4503-8461-2},
  keywords = {Artificial Intelligence,Distributed System,Energy Data,Federated Learning,Load Forecasting,Poisoning Attack,Security}
}

@inproceedings{quyen_FederatedIntrusionDetection_2022,
  title = {Federated {{Intrusion Detection}} on~{{Non-IID Data}} for~{{IIoT Networks Using Generative Adversarial Networks}} and~{{Reinforcement Learning}}},
  booktitle = {Information {{Security Practice}} and {{Experience}}},
  author = {Quyen, Nguyen Huu and Duy, Phan The and Vy, Nguyen Chi and Hien, Do Thi Thu and Pham, Van-Hau},
  editor = {Su, Chunhua and Gritzalis, Dimitris and Piuri, Vincenzo},
  date = {2022},
  pages = {364--381},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-21280-2_20},
  abstract = {Federated learning (FL) has become the promising approach for building collaborative intrusion detection systems (IDS) as providing privacy guaranteeing among data holders. Nevertheless, the non-independent and identically distributed (Non-IID) data in real-world scenarios negatively impacts the performance of aggregated models from training client updates. To this end, in this paper, we introduce Generative Adversarial Networks (GANs) and Reinforcement Learning (RL) approach for federated IDS that can deal with Non-IID data among organizational networks. More specifically, the imbalanced state between data classes is tackled by GAN-based data augmentation, while RL provides better performance in the client choosing process for federated IDS model training. Finally, the experimental results on Kitsune dataset indicate that our work can help to set up the collaboration between data holders for building more effective IDS to deploy in practice with distinguished data distribution.},
  isbn = {978-3-031-21280-2},
  langid = {english}
}

@article{radulescu_MultiObjectiveMultiAgentDecision_2019,
  title = {Multi-{{Objective Multi-Agent Decision Making}}: {{A Utility-based Analysis}} and {{Survey}}},
  author = {R\u adulescu, Roxana and Mannion, Patrick and Roijers, Diederik M. and Now\'e, Ann},
  date = {2019-09-06},
  journaltitle = {Autonomous Agents and Multi-Agent Systems},
  volume = {34},
  number = {1},
  pages = {10},
  issn = {1387-2532},
  doi = {10.1007/s10458-019-09433-x},
  url = {http://link.springer.com/10.1007/s10458-019-09433-x},
  abstract = {The majority of multi-agent system (MAS) implementations aim to optimise agents' policies with respect to a single objective, despite the fact that many real-world problem domains are inherently multi-objective in nature. Multi-objective multi-agent systems (MOMAS) explicitly consider the possible trade-offs between conflicting objective functions. We argue that, in MOMAS, such compromises should be analysed on the basis of the utility that these compromises have for the users of a system. As is standard in multi-objective optimisation, we model the user utility using utility functions that map value or return vectors to scalar values. This approach naturally leads to two different optimisation criteria: expected scalarised returns (ESR) and scalarised expected returns (SER). We develop a new taxonomy which classifies multi-objective multi-agent decision making settings, on the basis of the reward structures, and which and how utility functions are applied. This allows us to offer a structured view of the field, to clearly delineate the current state-of-the-art in multi-objective multi-agent decision making approaches and to identify promising directions for future research. Starting from the execution phase, in which the selected policies are applied and the utility for the users is attained, we analyse which solution concepts apply to the different settings in our taxonomy. Furthermore, we define and discuss these solution concepts under both ESR and SER optimisation criteria. We conclude with a summary of our main findings and a discussion of many promising future research directions in multi-objective multi-agent systems.},
  isbn = {1045801909}
}

@article{rahman_BlockchainbasedAIenabled_2022,
  title = {Blockchain Based {{AI-enabled Industry}} 4.0 {{CPS Protection}} against {{Advanced Persistent Threat}}},
  author = {Rahman, Ziaur and Yi, Xun and Khalil, Ibrahim},
  date = {2022},
  journaltitle = {IEEE Internet of Things Journal},
  shortjournal = {IEEE Internet Things J.},
  pages = {1--1},
  issn = {2327-4662, 2372-2541},
  doi = {10/gpch65},
  url = {https://ieeexplore.ieee.org/document/9695986/},
  urldate = {2022-02-04},
  abstract = {Industry 4.0 is all about doing things in a concurrent, secure, and fine-grained manner. IoT edge-sensors and their associated data play a predominant role in today's industry ecosystem. Breaching data or forging source devices after injecting advanced persistent threats (APT) damages the industry owners' money and loss of operators' lives. The existing challenges include APT injection attacks targeting vulnerable edge devices, insecure data transportation, trust inconsistencies among stakeholders, incompliant data storing mechanisms, etc. Edgeservers often suffer because of their lightweight computation capacity to stamp out unauthorized data or instructions, which in essence, makes them exposed to attackers. When attackers target edge servers while transporting data using traditional PKI-rendered trusts, consortium blockchain (CBC) offers proven techniques to transfer and maintain those sensitive data securely. With the recent improvement of edge machine learning, edge devices can filter malicious data at their end which largely motivates us to institute a Blockchain and AI aligned APT detection system. The unique contributions of the paper include efficient APT detection at the edge and transparent recording of the detection history in an immutable blockchain ledger. In line with that, the certificateless data transfer mechanism boost trust among collaborators and ensure an economical and sustainable mechanism after eliminating existing certificate authority. Finally, the edge-compliant storage technique facilitates efficient predictive maintenance. The respective experimental outcomes reveal that the proposed technique outperforms the other competing systems and models.},
  langid = {english}
}

@article{rahman_ICNIoTfederatedlearning_2023,
  title = {On the {{ICN-IoT}} with Federated Learning Integration of Communication: {{Concepts}}, Security-Privacy Issues, Applications, and Future Perspectives},
  shorttitle = {On the {{ICN-IoT}} with Federated Learning Integration of Communication},
  author = {Rahman, Anichur and Hasan, Kamrul and Kundu, Dipanjali and Islam, Md. Jahidul and Debnath, Tanoy and Band, Shahab S. and Kumar, Neeraj},
  date = {2023-01-01},
  journaltitle = {Future Generation Computer Systems},
  shortjournal = {Future Generation Computer Systems},
  volume = {138},
  pages = {61--88},
  issn = {0167-739X},
  doi = {10.1016/j.future.2022.08.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0167739X22002667},
  urldate = {2022-09-28},
  abstract = {The individual and integration use of the Internet of Things (IoT), Information-Centric Networking (ICN), and Federated Learning (FL) have recently been used in several network-related scenarios and have consequently experienced a growing interest in the research community. Federated learning addresses the privacy and security issues of the IoT data in a decentralized manner. Also, it can be capable of training the multiple learning algorithms through local content except for exchanging data through intelligent Artificial Intelligence (AI)-based algorithms. Moreover, in ICN, the content is retrieved and stored based on the content name rather than the content location address. On the other hand, it is challenging to support the massive IoT devices by the fifth generation (5G) mobile-cellular networks. Therefore, the cellular 6G networks are expected to increase the connection capabilities by 10--100 times over 5G, which necessitates a convergence of Communication, Computing, and Caching (3C). At the same time, the in-network caching capabilities of ICN can be attractive features for IoT networks. IoT aspires to link anybody and/or everything at any time and location. However, integrating IoT with different areas is a new academic topic and is still in its infancy. As a result, this research highlights the potential of ICN for IoTs by conducting an exhaustive literature review. This work provides a comprehensive survey regarding these three recent research trends (i.e., FL, IoT, and ICN) and reviews the related state-of-the-art literature. We first describe the main features of each technology and discuss their most common and used variants. Furthermore, we envision the integration of such technologies to take advantage efficiently. Indeed, we consider their group-wise (FL-ICN-IoT) utilization based on the need for more robust security and privacy. Additionally, we cover the application fields of these technologies both individually and combinedly. Finally, we discuss the open issues of the reviewed research and describe potential directions for future avenues regarding integrating IoT, ICN, and FL technologies.},
  langid = {english},
  keywords = {\_done,Artificial Intelligence,Communication,Computing,Confidentiality,Federated Learning,Information-Centric Networking,Internet of Things,Machine Learning,Privacy,Security}
}

@article{rahman_ICNIoTfederatedlearning_2023a,
  title = {On the {{ICN-IoT}} with Federated Learning Integration of Communication: {{Concepts}}, Security-Privacy Issues, Applications, and Future Perspectives},
  shorttitle = {On the {{ICN-IoT}} with Federated Learning Integration of Communication},
  author = {Rahman, Anichur and Hasan, Kamrul and Kundu, Dipanjali and Islam, Md. Jahidul and Debnath, Tanoy and Band, Shahab S. and Kumar, Neeraj},
  date = {2023-01-01},
  journaltitle = {Future Generation Computer Systems},
  shortjournal = {Future Generation Computer Systems},
  volume = {138},
  pages = {61--88},
  issn = {0167-739X},
  doi = {10.1016/j.future.2022.08.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0167739X22002667},
  urldate = {2024-04-12},
  abstract = {The individual and integration use of the Internet of Things (IoT), Information-Centric Networking (ICN), and Federated Learning (FL) have recently been used in several network-related scenarios and have consequently experienced a growing interest in the research community. Federated learning addresses the privacy and security issues of the IoT data in a decentralized manner. Also, it can be capable of training the multiple learning algorithms through local content except for exchanging data through intelligent Artificial Intelligence (AI)-based algorithms. Moreover, in ICN, the content is retrieved and stored based on the content name rather than the content location address. On the other hand, it is challenging to support the massive IoT devices by the fifth generation (5G) mobile-cellular networks. Therefore, the cellular 6G networks are expected to increase the connection capabilities by 10--100 times over 5G, which necessitates a convergence of Communication, Computing, and Caching (3C). At the same time, the in-network caching capabilities of ICN can be attractive features for IoT networks. IoT aspires to link anybody and/or everything at any time and location. However, integrating IoT with different areas is a new academic topic and is still in its infancy. As a result, this research highlights the potential of ICN for IoTs by conducting an exhaustive literature review. This work provides a comprehensive survey regarding these three recent research trends (i.e., FL, IoT, and ICN) and reviews the related state-of-the-art literature. We first describe the main features of each technology and discuss their most common and used variants. Furthermore, we envision the integration of such technologies to take advantage efficiently. Indeed, we consider their group-wise (FL-ICN-IoT) utilization based on the need for more robust security and privacy. Additionally, we cover the application fields of these technologies both individually and combinedly. Finally, we discuss the open issues of the reviewed research and describe potential directions for future avenues regarding integrating IoT, ICN, and FL technologies.},
  keywords = {Artificial Intelligence,Communication,Computing,Confidentiality,Federated Learning,Information-Centric Networking,Internet of Things,Machine Learning,Privacy,Security}
}

@article{rahman_InternetThingsIntrusion_2020,
  title = {Internet of {{Things Intrusion Detection}}: {{Centralized}}, {{On-Device}}, or {{Federated Learning}}?},
  shorttitle = {Internet of {{Things Intrusion Detection}}},
  author = {Rahman, Sawsan Abdul and Tout, Hanine and Talhi, Chamseddine and Mourad, Azzam},
  date = {2020-11},
  journaltitle = {IEEE Network},
  shortjournal = {IEEE Network},
  volume = {34},
  number = {6},
  pages = {310--317},
  issn = {0890-8044, 1558-156X},
  doi = {10.1109/MNET.011.2000286},
  url = {https://ieeexplore.ieee.org/document/9183799/},
  urldate = {2021-06-01},
  abstract = {With the ever increasing number of cyber-attacks, Internet of Things (IoT) devices are being exposed to serious malware, attacks, and malicious activities alongside their development. While past research has been focused on centralized intrusion detection assuming the existence of a central entity to store and perform analysis on data from all participant devices, these approaches cannot scale well with the fast growth of IoT connected devices and introduce a single-point failure risk that may compromise data privacy. Moreover, with data being widely spread across large networks of connected devices, decentralized computations are very much in need. In this context, we propose in this article a Federated Learning based scheme for IoT intrusion detection that maintains data privacy by performing local training and inference of detection models. In this scheme, not only privacy can be assured, but also devices can benefit from their peers' knowledge by communicating only their updates with a remote server that aggregates the latter and shares an improved detection model with participating devices. We perform thorough experiments on an NSL-KDD dataset to evaluate the efficiency of the proposed approach. Experimental results and empirical analysis explore the robustness and advantages of the proposed Federated Learning detection model by reaching an accuracy close to that of the centralized approach and outperforming the distributed unaggregated on-device trained models.},
  langid = {english},
  keywords = {survey-fids},
  annotation = {CorpusID:226401673}
}

@article{rajan_Blockchainbasedmultilayeredfederated_,
  title = {Blockchain-Based Multi-Layered Federated Extreme Learning Networks in Connected Vehicles},
  author = {Rajan, Durga and Eswaran, Poovammal and Srivastava, Gautam and Ramana, Kadiyala and Iwendi, Celestine},
  journaltitle = {Expert Systems},
  volume = {n/a},
  number = {n/a},
  pages = {e13222},
  issn = {1468-0394},
  doi = {10.1111/exsy.13222},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13222},
  urldate = {2023-01-09},
  abstract = {Intelligent and networked vehicles help build an efficient vehicular network's infrastructure. The widespread use of electronic software exposes these networks to cyber-attacks. Intrusion detection systems (IDS) are useful for preventing vehicle network assaults. IDS have been customized using machine and deep learning networks for greater real-time performance. Current learning-based intrusion detection systems demand substantial processing capabilities to train and update intricate training models in vehicular devices, resulting in decreased efficiency and ability to defend against assaults. This study presents Blockchain-based Multi-Layer Federated Extreme Learning Machines (MLFEM) enabled IDS (BEF-IDS) for safe data transfers. The proposed IDS leverages federated learning to generate Multi-Layered Extreme Learning Machines, which are offloaded to dispersed vehicular edge devices such as Road-Side Units (RSU) and connected vehicles. This federated strategy decreases resource use without sacrificing security. Blockchain technology records and shares training models, assuring network security. Using real-time data sets, the suggested algorithm's performance under different attack scenarios were extensively tested. The suggested method obtained 98\% accuracy and Recall, 97.9\% Precision, and 97.9\% F1 Score performance, which suggests it's incredibly secure and costs very little to transmit.},
  langid = {english},
  keywords = {blockchain,federated learning,intrusion detection systems,privacy,security}
}

@inproceedings{rajasekar_EfficientIntrusionDetection_2022,
  title = {An {{Efficient Intrusion Detection Model Based}} on {{Recurrent Neural Network}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Distributed Computing}} and {{Electrical Circuits}} and {{Electronics}} ({{ICDCECE}})},
  author = {Rajasekar, Vani and Sarika, Sabavath and S, Velliangiri and Joseph S, Iwin Thanakumar and S, Kalaivani K},
  date = {2022-04},
  pages = {1--6},
  doi = {10.1109/ICDCECE53908.2022.9793016},
  abstract = {Intrusion detection has proven to be an efficient strategy of information security since it can identify unknown attacks from network traffic. The existing method to detect network anomalies is often based on classic machine learning models like KNN, SVM, and others. Even though these techniques can provide some impressive results, they have a poor level of accuracy and rely primarily on manual system design is required in feature extraction which is no longer relevant in the big data era. A deep learning-based intrusion detection methodology is suggested in this method to address the issues of low accuracy and feature extraction. The recurrent neural network is used in this approach with three steps in preprocessing such as data numerical conversion, data normalization, and data balancing. It can efficiently represent network traffic flow and enhance the capacity to identify anomalies. The suggested model is put to the test using a publicly available benchmark dataset, and the findings show that it outperforms alternative comparison approaches. The result analysis of the proposed method shows that the average accuracy is 99.56\%, average TPR is 99.55\%, average TNR is 99.32\%.},
  eventtitle = {2022 {{IEEE International Conference}} on {{Distributed Computing}} and {{Electrical Circuits}} and {{Electronics}} ({{ICDCECE}})},
  keywords = {Data Balancing,Deep learning,Deep Learning,Feature extraction,Intrusion detection,Numerical models,Recurrent Neural Network,Recurrent neural networks,Support vector machines,Telecommunication traffic}
}

@inproceedings{rajput_DETOXRedundancybasedFramework_2019,
  title = {{{DETOX}}: {{A Redundancy-based Framework}} for {{Faster}} and {{More Robust Gradient Aggregation}}},
  shorttitle = {{{DETOX}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Rajput, Shashank and Wang, Hongyi and Charles, Zachary and Papailiopoulos, Dimitris},
  date = {2019},
  volume = {32},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2019/hash/415185ea244ea2b2bedeb0449b926802-Abstract.html},
  urldate = {2022-10-12},
  abstract = {To improve the resilience of distributed  training to worst-case, or Byzantine node failures, several recent methods have replaced gradient averaging with robust aggregation methods. Such techniques can have high computational costs, often quadratic in the number of compute nodes, and only have limited robustness guarantees. Other methods have instead used redundancy to guarantee robustness, but can only tolerate limited numbers of Byzantine failures. In this work, we present DETOX, a Byzantine-resilient distributed training framework that combines algorithmic redundancy with robust aggregation. DETOX operates in two steps, a filtering step that uses limited redundancy to significantly reduce the effect of Byzantine nodes, and a hierarchical aggregation step that can be used in tandem with any state-of-the-art robust aggregation method. We show theoretically that this leads to a substantial increase in robustness, and has a per iteration runtime that can be nearly linear in the number of compute nodes. We provide extensive experiments over real distributed setups across a variety of large-scale machine learning tasks, showing that DETOX leads to orders of magnitude accuracy and speedup improvements over many state-of-the-art Byzantine-resilient approaches.},
  keywords = {â›” No DOI found}
}

@article{ramirez_PoisoningAttacksDefenses_2016,
  title = {Poisoning {{Attacks}} and {{Defenses}} on {{Artificial Intelligence}}: {{A Survey}}},
  author = {Ramirez, Miguel A and Kim, Song-Kyoo and Hamadi, Hussam Al and Damiani, Ernesto and Kim, Tae-Yeon and Cho, Chung-Suk and Yeun, Chan Yeob},
  date = {2016},
  volume = {4},
  pages = {16},
  abstract = {Machine learning models have been widely adopted in several fields. However, most recent studies have shown several vulnerabilities from attacks with a potential to jeopardize the integrity of the model, presenting a new window of research opportunity in terms of cyber-security. This survey is conducted with a main intention of highlighting the most relevant information related to security vulnerabilities in the context of machine learning (ML) classifiers; more specifically, directed towards training procedures against data poisoning attacks, representing a type of attack that consists of tampering the data samples fed to the model during the training phase, leading to a degradation in the model's overall accuracy during the inference phase. This work compiles the most relevant insights and findings found in the latest existing literatures addressing this type of attacks. Moreover, this paper also covers several defense techniques that promise feasible detection and mitigation mechanisms, capable of conferring a certain level of robustness to a target model against an attacker. A thorough assessment is performed on the reviewed works, comparing the effects of data poisoning on a wide range of ML models in real-world conditions, performing quantitative and qualitative analyses. This paper analyzes the main characteristics for each approach including performance success metrics, required hyperparameters, and deployment complexity. Moreover, this paper emphasizes the underlying assumptions and limitations considered by both attackers and defenders along with their intrinsic properties such as: availability, reliability, privacy, accountability, interpretability, etc. Finally, this paper concludes by making references of some of main existing research trends that provide pathways towards future research directions in the field of cyber-security.},
  langid = {english}
}

@online{ramirez_PoisoningAttacksDefenses_2022,
  title = {Poisoning {{Attacks}} and {{Defenses}} on {{Artificial Intelligence}}: {{A Survey}}},
  shorttitle = {Poisoning {{Attacks}} and {{Defenses}} on {{Artificial Intelligence}}},
  author = {Ramirez, Miguel A. and Kim, Song-Kyoo and Hamadi, Hussam Al and Damiani, Ernesto and Byon, Young-Ji and Kim, Tae-Yeon and Cho, Chung-Suk and Yeun, Chan Yeob},
  date = {2022-02-22},
  eprint = {2202.10276},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2202.10276},
  url = {http://arxiv.org/abs/2202.10276},
  urldate = {2022-09-01},
  abstract = {Machine learning models have been widely adopted in several fields. However, most recent studies have shown several vulnerabilities from attacks with a potential to jeopardize the integrity of the model, presenting a new window of research opportunity in terms of cyber-security. This survey is conducted with a main intention of highlighting the most relevant information related to security vulnerabilities in the context of machine learning (ML) classifiers; more specifically, directed towards training procedures against data poisoning attacks, representing a type of attack that consists of tampering the data samples fed to the model during the training phase, leading to a degradation in the models accuracy during the inference phase. This work compiles the most relevant insights and findings found in the latest existing literatures addressing this type of attacks. Moreover, this paper also covers several defense techniques that promise feasible detection and mitigation mechanisms, capable of conferring a certain level of robustness to a target model against an attacker. A thorough assessment is performed on the reviewed works, comparing the effects of data poisoning on a wide range of ML models in real-world conditions, performing quantitative and qualitative analyses. This paper analyzes the main characteristics for each approach including performance success metrics, required hyperparameters, and deployment complexity. Moreover, this paper emphasizes the underlying assumptions and limitations considered by both attackers and defenders along with their intrinsic properties such as: availability, reliability, privacy, accountability, interpretability, etc. Finally, this paper concludes by making references of some of main existing research trends that provide pathways towards future research directions in the field of cyber-security.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security}
}

@article{rashid_FederatedLearningBasedApproach_2023,
  title = {A {{Federated Learning-Based Approach}} for {{Improving Intrusion Detection}} in {{Industrial Internet}} of {{Things Networks}}},
  author = {Rashid, Md Mamunur and Khan, Shahriar Usman and Eusufzai, Fariha and Redwan, Md Azharuddin and Sabuj, Saifur Rahman and Elsharief, Mahmoud},
  date = {2023-03},
  journaltitle = {Network},
  volume = {3},
  number = {1},
  pages = {158--179},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2673-8732},
  doi = {10.3390/network3010008},
  url = {https://www.mdpi.com/2673-8732/3/1/8},
  urldate = {2024-04-12},
  abstract = {The Internet of Things (IoT) is a network of electrical devices that are connected to the Internet wirelessly. This group of devices generates a large amount of data with information about users, which makes the whole system sensitive and prone to malicious attacks eventually. The rapidly growing IoT-connected devices under a centralized ML system could threaten data privacy. The popular centralized machine learning (ML)-assisted approaches are difficult to apply due to their requirement of enormous amounts of data in a central entity. Owing to the growing distribution of data over numerous networks of connected devices, decentralized ML solutions are needed. In this paper, we propose a Federated Learning (FL) method for detecting unwanted intrusions to guarantee the protection of IoT networks. This method ensures privacy and security by federated training of local IoT device data. Local IoT clients share only parameter updates with a central global server, which aggregates them and distributes an improved detection algorithm. After each round of FL training, each of the IoT clients receives an updated model from the global server and trains their local dataset, where IoT devices can keep their own privacy intact while optimizing the overall model. To evaluate the efficiency of the proposed method, we conducted exhaustive experiments on a new dataset named Edge-IIoTset. The performance evaluation demonstrates the reliability and effectiveness of the proposed intrusion detection model by achieving an accuracy (92.49\%) close to that offered by the conventional centralized ML models' accuracy (93.92\%) using the FL method.},
  issue = {1},
  langid = {english},
  keywords = {federated learning,Internet of Things,intrusion detection,machine learning,neural networks,privacy,security}
}

@article{rashme_InternationalJournalImage_,
  title = {International {{Journal}} of {{Image}}, {{Graphics}} and {{Signal Processing}}({{IJIGSP}})},
  author = {Rashme, Tamanna Yesmin and Uddin, Mohammed Nasir},
  journaltitle = {International Journal of Image, Graphics and Signal Processing(IJIGSP)},
  volume = {10},
  number = {10},
  pages = {63},
  url = {https://www.mecs-press.org/ijigsp/ijigsp-v10-n10/v10n10-7.html},
  urldate = {2023-01-25},
  langid = {english},
  keywords = {â›” No DOI found}
}

@article{rathore_BlockSecIoTNetBlockchainbaseddecentralized_2019,
  title = {{{BlockSecIoTNet}}: {{Blockchain-based}} Decentralized Security Architecture for {{IoT}} Network},
  author = {Rathore, Shailendra and Wook Kwon, Byung and Park, Jong Hyuk},
  date = {2019-10},
  journaltitle = {Journal of Network and Computer Applications},
  volume = {143},
  pages = {167--177},
  publisher = {Elsevier Ltd},
  issn = {10848045},
  doi = {10.1016/j.jnca.2019.06.019},
  url = {https://doi.org/10.1016/j.jnca.2019.06.019},
  abstract = {The exponential growth of the use of insecure stationary and portable devices in the Internet of Things (IoT) network of the smart city has made the security of the smart city against cyber-attacks a vital issue. Various mechanisms for detecting security attacks that rely on centralized and distributed architectures have already been proposed, but they tend to be inefficient due to such problems as storage constraints, the high cost of computation, high latency, and a single point of failure. Moreover, existing security mechanisms are faced with the issue of monitoring and collecting historic data throughout the entire IoT network of the smart city in order to deliver optimal security and defense against cyberattacks. To address the current challenges, this paper proposes a decentralized security architecture based on Software Defined Networking (SDN) coupled with a blockchain technology for IoT network in the smart city that relies on the three core technologies of SDN, Blockchain, and Fog and mobile edge computing in order to detect attacks in the IoT network more effectively. Thus, in the proposed architecture, SDN is liable to continuous monitoring and analysis of traffic data in the entire IoT network in order to provide an optimal attack detection model; Blockchain delivers decentralized attack detection to mitigate the ``single point of failure'' problem inherent to the existing architecture; and Fog and mobile edge computing supports attack detection at the fog node and, subsequently, attack mitigation at the edge node, thus enabling early detection and mitigation with lesser storage constraints, cheaper computation, and low latency. To validate the performance of the proposed architecture, it was subjected to an experimental evaluation, the results of which show that it outperforms both centralized and distributed architectures in terms of accuracy and detection time.},
  issue = {December 2018},
  keywords = {survey-fids}
}

@article{rauf_TaxonomyBioInspiredCyber_2018,
  title = {A {{Taxonomy}} of {{Bio-Inspired Cyber Security Approaches}}: {{Existing Techniques}} and {{Future Directions}}},
  author = {Rauf, Usman},
  date = {2018},
  journaltitle = {Arabian Journal for Science and Engineering},
  volume = {43},
  number = {12},
  pages = {6693--6708},
  publisher = {Springer Berlin Heidelberg},
  issn = {21914281},
  doi = {10.1007/s13369-018-3117-2},
  url = {https://doi.org/10.1007/s13369-018-3117-2},
  abstract = {After decades of deploying cyber security systems, it is a well-known fact that the existing cyber infrastructure has numerous inherent limitations that make the maintenance of the current network security devices un-scalable and provide the adversary with asymmetric advantages. These limitations include: (1) difficulty in obtaining the global knowledge due to the lack of mutual interactions among network devices, (2) no sense of self-awareness, (3) absence of self-correcting/organizing mechanisms; for instance, error-prone and time-consuming manual configuration, which is not effective in real-time attack mitigation, (4) disability to diagnose mis-configuration and conflict resolution due to multiparty management of security infrastructure. Biological systems, on the other hand, have intrinsic appealing characteristics as a result of billions of years of evolution, such as adaptivity to varying environmental conditions, inherent resiliency to failures and damages, successful and collaborative operation on the basis of a limited set of rules with global intelligence (which is larger than superposition of individuals). The aim of this survey is to review the existing bio-inspired approaches that have been used toward addressing the aforementioned issues and evaluate them accordingly. We also aim to provide information about the intrinsic potential of existing bio-inspired techniques which has not been explored yet, for improving cyber security.}
}

@article{raynaut_Dissimilaritesentrejeux_2017,
  title = {Dissimilarit\'es entre jeux de donn\'ees},
  author = {Raynaut, William and Soule-Dupuy, Chantal and Valles-Parlangeau, Nathalie},
  date = {2017-03-28},
  journaltitle = {Ing\'enierie des syst\`emes d'information},
  shortjournal = {isi},
  volume = {22},
  number = {3},
  pages = {35--63},
  issn = {16331311},
  doi = {10.3166/isi.22.3.35-63},
  url = {https://isi.revuesonline.com/article.jsp?articleId=38718},
  urldate = {2024-04-04},
  abstract = {Characterizing datasets has long been an important issue for algorithm selection and meta-level learning. Most approaches share a potential weakness in the aggregation of informations about individual features of the datasets. We propose a dissimilarity based approach avoiding this particular issue, and show the benefits it can yield in characterizing the appropriateness of classification algorithms, and in the context of meta-level classification. MOTS-CL\'ES : caract\'erisation de jeux de donn\'ees, dissimilarit\'e, m\'eta-attributs, s\'election d'algorithmes, m\'eta-apprentissage.},
  langid = {french}
}

@unpublished{reddi_AdaptiveFederatedOptimization_2021,
  title = {Adaptive {{Federated Optimization}}},
  author = {Reddi, Sashank and Charles, Zachary and Zaheer, Manzil and Garrett, Zachary and Rush, Keith and Kone\v cn\'y, Jakub and Kumar, Sanjiv and McMahan, H. Brendan},
  date = {2021-09-08},
  eprint = {2003.00295},
  eprinttype = {arXiv},
  eprintclass = {cs, math, stat},
  url = {http://arxiv.org/abs/2003.00295},
  urldate = {2022-01-28},
  abstract = {Federated learning is a distributed machine learning paradigm in which a large number of clients coordinate with a central server to learn a model without sharing their own training data. Standard federated optimization methods such as Federated Averaging (FEDAVG) are often difficult to tune and exhibit unfavorable convergence behavior. In non-federated settings, adaptive optimization methods have had notable success in combating such issues. In this work, we propose federated versions of adaptive optimizers, including ADAGRAD, ADAM, and YOGI, and analyze their convergence in the presence of heterogeneous data for general nonconvex settings. Our results highlight the interplay between client heterogeneity and communication efficiency. We also perform extensive experiments on these methods and show that the use of adaptive optimizers can significantly improve the performance of federated learning.},
  langid = {english},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},â›” No DOI found,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning}
}

@article{ren_FederatedLearningBasedComputation_2019,
  title = {Federated {{Learning-Based Computation Offloading Optimization}} in {{Edge Computing-Supported Internet}} of {{Things}}},
  author = {Ren, Jianji and Wang, Haichao and Hou, Tingting and Zheng, Shuai and Tang, Chaosheng},
  date = {2019},
  journaltitle = {IEEE Access},
  volume = {7},
  pages = {69194--69201},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2019.2919736},
  url = {https://ieeexplore.ieee.org/document/8728285/},
  abstract = {Recently, smart cities, smart homes, and smart medical systems have challenged the functionality and connectivity of the large-scale Internet of Things (IoT) devices. Thus, with the idea of offloading intensive computing tasks from them to edge nodes (ENs), edge computing emerged to supplement these limited devices. Benefit from this advantage, IoT devices can save more energy and still maintain the quality of the services they should provide. However, computational offload decisions involve federation and complex resource management and should be determined in the real-time face to dynamic workloads and radio environments. Therefore, in this work, we use multiple deep reinforcement learning (DRL) agents deployed on multiple edge nodes to indicate the decisions of the IoT devices. On the other hand, with the aim of making DRL-based decisions feasible and further reducing the transmission costs between the IoT devices and edge nodes, federated learning (FL) is used to train DRL agents in a distributed fashion. The experimental results demonstrate the effectiveness of the decision scheme and federated learning in the dynamic IoT system.}
}

@article{resnick_Reputationsystems_2000,
  title = {Reputation Systems},
  author = {Resnick, Paul and Kuwabara, Ko and Zeckhauser, Richard and Friedman, Eric},
  date = {2000-12-01},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {43},
  number = {12},
  pages = {45--48},
  issn = {0001-0782},
  doi = {10.1145/355112.355122},
  url = {https://doi.org/10.1145/355112.355122},
  urldate = {2023-02-01}
}

@article{resnick_Reputationsystems_2000a,
  title = {Reputation Systems},
  author = {Resnick, Paul and Kuwabara, Ko and Zeckhauser, Richard and Friedman, Eric},
  date = {2000-12-01},
  journaltitle = {Commun. ACM},
  volume = {43},
  number = {12},
  pages = {45--48},
  issn = {0001-0782},
  doi = {10.1145/355112.355122},
  url = {https://doi.org/10.1145/355112.355122},
  urldate = {2024-07-03}
}

@misc{rfc3954,
  title = {Cisco Systems {{NetFlow}} Services Export Version 9},
  author = {Claise, Beno\^it},
  date = {2004-10},
  series = {Request for Comments},
  number = {3954},
  doi = {10.17487/RFC3954},
  url = {https://www.rfc-editor.org/info/rfc3954},
  abstract = {This document specifies the data export format for version 9 of Cisco Systems' NetFlow services, for use by implementations on the network elements and/or matching collector programs. The version 9 export format uses templates to provide access to observations of IP packet flows in a flexible and extensible manner. A template defines a collection of fields, with corresponding descriptions of structure and semantics. This memo provides information for the Internet community.},
  howpublished = {RFC 3954},
  organization = {RFC Editor},
  pagetotal = {33}
}

@article{riahi_Gametheoryresource_2019,
  title = {Game Theory for Resource Sharing in Large Distributed Systems},
  author = {Riahi, Sara and Riahi, Azzeddine},
  date = {2019-04-01},
  journaltitle = {International Journal of Electrical and Computer Engineering (IJECE)},
  volume = {9},
  number = {2},
  pages = {1249},
  issn = {2088-8708},
  doi = {10.11591/ijece.v9i2.pp1249-1257},
  url = {http://ijece.iaescore.com/index.php/IJECE/article/view/10176},
  abstract = {In game theory, cooperative and non-cooperative approaches are distinguished in terms of two elements. The first refers to the player's ability to engage: in a non-cooperative context, they are entirely free to make decisions when they make their choices; However, in a cooperative context, they have the opportunity to engage contractually the strategies that should be adopted during the game, that during a phase of discussions held before the game and during combinations which may be formed.In this context, the problem is not so much to predict the outcome of the game between players to leave the benefit of cooperation. To achieve this, and this is the second major difference with the non-cooperative approach, it adopts an axiomatic approach (or normative) by which we set upstream properties a priori reasonable (or desirable) on the outcome of the game. The purpose of this paper is to present briefly the main types of non-cooperative games and the tools that allow them to be analyzed in a complete information context where all aspects of the game are well known to decision makers.}
}

@inproceedings{rieger_CrowdGuardFederatedBackdoor_2024,
  title = {{{CrowdGuard}}: {{Federated Backdoor Detection}} in {{Federated Learning}}},
  shorttitle = {{{CrowdGuard}}},
  booktitle = {Proceedings 2024 {{Network}} and {{Distributed System Security Symposium}}},
  author = {Rieger, Phillip and Krau\ss, Torsten and Miettinen, Markus and Dmitrienko, Alexandra and Sadeghi, Ahmad-Reza},
  date = {2024},
  publisher = {Internet Society},
  location = {San Diego, CA, USA},
  doi = {10.14722/ndss.2024.23233},
  url = {https://www.ndss-symposium.org/wp-content/uploads/2024-233-paper.pdf},
  urldate = {2024-04-12},
  abstract = {Federated Learning (FL) is a promising approach enabling multiple clients to train Deep Neural Networks (DNNs) collaboratively without sharing their local training data. However, FL is susceptible to backdoor (or targeted poisoning) attacks. These attacks are initiated by malicious clients who seek to compromise the learning process by introducing specific behaviors into the learned model that can be triggered by carefully crafted inputs. Existing FL safeguards have various limitations: They are restricted to specific data distributions or reduce the global model accuracy due to excluding benign models or adding noise, are vulnerable to adaptive defense-aware adversaries, or require the server to access local models, allowing data inference attacks.},
  eventtitle = {Network and {{Distributed System Security Symposium}}},
  isbn = {978-1-891562-93-8},
  langid = {english}
}

@article{ring_CreationFlowBasedData_2017,
  title = {Creation of {{Flow-Based Data Sets}} for {{Intrusion Detection}}},
  author = {Ring, Markus and Wunderlich, Sarah and Gr\"udl, Dominik and Landes, Dieter and Hotho, Andreas},
  date = {2017},
  journaltitle = {Journal of Information Warfare},
  volume = {16},
  number = {4},
  eprint = {26504117},
  eprinttype = {jstor},
  pages = {41--54},
  publisher = {Peregrine Technical Solutions},
  issn = {14453312, 14453347},
  url = {https://www.jstor.org/stable/26504117},
  abstract = {Publicly available labelled data sets are necessary for evaluating anomaly-based Intrusion Detection Systems (IDSs). However, existing data sets are often not up-to-date or not yet published because of privacy concerns. This paper identifies requirements for good data sets and proposes an approach for their generation. The key idea is to use a test environment and emulate realistic user behaviour with parameterised scripts on the clients. Comprehensive logging mechanisms provide additional information which may be used for a better understanding of the inner dynamics of an IDS. Finally, the proposed approach is used to generate the flow-based CIDDS-002 data set.},
  keywords = {â›” No DOI found}
}

@article{ring_Flowbasedbenchmarkdata_2017,
  title = {Flow-Based Benchmark Data Sets for Intrusion Detection},
  author = {Ring, Markus and Wunderlich, Sarah and Gr\"udl, Dominik and Landes, Dieter and Hotho, Andreas},
  date = {2017},
  journaltitle = {Proceedings of the 16th European Conference on Cyber Warfare and Security (ECCWS)},
  pages = {361--369},
  publisher = {ACPI},
  issn = {20488610},
  abstract = {Anomaly based intrusion detection systems suffer from a lack of appropriate evaluation data sets. Often, existing data sets may not be published due to privacy concerns or do not reflect actual and current attack scenarios. In order to overcome these problems, we identify characteristics of good data sets and develop an appropriate concept for the generation of labelled flow-based data sets that satisfy these criteria. The concept is implemented based on OpenStack, thus demonstrating the suitability of virtual environments. Virtual environments offer advantages compared to static data sets by easily creating up-to-date data sets with recent trends in user behaviour and new attack scenarios. In particular, we emulate a small business environment which includes several clients and typical servers. Network traffic is generated by scripts which emulate typical user activities like surfing the web, writing emails, or printing documents on the clients. These scripts follow some guidelines to ensure that the user behaviour is as realistic as possible, also with respect to working hours and lunch breaks. The generated network traffic is recorded in unidirectional NetFlow format. For generating malicious traffic, attacks like Denial of Service, Brute Force, and Port Scans are executed within the network. Since origins, targets, and timestamps of executed attacks are known, labelling of recorded NetFlow data is easily possible. For inclusion of actual traffic, which has its origin outside the OpenStack environment, an external server with two services is deployed. This server has a public IP address and is exposed to real and up-to-date attacks from the internet. We captured approximately 32 million flows over a period of four weeks and categorized them into five classes. Further, the chronological sequence of the flows is analysed and the distribution of normal and malicious traffic is discussed in detail. The main contribution of this paper is the demonstration of a novel approach to use OpenStack as a basis for generating realistic data sets that can be used for the evaluation of network intrusion detection systems.},
  isbn = {9781911218432},
  keywords = {â›” No DOI found}
}

@inproceedings{ring_IP2VecLearningSimilarities_2017,
  title = {{{IP2Vec}}: {{Learning Similarities Between IP Addresses}}},
  shorttitle = {{{IP2Vec}}},
  booktitle = {2017 {{IEEE International Conference}} on {{Data Mining Workshops}} ({{ICDMW}})},
  author = {Ring, Markus and Dallmann, Alexander and Landes, Dieter and Hotho, Andreas},
  date = {2017-11},
  pages = {657--666},
  issn = {2375-9259},
  doi = {10.1109/ICDMW.2017.93},
  abstract = {IP Addresses are a central part of packet- and flow-based network data. However, visualization and similarity computation of IP Addresses are challenging to due the missing natural order. This paper presents a novel similarity measure IP2Vec for IP Addresses that builds on ideas from Word2Vec, a popular approach in text mining. The key idea is to learn similarities by extracting available context information from network data. IP Addresses are similar if they appear in similar contexts. Thus, IP2Vec is automatically derived from the given network data set. The proposed approach is evaluated experimentally on two public flow-based data sets. In particular, we demonstrate the effectiveness of clustering IP Addresses within a botnet data set. In addition, we use visualization methods to analyse the learned similarities in more detail. These experiments indicate that IP2Vec is well suited to capture the similarity of IP Addresses based on their network communications.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Data Mining Workshops}} ({{ICDMW}})},
  keywords = {Biological neural networks,Data mining,Feature extraction,Intrusion Detection,IP Addresses,IP networks,Neurons,Similarity Measure,Training,Vocabulary,Word2Vec}
}

@article{ring_surveynetworkbasedintrusion_2019,
  title = {A Survey of Network-Based Intrusion Detection Data Sets},
  author = {Ring, Markus and Wunderlich, Sarah and Scheuring, Deniz and Landes, Dieter and Hotho, Andreas},
  date = {2019-09-01},
  journaltitle = {Computers \& Security},
  shortjournal = {Computers \& Security},
  volume = {86},
  pages = {147--167},
  issn = {0167-4048},
  doi = {10.1016/j.cose.2019.06.005},
  url = {https://www.sciencedirect.com/science/article/pii/S016740481930118X},
  urldate = {2024-07-07},
  abstract = {Labeled data sets are necessary to train and evaluate anomaly-based network intrusion detection systems. This work provides a focused literature survey of data sets for network-based intrusion detection and describes the underlying packet- and flow-based network data in detail. The paper identifies 15 different properties to assess the suitability of individual data sets for specific evaluation scenarios. These properties cover a wide range of criteria and are grouped into five categories such as data volume or recording environment for offering a structured search. Based on these properties, a comprehensive overview of existing data sets is given. This overview also highlights the peculiarities of each data set. Furthermore, this work briefly touches upon other sources for network-based data such as traffic generators and data repositories. Finally, we discuss our observations and provide some recommendations for the use and the creation of network-based data sets.},
  keywords = {Data mining,Data sets,Evaluation,IDS,Intrusion detection,NIDS}
}

@article{rjoub_OneShotFederatedLearningbased_2022,
  title = {One-{{Shot Federated Learning-based Model-Free Reinforcement Learning}}},
  author = {Rjoub, Gaith and Bentahar, Jamal and Wahab, Omar Abdel and Drawel, Nagat},
  date = {2022/0007},
  pages = {15},
  abstract = {The Federated Learning (FL) paradigm is emerging as a way to train machine learning (ML) models in distributed systems. A large population of interconnected devices (i.e. Internet of Things (IoT)) acting as local learners optimize the model parameters collectively (e.g., neural networks' weights), rather than sharing and disclosing the training data set with the server. FL approaches assume each participant has enough training data for the tasks of interest. Realistically, data collected by IoT devices may be insufficient and often unlabeled. In particular, each IoT device may only contain one or a few samples of every relevant data category, and may not have the time or interest to label them. In realistic applications, this severely limits FL's practicality and usability. In this paper, we propose a One-Shot Federated Learning (OSFL) framework considering a FL scenario wherein the local training is carried out on IoT devices and the global aggregation is done at the level of an edge server. Moreover, we combine model-free reinforcement learning with OSFL to design a more intelligent IoT device to infer whether to label a sample automatically or request the true label for the one-shot learning set-up. We validate our system on the SODA10M dataset. Experiments show that our solution achieves better performance than DQN and RS benchmark approaches.},
  langid = {english},
  keywords = {\_read\_urgently,â›” No DOI found}
}

@article{rjoub_TrustaugmentedDeepReinforcement_2022,
  title = {Trust-Augmented {{Deep Reinforcement Learning}} for {{Federated Learning Client Selection}}},
  author = {Rjoub, Gaith and Wahab, Omar Abdel and Cohen, Robin and Bataineh, Ahmed Saleh},
  date = {2022-07},
  pages = {33},
  langid = {english},
  keywords = {â›” No DOI found}
}

@inproceedings{rocha_IntrusionDetectionContainer_2022,
  title = {Intrusion {{Detection}} in {{Container Orchestration Clusters}} : {{A}} Framework Proposal Based on Real-Time System Call Analysis with Machine Learning for Anomaly Detection},
  shorttitle = {Intrusion {{Detection}} in {{Container Orchestration Clusters}}},
  booktitle = {2022 17th {{Iberian Conference}} on {{Information Systems}} and {{Technologies}} ({{CISTI}})},
  author = {Rocha, S\'avio Levy and Daniel Amvame Nze, Georges and Lopes de Mendon\c ca, F\'abio Lucio},
  date = {2022-06},
  pages = {1--4},
  issn = {2166-0727},
  doi = {10.23919/CISTI54924.2022.9820103},
  abstract = {Despite the benefits containerization brings, threats and risks of attacks against containerized technology have grown in equal proportion to its adoption. Intrusion Detection Systems (IDS) have been employed to secure cloud and container environments. However, the inherent characteristics of these environments have presented new challenges to ensuring an adequate level of security. In this paper, a framework is proposed for implementing a Host-based Intrusion Detection System (HIDS) by analyzing system calls with machine learning on a Kubernetes container orchestration cluster. The presented framework prevents the overhead of the cluster nodes from processing focused on intrusion detection through a distributed and scalable architecture. Alerts generated in the occurrence of detected anomalies can be used as a complementary source of information for decision making and action by the Security Operations Center (SOC) team to deal with an eventual security incident. The proposed architecture was implemented in the GNS3 software, emulating a corporate network environment to demonstrate the feasibility of implementing the framework in a real environment.},
  eventtitle = {2022 17th {{Iberian Conference}} on {{Information Systems}} and {{Technologies}} ({{CISTI}})},
  keywords = {Computer architecture,containers,Containers,Decision making,HIDS,intrusion detection,Intrusion detection,Machine learning,Security,SOC,Software,system calls}
}

@article{rodriguez-barroso_Backdoorattacksresilientaggregation_2022,
  title = {Backdoor Attacks-Resilient Aggregation Based on {{Robust Filtering}} of {{Outliers}} in Federated Learning for Image Classification},
  author = {Rodr\'iguez-Barroso, Nuria and Mart\'inez-C\'amara, Eugenio and Luz\'on, M. Victoria and Herrera, Francisco},
  date = {2022-06},
  journaltitle = {Knowledge-Based Systems},
  shortjournal = {Knowledge-Based Systems},
  volume = {245},
  pages = {108588},
  issn = {09507051},
  doi = {10.1016/j.knosys.2022.108588},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705122002635},
  urldate = {2022-07-05},
  abstract = {Federated Learning is a distributed machine learning paradigm vulnerable to different kind of adversarial attacks, since its distributed nature and the inaccessibility of the data by the central server. In this work, we focus on model-poisoning backdoor attacks, because they are characterized by their stealth and effectiveness. We claim that the model updates of the clients of a federated learning setting follow a Gaussian distribution, and those ones with an outlier behavior in that distribution are likely to be adversarial clients. We propose a new federated aggregation operator called Robust Filtering of one-dimensional Outliers (RFOut-1d), which works as a resilient defensive mechanism to modelpoisoning backdoor attacks. RFOut-1d is based on an univariate outlier detection method that filters out the model updates of the adversarial clients. The results on three federated image classification dataset show that RFOut-1d dissipates the impact of the backdoor attacks to almost nullifying them throughout all the learning rounds, as well as it keeps the performance of the federated learning model and it outperforms that state-of-the-art defenses against backdoor attacks.},
  langid = {english}
}

@article{rodriguez-barroso_Surveyfederatedlearning_2023,
  title = {Survey on Federated Learning Threats: {{Concepts}}, Taxonomy on Attacks and Defences, Experimental Study and Challenges},
  shorttitle = {Survey on Federated Learning Threats},
  author = {Rodr\'iguez-Barroso, Nuria and Jim\'enez-L\'opez, Daniel and Luz\'on, M. Victoria and Herrera, Francisco and Mart\'inez-C\'amara, Eugenio},
  date = {2023-02-01},
  journaltitle = {Information Fusion},
  shortjournal = {Information Fusion},
  volume = {90},
  pages = {148--173},
  issn = {1566-2535},
  doi = {10.1016/j.inffus.2022.09.011},
  url = {https://www.sciencedirect.com/science/article/pii/S1566253522001439},
  urldate = {2023-09-29},
  abstract = {Federated learning is a machine learning paradigm that emerges as a solution to the privacy-preservation demands in artificial intelligence. As machine learning, federated learning is threatened by adversarial attacks against the integrity of the learning model and the privacy of data via a distributed approach to tackle local and global learning. This weak point is exacerbated by the inaccessibility of data in federated learning, which makes the protection against adversarial attacks harder and evidences the need to furtherance the research on defence methods to make federated learning a real solution for safeguarding data privacy. In this paper, we present an extensive review of the threats of federated learning, as well as as their corresponding countermeasures, attacks versus defences. This survey provides a taxonomy of adversarial attacks and a taxonomy of defence methods that depict a general picture of this vulnerability of federated learning and how to overcome it. Likewise, we expound guidelines for selecting the most adequate defence method according to the category of the adversarial attack. Besides, we carry out an extensive experimental study from which we draw further conclusions about the behaviour of attacks and defences and the guidelines for selecting the most adequate defence method according to the category of the adversarial attack. Finally, we present our learned lessons and challenges.},
  keywords = {+survey,â›” No DOI found,Adversarial attacks,Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Defences,Federated learning,Privacy attacks}
}

@inproceedings{ronen_ExtendedFunctionalityAttacks_2016,
  title = {Extended {{Functionality Attacks}} on {{IoT Devices}}: {{The Case}} of {{Smart Lights}}},
  booktitle = {2016 {{IEEE European Symposium}} on {{Security}} and {{Privacy}} ({{EuroS}}\&{{P}})},
  author = {Ronen, Eyal and Shamir, Adi},
  date = {2016-03},
  pages = {3--12},
  publisher = {IEEE},
  doi = {10.1109/EuroSP.2016.13},
  url = {http://ieeexplore.ieee.org/document/7467343/},
  abstract = {In this paper we consider the security aspects of Internet of Things (IoT) devices, which bridge the physical and virtual worlds. We propose a new taxonomy of attacks, which classifies them into four broad categories. The most interesting category (which we call functionality extension attacks) uses the designed functionality of the IoT device to achieve a totally different effect. To demonstrate this type of attack, we consider the case of smart lights (whose original functionality is just to control the color and intensity of the lights in a particular room) and show how to use them to achieve unrelated effects. In the first attack, we use smart lights as a covert LIFI communication system to exfiltrate data from a highly secure (or even fully airgapped) office building. We implemented the attack and were able to read the leaked data from a distance of over 100 meters using only cheap and readily available equipment. In another attack, we showed that an attacker can strobe the lights at a frequency which may trigger seizures in people suffering from photosensitive epilepsy (in the same way that rapidly flashing video games can cause such seizures). In our experiments, we have tested both high-end and lower-end smart light systems, ranging from an expensive Philips HUE system to a cheap system manufactured by LimitlessLED. In addition, we consider other weaknesses of the systems we tested, and propose feasible remedies for the problems we found.},
  isbn = {978-1-5090-1751-5}
}

@article{rosa_Intrusionanomalydetection_2021,
  title = {Intrusion and Anomaly Detection for the Next-Generation of Industrial Automation and Control Systems},
  author = {Rosa, Luis and Cruz, Tiago and family=Freitas, given=Miguel Borges, prefix=de, useprefix=false and Quit\'erio, Pedro and Henriques, Jo\~ao and Caldeira, Filipe and Monteiro, Edmundo and Sim\~oes, Paulo},
  date = {2021-06},
  journaltitle = {Future Generation Computer Systems},
  volume = {119},
  pages = {50--67},
  publisher = {Elsevier B.V.},
  issn = {0167739X},
  doi = {10.1016/j.future.2021.01.033},
  url = {https://doi.org/10.1016/j.future.2021.01.033}
}

@article{roy_BrainTorrentPeertoPeerEnvironment_2019,
  title = {{{BrainTorrent}}: {{A Peer-to-Peer Environment}} for {{Decentralized Federated Learning}}},
  shorttitle = {{{BrainTorrent}}},
  author = {Roy, Abhijit Guha and Siddiqui, Shayan and P\"olsterl, Sebastian and Navab, Nassir and Wachinger, C.},
  date = {2019-05-16},
  journaltitle = {ArXiv},
  url = {https://www.semanticscholar.org/paper/BrainTorrent%3A-A-Peer-to-Peer-Environment-for-Roy-Siddiqui/aad543a5b7f231f085764ce0258fe8914a15006f},
  urldate = {2023-09-11},
  abstract = {Access to sufficient annotated data is a common challenge in training deep neural networks on medical images. As annotating data is expensive and time-consuming, it is difficult for an individual medical center to reach large enough sample sizes to build their own, personalized models. As an alternative, data from all centers could be pooled to train a centralized model that everyone can use. However, such a strategy is often infeasible due to the privacy-sensitive nature of medical data. Recently, federated learning (FL) has been introduced to collaboratively learn a shared prediction model across centers without the need for sharing data. In FL, clients are locally training models on site-specific datasets for a few epochs and then sharing their model weights with a central server, which orchestrates the overall training process. Importantly, the sharing of models does not compromise patient privacy. A disadvantage of FL is the dependence on a central server, which requires all clients to agree on one trusted central body, and whose failure would disrupt the training process of all clients. In this paper, we introduce BrainTorrent, a new FL framework without a central server, particularly targeted towards medical applications. BrainTorrent presents a highly dynamic peer-to-peer environment, where all centers directly interact with each other without depending on a central body. We demonstrate the overall effectiveness of FL for the challenging task of whole brain segmentation and observe that the proposed server-less BrainTorrent approach does not only outperform the traditional server-based one but reaches a similar performance to a model trained on pooled data.},
  keywords = {â›” No DOI found}
}

@inproceedings{roychowdhury_EIFFeLEnsuringIntegrity_2022,
  title = {{{EIFFeL}}: {{Ensuring Integrity}} for {{Federated Learning}}},
  shorttitle = {{{EIFFeL}}},
  booktitle = {Proceedings of the 2022 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Roy Chowdhury, Amrita and Guo, Chuan and Jha, Somesh and family=Maaten, given=Laurens, prefix=van der, useprefix=true},
  date = {2022-11-07},
  series = {{{CCS}} '22},
  pages = {2535--2549},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3548606.3560611},
  url = {https://doi.org/10.1145/3548606.3560611},
  urldate = {2023-02-08},
  abstract = {Federated learning (FL) enables clients to collaborate with a server to train a machine learning model. To ensure privacy, the server performs secure aggregation of updates from the clients. Unfortunately, this prevents verification of the well-formedness (integrity) of the updates as the updates are masked. Consequently, malformed updates designed to poison the model can be injected without detection. In this paper, we formalize the problem of ensuring both update privacy and integrity in FL and present a new system, EIFFeL, that enables secure aggregation of verified updates. EIFFeL is a general framework that can enforce arbitrary integrity checks and remove malformed updates from the aggregate, without violating privacy. Our empirical evaluation demonstrates the practicality of EIFFeL. For instance, with 100 clients and 10\% poisoning, EIFFeL can train an MNIST classification model to the same accuracy as that of a non-poisoned federated learner in just 2.4s per iteration.},
  isbn = {978-1-4503-9450-5},
  keywords = {input integrity,poisoning attacks,secure aggregation}
}

@article{ruby_AntiJammingStrategiesFederated_2022,
  title = {Anti-{{Jamming Strategies}} for {{Federated Learning Internet}} of {{Medical Things}}: {{A Game Approach}}},
  shorttitle = {Anti-{{Jamming Strategies}} for {{Federated Learning Internet}} of {{Medical Things}}},
  author = {Ruby, Rukhsana and Yang, Hailiang and Wu, Kaishun},
  date = {2022},
  journaltitle = {IEEE Journal of Biomedical and Health Informatics},
  pages = {1--12},
  issn = {2168-2208},
  doi = {10.1109/JBHI.2022.3183644},
  abstract = {Federated learning (FL) is a new dawn of artificial intelligence (AI), in which machine learning models are constructed in a distributed manner while communicating only model parameters between a centralized aggregator and client internet-of-medical-things (IoMT) nodes. The performance of such a learning technique can be seriously hampered by the activities of a malicious jammer robot. In this paper, we study client selection and channel allocation along with the power control problem of the uplink FL process in IoMT domain under the presence of a jammer from the perspective of long-term learning duration. We map the interaction between the FL network and the jammer in each learning iteration as a Stackelberg game, in which the jammer acts as the leader and the FL network serves as the follower. We consider the client and channel selection as well as the power control jointly as the strategy of this game. Upon formulating the game, we find the joint best response strategy for both types of players by leveraging the difference of convex (DC) programming approach and the dual decomposition technique. Beside the availability of the complete information to both the players, we also study the problem from the perspective that the FL network knows the partial information of the other player. Extensive simulations have been conducted to verify the effectiveness of the proposed algorithms in the jamming game.},
  eventtitle = {{{IEEE Journal}} of {{Biomedical}} and {{Health Informatics}}},
  keywords = {Anti-Jamming Strategy,Bit rate,Channel Selection,Data models,Federated Learning (FL),Games,Jamming,Medical diagnostic imaging,Power Control,Resource management,Stackelber Game,Training}
}

@inproceedings{rumesh_ComprehensiveAnalysisCentralized_2023,
  title = {Comprehensive {{Analysis Over Centralized}} and {{Federated Learning-Based Anomaly Detection}} in {{Networks}} with {{Explainable AI}} ({{XAI}})},
  booktitle = {{{ICC}} 2023 - {{IEEE International Conference}} on {{Communications}}},
  author = {Rumesh, Yasintha and Senevirathna, Thulitha Theekshana and Porambage, Pawani and Liyanage, Madhusanka and Ylianttila, Mika},
  date = {2023-05},
  pages = {4853--4859},
  issn = {1938-1883},
  doi = {10.1109/ICC45041.2023.10278845},
  url = {https://ieeexplore.ieee.org/document/10278845},
  urldate = {2024-04-12},
  abstract = {Many forms of machine learning (ML) and artificial intelligence (AI) techniques are adopted in communication networks to perform all optimizations, security management, and decision-making tasks. Instead of using conventional blackbox models, the tendency is to use explainable ML models that provide transparency and accountability. Moreover, Federate Learning (FL) type ML models are becoming more popular than the typical Centralized Learning (CL) models due to the distributed nature of the networks and security privacy concerns. Therefore, it is very timely to research how to find the explainability using Explainable AI (XAI) in different ML models. This paper comprehensively analyzes using XAI in CL and FL-based anomaly detection in networks. We use a deep neural network as the black-box model with two data sets, UNSW-NB15 and NSLKDD, and SHapley Additive exPlanations (SHAP) as the XAI model. We demonstrate that the FL explanation differs from CL with the client anomaly percentage.},
  eventtitle = {{{ICC}} 2023 - {{IEEE International Conference}} on {{Communications}}},
  keywords = {6G,Autonomous aerial vehicles,Centralized Learning,Closed box,Data models,Decision making,Explainable AI,Federated learning,Federated Learning,Privacy,Security,Security management}
}

@book{russell_Artificialintelligencemodern_2021,
  title = {Artificial Intelligence: A Modern Approach},
  shorttitle = {Artificial Intelligence},
  author = {Russell, Stuart J. and Norvig, Peter},
  namea = {Chang, Ming-wei and Devlin, Jacob and Dragan, Anca and Forsyth, David and Goodfellow, Ian and Malik, Jitendra and Mansinghka, Vikash and Pearl, Judea and Wooldridge, Michael J.},
  nameatype = {collaborator},
  date = {2021},
  series = {Pearson {{Series}} in {{Artificial Intelligence}}},
  edition = {Fourth Edition},
  publisher = {Pearson},
  location = {Hoboken, NJ},
  abstract = {"Updated edition of popular textbook on Artificial Intelligence. This edition specific looks at ways of keeping artificial intelligence under control"--},
  isbn = {978-0-13-461099-3},
  langid = {english},
  pagetotal = {1115}
}

@article{ruzafa-alcazar_IntrusionDetectionBased_2023,
  title = {Intrusion {{Detection Based}} on {{Privacy-Preserving Federated Learning}} for the {{Industrial IoT}}},
  author = {Ruzafa-Alc\'azar, Pedro and Fern\'andez-Saura, Pablo and M\'armol-Campos, Enrique and Gonz\'alez-Vidal, Aurora and Hern\'andez-Ramos, Jos\'e L. and Bernal-Bernabe, Jorge and Skarmeta, Antonio F.},
  date = {2023-02},
  journaltitle = {IEEE Transactions on Industrial Informatics},
  volume = {19},
  number = {2},
  pages = {1145--1154},
  issn = {1941-0050},
  doi = {10.1109/TII.2021.3126728},
  url = {https://ieeexplore.ieee.org/document/9609643},
  urldate = {2024-04-24},
  abstract = {Federated learning (FL) has attracted significant interest given its prominent advantages and applicability in many scenarios. However, it has been demonstrated that sharing updated gradients/weights during the training process can lead to privacy concerns. In the context of the Internet of Things (IoT), this can be exacerbated due to intrusion detection systems (IDSs), which are intended to detect security attacks by analyzing the devices' network traffic. Our work provides a comprehensive evaluation of differential privacy techniques, which are applied during the training of an FL-enabled IDS for industrial IoT. Unlike previous approaches, we deal with nonindependent and identically distributed data over the recent ToN\_IoT dataset, and compare the accuracy obtained considering different privacy requirements and aggregation functions, namely FedAvg and the recently proposed Fed+. According to our evaluation, the use of Fed+ in our setting provides similar results even when noise is included in the federated training process.},
  eventtitle = {{{IEEE Transactions}} on {{Industrial Informatics}}},
  keywords = {Collaborative work,Data models,Differential privacy,Differential privacy (DP),federated learning (FL),Informatics,Internet of Things (IoT),Intrusion detection,intrusion detection systems (IDSs),machine learning,Privacy,Training}
}

@article{safaeipour_ComprehendingIoTcyber_2019,
  title = {Comprehending the {{IoT}} Cyber Threat Landscape: {{A}} Data Dimensionality Reduction Technique to Infer and Characterize {{Internet-scale IoT}} Probing Campaigns},
  author = {Safaei Pour, Morteza and Bou-Harb, Elias and Varma, Kavita and Neshenko, Nataliia and Pados, Dimitris A. and Choo, Kim-Kwang Raymond},
  date = {2019-04},
  journaltitle = {Digital Investigation},
  volume = {28},
  pages = {S40-S49},
  publisher = {Elsevier Ltd},
  issn = {17422876},
  doi = {10.1016/j.diin.2019.01.014},
  url = {https://doi.org/10.1016/j.diin.2019.01.014},
  abstract = {The resource-constrained and heterogeneous nature of Internet-of-Things (IoT)devices coupled with the placement of such devices in publicly accessible venues complicate efforts to secure these devices and the networks they are connected to. The Internet-wide deployment of IoT devices also makes it challenging to operate security solutions at strategic locations within the network or to identify orchestrated activities from seemingly independent malicious events from such devices. Therefore, in this paper, we initially seek to determine the magnitude of IoT exploitations by examining more than 1 TB of passive measurement data collected from a/8 network telescope and by correlating it with 400 GB of information from the Shodan service. In the second phase of the study, we conduct in-depth discussions with Internet Service Providers (ISPs)and backbone network operators, as well as leverage geolocation databases to not only attribute such exploitations to their hosting environment (ISPs, countries, etc.)but also to classify such inferred IoT devices based on their hosting sector type (financial, education, manufacturing, etc.)and most abused IoT manufacturers. In the third phase, we automate the task of alerting realms that are determined to be hosting exploited IoT devices. Additionally, to address the problem of inferring orchestrated IoT campaigns by solely observing their activities targeting the network telescope, we further introduce a theoretically sound technique based on L1-norm PCA, and validate the utility of the proposed data dimensionality reduction technique against the conventional L2-norm PCA. Specifically, we identify ``in the wild'' IoT coordinated probing campaigns that are targeting generic ports and campaigns specifically searching for open resolvers (for amplification purposes). The results reveal more than 120,000 Internet-scale exploited IoT devices, some of which are operating in critical infrastructure sectors such as health and manufacturing. We also infer 140 large-scale IoT-centric probing campaigns; a sample of which includes a worldwide distributed campaign where close to 40\% of its population includes video surveillance cameras from a single manufacturer, and another very large inferred coordinated campaign consisting of more than 50,000 IoT devices. The reported findings highlight the insecurity of the IoT paradigm at large and thus demonstrate the importance of understanding such evolving threat landscape.}
}

@inproceedings{safri_FederatedLearningFramework_2022,
  title = {A {{Federated Learning Framework}} for {{IoT}}: {{Application}} to {{Industry}} 4.0},
  shorttitle = {A {{Federated Learning Framework}} for {{IoT}}},
  booktitle = {2022 22nd {{IEEE International Symposium}} on {{Cluster}}, {{Cloud}} and {{Internet Computing}} ({{CCGrid}})},
  author = {Safri, Hamza and Kandi, Mohamed Mehdi and Miloudi, Youssef and Bortolaso, Christophe and Trystram, Denis and Desprez, Fr\'ed\'eric},
  date = {2022-05},
  pages = {565--574},
  doi = {10.1109/CCGrid54584.2022.00066},
  abstract = {Predictive maintenance aims to anticipate indus-trial equipment failures in order to allow early scheduling of corrective actions. Such a maintenance approach is based on a detailed analysis that takes into account the technical and contextual characteristics of the target industrial equipment. However, this analysis requires a significant period of time to collect a representative quantity of data to learn a predictive model. Federated learning (FL in short) is a promising approach that allows several participants to build collaboratively a global predictive model. This approach has been widely explored in generic loT applications and large scale architectures. However, the implementation of FL in actual environments requires to consider several issues to adapt to existing loT architectures, including the management/orchestration of the federated tasks and handling the limitations of computational resources. Indeed, most of the current research focus on the aggregation of heavy deep learning algorithms. In this paper, we propose an architecture for FL in the context of loT based on the classical 3-layer architecture standardized by ETSI 11https://www.etsi.org/. We consider new features for performing federated tasks (training, aggregation and man-agement of each participant). We also propose a stacking-based aggregation method to build the global model in a cost-efficient way. We evaluate finally the performance and effectiveness of this approach on real use-case scenarios. The comparison with other models trained in a centralized way highlights the benefit of our approach.},
  eventtitle = {2022 22nd {{IEEE International Symposium}} on {{Cluster}}, {{Cloud}} and {{Internet Computing}} ({{CCGrid}})},
  keywords = {Collaborative work,Computer architecture,edge,Federated Learning,Fourth Industrial Revolution,Job shop scheduling,loT,Prediction algorithms,Predictive maintenance,Predictive models,Stacking algorithms,Training}
}

@unpublished{saha_FederatedTransferLearning_2021,
  title = {Federated {{Transfer Learning}}: Concept and Applications},
  shorttitle = {Federated {{Transfer Learning}}},
  author = {Saha, Sudipan and Ahmad, Tahir},
  date = {2021-03-06},
  eprint = {2010.15561},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2010.15561},
  urldate = {2021-10-04},
  abstract = {Development of Artificial Intelligence (AI) is inherently tied to the development of data. However, in most industries data exists in form of isolated islands, with limited scope of sharing between different organizations. This is an hindrance to the further development of AI. Federated learning has emerged as a possible solution to this problem in the last few years without compromising user privacy. Among different variants of the federated learning, noteworthy is federated transfer learning (FTL) that allows knowledge to be transferred across domains that do not have many overlapping features and users. In this work we provide a comprehensive survey of the existing works on this topic. In more details, we study the background of FTL and its different existing applications. We further analyze FTL from privacy and machine learning perspective.},
  langid = {english},
  keywords = {\_processed,â›” No DOI found,Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@online{samarakoon_5GNIDDComprehensiveNetwork_2022,
  title = {{{5G-NIDD}}: {{A Comprehensive Network Intrusion Detection Dataset Generated}} over {{5G Wireless Network}}},
  shorttitle = {{{5G-NIDD}}},
  author = {Samarakoon, Sehan and Siriwardhana, Yushan and Porambage, Pawani and Liyanage, Madhusanka and Chang, Sang-Yoon and Kim, Jinoh and Kim, Jonghyun and Ylianttila, Mika},
  date = {2022-12-02},
  eprint = {2212.01298},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2212.01298},
  urldate = {2022-12-14},
  abstract = {With a plethora of new connections, features, and services introduced, the 5th generation (5G) wireless technology reflects the development of mobile communication networks and is here to stay for the next decade. The multitude of services and technologies that 5G incorporates have made modern communication networks very complex and sophisticated in nature. This complexity along with the incorporation of Machine Learning (ML) and Artificial Intelligence (AI) provides the opportunity for the attackers to launch intelligent attacks against the network and network devices. These attacks often traverse undetected due to the lack of intelligent security mechanisms to counter these threats. Therefore, the implementation of real-time, proactive, and self-adaptive security mechanisms throughout the network would be an integral part of 5G as well as future communication systems. Therefore, large amounts of data collected from real networks will play an important role in the training of AI/ML models to identify and detect malicious content in network traffic. This work presents 5G-NIDD, a fully labeled dataset built on a functional 5G test network that can be used by those who develop and test AI/ML solutions. The work further analyses the collected data using common ML models and shows the achieved accuracy levels.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Networking and Internet Architecture}
}

@unpublished{santin_FrameworkVerifiableAuditable_2022,
  title = {A {{Framework}} for {{Verifiable}} and {{Auditable Federated Anomaly Detection}}},
  author = {Santin, Gabriele and Skarbovsky, Inna and Fournier, Fabiana and Lepri, Bruno},
  date = {2022-03-15},
  eprint = {2203.07802},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2203.07802},
  urldate = {2022-03-23},
  abstract = {Federated Leaning is an emerging approach to manage cooperation between a group of agents for the solution of Machine Learning tasks, with the goal of improving each agent's performance without disclosing any data. In this paper we present a novel algorithmic architecture that tackle this problem in the particular case of Anomaly Detection (or classification or rare events), a setting where typical applications often comprise data with sensible information, but where the scarcity of anomalous examples encourages collaboration. We show how Random Forests can be used as a tool for the development of accurate classifiers with an effective insight-sharing mechanism that does not break the data integrity. Moreover, we explain how the new architecture can be readily integrated in a blockchain infrastructure to ensure the verifiable and auditable execution of the algorithm. Furthermore, we discuss how this work may set the basis for a more general approach for the design of federated ensemble-learning methods beyond the specific task and architecture discussed in this paper.},
  langid = {english},
  keywords = {â›” No DOI found,Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@online{sarhan_CyberThreatIntelligence_2021,
  title = {A {{Cyber Threat Intelligence Sharing Scheme}} Based on {{Federated Learning}} for {{Network Intrusion Detection}}},
  author = {Sarhan, Mohanad and Layeghy, Siamak and Moustafa, Nour and Portmann, Marius},
  date = {2021-11-04},
  eprint = {2111.02791},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2111.02791},
  url = {http://arxiv.org/abs/2111.02791},
  urldate = {2022-12-09},
  abstract = {The uses of Machine Learning (ML) in detection of network attacks have been effective when designed and evaluated in a single organisation. However, it has been very challenging to design an ML-based detection system by utilising heterogeneous network data samples originating from several sources. This is mainly due to privacy concerns and the lack of a universal format of datasets. In this paper, we propose a collaborative federated learning scheme to address these issues. The proposed framework allows multiple organisations to join forces in the design, training, and evaluation of a robust ML-based network intrusion detection system. The threat intelligence scheme utilises two critical aspects for its application; the availability of network data traffic in a common format to allow for the extraction of meaningful patterns across data sources. Secondly, the adoption of a federated learning mechanism to avoid the necessity of sharing sensitive users' information between organisations. As a result, each organisation benefits from other organisations cyber threat intelligence while maintaining the privacy of its data internally. The model is trained locally and only the updated weights are shared with the remaining participants in the federated averaging process. The framework has been designed and evaluated in this paper by using two key datasets in a NetFlow format known as NF-UNSW-NB15-v2 and NF-BoT-IoT-v2. Two other common scenarios are considered in the evaluation process; a centralised training method where the local data samples are shared with other organisations and a localised training method where no threat intelligence is shared. The results demonstrate the efficiency and effectiveness of the proposed framework by designing a universal ML model effectively classifying benign and intrusive traffic originating from multiple organisations without the need for local data exchange.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Computer Science - Networking and Internet Architecture}
}

@online{sarhan_StandardFeatureSet_2021,
  title = {Towards a {{Standard Feature Set}} for {{Network Intrusion Detection System Datasets}}},
  author = {Sarhan, Mohanad and Layeghy, Siamak and Portmann, Marius},
  date = {2021-05-14},
  eprint = {2101.11315},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2101.11315},
  urldate = {2022-09-12},
  abstract = {Network Intrusion Detection Systems (NIDSs) are important tools for the protection of computer networks against increasingly frequent and sophisticated cyber attacks. Recently, a lot of research effort has been dedicated to the development of Machine Learning (ML) based NIDSs. As in any ML-based application, the availability of high-quality datasets is critical for the training and evaluation of ML-based NIDS. One of the key problems with the currently available NIDS datasets is the lack of a standard feature set. The use of a unique and proprietary set of features for each of the publicly available datasets makes it virtually impossible to compare the performance of ML-based traffic classifiers on different datasets, and hence to evaluate the ability of these systems to generalise across different network scenarios. To address that limitation, this paper proposes and evaluates standard NIDS feature sets based on the NetFlow network meta-data collection protocol and system. We evaluate and compare two NetFlow-based feature set variants, a version with 12 features, and another one with 43 features. For our evaluation, we converted four widely used NIDS datasets (UNSW-NB15, BoT-IoT, ToN-IoT, CSE-CIC-IDS2018) into new variants with our proposed NetFlow based feature sets. Based on an Extra Tree classifier, we compared the classification performance of the NetFlow-based feature sets with the proprietary feature sets provided with the original datasets. While the smaller feature set cannot match the classification performance of the proprietary feature sets, the larger set with 43 NetFlow features, surprisingly achieves a consistently higher classification performance compared to the original feature set, which was tailored to each of the considered NIDS datasets. The proposed NetFlow-based standard NIDS feature set, together with four benchmark datasets, made available to the research community, allow a fair comparison of ML-based network traffic classifiers across different NIDS datasets. We believe that having a standard feature set is critical for allowing a more rigorous and thorough evaluation of ML-based NIDSs and that it can help bridge the gap between academic research and the practical deployment of such systems.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Networking and Internet Architecture}
}

@article{sarhan_StandardFeatureSet_2022,
  title = {Towards a {{Standard Feature Set}} for {{Network Intrusion Detection System Datasets}}},
  author = {Sarhan, Mohanad and Layeghy, Siamak and Portmann, Marius},
  date = {2022-02-01},
  journaltitle = {Mobile Networks and Applications},
  shortjournal = {Mobile Netw Appl},
  volume = {27},
  number = {1},
  pages = {357--370},
  issn = {1572-8153},
  doi = {10.1007/s11036-021-01843-0},
  url = {https://doi.org/10.1007/s11036-021-01843-0},
  urldate = {2024-04-23},
  abstract = {Network Intrusion Detection Systems (NIDSs) are important tools for the protection of computer networks against increasingly frequent and sophisticated cyber attacks. Recently, a lot of research effort has been dedicated to the development of Machine Learning (ML) based NIDSs. As in any ML-based application, the availability of high-quality datasets is critical for the training and evaluation of ML-based NIDS. One of the key problems with the currently available NIDS datasets is the lack of a standard feature set. The use of a unique and proprietary set of features for each of the publicly available datasets makes it virtually impossible to compare the performance of ML-based traffic classifiers on different datasets, and hence to evaluate the ability of these systems to generalise across different network scenarios. To address that limitation, this paper proposes and evaluates standard NIDS feature sets based on the NetFlow network meta-data collection protocol and system. We evaluate and compare two NetFlow-based feature set variants, a version with 12 features, and another one with 43 features. For our evaluation, we converted four widely used NIDS datasets (UNSW-NB15, BoT-IoT, ToN-IoT, CSE-CIC-IDS2018) into new variants with our proposed NetFlow based feature sets. Based on an Extra Tree classifier, we compared the classification performance of the NetFlow-based feature sets with the proprietary feature sets provided with the original datasets. While the smaller feature set cannot match the classification performance of the proprietary feature sets, the larger set with 43 NetFlow features, surprisingly achieves a consistently higher classification performance compared to the original feature set, which was tailored to each of the considered NIDS datasets. The proposed NetFlow-based NIDS feature set, together with four benchmark datasets, made available to the research community, allow a fair comparison of ML-based network traffic classifiers across different NIDS datasets. We believe that having a standard feature set is critical for allowing a more rigorous and thorough evaluation of ML-based NIDSs and that it can help bridge the gap between academic research and the practical deployment of such systems.},
  langid = {english},
  keywords = {Machine learning,NetFlow,Network intrusion detection system}
}

@inproceedings{saurabh_NFDLMLightweightNetwork_2022,
  title = {{{NFDLM}}: {{A Lightweight Network Flow}} Based {{Deep Learning Model}} for {{DDoS Attack Detection}} in {{IoT Domains}}},
  shorttitle = {{{NFDLM}}},
  booktitle = {2022 {{IEEE World AI IoT Congress}} ({{AIIoT}})},
  author = {Saurabh, Kumar and Kumar, Tanuj and Singh, Uphar and Vyas, O.P. and Khondoker, Rahamatullah},
  date = {2022-06},
  pages = {736--742},
  doi = {10.1109/AIIoT54504.2022.9817297},
  abstract = {In the recent years, Distributed Denial of Service (DDoS) attacks on Internet of Things (IoT) devices have become one of the prime concerns to Internet users around the world. One of the sources of the attacks on IoT ecosystems are botnets. Intruders force IoT devices to become unavailable for its legitimate users by sending large number of messages within a short interval. This study proposes NFDLM, a lightweight and optimised Artificial Neural Network (ANN) based Distributed Denial of Services (DDoS) attack detection framework with mutual correlation as feature selection method which produces a superior result when compared with Long Short Term Memory (LSTM) and simple ANN. Overall, the detection performance achieves approximately 99\% accuracy for the detection of attacks from botnets. In this work, we have designed and compared four different models where two are based on ANN and the other two are based on LSTM to detect the attack types of DDoS.},
  eventtitle = {2022 {{IEEE World AI IoT Congress}} ({{AIIoT}})},
  keywords = {ANN,Biological system modeling,Botnet,Botnets,DDoS,Deep learning,Denial-of-service attack,Ecosystems,Feature extraction,Force,IoT,LSTM}
}

@inproceedings{schneble_Attackdetectionusing_2019,
  title = {Attack Detection Using Federated Learning in Medical Cyber-Physical Systems},
  shorttitle = {{{ICCCN}}},
  booktitle = {2019 28th {{International Conference}} on {{Computer Communication}} and {{Networks}} ({{ICCCN}})},
  author = {Schneble, William and Thamilarasu, Geethapriya},
  date = {2019-08},
  abstract = {Medical Cyber-Physical Systems (MCPS) are networked systems of medical devices that provide seamless integration of physical and computation components in healthcare environments to deliver high quality care by enabling continuous monitoring and treatment. As MCPS store sensitive medical data and personal health data, security breaches and unauthorized access to this information can lead to severe repercussions for both the patient and hospital in the form of loss of privacy, abuse, physical harm and liability. The heterogeneity of devices involved in these systems (such as body sensor nodes and mobile devices) introduce large attack surfaces and hence necessitate the design of effective security solutions for these environments. In this paper, we design and implement a massively distributed, machine-learning-based intrusion detection solution for MCPS. Specifically, we explore the concept of Federated Learning to minimize the communication and computation costs involved in traditional machine learning based solutions. We evaluate our design with real patient data and against security attacks such as Denial of Service, data modification, and data injection. Experimental results illustrate that our system achieves high detection accuracy of 99.0\% and a False Positive Rate of 1.0\% along with a reduced network communication overhead. Lastly, we show that the system can cope with unevenly distributed data and is a scalable solution that leverages the computing resources of many mobile devices.},
  eventtitle = {International {{Conference}} on {{Computer Communications}} and {{Networks}}},
  langid = {english},
  keywords = {survey-fids}
}

@inproceedings{schneble_OptimalFeatureSelection_2019,
  title = {Optimal {{Feature Selection}} for {{Intrusion Detection}} in {{Medical Cyber-Physical Systems}}},
  booktitle = {2019 11th {{International Conference}} on {{Advanced Computing}} ({{ICoAC}})},
  author = {Schneble, William and Thamilarasu, Geethapriya},
  date = {2019-12},
  pages = {238--243},
  publisher = {IEEE},
  location = {Chennai, India},
  doi = {10.1109/ICoAC48765.2019.246846},
  url = {https://ieeexplore.ieee.org/document/9087284/},
  urldate = {2022-05-28},
  abstract = {Medical cyber physical systems (MCPS) integrate the physical, communication and computation components of medical devices to enhance the quality and reliability of healthcare systems. With the remarkable progress of MCPS technologies in recent years, there is a need to advance the security measures to efficiently detect attacks in this domain. Research on intrusion detection for medical cyber physical systems is still in its infancy. For an efficient intrusion detection system (IDS), it is important to address the problem of feature selection to remove redundant, irrelevant and noisy features. Feature selection is even more relevant to address in MCPS as the use of entire feature space places unnecessary burden on resource constrained systems in this domain. Also since realtime detection of attacks is critical in healthcare systems, the amount of data processed by IDS must be reduced to achieve low detection latency. In this paper, we investigate the problem of feature selection in medical cyber physical systems. Our initial results demonstrate the laplacian scoring techniques are successful in optimal feature selection with reduced memory consumption.},
  eventtitle = {2019 11th {{International Conference}} on {{Advanced Computing}} ({{ICoAC}})},
  isbn = {978-1-72815-286-8},
  langid = {english}
}

@inproceedings{schneider_HighPerformanceUnsupervisedAnomaly_2018,
  title = {High-{{Performance Unsupervised Anomaly Detection}} for {{Cyber-Physical System Networks}}},
  booktitle = {Proceedings of the 2018 {{Workshop}} on {{Cyber-Physical Systems Security}} and {{PrivaCy}}},
  author = {Schneider, Peter and B\"ottinger, Konstantin},
  date = {2018-01-15},
  pages = {1--12},
  publisher = {ACM},
  location = {New York, NY, USA},
  issn = {15437221},
  doi = {10.1145/3264888.3264890},
  url = {https://dl.acm.org/doi/10.1145/3264888.3264890},
  abstract = {While the ever-increasing connectivity of cyber-physical systems enlarges their attack surface, existing anomaly detection frameworks often do not incorporate the rising heterogeneity of involved systems. Existing frameworks focus on a single fieldbus protocol or require more detailed knowledge of the cyber-physical system itself. Thus, we introduce a uniform method and framework for applying anomaly detection to a variety of fieldbus protocols. We use stacked denoising autoencoders to derive a feature learning and packet classification method in one step. As the approach is based on the raw byte stream of the network traffic, neither specific protocols nor detailed knowledge of the application is needed. Additionally, we pay attention on creating an efficient framework which can also handle the increased amount of communication in cyber-physical systems. Our evaluation on a Secure Water Treatment dataset using EtherNet/IP and a Modbus dataset shows that we can acquire network packets up to 100 times faster than packet parsing based methods. However, we still achieve precision and recall metrics for longer lasting attacks of over 99\%.},
  isbn = {978-1-4503-5992-4}
}

@article{schoen_genericqualityassessment_,
  title = {Towards Generic Quality Assessment of Synthetic Traffic for Evaluating Intrusion Detection Systems},
  author = {Schoen, Adrien and Blanc, Gregory and Gimenez, Pierre-Fran\c cois and Han, Yufei and Majorczyk, Fr\'ed\'eric and M\'e, Ludovic},
  abstract = {Network Intrusion Detection Systems (NIDSes) evaluation requires background traffic. However, real background traffic is hard to collect. We hence rely on synthetic traffic generated especially for this task. The quality of the generated traffic has to be evaluated according to some clearly defined criteria. In this paper, we show how to adapt the quality assessment solutions proposed for different fields of data generation such as image or text generation to network traffic. We summarize our study by discussing the criteria that evaluate the quality of a generated network traffic and by proposing functions to evaluate these criteria. This is the first contribution in the context of the Ph.D. thesis of Adrien Schoen.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@article{schwab_FourthIndustrialRevolution_2016,
  entrysubtype = {magazine},
  title = {The {{Fourth Industrial Revolution}}},
  author = {Schwab, Klaus},
  date = {2016-01-26T14:45:54-05:00},
  issn = {0015-7120},
  url = {https://www.foreignaffairs.com/articles/2015-12-12/fourth-industrial-revolution},
  urldate = {2021-05-26},
  abstract = {We stand on the brink of a technological revolution that will fundamentally alter the way we live, work, and relate to one another. In its scale, scope, and complexity, the transformation will be unlike anything humankind has experienced before.},
  langid = {american}
}

@article{schwartz_AutomatingThreatSharing_2017,
  title = {Automating {{Threat Sharing}} : {{How Companies Can Best Ensure Liability Protection When Sharing Cyber Threat Information With Other Companies}} or {{Organizations}}},
  author = {Schwartz, Ari and Mackenzie, Matthew H},
  date = {2017},
  volume = {50}
}

@inproceedings{selamnia_EdgeComputingenabledIntrusion_2022,
  title = {Edge {{Computing-enabled Intrusion Detection}} for {{C-V2X Networks}} Using {{Federated Learning}}},
  booktitle = {{{GLOBECOM}} 2022 - 2022 {{IEEE Global Communications Conference}}},
  author = {Selamnia, Aymene and Brik, Bouziane and Senouci, Sidi Mohammed and Boualouache, Abdelwahab and Hossain, Shajjad},
  date = {2022-12},
  pages = {2080--2085},
  doi = {10.1109/GLOBECOM48099.2022.10001675},
  url = {https://ieeexplore.ieee.org/document/10001675},
  urldate = {2024-06-11},
  abstract = {Intrusion detection systems (IDS) have already demonstrated their effectiveness in detecting various attacks in cellular vehicle-to-everything (C-V2X) networks, especially when using machine learning (ML) techniques. However, it has been shown that generating ML-based models in a centralized way consumes a massive quantity of network resources, such as CPU/memory and bandwidth, which may represent a critical issue in such networks. To avoid this problem, the new concept of Federated Learning (FL) emerged to build ML-based models in a distributed and collaborative way. In such an approach, the set of nodes, e.g., vehicles or gNodeB, collaborate to create a global ML model trained across these multiple decentralized nodes; each one with its respective data samples that are not shared with any other nodes. In this way, FL enables, on the one hand, data privacy since sharing data with a central location is not always feasible and, on the other hand, network overhead reduction. This paper designs a new IDS for C-V2X networks based on FL. It leverages edge computing to not only build a prediction model in a distributed way, but also to enable low latency intrusion detection. Moreover, we build our FL-based IDS on top of well-know CIC-IDS2018 dataset, that includes the main network attacks. Noting that, we first perform a feature engineering on the dataset using the ANOVA method to consider only the most informative features. Simulation results show the efficiency of our system compared to the existing solutions in terms of attack detection accuracy while reducing the network resource consumption.},
  eventtitle = {{{GLOBECOM}} 2022 - 2022 {{IEEE Global Communications Conference}}},
  keywords = {â›” No DOI found,C-V2X,Edge computing,Federated deep learning,Federated learning,Global communication,Image edge detection,Information sharing,Intrusion detection,Intrusion detection system,Predictive models,Simulation}
}

@article{sengupta_ComprehensiveSurveyAttacks_2020,
  title = {A {{Comprehensive Survey}} on {{Attacks}}, {{Security Issues}} and {{Blockchain Solutions}} for {{IoT}} and {{IIoT}}},
  author = {Sengupta, Jayasree and Ruj, Sushmita and Das Bit, Sipra},
  date = {2020-01},
  journaltitle = {Journal of Network and Computer Applications},
  volume = {149},
  pages = {102481},
  publisher = {Elsevier Ltd},
  issn = {10848045},
  doi = {10.1016/j.jnca.2019.102481},
  url = {https://doi.org/10.1016/j.jnca.2019.102481},
  abstract = {In recent years, the growing popularity of Internet of Things (IoT) is providing a promising opportunity not only for the development of various home automation systems but also for different industrial applications. By leveraging these benefits, automation is brought about in the industries giving rise to the Industrial Internet of Things (IIoT). IoT is prone to several cyberattacks and needs challenging approaches to achieve the desired security. Moreover, with the emergence of IIoT, the security vulnerabilities posed by it are even more devastating. Therefore, in order to provide a guideline to researchers, this survey primarily attempts to classify the attacks based on the objects of vulnerability. Subsequently, each of the individual attacks is mapped to one or more layers of the generalized IoT/IIoT architecture followed by a discussion on the countermeasures proposed in literature. Some relevant real-life attacks for each of these categories are also discussed. We further discuss the countermeasures proposed for the most relevant security threats in IIoT. A case study on two of the most important industrial IoT applications is also highlighted. Next, we explore the challenges brought by the centralized IoT/IIoT architecture and how blockchain can effectively be used towards addressing such challenges. In this context, we also discuss in detail one IoT specific Blockchain design known as Tangle, its merits and demerits. We further highlight the most relevant Blockchain-based solutions provided in recent times to counter the challenges posed by the traditional cloud-centered applications. The blockchain-related solutions provided in the context of two of the most relevant applications for each of IoT and IIoT is also discussed. Subsequently, we design a taxonomy of the security research areas in IoT/IIoT along with their corresponding solutions. Finally, several open research directions relevant to the focus of this survey are identified.},
  issue = {April 2019}
}

@article{settanni_collaborativecyberincident_2017,
  title = {A Collaborative Cyber Incident Management System for {{European}} Interconnected Critical Infrastructures},
  author = {Settanni, Giuseppe and Skopik, Florian and Shovgenya, Yegor and Fiedler, Roman and Carolan, Mark and Conroy, Damien and Boettinger, Konstantin and Gall, Mark and Brost, Gerd and Ponchel, Christophe and Haustein, Mirko and Kaufmann, Helmut and Theuerkauf, Klaus and Olli, Pia},
  date = {2017-06},
  journaltitle = {Journal of Information Security and Applications},
  volume = {34},
  pages = {166--182},
  publisher = {Elsevier Ltd},
  issn = {22142126},
  doi = {10.1016/j.jisa.2016.05.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2214212616300576},
  abstract = {Today's Industrial Control Systems (ICSs) operating in critical infrastructures (CIs) are becoming increasingly complex; moreover, they are extensively interconnected with corporate information systems for cost-efficient monitoring, management and maintenance. This exposes ICSs to modern advanced cyber threats. Existing security solutions try to prevent, detect, and react to cyber threats by employing security measures that typically do not cross the organization's boundaries. However, novel targeted multi-stage attacks such as Advanced Persistent Threats (APTs) take advantage of the interdependency between organizations. By exploiting vulnerabilities of various systems, APT campaigns intrude several organizations using them as stepping stones to reach the target infrastructure. A coordinated effort to timely reveal such attacks, and promptly deploy mitigation measures is therefore required. Organizations need to cooperatively exchange security-relevant information to obtain a broader knowledge on the current cyber threat landscape and subsequently obtain new insight into their infrastructures and timely react if necessary. Cyber security operation centers (SOCs), as proposed by the European NIS directive, are being established worldwide to achieve this goal. CI providers are asked to report to the responsible SOCs about security issues revealed in their networks. National SOCs correlate all the gathered data, analyze it and eventually provide support and mitigation strategies to the affiliated organizations. Although many of these tasks can be automated, human involvement is still necessary to enable SOCs to adequately take decisions on occurring incidents and quickly implement counteractions. In this paper we present a collaborative approach to cyber incident information management for gaining situational awareness on interconnected European CIs. We provide a scenario and an illustrative use-case for our approach; we propose a system architecture for a National SOC, defining the functional components and interfaces it comprises. We further describe the functionalities provided by the different system components to support SOC operators in performing incident management tasks.}
}

@online{severi_NetworkLevelAdversariesFederated_2022,
  title = {Network-{{Level Adversaries}} in {{Federated Learning}}},
  author = {Severi, Giorgio and Jagielski, Matthew and Yar, G\"okberk and Wang, Yuxuan and Oprea, Alina and Nita-Rotaru, Cristina},
  date = {2022-08-26},
  eprint = {2208.12911},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2208.12911},
  urldate = {2022-09-05},
  abstract = {Federated learning is a popular strategy for training models on distributed, sensitive data, while preserving data privacy. Prior work identified a range of security threats on federated learning protocols that poison the data or the model. However, federated learning is a networked system where the communication between clients and server plays a critical role for the learning task performance. We highlight how communication introduces another vulnerability surface in federated learning and study the impact of network-level adversaries on training federated learning models. We show that attackers dropping the network traffic from carefully selected clients can significantly decrease model accuracy on a target population. Moreover, we show that a coordinated poisoning campaign from a few clients can amplify the dropping attacks. Finally, we develop a server-side defense which mitigates the impact of our attacks by identifying and up-sampling clients likely to positively contribute towards target accuracy. We comprehensively evaluate our attacks and defenses on three datasets, assuming encrypted communication channels and attackers with partial visibility of the network.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Computer Science - Networking and Internet Architecture}
}

@online{severi_NetworkLevelAdversariesFederated_2022a,
  title = {Network-{{Level Adversaries}} in {{Federated Learning}}},
  author = {Severi, Giorgio and Jagielski, Matthew and Yar, G\"okberk and Wang, Yuxuan and Oprea, Alina and Nita-Rotaru, Cristina},
  date = {2022-08-26},
  eprint = {2208.12911},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2208.12911},
  urldate = {2022-09-05},
  abstract = {Federated learning is a popular strategy for training models on distributed, sensitive data, while preserving data privacy. Prior work identified a range of security threats on federated learning protocols that poison the data or the model. However, federated learning is a networked system where the communication between clients and server plays a critical role for the learning task performance. We highlight how communication introduces another vulnerability surface in federated learning and study the impact of network-level adversaries on training federated learning models. We show that attackers dropping the network traffic from carefully selected clients can significantly decrease model accuracy on a target population. Moreover, we show that a coordinated poisoning campaign from a few clients can amplify the dropping attacks. Finally, we develop a server-side defense which mitigates the impact of our attacks by identifying and up-sampling clients likely to positively contribute towards target accuracy. We comprehensively evaluate our attacks and defenses on three datasets, assuming encrypted communication channels and attackers with partial visibility of the network.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Computer Science - Networking and Internet Architecture}
}

@article{sha_surveyedgecomputingbased_2020,
  title = {A Survey of Edge Computing-Based Designs for {{IoT}} Security},
  author = {Sha, Kewei and Yang, T. Andrew and Wei, Wei and Davari, Sadegh},
  date = {2020-05},
  journaltitle = {Digital Communications and Networks},
  volume = {6},
  number = {2},
  pages = {195--202},
  publisher = {Elsevier Ltd},
  issn = {23528648},
  doi = {10.1016/j.dcan.2019.08.006},
  url = {https://doi.org/10.1016/j.dcan.2019.08.006},
  abstract = {Pervasive IoT applications enable us to perceive, analyze, control, and optimize the traditional physical systems. Recently, security breaches in many IoT applications have indicated that IoT applications may put the physical systems at risk. Severe resource constraints and insufficient security design are two major causes of many security problems in IoT applications. As an extension of the cloud, the emerging edge computing with rich resources provides us a new venue to design and deploy novel security solutions for IoT applications. Although there are some research efforts in this area, edge-based security designs for IoT applications are still in its infancy. This paper aims to present a comprehensive survey of existing IoT security solutions at the edge layer as well as to inspire more edge-based IoT security designs. We first present an edge-centric IoT architecture. Then, we extensively review the edge-based IoT security research efforts in the context of security architecture designs, firewalls, intrusion detection systems, authentication and authorization protocols, and privacy-preserving mechanisms. Finally, we propose our insight into future research directions and open research issues.}
}

@inproceedings{shafee_MimicLearningGenerate_2020,
  title = {Mimic {{Learning}} to {{Generate}} a {{Shareable Network Intrusion Detection Model}}},
  booktitle = {2020 {{IEEE}} 17th {{Annual Consumer Communications}} \& {{Networking Conference}} ({{CCNC}})},
  author = {Shafee, Ahmed and Baza, Mohamed and Talbert, Douglas A. and Fouda, Mostafa M. and Nabil, Mahmoud and Mahmoud, Mohamed},
  date = {2020-01},
  pages = {1--6},
  publisher = {IEEE},
  location = {Las Vegas, NV, USA},
  doi = {10.1109/CCNC46108.2020.9045236},
  url = {https://ieeexplore.ieee.org/document/9045236/},
  urldate = {2022-07-05},
  abstract = {Purveyors of malicious network attacks continue to increase the complexity and the sophistication of their techniques, and their ability to evade detection continues to improve as well. Hence, intrusion detection systems must also evolve to meet these increasingly challenging threats. Machine learning is often used to support this needed improvement. However, training a good prediction model can require a large set of labeled training data. Such datasets are difficult to obtain because privacy concerns prevent the majority of intrusion detection agencies from sharing their sensitive data. In this paper, we propose the use of mimic learning to enable the transfer of intrusion detection knowledge through a teacher model trained on private data to a student model. This student model provides a mean of publicly sharing knowledge extracted from private data without sharing the data itself. Our results confirm that the proposed scheme can produce a student intrusion detection model that mimics the teacher model without requiring access to the original dataset.},
  eventtitle = {2020 {{IEEE}} 17th {{Annual Consumer Communications}} \& {{Networking Conference}} ({{CCNC}})},
  isbn = {978-1-72813-893-0},
  langid = {english}
}

@article{shafiq_Selectioneffectivemachine_2020,
  title = {Selection of Effective Machine Learning Algorithm and {{Bot-IoT}} Attacks Traffic Identification for Internet of Things in Smart City},
  author = {Shafiq, Muhammad and Tian, Zhihong and Sun, Yanbin and Du, Xiaojiang and Guizani, Mohsen},
  date = {2020-06-01},
  journaltitle = {Future Generation Computer Systems},
  shortjournal = {Future Generation Computer Systems},
  volume = {107},
  pages = {433--442},
  issn = {0167-739X},
  doi = {10.1016/j.future.2020.02.017},
  url = {https://www.sciencedirect.com/science/article/pii/S0167739X19334880},
  urldate = {2023-03-22},
  abstract = {Identifying cyber attacks traffic is very important for the Internet of things (IoT) security in smart city. Recently, the research community in the field of IoT Security endeavor hard to build anomaly, intrusion and cyber attacks traffic identification model using Machine Learning (ML) algorithms for IoT security analysis. However, the critical and significant problem still not studied in depth that is how to select an effective ML algorithm when there are numbers of ML algorithms for cyber attacks detection system for IoT security. In this paper, we proposed a new framework model and a hybrid algorithm to solve this problem. Firstly BoT-IoT identification dataset is applied and its 44 effective features are selected from a number of features for the machine learning algorithm. Then five effective machine learning algorithm is selected for the identification of malicious and anomaly traffic identification and also select the most widely ML algorithm performance evaluation metrics. To find out which ML algorithm is effective and should be used to select for IoT anomaly and intrusion traffic identification, a bijective soft set approach and its algorithm is applied. Then we applied the proposed algorithm based on bijective soft set approach. Our experimental results show that the proposed model with the algorithm is effective for the selection ML algorithm out of numbers of ML algorithms.},
  langid = {english},
  keywords = {Bot-IoT attacks,Identification,IoT,Machine learning,Selection,Smart city}
}

@article{shamir_CommunicationEfficientDistributedOptimization_2014,
  title = {Communication-{{Efficient Distributed Optimization}} Using an {{Approximate Newton-type Method}}},
  author = {Shamir, Ohad and Srebro, Nathan and Zhang, Tong},
  date = {2014},
  pages = {9},
  abstract = {We present a novel Newton-type method for distributed optimization, which is particularly well suited for stochastic optimization and learning problems. For quadratic objectives, the method enjoys a linear rate of convergence which provably improves with the data size, requiring an essentially constant number of iterations under reasonable assumptions. We provide theoretical and empirical evidence of the advantages of our method compared to other approaches, such as one-shot parameter averaging and ADMM.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@article{shan_CFLIDSEffectiveClustered_2024,
  title = {{{CFL-IDS}}: {{An Effective Clustered Federated Learning Framework}} for {{Industrial Internet}} of {{Things Intrusion Detection}}},
  shorttitle = {{{CFL-IDS}}},
  author = {Shan, Yao and Yao, Yu and Zhou, Xiaoming and Zhao, Tong and Hu, Bo and Wang, Lei},
  date = {2024-03},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {11},
  number = {6},
  pages = {10007--10019},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2023.3324302},
  url = {https://ieeexplore.ieee.org/abstract/document/10285326},
  urldate = {2024-04-12},
  abstract = {The Industrial Internet of Things (IIoT) offers the manufacturing sector opportunities for transformation and upgrade but also carries significant security risks. Traditional federated learning (FL) as a potential security solution is challenging in complicated application environments with heterogeneous data, imbalanced data, and poisoning attacks. To address these challenges, we construct a clustered FL Framework for IIoT intrusion detection (CFL-IDS) based on local models' evaluation metrics (EMs). First, we designed an intrusion detection model with a dynamic focal loss (DFL) for all edge nodes (ENs). This model's performance is enhanced under various imbalanced data partitions by dynamically altering the focus on samples during the loss minimization training process. Second, the time series of EMs of local models to reflect the data distribution of ENs implicitly, and use clustering algorithms to facilitate knowledge sharing among those ENs with similar data distribution to co-optimize a common model for them. Finally, an intelligent cooperative model aggregation mechanism (ICMAM) adaptively adjusts each local model's weight distribution, which substantially improves the benefits of FL and alleviates subpar models' alleviates interference from subpar models to FL. Experiments demonstrate that CFL-IDS has stronger robustness and displays superior performance under data imbalance and non-independent and identically distributed (non-IID) situations while being effective against poisoning attacks.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {Adaptation models,Clustered federated learning (FL),Computational modeling,data imbalanced,Data models,evaluation metrics (EMs),Industrial Internet of Things,Industrial Internet of Things (IIoT) Intrusion detection,Intrusion detection,non-independent and identically distributed (non-IID),poisoning attack,Robustness,Training}
}

@inproceedings{sharafaldin_GeneratingNewIntrusion_2018,
  title = {Toward {{Generating}} a {{New Intrusion Detection Dataset}} and {{Intrusion Traffic Characterization}}},
  shorttitle = {Toward {{Generating}} a {{New Intrusion Detection Dataset}} and {{Intrusion Traffic Characterization}}},
  booktitle = {Proceedings of the 4th {{International Conference}} on {{Information Systems Security}} and {{Privacy}}},
  author = {Sharafaldin, Iman and Habibi Lashkari, Arash and Ghorbani, Ali A.},
  date = {2018},
  pages = {108--116},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  location = {Funchal, Madeira, Portugal},
  doi = {10.5220/0006639801080116},
  url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006639801080116},
  urldate = {2021-10-14},
  abstract = {Intrusion Detection, IDS Dataset, DoS, Web Attack, Infiltration, Brute Force.},
  eventtitle = {4th {{International Conference}} on {{Information Systems Security}} and {{Privacy}}},
  isbn = {978-989-758-282-0},
  langid = {english}
}

@inproceedings{sharafaldin_GeneratingNewIntrusion_2018a,
  title = {Toward {{Generating}} a {{New Intrusion Detection Dataset}} and {{Intrusion Traffic Characterization}}},
  shorttitle = {Toward {{Generating}} a {{New Intrusion Detection Dataset}} and {{Intrusion Traffic Characterization}}},
  booktitle = {Proceedings of the 4th {{International Conference}} on {{Information Systems Security}} and {{Privacy}}},
  author = {Sharafaldin, Iman and Habibi Lashkari, Arash and Ghorbani, Ali A.},
  date = {2018},
  pages = {108--116},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  location = {Funchal, Madeira, Portugal},
  doi = {10.5220/0006639801080116},
  url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006639801080116},
  urldate = {2023-03-22},
  abstract = {Intrusion Detection, IDS Dataset, DoS, Web Attack, Infiltration, Brute Force.},
  eventtitle = {4th {{International Conference}} on {{Information Systems Security}} and {{Privacy}}},
  isbn = {978-989-758-282-0},
  langid = {english}
}

@inproceedings{sharafaldin_GeneratingNewIntrusion_2023,
  title = {Toward {{Generating}} a {{New Intrusion Detection Dataset}} and {{Intrusion Traffic Characterization}}},
  author = {Sharafaldin, Iman and Lashkari, Arash Habibi and Ghorbani, Ali A.},
  date = {2023-03-22},
  pages = {108--116},
  url = {https://www.scitepress.org/Link.aspx?doi=10.5220/0006639801080116},
  urldate = {2023-03-22},
  abstract = {Digital Library},
  eventtitle = {4th {{International Conference}} on {{Information Systems Security}} and {{Privacy}}},
  isbn = {978-989-758-282-0}
}

@article{sharma_Edgeassistedfederatedlearning_2024,
  title = {Edge-Assisted Federated Learning for Anomaly Detection in Diverse {{IoT}} Network},
  author = {Sharma, Priya and Sharma, Sanjay Kumar and Dani, Diksha},
  date = {2024-02-15},
  journaltitle = {International Journal of Information Technology},
  shortjournal = {Int. j. inf. tecnol.},
  issn = {2511-2112},
  doi = {10.1007/s41870-024-01728-x},
  url = {https://doi.org/10.1007/s41870-024-01728-x},
  urldate = {2024-04-12},
  abstract = {The rapid expansion and increasing complexity of Internet of Things (IoT) networks have led to a heightened need for effective and adaptable anomaly detection techniques. The vast variety of devices, communication protocols over 5G and other networks, and data types present in diverse IoT environments poses significant challenges for traditional centralized methods. With the rapid increase of users in 5G networks will require drastic security measures in IoT. This paper proposes an edge-assisted federated learning approach for detecting anomalies in heterogeneous IoT networks, enabling robust and efficient performance across a wide range of devices and scenarios. Our proposed method combines the advantages of federated learning and edge computing, allowing IoT devices to collaboratively train a shared machine learning model while keeping their data local. This approach not only preserves privacy but also reduces communication overhead and latency, providing a scalable solution for large-scale IoT deployments. By incorporating edge computing, our method ensures that data processing occurs closer to the source, further improving efficiency and reducing the reliance on centralized cloud resources. We present a thorough evaluation of our edge-assisted federated learning approach, comparing it to traditional centralized techniques as well as other distributed learning methods. The results demonstrate that our approach achieves superior performance in detecting anomalies in diverse IoT environments while maintaining low latency, communication overhead over network, and energy consumption. Additionally, we showcase the adaptability of our method to various IoT network configurations and device capabilities, highlighting its potential as a versatile solution for real-world IoT anomaly detection challenges.},
  langid = {english},
  keywords = {5G,Anomaly detection,Distributed machine learning,Edge computing,Federated learning,Heterogeneous networks,Internet of things (IoT) network,Privacy preservation,Scalability}
}

@inproceedings{shen_Aurordefendingpoisoning_2016,
  title = {Auror: Defending against Poisoning Attacks in Collaborative Deep Learning Systems},
  booktitle = {Proceedings of the 32nd {{Annual Conference}} on {{Computer Security Applications}}},
  author = {Shen, Shiqi and Tople, Shruti and Saxena, Prateek},
  date = {2016-12-05},
  pages = {508--519},
  publisher = {ACM},
  location = {New York, NY, USA},
  doi = {10.1145/2991079.2991125},
  url = {https://dl.acm.org/doi/10.1145/2991079.2991125},
  isbn = {978-1-4503-4771-6},
  keywords = {obsidian}
}

@report{shen_BlockchainAssistedCrosssiloGraph_2023,
  type = {preprint},
  title = {Blockchain-{{Assisted Cross-silo Graph Federated Learning}} for {{Network Intrusion Detection}}},
  author = {Shen, Hang and Zhou, Yanjing and Wang, Tianjing and Zhang, Yu and Bai, Guangwei and Miao, Xiaodong},
  date = {2023-09-12},
  institution = {In Review},
  doi = {10.21203/rs.3.rs-3330608/v1},
  url = {https://www.researchsquare.com/article/rs-3330608/v1},
  urldate = {2023-10-13},
  abstract = {In this paper, a blockchain-assisted cross-silo graph federated learning (B-CGFL) framework is presented for large-scale network intrusion detection, aiming to break down barriers among different organizations and achieve a secure and transparent multi-party collaboration ecosystem. The network scenario is divided into multiple regions. Organizations in each region leverage graph neural networks to analyze local network flow topology information and identify traffic types accurately. With cross-silo graph federated learning, coordinators and organizations collaboratively complete the training and updating of global intrusion detection models. Multiple coordinators jointly maintain a chain to improve the global model's scalability and storage security. Oracle nodes bridge the off-chain data provider and on-chain smart contracts, enabling secure transmission in off-chain model accuracy testing. For fair competition, a reputation-aware model incentive mechanism is designed to improve global model quality. Security analysis confirms that B-CGFL can defend against inference attacks, model plagiarism, and tampering with model test results. Experiments on three challenging datasets ToN-IoT, CSE-CIC-IDS2018, and BoT-IoT demonstrate that compared with benchmark machine learning methods, B-CGFL exhibits superior performance in accuracy and F1-score and facilitates model quality improvement.},
  langid = {english},
  keywords = {\_unpublished}
}

@article{shen_DistributedMachineLearning_2020,
  title = {From {{Distributed Machine Learning To Federated Learning}}: {{In The View Of Data Privacy And Security}}},
  shorttitle = {From {{Distributed Machine Learning To Federated Learning}}},
  author = {Shen, Sheng and Zhu, Tianqing and Wu, Di and Wang, Wei and Zhou, Wanlei},
  date = {2020-09-23},
  journaltitle = {Concurrency and Computation: Practice and Experience},
  shortjournal = {Concurrency Computat Pract Exper},
  eprint = {2010.09258},
  eprinttype = {arXiv},
  pages = {cpe.6002},
  issn = {1532-0626, 1532-0634},
  doi = {10.1002/cpe.6002},
  url = {http://arxiv.org/abs/2010.09258},
  urldate = {2021-10-04},
  abstract = {Federated learning is an improved version of distributed machine learning that further offloads operations which would usually be performed by a central server. The server becomes more like an assistant coordinating clients to work together rather than micro-managing the workforce as in traditional DML. One of the greatest advantages of federated learning is the additional privacy and security guarantees it affords. Federated learning architecture relies on smart devices, such as smartphones and IoT sensors, that collect and process their own data, so sensitive information never has to leave the client device. Rather, clients train a sub-model locally and send an encrypted update to the central server for aggregation into the global model. These strong privacy guarantees make federated learning an attractive choice in a world where data breaches and information theft are common and serious threats. This survey outlines the landscape and latest developments in data privacy and security for federated learning. We identify the different mechanisms used to provide privacy and security, such as differential privacy, secure multi-party computation and secure aggregation. We also survey the current attack models, identifying the areas of vulnerability and the strategies adversaries use to penetrate federated systems. The survey concludes with a discussion on the open challenges and potential directions of future work in this increasingly popular learning paradigm.},
  langid = {english},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},\_read}
}

@inproceedings{shi_DataPrivacySecurity_2021,
  title = {Data {{Privacy Security Guaranteed Network Intrusion Detection System Based}} on {{Federated Learning}}},
  booktitle = {{{IEEE INFOCOM}} 2021 - {{IEEE Conference}} on {{Computer Communications Workshops}} ({{INFOCOM WKSHPS}})},
  author = {Shi, Jibo and Ge, Bin and Liu, Yang and Yan, Yu and Li, Shuang},
  date = {2021-05},
  pages = {1--6},
  doi = {10.1109/INFOCOMWKSHPS51825.2021.9484545},
  abstract = {With the development of computer software, the amount of network data has increased geometrically. Therefore, how to quickly identify attacks from a large amount of network information is a meaningful research direction. The intrusion detection system (IDS) is the core contributor to protecting the host from attack. It can distinguish the characteristics of intrusion behavior and the intrusion action from the data of the host. However, with the huge increase in the amount of data now, the efficiency of identifying data characteristics is getting lower and lower. In addition, smart terminal equipment such as notebooks, smart phones and wearable devices are also emerging, and these devices are connected to the internet through wireless or wired means. The physical data generated by terminal equipment involves huge amount of personal sensitive data, which poses a challenge to data privacy and security. Federated learning, as a new type of distributed learning framework, allows training data to be shared among multiple participants without revealing their data privacy. In order to solve the problem of privacy data in intrusion detection,, this paper proposes a network intrusion detection method based on federated learning and conducting experiments on the UNSW-NB15 dataset and CICIDS2018 dataset. The simulation results show that the method proposed in this paper can protect data privacy under the premise of achieving acceptable accuracy of intrusion traffic identification.},
  eventtitle = {{{IEEE INFOCOM}} 2021 - {{IEEE Conference}} on {{Computer Communications Workshops}} ({{INFOCOM WKSHPS}})},
  keywords = {CICIDS2018,Conferences,Data privacy,federated learning,IDS,Network intrusion detection,Privacy security,Training data,UNSW-NB15,Wearable computers,Wireless communication,Wireless sensor networks}
}

@article{shiravi_developingsystematicapproach_2012,
  title = {Toward Developing a Systematic Approach to Generate Benchmark Datasets for Intrusion Detection},
  author = {Shiravi, Ali and Shiravi, Hadi and Tavallaee, Mahbod and Ghorbani, Ali A.},
  date = {2012-05-01},
  journaltitle = {Computers \& Security},
  shortjournal = {Computers \& Security},
  volume = {31},
  number = {3},
  pages = {357--374},
  issn = {0167-4048},
  doi = {10.1016/j.cose.2011.12.012},
  url = {https://www.sciencedirect.com/science/article/pii/S0167404811001672},
  urldate = {2024-06-19},
  abstract = {In network intrusion detection, anomaly-based approaches in particular suffer from accurate evaluation, comparison, and deployment which originates from the scarcity of adequate datasets. Many such datasets are internal and cannot be shared due to privacy issues, others are heavily anonymized and do not reflect current trends, or they lack certain statistical characteristics. These deficiencies are primarily the reasons why a perfect dataset is yet to exist. Thus, researchers must resort to datasets that are often suboptimal. As network behaviors and patterns change and intrusions evolve, it has very much become necessary to move away from static and one-time datasets toward more dynamically generated datasets which not only reflect the traffic compositions and intrusions of that time, but are also modifiable, extensible, and reproducible. In this paper, a systematic approach to generate the required datasets is introduced to address this need. The underlying notion is based on the concept of profiles which contain detailed descriptions of intrusions and abstract distribution models for applications, protocols, or lower level network entities. Real traces are analyzed to create profiles for agents that generate real traffic for HTTP, SMTP, SSH, IMAP, POP3, and FTP. In this regard, a set of guidelines is established to outline valid datasets, which set the basis for generating profiles. These guidelines are vital for the effectiveness of the dataset in terms of realism, evaluation capabilities, total capture, completeness, and malicious activity. The profiles are then employed in an experiment to generate the desirable dataset in a testbed environment. Various multi-stage attacks scenarios were subsequently carried out to supply the anomalous portion of the dataset. The intent for this dataset is to assist various researchers in acquiring datasets of this kind for testing, evaluation, and comparison purposes, through sharing the generated datasets and profiles.},
  keywords = {Dataset generation,Intrusion detection,Network traffic profile}
}

@article{short_ImprovingSecurityFairness_2021,
  title = {Improving {{Security}} and {{Fairness}} in {{Federated Learning Systems}}},
  author = {Short, Andrew and Orfanoudakis, {$T$}heofanis and Helen, Leligou},
  date = {2021-11-30},
  journaltitle = {International Journal of Network Security \& Its Applications},
  shortjournal = {International Journal of Network Security \& Its Applications},
  volume = {13},
  pages = {37--53},
  doi = {10.5121/ijnsa.2021.13604},
  abstract = {The ever-increasing use of Artificial Intelligence applications has made apparent that the quality of the training datasets affects the performance of the models. To this end, Federated Learning aims to engage multiple entities to contribute to the learning process with locally maintained data, without requiring them to share the actual datasets. Since the parameter server does not have access to the actual training datasets, it becomes challenging to offer rewards to users by directly inspecting the dataset quality. Instead, this paper focuses on ways to strengthen user engagement by offering ``fair'' rewards, proportional to the model improvement (in terms of accuracy) they offer. Furthermore, to enable objective judgment of the quality of contribution, we devise a point system to record user performance assisted by blockchain technologies. More precisely, we have developed a verification algorithm that evaluates the performance of users' contributions by comparing the resulting accuracy of the global model against a verification dataset and we demonstrate how this metric can be used to offer security improvements in a Federated Learning process. Further on, we implement the solution in a simulation environment in order to assess the feasibility and collect baseline results using datasets of varying quality.}
}

@inproceedings{short_UsingBlockchainTechnologies_2020,
  title = {Using {{Blockchain Technologies}} to {{Improve Security}} in {{Federated Learning Systems}}},
  booktitle = {2020 {{IEEE}} 44th {{Annual Computers}}, {{Software}}, and {{Applications Conference}} ({{COMPSAC}})},
  author = {Short, Andrew Ronald and Leligou, Helen C. and Papoutsidakis, Michael and Theocharis, Efstathios},
  date = {2020-07},
  pages = {1183--1188},
  issn = {0730-3157},
  doi = {10.1109/COMPSAC48688.2020.00-96},
  abstract = {The potential of Federated Learning (FL) deployment increases rapidly as the number of connected devices increases, the value of artificial intelligence is recognized and networking technologies and edge computing evolves. However, as in any distributed system, a set of security issues arise in FL systems. In this paper, we discuss the use of blockchain technology to address diverse security aspects of FL systems and focus on the model poisoning attack for which we propose a novel Blockchain-based defense scheme. An assessment using data from the MNIST database has shown that the proposed approach, which has been designed to be implemented on blockchain technology, offers significant protection against adversaries attempting model poisoning attacks. The approach adopts a novel algorithm for evaluating the model updates, by verifying each model update separately against a verification dataset, without requiring information about the training dataset size, which is often unavailable or easily falsified.},
  eventtitle = {2020 {{IEEE}} 44th {{Annual Computers}}, {{Software}}, and {{Applications Conference}} ({{COMPSAC}})},
  keywords = {{Blockchain, Federated Learning, Security attacks},Computers,Conferences,Software}
}

@unpublished{si-ahmed_SurveyMachineLearning_2022,
  title = {Survey of {{Machine Learning Based Intrusion Detection Methods}} for {{Internet}} of {{Medical Things}}},
  author = {Si-Ahmed, Ayoub and Al-Garadi, Mohammed Ali and Boustia, Narhimene},
  date = {2022-02-19},
  eprint = {2202.09657},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2202.09657},
  urldate = {2022-03-01},
  abstract = {Internet of Medical Things (IoMT) represents an application of the Internet of Things, where health professionals perform remote analysis of physiological data collected using sensors that are associated with patients, allowing real-time and permanent monitoring of the patient's health condition and the detection of possible diseases at an early stage. However, the use of wireless communication for data transfer exposes this data to cyberattacks, and the sensitive and private nature of this data may represent a prime interest for attackers. The use of traditional security methods on equipment that is limited in terms of storage and computing capacity is ineffective. In this context, we have performed a comprehensive survey to investigate the use of the intrusion detection system based on machine learning (ML) for IoMT security. We presented the generic three-layer architecture of IoMT, the security requirement of IoMT security. We review the various threats that can affect IoMT security and identify the advantage, disadvantages, methods, and datasets used in each solution based on ML. Then we provide some challenges and limitations of applying ML on each layer of IoMT, which can serve as direction for future study.},
  langid = {english},
  keywords = {+survey,â›” No DOI found,Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@online{sidd_dataset,
  title = {{{SIDD}} ({{Segmented Intrusion Detection Dataset}})},
  author = {Sun, Yuwei},
  date = {2020},
  url = {https://www.kaggle.com/datasets/yuweisunut/sidd-segmented-intrusion-detection-dataset},
  urldate = {2022-07-05},
  abstract = {A Large-Scale Network Intrusion Image Dataset},
  langid = {english},
  keywords = {pinned}
}

@inproceedings{sifalakis_informationcentricnetwork_2014,
  title = {An Information Centric Network for Computing the Distribution of Computations},
  booktitle = {Proceedings of the 1st {{ACM Conference}} on {{Information-Centric Networking}}},
  author = {Sifalakis, Manolis and Kohler, Basil and Scherb, Christopher and Tschudin, Christian},
  date = {2014-09-24},
  series = {{{ACM-ICN}} '14},
  pages = {137--146},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/2660129.2660150},
  url = {https://doi.org/10.1145/2660129.2660150},
  urldate = {2022-09-29},
  abstract = {Named Function Networking (NFN) extends classic Information Centric Networking (ICN), such that in addition to resolving data access by name, it also supports the concept of function definition and application to data (or other functions) in the same resolution-by-name process. This empowers the network to select internally (optimal) places for fulfilling a potentially complex user expression. Forwarding optimization and routing policies become thereafter a basis of dynamic decisions for (re)-distributing computations, and retrieving results. In this paper we describe the intrinsic operations and mechanisms of an instantiation of NFN based on untyped Lambda expressions and Scala procedures. Then, we demonstrate through a series of proof-of-concept experiments how they extend the capabilities of an information centric network (CCN), for orchestrating and distributing data computations, and re-using cached results from previous computations. In the end we report and discuss the main observations stemming from these experiments and highlight important insights that can impact the architecting of ICN protocols that focus on named-data.},
  isbn = {978-1-4503-3206-4},
  keywords = {information centric networking,named data networking,named-function networking,network architectures}
}

@inproceedings{sillaber_DataQualityChallenges_2016,
  title = {Data {{Quality Challenges}} and {{Future Research Directions}} in {{Threat Intelligence Sharing Practice}}},
  booktitle = {Proceedings of the 2016 {{ACM}} on {{Workshop}} on {{Information Sharing}} and {{Collaborative Security}} - {{WISCS}}'16},
  author = {Sillaber, Christian and Sauerwein, Clemens and Mussmann, Andrea and Breu, Ruth},
  date = {2016},
  pages = {65--70},
  publisher = {ACM Press},
  location = {New York, New York, USA},
  doi = {10.1145/2994539.2994546},
  url = {http://dl.acm.org/citation.cfm?doid=2994539.2994546},
  abstract = {In the last couple of years, organizations have demonstrated an increased willingness to participate in threat intelligence sharing platforms. The open exchange of information and knowledge regarding threats, vulnerabilities, incidents and mitigation strategies results from the organizations' growing need to protect against today's sophisticated cyber attacks. To investigate data quality challenges that might arise in threat intelligence sharing, we conducted focus group discussions with ten expert stakeholders from security operations centers of various globally operating organizations. The study addresses several factors affecting shared threat intelligence data quality at multiple levels, including collecting, processing, sharing and storing data. As expected, the study finds that the main factors that affect shared threat intelligence data stem from the limitations and complexities associated with integrating and consolidating shared threat intelligence from different sources while ensuring the data's usefulness for an inhomogeneous group of participants.Data quality is extremely important for shared threat intelligence. As our study has shown, there are no fundamentally new data quality issues in threat intelligence sharing. However, as threat intelligence sharing is an emerging domain and a large number of threat intelligence sharing tools are currently being rushed to market, several data quality issues - particularly related to scalability and data source integration - deserve particular attention.},
  isbn = {978-1-4503-4565-1}
}

@inproceedings{singh_AndroidWebSecurity_2022,
  title = {Android {{Web Security Solution}} Using {{Cross-device Federated Learning}}},
  booktitle = {2022 14th {{International Conference}} on {{COMmunication Systems}} \& {{NETworkS}} ({{COMSNETS}})},
  author = {Singh, A K and Goyal, Navneet},
  date = {2022-01},
  pages = {473--481},
  issn = {2155-2509},
  doi = {10.1109/COMSNETS53615.2022.9668449},
  url = {https://ieeexplore.ieee.org/abstract/document/9668449},
  urldate = {2024-04-12},
  abstract = {Over the last one decade or so, Machine Learning has changed the global technology landscape with applications in almost all disciplines and verticals. Mobile and Web Security is an important research area in which researchers have been trying to apply Machine Learning, but data privacy concerns and high data communication costs to a central Machine Learning server have limited its use. Federated Learning is emerging as a promising solution which addresses privacy concerns and drastically reduces communication costs. In Federated Learning, data from individual devices is not communicated to a central server and model learning happens in a distributed manner. In this paper, we propose a Federated Learning solution for security of Android based devices. Mobile and Web Security solutions have evolved from signature-based detections to building Machine Learning models which are trained over large centralized malware repositories. We have used Federated Learning to learn security patterns from users' browsing data, which resides on individual devices and will never leave the devices. Federated Learning preserves users' privacy as it shares with the central server only the model that it learns from users' browsing data, and not the data itself. This way each mobile platform trains its own web security model from its data, and shares it to the centralized server. The centralized server aggregates these trained models received from numerous mobile devices and compiles an aggregated global model, which in turn is sent to mobile devices for inference. Mobile security solutions based on this concept create a sustained self-evolving security ecosystem, in which millions of mobile platforms share their learned models to form a robust distributed security paradigm. The results obtained using Federated Learning are found to be comparable with the results of centralized Machine Learning.},
  eventtitle = {2022 14th {{International Conference}} on {{COMmunication Systems}} \& {{NETworkS}} ({{COMSNETS}})},
  keywords = {Android Security,Collaborative work,Costs,Data models,Data privacy,Federated Learning,Machine learning,Machine Learning,Mobile handsets,Privacy,Web Security}
}

@article{singh_DetectionmitigationDDoS_2020,
  title = {Detection and Mitigation of {{DDoS}} Attacks in {{SDN}}: {{A}} Comprehensive Review, Research Challenges and Future Directions},
  shorttitle = {Detection and Mitigation of {{DDoS}} Attacks in {{SDN}}},
  author = {Singh, Jagdeep and Behal, Sunny},
  date = {2020-08},
  journaltitle = {Computer Science Review},
  shortjournal = {Computer Science Review},
  volume = {37},
  pages = {100279},
  issn = {15740137},
  doi = {10.1016/j.cosrev.2020.100279},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1574013720301647},
  urldate = {2022-04-09},
  abstract = {Many security solutions have been proposed in the past to protect Internet architecture from a diversity of malware. However, the security of the Internet and its applications is still an open research challenge. Researchers continuously working on novel network architectures such as HTTP as the narrow waist, Named Data Networking (NDN), programmable networks and Software-Defined Networking (SDN) for designing a more reliable network. Among these, SDN has emerged as a more robust and secure solution to combat against such malicious activities. In SDN, bifurcation of control plane and data plane provides more manageability, control, dynamic updating of rules, analysis, and global view of the network using a centralized controller. Though SDN seems a secured network architecture as compared to the conventional IP-based networks, still, SDN itself is vulnerable to many types of network intrusions and facing severe deployment challenges. This paper systematically reviews around 70 prominent DDoS detection and mitigation mechanisms in SDN networks. These mechanisms are characterized into four categories, viz: Information theory-based methods, Machine learning-based methods, Artificial Neural Networks (ANN) based methods and other miscellaneous methods. The paper also dowries and deliberates on various open research issues, gaps and challenges in the deployment of a secure SDN-based DDoS defence solution. Such an exhaustive review will surely help the researcher community to provide more robust and reliable DDoS solutions in SDN networks. \copyright{} 2020 Elsevier Inc. All rights reserved.},
  langid = {english}
}

@article{singh_DewCloudBasedHierarchicalFederated_2022,
  title = {Dew-{{Cloud-Based Hierarchical Federated Learning}} for {{Intrusion Detection}} in {{IoMT}}},
  author = {Singh, Parminder and Gaba, Gurjot Singh and Kaur, Avinash and Hedabou, Mustapha and Gurtov, Andrei},
  date = {2022-07-11},
  journaltitle = {IEEE journal of biomedical and health informatics},
  shortjournal = {IEEE J Biomed Health Inform},
  volume = {PP},
  eprint = {35816521},
  eprinttype = {pmid},
  issn = {2168-2208},
  doi = {10.1109/JBHI.2022.3186250},
  abstract = {The coronavirus pandemic has overburdened medical institutions, forcing physicians to diagnose and treat their patients remotely. Moreover, COVID-19 has made humans more conscious about their health, resulting in the extensive purchase of IoT-enabled medical devices. The rapid boom in the market worth of the internet of medical things (IoMT) captured cyber attackers' attention. Like health, medical data is also sensitive and worth a lot on the dark web. Despite the fact that the patient's health details have not been protected appropriately, letting the trespassers exploit them. The system administrator is unable to fortify security measures due to the limited storage capacity and computation power of the resource-constrained network devices'. Although various supervised and unsupervised machine learning algorithms have been developed to identify anomalies, the primary undertaking is to explore the swift progressing malicious attacks before they deteriorate the wellness system's integrity. In this paper, a Dew-Cloud based model is designed to enable hierarchical federated learning (HFL). The proposed Dew-Cloud model provides a higher level of data privacy with greater availability of IoMT critical application(s). The hierarchical long-term memory (HLSTM) model is deployed at distributed Dew servers with a backend supported by cloud computing. Data pre-processing feature helps the proposed model achieve high training accuracy ( 99.31 \%) with minimum training loss (0.034). The experiment results demonstrate that the proposed HFL-HLSTM model is superior to existing schemes in terms of performance metrics such as accuracy, precision, recall, and f-score.},
  langid = {english}
}

@article{singh_DewCloudBasedHierarchicalFederated_2023,
  title = {Dew-{{Cloud-Based Hierarchical Federated Learning}} for {{Intrusion Detection}} in {{IoMT}}},
  author = {Singh, Parminder and Gaba, Gurjot Singh and Kaur, Avinash and Hedabou, Mustapha and Gurtov, Andrei},
  date = {2023-02},
  journaltitle = {IEEE journal of biomedical and health informatics},
  shortjournal = {IEEE J Biomed Health Inform},
  volume = {27},
  number = {2},
  eprint = {35816521},
  eprinttype = {pmid},
  pages = {722--731},
  issn = {2168-2208},
  doi = {10.1109/JBHI.2022.3186250},
  abstract = {The coronavirus pandemic has overburdened medical institutions, forcing physicians to diagnose and treat their patients remotely. Moreover, COVID-19 has made humans more conscious about their health, resulting in the extensive purchase of IoT-enabled medical devices. The rapid boom in the market worth of the internet of medical things (IoMT) captured cyber attackers' attention. Like health, medical data is also sensitive and worth a lot on the dark web. Despite the fact that the patient's health details have not been protected appropriately, letting the trespassers exploit them. The system administrator is unable to fortify security measures due to the limited storage capacity and computation power of the resource-constrained network devices'. Although various supervised and unsupervised machine learning algorithms have been developed to identify anomalies, the primary undertaking is to explore the swift progressing malicious attacks before they deteriorate the wellness system's integrity. In this paper, a Dew-Cloud based model is designed to enable hierarchical federated learning (HFL). The proposed Dew-Cloud model provides a higher level of data privacy with greater availability of IoMT critical application(s). The hierarchical long-term memory (HLSTM) model is deployed at distributed Dew servers with a backend supported by cloud computing. Data pre-processing feature helps the proposed model achieve high training accuracy (99.31\%) with minimum training loss (0.034). The experiment results demonstrate that the proposed HFL-HLSTM model is superior to existing schemes in terms of performance metrics such as accuracy, precision, recall, and f-score.},
  langid = {english},
  keywords = {Algorithms,Cloud Computing,COVID-19,Humans,Internet,Internet of Things}
}

@inproceedings{singh_EnhancingCollaborativeIntrusion_2022,
  title = {Enhancing {{Collaborative Intrusion}} Detection Networks against Insider Attack Using Supervised Learning Technique},
  booktitle = {2022 {{IEEE}} 2nd {{Mysore Sub Section International Conference}} ({{MysuruCon}})},
  author = {Singh, Rajesh and Deorari, Rajesh},
  date = {2022-10},
  pages = {1--6},
  doi = {10.1109/MysuruCon55714.2022.9972599},
  abstract = {As network are being used, intrusion occurs from a variety of sources. According to their actions to damage network functioning, cyberattack is a significant issue in communication systems. The privacy, authenticity, or accessibility of a resource may be compromised by unauthorized activity or attacks, which intrusion detection systems (IDS) can help identify. Researchers explore the findings of research articles on the past, present, and potential of intrusion detection systems on wireless networks. Statistical modelling and deep learning are used to analyses the findings of journals. Isolation forest are one of the strategies that can acquire accurate network measures and produce appropriate choices by raising the detection rate and accuracy. In this paper, we propose a decision tree-based method for detection of network intrusions with improved data quality. In order to improve the data quality and provide appropriate training, networking data pre-processing and attributes selection based on entropy are specifically carried out. A isolation forest classifier is then constructed for accurate intrusion detection. Experimental analysis of two datasets demonstrates the proposed model's ability to produce reliable results. Actually, using the CICIDS2017 and NSL-KDD datasets, our model's accuracy is 99.98\% and 99.82\%, respectively. When compared to existing models, the new approach has many benefits in terms of false alarm rate (FAR), detection rate (DR), and accuracy (ACC).},
  eventtitle = {2022 {{IEEE}} 2nd {{Mysore Sub Section International Conference}} ({{MysuruCon}})},
  keywords = {Analytical models,Collaboration,collaborative intrusion detection,Data integrity,insider attacks and intrusion datasets,Intrusion detection,supervised learning,Supervised learning,Training,Wireless networks}
}

@article{singh_Fairdetectionpoisoning_2023,
  title = {Fair Detection of Poisoning Attacks in Federated Learning on Non-i.i.d. Data},
  author = {Singh, Ashneet Khandpur and Blanco-Justicia, Alberto and Domingo-Ferrer, Josep},
  date = {2023-01-04},
  journaltitle = {Data Mining and Knowledge Discovery},
  shortjournal = {Data Min Knowl Disc},
  issn = {1573-756X},
  doi = {10.1007/s10618-022-00912-6},
  url = {https://doi.org/10.1007/s10618-022-00912-6},
  urldate = {2023-01-25},
  abstract = {Reconciling machine learning with individual privacy is one of the main motivations behind federated learning (FL), a decentralized machine learning technique that aggregates partial models trained by clients on their own private data to obtain a global deep learning model. Even if FL provides stronger privacy guarantees to the participating clients than centralized learning collecting the clients' data in a central server, FL is vulnerable to some attacks whereby malicious clients submit bad updates in order to prevent the model from converging or, more subtly, to introduce artificial bias in the classification (poisoning). Poisoning detection techniques compute statistics on the updates to identify malicious clients. A downside of anti-poisoning techniques is that they might lead to discriminate minority groups whose data are significantly and legitimately different from those of the majority of clients. This would not only be unfair, but would yield poorer models that would fail to capture the knowledge in the training data, especially when data are not independent and identically distributed (non-i.i.d.). In this work, we strive to strike a balance between fighting poisoning and accommodating diversity to help learning fairer and less discriminatory federated learning models. In this way, we forestall the exclusion of diverse clients while still ensuring detection of poisoning attacks. Empirical work on three data sets shows that employing our approach to tell legitimate from malicious updates produces models that are more accurate than those obtained with state-of-the-art poisoning detection techniques. Additionally, we explore the impact of our proposal on the performance of models on non-i.i.d local training data.},
  langid = {english},
  keywords = {Fairness,Federated learning,Minorities.,Privacy,Security}
}

@article{singh_Fairdetectionpoisoning_2023a,
  title = {Fair Detection of Poisoning Attacks in Federated Learning on Non-i.i.d. Data},
  author = {Singh, Ashneet Khandpur and Blanco-Justicia, Alberto and Domingo-Ferrer, Josep},
  date = {2023-01-04},
  journaltitle = {Data Mining and Knowledge Discovery},
  shortjournal = {Data Min Knowl Disc},
  issn = {1573-756X},
  doi = {10.1007/s10618-022-00912-6},
  url = {https://doi.org/10.1007/s10618-022-00912-6},
  urldate = {2023-08-06},
  abstract = {Reconciling machine learning with individual privacy is one of the main motivations behind federated learning (FL), a decentralized machine learning technique that aggregates partial models trained by clients on their own private data to obtain a global deep learning model. Even if FL provides stronger privacy guarantees to the participating clients than centralized learning collecting the clients' data in a central server, FL is vulnerable to some attacks whereby malicious clients submit bad updates in order to prevent the model from converging or, more subtly, to introduce artificial bias in the classification (poisoning). Poisoning detection techniques compute statistics on the updates to identify malicious clients. A downside of anti-poisoning techniques is that they might lead to discriminate minority groups whose data are significantly and legitimately different from those of the majority of clients. This would not only be unfair, but would yield poorer models that would fail to capture the knowledge in the training data, especially when data are not independent and identically distributed (non-i.i.d.). In this work, we strive to strike a balance between fighting poisoning and accommodating diversity to help learning fairer and less discriminatory federated learning models. In this way, we forestall the exclusion of diverse clients while still ensuring detection of poisoning attacks. Empirical work on three data sets shows that employing our approach to tell legitimate from malicious updates produces models that are more accurate than those obtained with state-of-the-art poisoning detection techniques. Additionally, we explore the impact of our proposal on the performance of models on non-i.i.d local training data.},
  langid = {english},
  keywords = {Fairness,Federated learning,Minorities.,Privacy,Security}
}

@article{singh_Fairdetectionpoisoning_2023b,
  title = {Fair Detection of Poisoning Attacks in Federated Learning on Non-i.i.d. Data},
  author = {Singh, Ashneet Khandpur and Blanco-Justicia, Alberto and Domingo-Ferrer, Josep},
  date = {2023-09-01},
  journaltitle = {Data Mining and Knowledge Discovery},
  shortjournal = {Data Min Knowl Disc},
  volume = {37},
  number = {5},
  pages = {1998--2023},
  issn = {1573-756X},
  doi = {10.1007/s10618-022-00912-6},
  url = {https://doi.org/10.1007/s10618-022-00912-6},
  urldate = {2024-04-12},
  abstract = {Reconciling machine learning with individual privacy is one of the main motivations behind federated learning (FL), a decentralized machine learning technique that aggregates partial models trained by clients on their own private data to obtain a global deep learning model. Even if FL provides stronger privacy guarantees to the participating clients than centralized learning collecting the clients' data in a central server, FL is vulnerable to some attacks whereby malicious clients submit bad updates in order to prevent the model from converging or, more subtly, to introduce artificial bias in the classification (poisoning). Poisoning detection techniques compute statistics on the updates to identify malicious clients. A downside of anti-poisoning techniques is that they might lead to discriminate minority groups whose data are significantly and legitimately different from those of the majority of clients. This would not only be unfair, but would yield poorer models that would fail to capture the knowledge in the training data, especially when data are not independent and identically distributed (non-i.i.d.). In this work, we strive to strike a balance between fighting poisoning and accommodating diversity to help learning fairer and less discriminatory federated learning models. In this way, we forestall the exclusion of diverse clients while still ensuring detection of poisoning attacks. Empirical work on three data sets shows that employing our approach to tell legitimate from malicious updates produces models that are more accurate than those obtained with state-of-the-art poisoning detection techniques. Additionally, we explore the impact of our proposal on the performance of models on non-i.i.d local training data.},
  langid = {english},
  keywords = {Fairness,Federated learning,Minorities.,Privacy,Security}
}

@inproceedings{sinha_OverviewMicrosoftAcademic_2015,
  title = {An {{Overview}} of {{Microsoft Academic Service}} ({{MAS}}) and {{Applications}}},
  booktitle = {Proceedings of the 24th {{International Conference}} on {{World Wide Web}}},
  author = {Sinha, Arnab and Shen, Zhihong and Song, Yang and Ma, Hao and Eide, Darrin and Hsu, Bo-June (Paul) and Wang, Kuansan},
  date = {2015-05-18},
  pages = {243--246},
  publisher = {ACM},
  location = {Florence Italy},
  doi = {10.1145/2740908.2742839},
  url = {https://dl.acm.org/doi/10.1145/2740908.2742839},
  urldate = {2021-10-22},
  abstract = {In this paper we describe a new release of a Web scale entity graph that serves as the backbone of Microsoft Academic Service (MAS), a major production effort with a broadened scope to the namesake vertical search engine that has been publicly available since 2008 as a research prototype. At the core of MAS is a heterogeneous entity graph comprised of six types of entities that model the scholarly activities: field of study, author, institution, paper, venue, and event. In addition to obtaining these entities from the publisher feeds as in the previous effort, we in this version include data mining results from the Web index and an in-house knowledge base from Bing, a major commercial search engine. As a result of the Bing integration, the new MAS graph sees significant increase in size, with fresh information streaming in automatically following their discoveries by the search engine. In addition, the rich entity relations included in the knowledge base provide additional signals to disambiguate and enrich the entities within and beyond the academic domain. The number of papers indexed by MAS, for instance, has grown from low tens of millions to 83 million while maintaining an above 95\% accuracy based on test data sets derived from academic activities at Microsoft Research. Based on the data set, we demonstrate two scenarios in this work: a knowledge driven, highly interactive dialog that seamlessly combines reactive search and proactive suggestion experience, and a proactive heterogeneous entity recommendation.},
  eventtitle = {{{WWW}} '15: 24th {{International World Wide Web Conference}}},
  isbn = {978-1-4503-3473-0},
  langid = {english}
}

@inproceedings{siniosoglou_NeuralPotIndustrialHoneypot_2020,
  title = {{{NeuralPot}}: {{An Industrial Honeypot Implementation Based On Deep Neural Networks}}},
  booktitle = {2020 {{IEEE Symposium}} on {{Computers}} and {{Communications}} ({{ISCC}})},
  author = {Siniosoglou, Ilias and Efstathopoulos, Georgios and Pliatsios, Dimitrios and Moscholios, Ioannis D. and Sarigiannidis, Antonios and Sakellari, Georgia and Loukas, Georgios and Sarigiannidis, Panagiotis},
  date = {2020-07},
  pages = {1--7},
  publisher = {IEEE},
  doi = {10.1109/ISCC50000.2020.9219712},
  url = {https://ieeexplore.ieee.org/document/9219712/},
  isbn = {978-1-72818-086-1}
}

@article{siriwardhana_RobustResilientFederated_2022,
  title = {Robust and {{Resilient Federated Learning}} for {{Securing Future Networks}}},
  author = {Siriwardhana, Yushan and Porambage, Pawani and Liyanage, Madhusanka and Ylianttila, Mika},
  date = {2022-06},
  pages = {7},
  abstract = {Machine Learning (ML) and Artificial Intelligence (AI) techniques are widely adopted in the telecommunication industry, especially to automate beyond 5G networks. Federated Learning (FL) recently emerged as a distributed ML approach that enables localized model training to keep data decentralized to ensure data privacy. In this paper, we identify the applicability of FL for securing future networks and its limitations due to the vulnerability to poisoning attacks. First, we investigate the shortcomings of state-of-the-art security algorithms for FL and perform an attack to circumvent FoolsGold algorithm, which is known as one of the most promising defense techniques currently available. The attack is launched with the addition of intelligent noise at the poisonous model updates. Then we propose a more sophisticated defense strategy, a threshold-based clustering mechanism to complement FoolsGold. Moreover, we provide a comprehensive analysis of the impact of the attack scenario and the performance of the defense mechanism.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@report{sivamohan_KHOXAIKrillherd_2022,
  type = {preprint},
  title = {{{KHO-XAI}}: {{Krill}} Herd Optimization and {{Explainable Artificial Intelligence}} Framework for {{Network Intrusion Detection Systems}} in {{Industry}} 4.0},
  shorttitle = {{{KHO-XAI}}},
  author = {Sivamohan, S and Sri, S. S.},
  date = {2022-06-10},
  institution = {In Review},
  doi = {10.21203/rs.3.rs-1683748/v1},
  url = {https://www.researchsquare.com/article/rs-1683748/v1},
  urldate = {2022-07-05},
  abstract = {Industry 4.0 enable novel business cases, such as client-specific production, real-time monitoring of process condition and progress, independent decision making and remote maintenance, to name a few. However, they are more susceptible to a broad range of cyber threats because of limited resources and heterogeneous nature. Such risks cause financial and reputational damages for businesses, well as the theft of sensitive information. The higher level of diversity in industrial network prevents the attackers from such attacks. Therefore, to efficiently detect the intrusions, a novel intrusion detection system known as Bidirectional Long Short-Term Memory based Explainable Artificial Intelligence framework (BiLSTM-XAI) is developed. Initially, the preprocessing task using normalization and standardization is performed to enhance the data quality for detecting network intrusions. Subsequently, the significant features are selected from the databases using the Krill herd optimization (KHO) algorithm. The proposed BiLSTM-XAI approach provides better security and privacy inside the industry networking system by detecting intrusions very precisely. In this, we utilized SHAP and LIME explainable AI algorithms to further improve the prediction accuracy. The experimental setup is made by MATLAB 2016 software using Honeypot and NSL-KDD datasets as input. The analysis result reveals that the proposed method achieves superior performance in detecting intrusions with a classification accuracy of 98.2\%.},
  langid = {english}
}

@inproceedings{sivanathan_CharacterizingclassifyingIoT_2017,
  title = {Characterizing and Classifying {{IoT}} Traffic in Smart Cities and Campuses},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Communications Workshops}} ({{INFOCOM WKSHPS}})},
  author = {Sivanathan, Arunan and Sherratt, Daniel and Gharakheili, Hassan Habibi and Radford, Adam and Wijenayake, Chamith and Vishwanath, Arun and Sivaraman, Vijay},
  date = {2017-05},
  pages = {559--564},
  publisher = {IEEE},
  doi = {10.1109/INFCOMW.2017.8116438},
  url = {http://ieeexplore.ieee.org/document/8116438/},
  abstract = {Campuses and cities of the near future will be equipped with vast numbers of IoT devices. Operators of such environments may not even be fully aware of their IoT assets, let alone whether each IoT device is functioning properly safe from cyber-attacks. This paper proposes the use of network traffic analytics to characterize IoT devices, including their typical behaviour mode. We first collect and synthesize traffic traces from a smart-campus environment instrumented with a diversity of IoT devices including cameras, lights, appliances, and health-monitors; our traces, collected over a period of 3 weeks, are released as open data to the public. We then analyze the traffic traces to characterize statistical attributes such as data rates and burstiness, activity cycles, and signalling patterns, for over 20 IoT devices deployed in our environment. Finally, using these attributes, we develop a classification method that can not only distinguish IoT from non-IoT traffic, but also identify specific IoT devices with over 95\% accuracy. Our study empowers operators of smart cities and campuses to discover and monitor their IoT assets based on their network behaviour.},
  isbn = {978-1-5386-2784-6}
}

@article{sivanathan_ClassifyingIoTDevices_2019,
  title = {Classifying {{IoT Devices}} in {{Smart Environments Using Network Traffic Characteristics}}},
  author = {Sivanathan, Arunan and Gharakheili, Hassan Habibi and Loi, Franco and Radford, Adam and Wijenayake, Chamith and Vishwanath, Arun and Sivaraman, Vijay},
  date = {2019-08-01},
  journaltitle = {IEEE Transactions on Mobile Computing},
  shortjournal = {IEEE Trans. on Mobile Comput.},
  volume = {18},
  number = {8},
  pages = {1745--1759},
  issn = {1536-1233, 1558-0660, 2161-9875},
  doi = {10.1109/TMC.2018.2866249},
  url = {https://ieeexplore.ieee.org/document/8440758/},
  urldate = {2021-05-21},
  abstract = {The Internet of Things (IoT) is being hailed as the next wave revolutionizing our society, and smart homes, enterprises, and cities are increasingly being equipped with a plethora of IoT devices. Yet, operators of such smart environments may not even be fully aware of their IoTassets, let alone whether each IoT device is functioning properly safe from cyber-attacks. In this paper, we address this challenge by developing a robust framework for IoT device classification using traffic characteristics obtained at the network level. Our contributions are fourfold. First, we instrument a smart environment with 28 different IoT devices spanning cameras, lights, plugs, motion sensors, appliances, and health-monitors. We collect and synthesize traffic traces from this infrastructure for a period of six months, a subset of which we release as open data for the community to use. Second, we present insights into the underlying network traffic characteristics using statistical attributes such as activity cycles, port numbers, signalling patterns, and cipher suites. Third, we develop a multi-stage machine learning based classification algorithm and demonstrate its ability to identify specific IoT devices with over 99 percent accuracy based on their network activity. Finally, we discuss the trade-offs between cost, speed, and performance involved in deploying the classification framework in real-time. Our study paves the way for operators of smart environments to monitor their IoT assets for presence, functionality, and cyber-security without requiring any specialized devices or protocols.},
  langid = {english}
}

@article{sivanathan_ManagingIoTCyberSecurity_2020,
  title = {Managing {{IoT Cyber-Security Using Programmable Telemetry}} and {{Machine Learning}}},
  author = {Sivanathan, Arunan and Habibi Gharakheili, Hassan and Sivaraman, Vijay},
  date = {2020-03},
  journaltitle = {IEEE Transactions on Network and Service Management},
  volume = {17},
  number = {1},
  pages = {60--74},
  publisher = {IEEE},
  issn = {1932-4537},
  doi = {10.1109/TNSM.2020.2971213},
  url = {https://ieeexplore.ieee.org/document/8981946/},
  abstract = {Cyber-security risks for Internet of Things (IoT) devices sourced from a diversity of vendors and deployed in large numbers, are growing rapidly. Therefore, management of these devices is becoming increasingly important to network operators. Existing network monitoring technologies perform traffic analysis using specialized acceleration on network switches, or full inspection of packets in software, which can be complex, expensive, inflexible, and unscalable. In this paper, we use SDN paradigm combined with machine learning to leverage the benefits of programmable flow-based telemetry with flexible data-driven models to manage IoT devices based on their network activity. Our contributions are three-fold: (1) We analyze traffic traces of 17 real consumer IoT devices collected in our lab over a six-month period and identify a set of traffic flows (per-device) whose time-series attributes computed at multiple timescales (from a minute to an hour) characterize the network behavior of various IoT device types, and their operating states (i.e., booting, actively interacted with user, or being idle); (2) We develop a multi-stage architecture of inference models that use flow-level attributes to automatically distinguish IoT devices from non-IoTs, classify individual types of IoT devices, and identify their states during normal operations. We train our models and validate their efficacy using real traffic traces; and (3) We quantify the trade-off between performance and cost of our solution, and demonstrate how our monitoring scheme can be used in operation for detecting behavioral changes (firmware upgrade or cyber attacks).}
}

@inproceedings{sklyar_ENISADocumentsCybersecurity_2019,
  title = {{{ENISA Documents}} in {{Cybersecurity Assurance}} for {{Industry}} 4.0: {{IIoT Threats}} and {{Attacks Scenarios}}},
  booktitle = {2019 10th {{IEEE International Conference}} on {{Intelligent Data Acquisition}} and {{Advanced Computing Systems}}: {{Technology}} and {{Applications}} ({{IDAACS}})},
  author = {Sklyar, Vladimir and Kharchenko, Vyacheslav},
  date = {2019-09},
  volume = {2},
  pages = {1046--1049},
  publisher = {IEEE},
  doi = {10.1109/IDAACS.2019.8924452},
  url = {https://ieeexplore.ieee.org/document/8924452/},
  abstract = {The paper is devoted to analysis of a set of the European Union Agency for Network and Information Security (ENISA) documents in area of IoT security. Industrial IoT (IIoT) characteristics are studied for differences between IIoT and IoT, IIoT asset taxonomy and IIoT security challenges. After that ENISA IoT/IIoT Security Framework has been formed on the base of semantic details of the six studied ENISA documents. Additional attention is paid to IIoT treats taxonomy and attacks scenarios.},
  isbn = {978-1-72814-069-8}
}

@article{skopik_problemsharedproblem_2016,
  title = {A Problem Shared Is a Problem Halved: {{A}} Survey on the Dimensions of Collective Cyber Defense through Security Information Sharing},
  author = {Skopik, Florian and Settanni, Giuseppe and Fiedler, Roman},
  date = {2016},
  journaltitle = {Computers \& Security},
  volume = {60},
  pages = {154--176},
  publisher = {Elsevier Ltd},
  issn = {01674048},
  doi = {10.1016/j.cose.2016.04.003},
  abstract = {The Internet threat landscape is fundamentally changing. A major shift away from hobby hacking toward well-organized cyber crime can be observed. These attacks are typically carried out for commercial reasons in a sophisticated and targeted manner, and specifically in a way to circumvent common security measures. Additionally, networks have grown to a scale and complexity, and have reached a degree of interconnectedness, that their protection can often only be guaranteed and financed as shared efforts. Consequently, new paradigms are required for detecting contemporary attacks and mitigating their effects. Today, many attack detection tasks are performed within individual organizations, and there is little cross-organizational information sharing. However, information sharing is a crucial step to acquiring a thorough understanding of large-scale cyber-attack situations, and is therefore seen as one of the key concepts to protect future networks. Discovering covert cyber attacks and new malware, issuing early warnings, advice about how to secure networks, and selectively distribute threat intelligence data are just some of the many use cases. In this survey article we provide a structured overview about the dimensions of cyber security information sharing. First, we motivate the need in more detail and work out the requirements for an information sharing system. Second, we highlight legal aspects and efforts from standardization bodies such as ISO and the National Institute of Standards and Technology (NIST). Third, we survey implementations in terms of both organizational and technological matters. In this regard, we study the structures of Computer Emergency Response Teams (CERTs) and Computer Security Incident Response Teams (CSIRTs), and evaluate what we could learn from them in terms of applied processes, available protocols and implemented tools. We conclude with a critical review of the state of the art and highlight important considerations when building effective security information sharing platforms for the future.}
}

@inproceedings{slevi_surveyDeepLearning_2021,
  title = {A Survey on {{Deep Learning}} Based {{Intrusion Detection Systems}} on {{Internet}} of {{Things}}},
  booktitle = {2021 {{Fifth International Conference}} on {{I-SMAC}} ({{IoT}} in {{Social}}, {{Mobile}}, {{Analytics}} and {{Cloud}}) ({{I-SMAC}})},
  author = {Slevi, S. Tamil and Visalakshi, P.},
  date = {2021-11-11},
  pages = {1488--1496},
  publisher = {IEEE},
  location = {Palladam, India},
  doi = {10/gpbg3p},
  url = {https://ieeexplore.ieee.org/document/9641050/},
  urldate = {2022-01-31},
  abstract = {The integration of IDS and Internet of Things (IoT) with deep learning plays a significant role in safety. S ecurity has a strong role to play. Application of the IoT network decreases the time complexity and resources. In the traditional intrusion detection systems (IDS ), this research work implements the cutting-edge methodologies in the IoT environment. This research is based on analysis, conception, testing and execution. Detection of intrusio ns can be performed by using the advanced deep learning system and multiagent. The NS L-KDD dataset is used to test the IoT system. The IoT system is used to test the IoT system. In order to detect attacks from intruders of transport layer, efficiency result rely on advanced deep learning idea. In order to increase the system performance, multi -agent algorithms could be employed to train communications agencies and to optimize the feedback training process. Advanced deep learning techniques such as CNN will be researched to boost system performance. The testing part an IoT includes data simulator which will be used to generate in continuous of research work finding with deep learning algorithms of suitable IDS in IoT network environment of current scenario wi thout time complexity.},
  eventtitle = {2021 {{Fifth International Conference}} on {{I-SMAC}} ({{IoT}} in {{Social}}, {{Mobile}}, {{Analytics}} and {{Cloud}}) ({{I-SMAC}})},
  isbn = {978-1-66542-642-8},
  langid = {english},
  keywords = {+survey}
}

@inproceedings{snapp_DIDSdistributedintrusion_1992,
  title = {The {{DIDS}} (Distributed Intrusion Detection System) Prototype},
  booktitle = {{{USENIX}} Summer 1992 Technical Conference ({{USENIX}} Summer 1992 Technical Conference)},
  author = {Snapp, Steven R. and Smaha, Stephen E. and Teal, Daniel M. and Grance, Tim},
  date = {1992-06},
  publisher = {USENIX Association},
  location = {San Antonio, TX},
  url = {https://www.usenix.org/conference/usenix-summer-1992-technical-conference/dids-distributed-intrusion-detection-system}
}

@inproceedings{sommer_OutsideClosedWorld_2010,
  title = {Outside the {{Closed World}}: {{On Using Machine Learning}} for {{Network Intrusion Detection}}},
  booktitle = {2010 {{IEEE Symposium}} on {{Security}} and {{Privacy}}},
  author = {Sommer, Robin and Paxson, Vern},
  date = {2010},
  pages = {305--316},
  publisher = {IEEE},
  issn = {10816011},
  doi = {10.1109/SP.2010.25},
  url = {http://ieeexplore.ieee.org/document/5504793/},
  abstract = {In network intrusion detection research, one popular strategy for finding attacks is monitoring a network's activity for anomalies: deviations from profiles of normality previously learned from benign traffic, typically identified using tools borrowed from the machine learning community. However, despite extensive academic research one finds a striking gap in terms of actual deployments of such systems: compared with other intrusion detection approaches, machine learning is rarely employed in operational "real world" settings. We examine the differences between the network intrusion detection problem and other areas where machine learning regularly finds much more success. Our main claim is that the task of finding attacks is fundamentally different from these other applications, making it significantly harder for the intrusion detection community to employ machine learning effectively. We support this claim by identifying challenges particular to network intrusion detection, and provide a set of guidelines meant to strengthen future research on anomaly detection. \copyright{} 2010 IEEE.},
  isbn = {978-1-4244-6894-2},
  keywords = {\_read\_urgently}
}

@article{song_Intrusiondetectionmodel_2023,
  title = {Intrusion Detection Model Using Gene Expression Programming to Optimize Parameters of Convolutional Neural Network for Energy Internet},
  author = {Song, Deng and Yuan, Xinya and Li, Qianliang and Zhang, Jie and Sun, Mengfei and Fu, Xiong and Yang, Lechan},
  date = {2023-02-01},
  journaltitle = {Applied Soft Computing},
  shortjournal = {Applied Soft Computing},
  volume = {134},
  pages = {109960},
  issn = {1568-4946},
  doi = {10.1016/j.asoc.2022.109960},
  url = {https://www.sciencedirect.com/science/article/pii/S1568494622010092},
  urldate = {2023-01-09},
  abstract = {The open, interconnected, and shared operational characteristics of the energy Internet introduce more sophisticated cybersecurity attacks. How to accurately detect these cyber attacks is crucial for energy Internet security protection. Existing machine learning-based intrusion detection algorithms cannot cope with the continuous increase of network traffic and features in the energy Internet. And convolutional neural networks (CNN) can be a good solution for the descending and optimal selection of high-dimensional intrusion features. Unfortunately, traditional convolutional neural networks have complex structures with many parameters and are prone to fall into local optimality. To fill the gap of CNN, in this paper, we use a gene expression programming (GEP) to optimize the parameters of CNN and propose an intrusion detection algorithm based on GEP-CNN (GCNN-IDS). Our key idea is to avoid the convolutional neural network from falling into local optimum by designing a new code on GEP and fitness function to optimize the parameters of the CNN using the global search capability of GEP. The experimental results on two benchmark datasets and a real dataset substantiate that the detection accuracy of the optimized CNN-based intrusion detection algorithm (ICNN-IDS) reaches up to 0.9143 under different parameter combinations; meanwhile, compared with other algorithms, the detection accuracy, precision, recall, F1 and false detection rate of the intrusion detection model proposed in this paper reach 0.9897, 0.99, 0.98, 0.97 and 0.0126, respectively.},
  langid = {english},
  keywords = {Convolutional neural network,Gene expression programming,Intrusion detection,Parameter optimization}
}

@inproceedings{song_ProfitAllocationFederated_2019,
  title = {Profit {{Allocation}} for {{Federated Learning}}},
  booktitle = {2019 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  author = {Song, Tianshu and Tong, Yongxin and Wei, Shuyue},
  date = {2019-12},
  pages = {2577--2586},
  doi = {10.1109/BigData47090.2019.9006327},
  abstract = {Due to stricter data management regulations such as General Data Protection Regulation (GDPR), traditional production mode of machine learning services is shifting to federated learning, a paradigm that allows multiple data providers to train a joint model collaboratively with their data kept locally. A key enabler for practical adoption of federated learning is how to allocate the prolit earned by the joint model to each data provider. For fair prolit allocation, a metric to quantify the contribution of each data provider to the joint model is essential. Shapley value is a classical concept in cooperative game theory which assigns a unique distribution (among the players) of a total surplus generated by the coalition of all players and has been used for data valuation in machine learning services. However, prior Shapley value based data valuation schemes either do not apply to federated learning or involve extra model training which leads to high cost. In this paper, given n data providers with data sets D1, D2, {$\cdots$}, Dn, a federated learning algorithm A and a standard test set T, we propose the contribution index, a new Shapley value based metric lit for assessing the contribution of each data provider for the joint model trained by federated learning. The contribution index shares the same properties as Shapley value. However, direct calculation of the contribution index is time consuming, since a large number of joint models with different combinations of data sets are required to be trained and evaluated. To solve this problem, we propose two gradient based methods. The idea is to reconstruct approximately the models on different combinations of the data sets through the intermediate results of the training process of federated learning so as to avoid extra training. The lirst method reconstructs models by updating the initial global model in federated learning with the gradients in different rounds. Then it calculates the contribution index by the performance of these reconstructed models. The second method calculates contribution index in each round by updating the global model in the previous round with the gradients in the current round. Contribution indexes of multiple rounds are then added with elaborated weights to get the linal result. We conduct extensive experiments on the MNIST data set in different settings. The results demonstrate that the proposed methods can approximate the exact contribution index effectively and achieve a time speed up of up to 2x-100x compared with the exact calculation and other baselines extended from existing work.},
  eventtitle = {2019 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  keywords = {Data models,Federated Learning,Google,Incentive Mechanism,Indexes,Machine learning,Servers,Shapley Value,Task analysis,Training}
}

@article{song_ReputationBasedFederatedLearning_2022,
  title = {Reputation-{{Based Federated Learning}} for {{Secure Wireless Networks}}},
  author = {Song, Zhendong and Sun, Hongguang and Yang, Howard H. and Wang, Xijun and Zhang, Yan and Quek, Tony Q. S.},
  date = {2022-01},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {9},
  number = {2},
  pages = {1212--1226},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2021.3079104},
  abstract = {The dilemma between the ever-increasing demands for data processing, and the limited capabilities of mobile devices in a wireless communication system calls for the appearance of federated learning (FL). As a distributed machine learning (ML) method, FL executes in an iterative manner by distributing the global model parameters and aggregating the local model parameters, which avoids the transmission of huge raw data and preserves data privacy during the training process. However, since FL cannot control the local training and transmission process, this gives malicious users the opportunity to deteriorate the global aggregation. We adopt a reputation model based on beta distribution function to measure the credibility of local users, and propose a reputation-based scheduling policy with user fairness constraint. By taking into account the impact of wireless channel conditions and malicious attack features, we derive tractable expressions for the convergence rate of FL in a wireless setting. Moreover, we validate the superiority of the proposed reputation-based scheduling policy via numerical analysis and empirical simulations. The results show that the proposed secure wireless FL framework can not only distinguish malicious users from normal users but also effectively defend against several typical attack types featured in attack intensity and attack frequency. The analysis also reveals that the effect of average attack intensity on the convergence performance of FL is dominated by the percentage of malicious user equipments (UEs), and imposes even greater negative effect on the convergence performance of FL as the percentage of malicious UEs increases.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {Communication system security,Convergence,Convergence analysis,Data models,federated learning (FL),malicious users,Reliability,reputation-based scheduling policy,Scheduling,secure wireless networks,Training,Wireless networks}
}

@article{soule_OrganisationSystemesMultiAgents_[review],
  title = {De l'Organisation des Syst\`emes Multi-Agents de Cyber-defense},
  author = {Soul\'e, Julien and Th\'eron, Paul and Jamont, Jean-Paul and Occello, Michel and Traonouez, Louis-Marie},
  year = {[review]},
  langid = {french},
  keywords = {\_done,\_unpublished,â›” No DOI found}
}

@article{staudemeyer_Applyinglongshortterm_2015,
  title = {Applying Long Short-Term Memory Recurrent Neural Networks to Intrusion Detection},
  author = {Staudemeyer, Ralf C.},
  date = {2015-07-11},
  journaltitle = {South African Computer Journal},
  shortjournal = {SACJ},
  volume = {56},
  issn = {2313-7835, 1015-7999},
  doi = {10.18489/sacj.v56i1.248},
  url = {https://sacj.cs.uct.ac.za/index.php/sacj/article/view/248},
  urldate = {2021-10-13},
  abstract = {We claim that modelling network traffic as a time series with a supervised learning approach, using known genuine and malicious behaviour, improves intrusion detection. To substantiate this, we trained long short-term memory (LSTM) recurrent neural networks with the training data provided by the DARPA / KDD Cup '99 challenge. To identify suitable LSTM-RNN network parameters and structure we experimented with various network topologies. We found networks with four memory blocks containing two cells each offer a good compromise between computational cost and detection performance. We applied forget gates and shortcut connections respectively. A learning rate of 0.1 and up to 1,000 epochs showed good results.},
  langid = {english}
}

@inproceedings{steinhardt_CertifiedDefensesData_2017,
  title = {Certified {{Defenses}} for {{Data Poisoning Attacks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Steinhardt, Jacob and Koh, Pang Wei W and Liang, Percy S},
  date = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2017/hash/9d7311ba459f9e45ed746755a32dcd11-Abstract.html},
  urldate = {2024-03-06},
  abstract = {Machine learning systems trained on user-provided data are susceptible to data poisoning attacks, whereby malicious users inject false training data with the aim of corrupting the learned model. While recent work has proposed a number of attacks and defenses, little is understood about the worst-case loss of a defense in the face of a determined attacker. We address this by constructing approximate upper bounds on the loss across a broad family  of attacks, for defenders that first perform outlier removal followed by empirical risk minimization. Our approximation relies on two assumptions: (1) that the dataset is large enough for  statistical concentration between train and test error to hold, and (2) that outliers  within the clean (non-poisoned) data do not have a strong effect on the model. Our bound comes paired with a candidate attack that often nearly matches the upper bound, giving us a powerful tool for quickly assessing defenses on a given dataset. Empirically, we find that even under a simple defense, the MNIST-1-7 and Dogfish datasets are resilient to attack, while in contrast the IMDB sentiment dataset can be driven from 12\% to 23\% test error by adding only 3\% poisoned data.}
}

@inproceedings{sterritt_AutonomousAutonomicSystems_2009,
  title = {Autonomous and {{Autonomic Systems}}: {{Paradigm}} for {{Engineering Effective Software-Based Systems}}?},
  booktitle = {2009 33rd {{Annual IEEE Software Engineering Workshop}}},
  author = {Sterritt, Roy},
  date = {2009-10},
  pages = {57--57},
  publisher = {IEEE},
  doi = {10.1109/SEW.2009.22},
  url = {http://ieeexplore.ieee.org/document/5621784/},
  abstract = {The Autonomous and Autonomic Systems initiative has as its vision the creation of self-directed and self-managing systems to address today's concerns of complexity and total cost of ownership while meeting tomorrow's needs for pervasive and ubiquitous software-based computation and communication. The future of computing and communications is being researched under many areas, including cloud, grid, utility, pervasive, ubiquitous, invisible, world, ambient, paint and so forth. The driving force behind these future paradigms of computer-based systems is the increasing convergence between proliferation of devices, wireless networking, and mobile software. Weiser first described what has become known as ubiquitous computing as the move away from the \&amp;\#x201C;dramatic\&amp;\#x201D; machine, where hardware and software's focus was on being so exciting that we as users would not want to be without it, towards making the machine \&amp;\#x201C;invisible\&amp;\#x201D;, so embedded in our lives it is used without thinking or recognising it as computing. Behind these different terms and research areas, lie three key properties: nomadic, embedded and invisible. In effect, leading to, the creation of a single system with (potentially) billions of networked information devices and resulting in a Complexity Quagmire? As such, the case can be made that all of the next generation paradigms, in one form or another, will require an autonomic-self-managing-infrastructure to be able to provide the successful reality of this envisaged level of pervasiveness, invisibility and mobility. This keynote talk reports on research and development, with examples from Biometric Identification and Tracking Systems, Autonomic Communications, and Space Exploration Systems, utilizing the biological metaphor of the autonomic nervous system to computing and communications, in which computer-based systems self-regulate by using automatic reactions to defend, optimize and heal.},
  isbn = {978-1-4244-6863-8}
}

@inproceedings{stolfo_Costbasedmodelingfraud_2000,
  title = {Cost-Based Modeling for Fraud and Intrusion Detection: Results from the {{JAM}} Project},
  shorttitle = {Cost-Based Modeling for Fraud and Intrusion Detection},
  booktitle = {Proceedings {{DARPA Information Survivability Conference}} and {{Exposition}}. {{DISCEX}}'00},
  author = {Stolfo, S.J. and Fan, Wei and Lee, Wenke and Prodromidis, A. and Chan, P.K.},
  date = {2000-01},
  volume = {2},
  pages = {130-144 vol.2},
  doi = {10.1109/DISCEX.2000.821515},
  url = {https://ieeexplore.ieee.org/document/821515},
  urldate = {2024-06-20},
  abstract = {We describe the results achieved using the JAM distributed data mining system for the real world problem of fraud detection in financial information systems. For this domain we provide clear evidence that state-of-the-art commercial fraud detection systems can be substantially improved in stopping losses due to fraud by combining multiple models of fraudulent transaction shared among banks. We demonstrate that the traditional statistical metrics used to train and evaluate the performance of learning systems (ie. statistical accuracy or ROC analysis) are misleading and perhaps inappropriate for this application. Cost-based metrics are more relevant in certain domains, and defining such metrics poses significant and interesting research questions both in evaluating systems and alternative models, and in formalizing the problems to which one may wish to apply data mining technologies. This paper also demonstrates how the techniques developed for fraud detection can be generalized and applied to the important area of intrusion detection in networked information systems. We report the outcome of recent evaluations of our system applied to tcpdump network intrusion data specifically with respect to statistical accuracy. This work involved building additional components of JAM that we have come to call, MADAM ID (Mining Audit Data for Automated Models for Intrusion Detection). However, taking the next step to define cost-based models for intrusion detection poses interesting new research questions. We describe our initial ideas about how to evaluate intrusion detection systems using cost models learned during our work on fraud detection.},
  eventtitle = {Proceedings {{DARPA Information Survivability Conference}} and {{Exposition}}. {{DISCEX}}'00},
  keywords = {Computer science,Cost accounting,Data mining,Ear,Electrical capacitance tomography,Identity-based encryption,Intrusion detection,Java,Statistical analysis,Statistics}
}

@report{strom_MITREATTCK_2020,
  title = {{{MITRE ATT}}\textbackslash\&{{CK}}\textregistered : {{Design}} and {{Philosophy}}},
  author = {Strom, Blake E. and Applebaum, Andy and Miller, Doug P. and Nickels, Kathryn C. and Pennington, Adam G. and Thomas, Cody B.},
  date = {2020-03},
  number = {10AOH08A-JC},
  url = {https://attack.mitre.org/docs/ATTACK_Design_and_Philosophy_March_2020.pdf},
  urldate = {2022-07-07},
  abstract = {MITRE ATT\textbackslash\&CK is a globally-accessible knowledge base of adversary tactics and techniques based on real-world observations. The ATT\textbackslash\&CK knowledge base is used as a foundation for the development of specific threat models and methodologies in the private sector, in government, and in the cybersecurity product and service community. ATT\textbackslash\&CK provides a common taxonomy for both offense and defense, and has become a useful conceptual tool across many cyber security disciplines to convey threat intelligence, perform testing through red teaming or adversary emulation, and improve network and system defenses against intrusions. The process MITRE used to create ATT\textbackslash\&CK, and the philosophy that has developed for curating new content, are critical aspects of the work and are useful for other efforts that strive to create similar adversary models and information repositories.}
}

@article{su_APFedAdaptivepersonalized_2024,
  title = {{{APFed}}: {{Adaptive}} Personalized Federated Learning for Intrusion Detection in Maritime Meteorological Sensor Networks},
  shorttitle = {{{APFed}}},
  author = {Su, Xin and Zhang, Guifu},
  date = {2024-02-09},
  journaltitle = {Digital Communications and Networks},
  shortjournal = {Digital Communications and Networks},
  issn = {2352-8648},
  doi = {10.1016/j.dcan.2024.02.001},
  url = {https://www.sciencedirect.com/science/article/pii/S2352864824000191},
  urldate = {2024-04-12},
  abstract = {With the rapid development of advanced networking and computing technologies such as the Internet of Things, network function virtualization, and 5G infrastructure, new development opportunities are emerging for Maritime Meteorological Sensor Networks (MMSNs). However, the increasing number of intelligent devices joining the MMSN poses a growing threat to network security. Current Artificial Intelligence (AI) intrusion detection techniques turn intrusion detection into a classification problem, where AI excels. These techniques assume sufficient high-quality instances for model construction, which is often unsatisfactory for real-world operation with limited attack instances and constantly evolving characteristics. This paper proposes an Adaptive Personalized Federated learning (APFed) framework that allows multiple MMSN owners to engage in collaborative training. By employing an adaptive personalized update and a shared global classifier, the adverse effects of imbalanced, Non-Independent and Identically Distributed (Non-IID) data are mitigated, enabling the intrusion detection model to possess personalized capabilities and good global generalization. In addition, a lightweight intrusion detection model is proposed to detect various attacks with an effective adaptation to the MMSN environment. Finally, extensive experiments on a classical network dataset show that the attack classification accuracy is improved by about 5\% compared to most baselines in the global scenarios.},
  keywords = {Deep learning,Federated learning,Intrusion detection,Maritime meteorological sensor network,Personalized model}
}

@inproceedings{su_DetectionDDoSAttacks_2022,
  title = {Detection {{DDoS}} of~{{Attacks Based}} on~{{Federated Learning}} with~{{Digital Twin Network}}},
  booktitle = {Knowledge {{Science}}, {{Engineering}} and {{Management}}},
  author = {Su, Dingling and Qu, Zehui},
  editor = {Memmi, Gerard and Yang, Baijian and Kong, Linghe and Zhang, Tianwei and Qiu, Meikang},
  date = {2022},
  pages = {153--164},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-10989-8_13},
  abstract = {With Intrusion detection algorithms based on deep learning becoming a hot research topic, most studies pay attention to improving detection accuracy but ignore the problem that can not train a high-precision model due to the limited data of each client. This paper proposes an intrusion detection method based on federated learning and the LSTM model to protect the privacy and improve the classification effect in limited data. As a result of the experiments carried out on the KDD CUP 1999 dataset containing the current DDoS attack types, it was observed that the attacks on network traffic were detected with up to 99.17\% success. Furthermore, the federated learning model was constructed in the Digital Twin Network (DTN), an emerging network that utilizes digital twin (DT) technology to create the virtual twins of physical objects. It can real-time monitor the status of physical entities and feedback information to entities in time. Meanwhile, we propose a new optimization framework based on FedProx to tackle the system and statistical heterogeneity inherent in federated networks. This framework shows significantly more stable and accurate convergence behaviour and higher detection accuracy than FedProx and FedAvg.},
  isbn = {978-3-031-10989-8},
  langid = {english}
}

@unpublished{sun_AdaptiveFederatedLearning_2020,
  title = {Adaptive {{Federated Learning}} and {{Digital Twin}} for {{Industrial Internet}} of {{Things}}},
  author = {Sun, Wen and Lei, Shiyu and Wang, Lu and Liu, Zhiqiang and Zhang, Yan},
  date = {2020-10-31},
  eprint = {2010.13058},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2010.13058},
  urldate = {2021-10-04},
  abstract = {Industrial Internet of Things (IoT) enables distributed intelligent services varying with the dynamic and realtime industrial environment to achieve Industry 4.0 benefits. In this paper, we consider a new architecture of digital twin empowered Industrial IoT where digital twins capture the characteristics of industrial devices to assist federated learning. Noticing that digital twins may bring estimation deviations from the actual value of device state, a trusted based aggregation is proposed in federated learning to alleviate the effects of such deviation. We adaptively adjust the aggregation frequency of federated learning based on Lyapunov dynamic deficit queue and deep reinforcement learning, to improve the learning performance under the resource constraints. To further adapt to the heterogeneity of Industrial IoT, a clustering-based asynchronous federated learning framework is proposed. Numerical results show that the proposed framework is superior to the benchmark in terms of learning accuracy, convergence, and energy saving.},
  langid = {english},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},\_processed,â›” No DOI found,Computer Science - Machine Learning}
}

@article{sun_AdaptiveIntrusionDetection_2021,
  title = {Adaptive {{Intrusion Detection}} in the {{Networking}} of {{Large-Scale LANs With Segmented Federated Learning}}},
  author = {Sun, Yuwei and Esaki, Hiroshi and Ochiai, Hideya},
  date = {2021},
  journaltitle = {IEEE Open Journal of the Communications Society},
  shortjournal = {IEEE Open J. Commun. Soc.},
  volume = {2},
  pages = {102--112},
  issn = {2644-125X},
  doi = {10.1109/OJCOMS.2020.3044323},
  url = {https://ieeexplore.ieee.org/document/9296578/},
  urldate = {2021-10-04},
  abstract = {Predominant network intrusion detection systems (NIDS) aim to identify malicious traffic patterns based on a handcrafted dataset of rules. Recently, the application of machine learning in NIDS helps alleviate the enormous effort of human observation. Federated learning (FL) is a collaborative learning scheme concerning distributed data. Instead of sharing raw data, it allows a participant to share only a trained local model. Despite the success of existing FL solutions, in NIDS, a network's traffic data distribution does not always fit into the single global model of FL; some networks have similarities with each other but other networks do not. We propose Segmented-Federated Learning (Segmented-FL), where by employing periodic local model evaluation and network segmentation, we aim to bring similar network environments to the same group. A comparison between FL and our method was conducted against a range of metrics including the weighted precision, recall, and F1 score, using a collected dataset from 20 massively distributed networks within 60 days. By studying the optimized hyperparameters of Segmented-FL and employing three evaluation methods, it shows that Segmented-FL has better performance in all three types of intrusion detection tasks, achieving validation weighted F1 scores of 0.964, 0.803, and 0.912 with Method A, Method B, and Method C respectively. For each method, this scheme shows a gain of 0.1\%, 4.0\% and 1.1\% in performance compared with FL.},
  langid = {english},
  keywords = {survey-fids}
}

@online{sun_CanYouReally_2019,
  title = {Can {{You Really Backdoor Federated Learning}}?},
  author = {Sun, Ziteng and Kairouz, Peter and Suresh, Ananda Theertha and McMahan, H. Brendan},
  date = {2019-12-02},
  eprint = {1911.07963},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1911.07963},
  urldate = {2023-11-02},
  abstract = {The decentralized nature of federated learning makes detecting and defending against adversarial attacks a challenging task. This paper focuses on backdoor attacks in the federated learning setting, where the goal of the adversary is to reduce the performance of the model on targeted tasks while maintaining a good performance on the main task. Unlike existing works, we allow non-malicious clients to have correctly labeled samples from the targeted tasks. We conduct a comprehensive study of backdoor attacks and defenses for the EMNIST dataset, a real-life, user-partitioned, and non-iid dataset. We observe that in the absence of defenses, the performance of the attack largely depends on the fraction of adversaries present and the ``complexity'' of the targeted task. Moreover, we show that norm clipping and ``weak'' differential privacy mitigate the attacks without hurting the overall performance. We have implemented the attacks and defenses in TensorFlow Federated (TFF), a TensorFlow framework for federated learning. In open sourcing our code, our goal is to encourage researchers to contribute new attacks and defenses and evaluate them on standard federated datasets.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{sun_DataPoisoningAttacks_2022,
  title = {Data {{Poisoning Attacks}} on {{Federated Machine Learning}}},
  author = {Sun, Gan and Cong, Yang and Dong, Jiahua and Wang, Qiang and Lyu, Lingjuan and Liu, Ji},
  date = {2022-07},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {9},
  number = {13},
  pages = {11365--11375},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2021.3128646},
  url = {https://ieeexplore.ieee.org/abstract/document/9618642},
  urldate = {2023-12-06},
  abstract = {Federated machine learning which enables resource-constrained node devices (e.g., Internet of Things (IoT) devices and smartphones) to establish a knowledge-shared model while keeping the raw data local, could provide privacy preservation, and economic benefit by designing an effective communication protocol. However, this communication protocol can be adopted by attackers to launch data poisoning attacks for different nodes, which has been shown as a big threat to most machine learning models. Therefore, we in this article intend to study the model vulnerability of federated machine learning, and even on IoT systems. To be specific, we here attempt to attacking a popular federated multitask learning framework, which uses a general multitask learning framework to handle statistical challenges in the federated learning setting. The problem of calculating optimal poisoning attacks on federated multitask learning is formulated as a bilevel program, which is adaptive to the arbitrary selection of target nodes and source attacking nodes. We then propose a novel systems-aware optimization method, called as attack on federated learning (AT2FL), to efficiently derive the implicit gradients for poisoned data, and further attain optimal attack strategies in the federated machine learning. This is an earlier work, to our knowledge, that explores attacking federated machine learning via data poisoning. Finally, experiments on several real-world data sets demonstrate that when the attackers directly poison the target nodes or indirectly poison the related nodes via using the communication protocol, the federated multitask learning model is sensitive to both poisoning attacks.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}}
}

@online{sun_DPAUCDifferentiallyPrivate_2022,
  title = {{{DPAUC}}: {{Differentially Private AUC Computation}} in {{Federated Learning}}},
  shorttitle = {{{DPAUC}}},
  author = {Sun, Jiankai and Yang, Xin and Yao, Yuanshun and Xie, Junyuan and Wu, Di and Wang, Chong},
  date = {2022-08-25},
  eprint = {2208.12294},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2208.12294},
  urldate = {2022-09-05},
  abstract = {Federated learning (FL) has gained significant attention recently as a privacyenhancing tool to jointly train a machine learning model by multiple participants. The prior work on FL has mostly studied how to protect label privacy during model training. However, model evaluation in FL might also lead to potential leakage of private label information. In this work, we propose an evaluation algorithm that can accurately compute the widely used AUC (area under the curve) metric when using the label differential privacy (DP) in FL. Through extensive experiments, we show our algorithms can compute accurate AUCs compared to the ground truth.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@online{sun_DPAUCDifferentiallyPrivate_2022a,
  title = {{{DPAUC}}: {{Differentially Private AUC Computation}} in {{Federated Learning}}},
  shorttitle = {{{DPAUC}}},
  author = {Sun, Jiankai and Yang, Xin and Yao, Yuanshun and Xie, Junyuan and Wu, Di and Wang, Chong},
  date = {2022-08-25},
  eprint = {2208.12294},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2208.12294},
  urldate = {2022-09-05},
  abstract = {Federated learning (FL) has gained significant attention recently as a privacyenhancing tool to jointly train a machine learning model by multiple participants. The prior work on FL has mostly studied how to protect label privacy during model training. However, model evaluation in FL might also lead to potential leakage of private label information. In this work, we propose an evaluation algorithm that can accurately compute the widely used AUC (area under the curve) metric when using the label differential privacy (DP) in FL. Through extensive experiments, we show our algorithms can compute accurate AUCs compared to the ground truth.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@article{sun_FedSEASemiAsynchronousFederated_2022,
  title = {{{FedSEA}}: {{A Semi-Asynchronous Federated Learning Framework}} for {{Extremely Heterogeneous Devices}}},
  author = {Sun, Jingwei and Li, Ang and Duan, Lin and Alam, Samiul and Deng, Xuliang and Guo, Xin and Wang, Haiming and Gorlatova, Maria and Zhang, Mi and Li, Hai and Chen, Yiran},
  date = {2022},
  abstract = {Federated learning (FL) has attracted increasing attention as a promising technique to drive a vast number of edge devices with artificial intelligence. However, it is very challenging to guarantee the efficiency of a FL system in practice due to the heterogeneous computation resources on different devices. To improve the efficiency of FL systems in the real world, asynchronous FL (AFL) and semiasynchronous FL (SAFL) methods are proposed such that the server does not need to wait for stragglers. However, existing AFL and SAFL systems suffer from poor accuracy and low efficiency in realistic settings where the data is non-IID distributed across devices and the on-device resources are extremely heterogeneous. In this work, we propose FedSEA -- a semi-asynchronous FL framework for extremely heterogeneous devices. We theoretically disclose that the unbalanced aggregation frequency is a root cause of accuracy drop in SAFL. Based on this analysis, we design a training configuration scheduler to balance the aggregation frequency of devices such that the accuracy can be improved. To improve the efficiency of the system in realistic settings where the devices have dynamic on-device resource availability, we design a scheduler that can efficiently predict the arriving time of local updates from devices and adjust the synchronization time point according to the devices' predicted arriving time. We also consider the extremely heterogeneous settings where there exist extremely lagging devices that take hundreds of times as long as the training time of the other devices. In the real world, there might be even some extreme stragglers which are not capable of training the global model. To enable these devices to join in training without impairing the systematic efficiency, FedSEA enables these extreme stragglers to conduct local training on much smaller models. Our experiments show that compared with status quo approaches, FedSEA improves the inference accuracy by 44.34\% and reduces the systematic time cost and local training time cost by 87.02\texttimes{} and 792.9\texttimes. FedSEA also reduces the energy consumption of the devices with extremely limited resources by 752.9\texttimes.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@inproceedings{sun_IntrusionDetectionSegmented_2020,
  title = {Intrusion {{Detection}} with {{Segmented Federated Learning}} for {{Large-Scale Multiple LANs}}},
  booktitle = {2020 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Sun, Yuwei and Ochiai, Hideya and Esaki, Hiroshi},
  date = {2020-07},
  pages = {1--8},
  publisher = {IEEE},
  location = {Glasgow, United Kingdom},
  doi = {10.1109/IJCNN48605.2020.9207094},
  url = {https://ieeexplore.ieee.org/document/9207094/},
  urldate = {2021-10-01},
  abstract = {Traditional approaches to cybersecurity issues usually protect users from attacks after the occurrence of specific types of attacks. Besides, patterns of recent cyberattacks tend to be changeable, which add up to unpredictability of them. On the other hand, machine learning, as a new method used to detect intrusion, is attracting more and more attention. Moreover, through the sharing of local training data, the centralized learning approach has proven to improve a model's performance. In this research, a segmented federated learning is proposed, different from a collaborative learning based on single global model in a traditional federated learning model, it keeps multiple global models which allow each segment of participants to conduct collaborative learning separately and rearranges the segmentation of participants dynamically as well. Furthermore, these multiple global models interact with each other for updating parameters, thus being adaptable to various participants' LANs. A dataset covering two months' traffic data from 20 participants' LANs in the LAN-Security Monitoring Project is used. We adopt three types of knowledgebased methods for labeling network events and train a CNN model based on the dataset. At last, we achieve validation accuracies of 0.923, 0.813 and 0.877 individually with these labeling methods.},
  eventtitle = {2020 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  isbn = {978-1-72816-926-2},
  langid = {english},
  keywords = {survey-fids}
}

@inproceedings{sun_IntrusionDetectionSegmented_2020a,
  title = {Intrusion {{Detection}} with {{Segmented Federated Learning}} for {{Large-Scale Multiple LANs}}},
  booktitle = {2020 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Sun, Yuwei and Ochiai, Hideya and Esaki, Hiroshi},
  date = {2020-07},
  pages = {1--8},
  issn = {2161-4407},
  doi = {10.1109/IJCNN48605.2020.9207094},
  abstract = {Traditional approaches to cybersecurity issues usually protect users from attacks after the occurrence of specific types of attacks. Besides, patterns of recent cyberattacks tend to be changeable, which add up to unpredictability of them. On the other hand, machine learning, as a new method used to detect intrusion, is attracting more and more attention. Moreover, through the sharing of local training data, the centralized learning approach has proven to improve a model's performance. In this research, a segmented federated learning is proposed, different from a collaborative learning based on single global model in a traditional federated learning model, it keeps multiple global models which allow each segment of participants to conduct collaborative learning separately and rearranges the segmentation of participants dynamically as well. Furthermore, these multiple global models interact with each other for updating parameters, thus being adaptable to various participants' LANs. A dataset covering two months' traffic data from 20 participants' LANs in the LAN-Security Monitoring Project is used. We adopt three types of knowledge-based methods for labeling network events and train a CNN model based on the dataset. At last, we achieve validation accuracies of 0.923, 0.813 and 0.877 individually with these labeling methods.},
  eventtitle = {2020 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  keywords = {Adaptation models,CNN,cybersecurity,Data models,Intrusion detection,LAN,machine learning,Machine learning,Monitoring,segmented federated learning,Servers,Telecommunication traffic}
}

@inproceedings{sun_TrustManagementModel_2011,
  title = {A {{Trust Management Model}} to {{Enhance Security}} of {{Cloud Computing Environments}}},
  booktitle = {2011 {{Second International Conference}} on {{Networking}} and {{Distributed Computing}}},
  author = {family=Sun, given=Xiaodong, given-i={{Xi}} and Chang, Guiran and Li, Fengyun},
  date = {2011-09},
  pages = {244--248},
  issn = {2165-5006},
  doi = {10.1109/ICNDC.2011.56},
  url = {https://ieeexplore.ieee.org/document/6047143},
  urldate = {2024-07-03},
  abstract = {With the proliferation of cloud computing, the way of reasonable establishment of trust relationship among entities, as a vital part for forming security mechanism in cloud computing environments, is attracting increasing attention. This article introduces a trust management model based on fuzzy set theory and named TMFC including direct trust measurement and computing, connecting, and trust chain incorporating where the issue of recommended trust similarity has been addressed to prevent the behavior of associated cheat of middle nodes. And this model is geared toward the cloud users who are making their decision on whether to use services of some cloud computing providers by giving them trust evaluation sets about providers and then building reasonable trust relationship between them. Our motivation is trying to propose a new idea and method on trust management in cloud computing and further studies are still required to justify the rationality and practicability of this model.},
  eventtitle = {2011 {{Second International Conference}} on {{Networking}} and {{Distributed Computing}}},
  keywords = {associated cheat,Cloud computing,cloud security,Computational modeling,Conferences,Data models,Educational institutions,fuzzy set,IEEE Press,Security,subjective trust,trust management}
}

@online{suricata,
  title = {Suricata {{IDS}}},
  author = {{The Open Information Security Foundation}},
  url = {https://suricata.io/},
  urldate = {2024-06-30},
  langid = {american}
}

@article{tabassum_FEDGANIDSPrivacypreservingIDS_2022,
  title = {{{FEDGAN-IDS}}: {{Privacy-preserving IDS}} Using {{GAN}} and {{Federated Learning}}},
  shorttitle = {{{FEDGAN-IDS}}},
  author = {Tabassum, Aliya and Erbad, Aiman and Lebda, Wadha and Mohamed, Amr and Guizani, Mohsen},
  date = {2022-08-01},
  journaltitle = {Computer Communications},
  shortjournal = {Computer Communications},
  volume = {192},
  pages = {299--310},
  issn = {0140-3664},
  doi = {10.1016/j.comcom.2022.06.015},
  url = {https://www.sciencedirect.com/science/article/pii/S0140366422002171},
  urldate = {2024-04-12},
  abstract = {Federated Learning (FL) is a promising distributed training model that aims to minimize the data sharing to enhance privacy and performance. FL requires sufficient and diverse training data to build efficient models. Lack of data balance as seen in rare classes affects the model accuracy. Generative Adversarial Networks (GAN) are remarkable in data augmentation to balance the available training data. In this article, we propose a novel Federated Deep Learning (DL) Intrusion Detection System (IDS) using GAN, named FEDGAN-IDS, to detect cyber threats in smart Internet of Things (IoT) systems; smarthomes, smart e-healthcare systems and smart cities. We distribute the GAN network over IoT devices to act as a classifier and train using augmented local data. We compare the convergence and accuracy of our model with other federated intrusion detection models. Extensive experiments with multiple datasets demonstrates the effectiveness of the proposed FEDGAN-IDS. The model performs better and converges earlier than the state-of-the-art standalone IDS.},
  keywords = {\_read\_urgently,Deep Learning (DL),Federated Learning (FL),Generative Adversarial Network (GAN),Internet of Things (IoT),Intrusion Detection System (IDS)}
}

@article{tahir_ExperienceDrivenAttackDesign_2022,
  title = {Experience-{{Driven Attack Design}} and {{Federated-Learning-Based Intrusion Detection}} in {{Industry}} 4.0},
  author = {Tahir, Bushra and Jolfaei, Alireza and Tariq, Muhammad},
  date = {2022-09},
  journaltitle = {IEEE Transactions on Industrial Informatics},
  volume = {18},
  number = {9},
  pages = {6398--6405},
  issn = {1941-0050},
  doi = {10.1109/TII.2021.3133384},
  url = {https://ieeexplore.ieee.org/abstract/document/9640584},
  urldate = {2024-04-12},
  abstract = {The advent of Industry 4.0 facilitates the Int- ernet-of-Things-based-transactive energy system (IoTES), which enables innovative services with numerous independent distributed systems. These systems generate heterogeneous data in bulk, which become susceptible to cyber-attacks, particularly the stealthy false data injection attacks (FDIAs). The existing centralized FDIA detection algorithms often breach data privacy and fail to perform effectively in highly dynamic and distributed environments, such as IoTES. To resolve the issue, initially, a recurrent deep deterministic policy gradient is utilized to invent an experience-driven FDIA in a complex IoTES. The attacker intends to intelligently exploit the data integrity of smart energy meters with insufficient knowledge of the system. Subsequently, to countermove the stealth and enable independent clients to train a centralized model while keeping each client's data privacy intact, a deep-federated-learning-based decentralized FDIA detection method using an attentive aggregation is exploited in this article. The proposed approach is capable of parallel computing and can reliably identify the stealthy FDIA on all the nodes simultaneously. Simulation results validate that the proposed scheme outperforms the state-of-the-art methods under a distributed environment with a significantly higher detection accuracy and lower computational complexity while keeping the data privacy intact.},
  eventtitle = {{{IEEE Transactions}} on {{Industrial Informatics}}},
  keywords = {Collaborative work,Computational complexity,Data models,Data privacy,Deep federated learning,deep reinforcement learning,false data injection,Fourth Industrial Revolution,Industry 4.0,Meters,privacy preservation,Supply and demand}
}

@article{tan_ReputationAwareFederatedLearning_2022,
  title = {Reputation-{{Aware Federated Learning Client Selection}} Based on {{Stochastic Integer Programming}}},
  author = {Tan, Xavier and Ng, Wei Chong and Lim, Wei Yang Bryan and Xiong, Zehui and Niyato, Dusit and Yu, Han},
  date = {2022},
  journaltitle = {IEEE Transactions on Big Data},
  pages = {1--12},
  issn = {2332-7790},
  doi = {10.1109/TBDATA.2022.3191332},
  abstract = {Federated Learning(FL) has attracted wide research interest due to its potential in building machine learning models while preserving users' data privacy. However, due to the distributive nature of FL, it is vulnerable to misbehavior from participating worker nodes. Thus, it is important to select clients to participate in FL. Recent studies on FL client selection focus on the perspective of improving model training efficiency and performance, without holistically considering potential misbehavior and the cost of hiring. To bridge this gap, we propose a first-of-its-kind reputation-aware Stochastic integer programming-based FL Client Selection method (SCS). It can optimally select and compensate clients with different reputation profiles. Extensive experiments show that SCS achieves the most advantageous performance-cost trade-off compared to other existing state-of-the-art approaches.},
  eventtitle = {{{IEEE Transactions}} on {{Big Data}}},
  keywords = {Biological system modeling,client selection,Computational modeling,Costs,Data models,Federated learning,reputation,stochastic integer programming,Stochastic processes,Training,Uncertainty}
}

@article{tan_ReputationAwareFederatedLearning_2022a,
  title = {Reputation-{{Aware Federated Learning Client Selection}} Based on {{Stochastic Integer Programming}}},
  author = {Tan, Xavier and Ng, Wei Chong and Lim, Wei Yang Bryan and Xiong, Zehui and Niyato, Dusit and Yu, Han},
  date = {2022},
  journaltitle = {IEEE Transactions on Big Data},
  pages = {1--12},
  issn = {2332-7790},
  doi = {10.1109/TBDATA.2022.3191332},
  abstract = {Federated Learning(FL) has attracted wide research interest due to its potential in building machine learning models while preserving users' data privacy. However, due to the distributive nature of FL, it is vulnerable to misbehavior from participating worker nodes. Thus, it is important to select clients to participate in FL. Recent studies on FL client selection focus on the perspective of improving model training efficiency and performance, without holistically considering potential misbehavior and the cost of hiring. To bridge this gap, we propose a first-of-its-kind reputation-aware Stochastic integer programming-based FL Client Selection method (SCS). It can optimally select and compensate clients with different reputation profiles. Extensive experiments show that SCS achieves the most advantageous performance-cost trade-off compared to other existing state-of-the-art approaches.},
  eventtitle = {{{IEEE Transactions}} on {{Big Data}}},
  keywords = {Biological system modeling,client selection,Computational modeling,Costs,Data models,Federated learning,reputation,stochastic integer programming,Stochastic processes,Training,Uncertainty}
}

@article{tang_federatedlearningmethod_2022,
  title = {A Federated Learning Method for Network Intrusion Detection},
  author = {Tang, Zhongyun and Hu, Haiyang and Xu, Chonghuan},
  date = {2022},
  journaltitle = {Concurrency and Computation: Practice and Experience},
  volume = {34},
  number = {10},
  pages = {e6812},
  issn = {1532-0634},
  doi = {10.1002/cpe.6812},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.6812},
  urldate = {2024-04-12},
  abstract = {Intrusion detection is a common network security defense technology. At present, there are many research using deep learning to realize network intrusion detection. This method has been proved to have high detection accuracy. However, deep learning requires large-scale data sets for training. The network intrusion detection data set of some institution is lacking. If the network traffic data set is uploaded for centralized deep learning training, it will face privacy problems. Combined with the characteristics of network traffic, this article proposes a network intrusion detection method based on federated learning. This method allows multiple ISPs or other institutions to conduct joint deep learning training on the premise of retaining local data. It not only improves the detection accuracy of the model but also protects privacy in network traffic. This article conducts experiments on the CICIDS2017 network intrusion detection data set. Experimental results show that worker participating in federated learning have higher detection accuracy. The accuracy and other performance of federated learning are almost equal to those of centralized deep learning models.},
  langid = {english},
  keywords = {\_read\_urgently,CICIDS2017,deep learning,federated learning,GRU,network intrusion detection}
}

@article{tang_GossipFLDecentralizedFederated_2023,
  title = {{{GossipFL}}: {{A Decentralized Federated Learning Framework With Sparsified}} and {{Adaptive Communication}}},
  shorttitle = {{{GossipFL}}},
  author = {Tang, Zhenheng and Shi, Shaohuai and Li, Bo and Chu, Xiaowen},
  date = {2023-03},
  journaltitle = {IEEE Transactions on Parallel and Distributed Systems},
  volume = {34},
  number = {3},
  pages = {909--922},
  issn = {1558-2183},
  doi = {10.1109/TPDS.2022.3230938},
  url = {https://ieeexplore.ieee.org/document/9996127},
  urldate = {2024-06-23},
  abstract = {Recently, federated learning (FL) techniques have enabled multiple users to train machine learning models collaboratively without data sharing. However, existing FL algorithms suffer from the communication bottleneck due to network bandwidth pressure and/or low bandwidth utilization of the participating clients in both centralized and decentralized architectures. To deal with the communication problem while preserving the convergence performance, we introduce a communication-efficient decentralized FL framework GossipFL. In GossipFL, we 1) design a novel sparsification algorithm to enable that each client only needs to communicate with one peer with a highly sparsified model, and 2) propose a new and novel gossip matrix generation algorithm that can better utilize the bandwidth resources while preserving the convergence property. We also theoretically prove that GossipFL has convergence guarantees. We conduct experiments with three convolutional neural networks on two datasets (IID and non-IID) under two distributed environments (14 clients and 100 clients) to verify the effectiveness of GossipFL. Experimental results show that GossipFL takes less communication traffic for 38.5\% and less communication time for 49.849.8\% than state-of-the-art solutions while achieving comparative model accuracy.},
  eventtitle = {{{IEEE Transactions}} on {{Parallel}} and {{Distributed Systems}}},
  keywords = {Bandwidth,communication efficiency,Convergence,Data models,Deep learning,federated learning,Federated learning,Servers,Topology,Training}
}

@article{tangmunarunkit_Networktopologygenerators_2002,
  title = {Network Topology Generators: Degree-Based vs. Structural},
  shorttitle = {Network Topology Generators},
  author = {Tangmunarunkit, Hongsuda and Govindan, Ramesh and Jamin, Sugih and Shenker, Scott and Willinger, Walter},
  date = {2002-08-19},
  journaltitle = {SIGCOMM Comput. Commun. Rev.},
  volume = {32},
  number = {4},
  pages = {147--159},
  issn = {0146-4833},
  doi = {10.1145/964725.633040},
  url = {https://doi.org/10.1145/964725.633040},
  urldate = {2024-07-07},
  abstract = {Following the long-held belief that the Internet is hierarchical, the network topology generators most widely used by the Internet research community, Transit-Stub and Tiers, create networks with a deliberately hierarchical structure. However, in 1999 a seminal paper by Faloutsos et al. revealed that the Internet's degree distribution is a power-law. Because the degree distributions produced by the Transit-Stub and Tiers generators are not power-laws, the research community has largely dismissed them as inadequate and proposed new network generators that attempt to generate graphs with power-law degree distributions.Contrary to much of the current literature on network topology generators, this paper starts with the assumption that it is more important for network generators to accurately model the large-scale structure of the Internet (such as its hierarchical structure) than to faithfully imitate its local properties (such as the degree distribution). The purpose of this paper is to determine, using various topology metrics, which network generators better represent this large-scale structure. We find, much to our surprise, that network generators based on the degree distribution more accurately capture the large-scale structure of measured topologies. We then seek an explanation for this result by examining the nature of hierarchy in the Internet more closely; we find that degree-based generators produce a form of hierarchy that closely resembles the loosely hierarchical nature of the Internet.}
}

@inproceedings{taowan_IntruDetectorsoftwareplatform_2001,
  title = {{{IntruDetector}}: A Software Platform for Testing Network Intrusion Detection Algorithms},
  shorttitle = {{{IntruDetector}}},
  booktitle = {Seventeenth {{Annual Computer Security Applications Conference}}},
  author = {{Tao Wan} and {Xue Dong Yang}},
  date = {2001},
  pages = {3--11},
  publisher = {IEEE Comput. Soc},
  location = {New Orleans, LA, USA},
  doi = {10/cwrznf},
  url = {http://ieeexplore.ieee.org/document/991516/},
  urldate = {2022-01-12},
  abstract = {An Intrusion Detection System (IDS), that monitors passively specific computing resources, and reports anomalous or intrusive activities, is becoming an important component in the security system of information infrastructure. Algorithms for detecting intrusions are under rapid development, but far from being mature. One interesting and difficult issue is how to study and test a new intrusion detection algorithm against a variety of (perhaps simulated) intrusive activities under realistic background traffic. A flexible and general-purpose platform for testing intrusion detection algorithms is clearly desirable. This paper presents such a software platform, called IntruDetector. With this platform, detection algorithms can be tested directly in a real environment with wide range of intrusive activities. The data of normal system activities are directly collected from the live environment, and are mixed with intrusive activities that are simulated by hybrid simulation. The main properties of this approach are: (1) the background traffic is realistic; (2) it allows flexible simulation of various types of intrusions; and (3) normal system operation will not be disrupted by virtually simulated destructive intrusions during testing.},
  eventtitle = {Seventeenth {{Annual Computer Security Applications Conference}}},
  isbn = {978-0-7695-1405-5},
  langid = {english},
  keywords = {\_read\_urgently}
}

@article{tarasov_GeneratingRealisticDatasets_2021,
  title = {Generating {{Realistic Datasets}} for {{Deduplication Analysis}}},
  author = {Tarasov, Vasily and Mudrankit, Amar},
  date = {2021},
  pages = {12},
  abstract = {Deduplication is a popular component of modern storage systems, with a wide variety of approaches. Unlike traditional storage systems, deduplication performance depends on data content as well as access patterns and meta-data characteristics. Most datasets that have been used to evaluate deduplication systems are either unrepresentative, or unavailable due to privacy issues, preventing easy comparison of competing algorithms. Understanding how both content and meta-data evolve is critical to the realistic evaluation of deduplication systems.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@inproceedings{tavallaee_detailedanalysisKDD_2009,
  title = {A Detailed Analysis of the {{KDD CUP}} 99 Data Set},
  booktitle = {2009 {{IEEE Symposium}} on {{Computational Intelligence}} for {{Security}} and {{Defense Applications}}},
  author = {Tavallaee, Mahbod and Bagheri, Ebrahim and Lu, Wei and Ghorbani, Ali A.},
  date = {2009-07},
  pages = {1--6},
  publisher = {IEEE},
  doi = {10.1109/CISDA.2009.5356528},
  url = {http://ieeexplore.ieee.org/document/5356528/},
  abstract = {During the last decade, anomaly detection has attracted the attention of many researchers to overcome the weakness of signature-based IDSs in detecting novel attacks, and KDDCUP'99 is the mostly widely used data set for the evaluation of these systems. Having conducted a statistical analysis on this data set, we found two important issues which highly affects the performance of evaluated systems, and results in a very poor evaluation of anomaly detection approaches. To solve these issues, we have proposed a new data set, NSL-KDD, which consists of selected records of the complete KDD data set and does not suffer from any of mentioned shortcomings. \copyright{} 2009 IEEE.},
  isbn = {978-1-4244-3763-4},
  issue = {Cisda}
}

@article{teixeira_VoteBasedArchitectureGenerate_2022,
  title = {A {{Vote-Based Architecture}} to {{Generate Classified Datasets}} and {{Improve Performance}} of {{Intrusion Detection Systems Based}} on {{Supervised Learning}}},
  author = {Teixeira, Diogo and Malta, Silvestre and Pinto, Pedro},
  date = {2022-02-25},
  journaltitle = {Future Internet},
  shortjournal = {Future Internet},
  volume = {14},
  number = {3},
  pages = {72},
  issn = {1999-5903},
  doi = {10.3390/fi14030072},
  url = {https://www.mdpi.com/1999-5903/14/3/72},
  urldate = {2022-07-05},
  abstract = {An intrusion detection system (IDS) is an important tool to prevent potential threats to systems and data. Anomaly-based IDSs may deploy machine learning algorithms to classify events either as normal or anomalous and trigger the adequate response. When using supervised learning, these algorithms require classified, rich, and recent datasets. Thus, to foster the performance of these machine learning models, datasets can be generated from different sources in a collaborative approach, and trained with multiple algorithms. This paper proposes a vote-based architecture to generate classified datasets and improve the performance of supervised learning-based IDSs. On a regular basis, multiple IDSs in different locations send their logs to a central system that combines and classifies them using different machine learning models and a majority vote system. Then, it generates a new and classified dataset, which is trained to obtain the best updated model to be integrated into the IDS of the companies involved. The proposed architecture trains multiple times with several algorithms. To shorten the overall runtimes, the proposed architecture was deployed in Fed4FIRE+ with Ray to distribute the tasks by the available resources. A set of machine learning algorithms and the proposed architecture were assessed. When compared with a baseline scenario, the proposed architecture enabled to increase the accuracy by 11.5\% and the precision by 11.2\%.},
  langid = {english},
  keywords = {\_read\_urgently}
}

@inproceedings{thai_AdversarialAutoEncoderGenerative_2022,
  title = {Adversarial {{AutoEncoder}} and {{Generative Adversarial Networks}} for {{Semi-Supervised Learning Intrusion Detection System}}},
  booktitle = {2022 {{RIVF International Conference}} on {{Computing}} and {{Communication Technologies}} ({{RIVF}})},
  author = {Thai, Ho Huy and Hieu, Nguyen Duc and Van Tho, Nguyen and Hoang, Hien Do and Duy, Phan The and Pham, Van-Hau},
  date = {2022-12},
  pages = {584--589},
  issn = {2162-786X},
  doi = {10.1109/RIVF55975.2022.10013926},
  abstract = {As one of the defensive solutions against cyberattacks, an Intrusion Detection System (IDS) plays an important role in observing the network state and alerting suspicious actions that can break down the system. There are many attempts of adopting Machine Learning (ML) in IDS to achieve high performance in intrusion detection. However, all of them necessitate a large amount of labeled data. In addition, labeling attack data is a time-consuming and expensive human-labor operation, it makes existing ML methods difficult to deploy in a new system or yields lower results due to a lack of labels on pre-trained data. To address these issues, we propose a semi-supervised IDS model that leverages Generative Adversarial Networks (GANs) and Adversarial AutoEncoder (AAE), called a semi-supervised adversarial autoencoder (SAAE). Our SAAE experimental results on two public datasets for benchmarking ML-based IDS, including NF-CSE-CIC-IDS2018 and NF-UNSW-NB15, demonstrate the effectiveness of AAE and GAN in case of using only a small number of labeled data. In particular, our approach outperforms other ML methods with the highest detection rates in spite of the scarcity of labeled data for model training, even with only 1\% labeled data.},
  eventtitle = {2022 {{RIVF International Conference}} on {{Computing}} and {{Communication Technologies}} ({{RIVF}})},
  keywords = {Adversarial Auto Encoder,Benchmark testing,Data models,Generative adversarial networks,Generative Adversarial Networks,Intrusion detection,Intrusion Detection,Network architecture,Semi-supervised Learning,Semisupervised learning,Training}
}

@inproceedings{thakkar_Gametheoreticapproach_2020,
  title = {Game Theoretic Approach Applied in Cybersecurity Information Exchange Framework},
  booktitle = {2020 {{IEEE}} 17th {{Annual Consumer Communications}} \& {{Networking Conference}} ({{CCNC}})},
  author = {Thakkar, Ankita and Badsha, Shahriar and Sengupta, Shamik},
  date = {2020-01},
  pages = {1--7},
  publisher = {IEEE},
  location = {Las Vegas, NV, USA},
  doi = {10.1109/CCNC46108.2020.9045430},
  url = {https://ieeexplore.ieee.org/document/9045430/},
  urldate = {2022-03-17},
  abstract = {In CYBersecurity information EXchange (CYBEX) framework, Cyber Threat Intelligence (CTI) is shared among multiple organizations with a view of creating situational awareness. But there is a possibility that malicious organizations coexist with regular ones in this framework, which can get hold of the threat data shared by other organizations and can use it for carrying out malicious activities. We formulate the aforementioned problem as an incomplete information game assuming that whenever CYBEX receives any information, it processes the information for anomaly detection. We find the mixed strategy Nash equilibrium probabilities and corresponding Bayesian belief updates. We simulate the game to find the best response strategies with which regular and malicious organizations can play to increase their payoffs. Based on the best response strategies of organizations, we analyze that achieving more anomaly detection rate while keeping the processing rate minimum is the best action strategy with which CYBEX can play to increase the gain of both CYBEX and regular organizations over malicious organizations. We also find the approximate average minimum processing rate and anomaly detection rate with which CYBEX can play in order to maintain the payoff of itself and regular organizations higher than the malicious ones.},
  eventtitle = {2020 {{IEEE}} 17th {{Annual Consumer Communications}} \& {{Networking Conference}} ({{CCNC}})},
  isbn = {978-1-72813-893-0},
  langid = {english}
}

@inproceedings{thanigaivelan_Distributedinternalanomaly_2016,
  title = {Distributed Internal Anomaly Detection System for {{Internet-of-Things}}},
  booktitle = {2016 13th {{IEEE Annual Consumer Communications}} \& {{Networking Conference}} ({{CCNC}})},
  author = {Thanigaivelan, Nanda Kumar and Nigussie, Ethiopia and Kanth, Rajeev Kumar and Virtanen, Seppo and Isoaho, Jouni},
  date = {2016-01},
  pages = {319--320},
  publisher = {IEEE},
  doi = {10.1109/CCNC.2016.7444797},
  url = {http://ieeexplore.ieee.org/document/7444797/},
  abstract = {We present overview of a distributed internal anomaly detection system for Internet-of-things. In the detection system, each node monitors its neighbors and if abnormal behavior is detected, the monitoring node will block the packets from the abnormally behaving node at the data link layer and reports to its parent node. The reporting propagates from child to parent nodes until it reaches the root. A novel control message, distress propagation object (DPO), is devised to report the anomaly to the subsequent parents and ultimately the edge-router. The DPO message is integrated to routing protocol for low-power and lossy networks (RPL). The system has configurable profile settings and it is able to learn and differentiate the nodes' normal and suspicious activities without a need for prior knowledge. It has different subsystems and operation phases at data link and network layers, which share a common repository in a node. The system uses network fingerprinting to be aware of changes in network topology and nodes' positions without any assistance from a positioning system.},
  isbn = {978-1-4673-9292-1}
}

@article{thein_Personalizedfederatedlearningbased_2024,
  title = {Personalized Federated Learning-Based Intrusion Detection System: {{Poisoning}} Attack and Defense},
  shorttitle = {Personalized Federated Learning-Based Intrusion Detection System},
  author = {Thein, Thin Tharaphe and Shiraishi, Yoshiaki and Morii, Masakatu},
  date = {2024-04-01},
  journaltitle = {Future Generation Computer Systems},
  shortjournal = {Future Generation Computer Systems},
  volume = {153},
  pages = {182--192},
  issn = {0167-739X},
  doi = {10.1016/j.future.2023.10.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0167739X23003783},
  urldate = {2024-04-12},
  abstract = {To deal with the increasing number of cyber-attacks, intrusion detection system (IDS) plays an important role in monitoring and ensuring the security of the computer network. With the power of machine learning and deep learning, intelligent IDS systems have gained increasing attention due to their efficiency and high classification accuracy. However, the premise of machine learning/deep learning is that the data must be in one central entity (e.g., server) to train the model. This causes additional concerns, such as data transmission costs and privacy leakage. Federated learning complements this shortcoming with a privacy-preserving decentralized learning technique. In federated learning, the data are not shared with the server, local model training is performed where the data reside and only the model parameters are exchanged with the server. This work investigates the federated learning-based IDS approach in the context of IoT data to study the main challenges imposed by federated learning. Two main issues, such as data heterogeneity and poisoning attacks launched by malicious clients, are the main focus of this study. As real-world IoT datasets are heterogeneous, we propose a personalized federated learning-based IDS approach to handle imbalanced data distributions. Moreover, a curious yet malicious client can poison the local data or model to corrupt the global intrusion detection model due to the distributed nature of federated learning, where the central server has no control over the client's local training process. This study demonstrates that the existence of a malicious client can degrade the performance of the federated learning-based IDS model. Accordingly, we propose a robust approach called pFL-IDS to combat poisoning attacks against the federated learning-enabled IDS on heterogeneous IoT data. Our approach introduces mini-batch logit adjustment loss to local model training to obtain a personalized model tailored to each local data distribution. Moreover, we design a detection mechanism at the server to identify malicious agents by considering the cosine similarity of local models from the non-poisoned client's centroid. The non-poisoned centroid is determined from the similarity between the pre-computed global model and the local models. If the poisoning attack is successful, poisoned clients will be closer to the pre-computed global model; any models further from the pre-computed model are taken as the non-poisoned clients. With this two-phase client similarity alignment, we identify poisoned clients and restrict their aggregation on the global intrusion detection model. In comparison with the baseline methods, we demonstrate that our pFL-IDS can detect poisoning attacks without compromising performance.},
  keywords = {Intrusion detection system,Personalized federated learning,Poisoning attacks,Poisoning defense}
}

@inproceedings{thi_FederatedLearningBasedCyber_2022,
  title = {Federated {{Learning-Based Cyber Threat Hunting}} for {{APT Attack Detection}} in {{SDN-Enabled Networks}}},
  booktitle = {2022 21st {{International Symposium}} on {{Communications}} and {{Information Technologies}} ({{ISCIT}})},
  author = {Thi, Huynh Thai and Hoang Son, Ngo Duc and Duy, Phan The and Pham, Van-Hau},
  date = {2022-09},
  pages = {1--6},
  issn = {2643-6175},
  doi = {10.1109/ISCIT55906.2022.9931222},
  url = {https://ieeexplore.ieee.org/abstract/document/9931222},
  urldate = {2024-04-12},
  abstract = {Threat hunting is the action of seeking harmful actors lurking in the network or the system in the early stage with the assumption of attackers already broke the cy-ber defense solution. This defense solution requires collecting more knowledge inside and outside to search potential threats in each organization. To leverage the knowledge of multiple organizations and experts for cyber threat detection, there is a need for the collaboration without breaking data among data owners across the cybersecurity community. Meanwhile, Software Defined Networking (SDN) is the flexible and programmable network architecture, which enables network administrator to proactively enforce the security policy in the large-scale network. Obviously, it can help organizations to enforce dynamically threat hunting services. Thus, this work introduces a federated learning (FL) approach for cyber threat hunting in SDN-enabled networks to deploy a proactive APT attack detection and response by leveraging threat intelligence from collaborative parties. Our approach can enrich the outcome of machine learning (ML)-based or deep learning (DL)-based threat detectors in recognizing malicious indicators. The experimental results on NF-UQ-NIDS dataset and FedPlus model aggregation algorithm demonstrate the feasibility of FL-based cyber threat hunting with privacy preservation among data holders in SDN context.},
  eventtitle = {2022 21st {{International Symposium}} on {{Communications}} and {{Information Technologies}} ({{ISCIT}})},
  keywords = {APT detection,Collaboration,Cyber threat hunting,cyberattack detection,Detectors,federated learning,Machine learning algorithms,Organizations,Privacy,Protocols,Software Defined Networking,Training}
}

@article{tian_ComprehensiveSurveyPoisoning_2022,
  title = {A {{Comprehensive Survey}} on {{Poisoning Attacks}} and {{Countermeasures}} in {{Machine Learning}}},
  author = {Tian, Zhiyi and Cui, Lei and Liang, Jie and Yu, Shui},
  date = {2022-07-18},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  issn = {0360-0300},
  doi = {10.1145/3551636},
  url = {https://doi.org/10.1145/3551636},
  urldate = {2022-09-01},
  abstract = {The prosperity of machine learning has been accompanied by increasing attacks on the training process. Among them, poisoning attacks have become an emerging threat during model training. Poisoning attacks have profound impacts on the target models, e.g., making them unable to converge or manipulating their prediction results. Moreover, the rapid development of recent distributed learning frameworks, especially federated learning, has further stimulated the development of poisoning attacks. Defending against poisoning attacks is challenging and urgent. However, the systematic review from a unified perspective remains blank. This survey provides an in-depth and up-to-date overview of poisoning attacks and corresponding countermeasures in both centralized and federated learning. We firstly categorize attack methods based on their goals. Secondly, we offer detailed analysis of the differences and connections among the attack techniques. Furthermore, we present countermeasures in different learning framework and highlight their advantages and disadvantages. Finally, we discuss the reasons for the feasibility of poisoning attacks and address the potential research directions from attacks and defenses perspectives, separately.},
  keywords = {backdoor attack,Deep learning,federated learning,poisoning attack},
  annotation = {Just Accepted}
}

@inproceedings{tolpegin_DataPoisoningAttacks_2020,
  title = {Data {{Poisoning Attacks Against Federated Learning Systems}}},
  booktitle = {Computer {{Security}} -- {{ESORICS}} 2020},
  author = {Tolpegin, Vale and Truex, Stacey and Gursoy, Mehmet Emre and Liu, Ling},
  editor = {Chen, Liqun and Li, Ninghui and Liang, Kaitai and Schneider, Steve},
  date = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {480--501},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-58951-6_24},
  abstract = {Federated learning (FL) is an emerging paradigm for distributed training of large-scale deep neural networks in which participants' data remains on their own devices with only model updates being shared with a central server. However, the distributed nature of FL gives rise to new threats caused by potentially malicious participants. In this paper, we study targeted data poisoning attacks against FL systems in which a malicious subset of the participants aim to poison the global model by sending model updates derived from mislabeled data. We first demonstrate that such data poisoning attacks can cause substantial drops in classification accuracy and recall, even with a small percentage of malicious participants. We additionally show that the attacks can be targeted, i.e., they have a large negative impact only on classes that are under attack. We also study attack longevity in early/late round training, the impact of malicious participant availability, and the relationships between the two. Finally, we propose a defense strategy that can help identify malicious participants in FL to circumvent poisoning attacks, and demonstrate its effectiveness.},
  isbn = {978-3-030-58951-6},
  langid = {english},
  keywords = {Adversarial machine learning,Data poisoning,Deep learning,Federated learning,Label flipping,obsidian}
}

@online{ToN_IoT_url,
  title = {The~{{TON}}\_{{IoT~Datasets}}},
  url = {https://research.unsw.edu.au/projects/toniot-datasets},
  urldate = {2023-03-22}
}

@article{tounsi_surveytechnicalthreat_2018,
  title = {A Survey on Technical Threat Intelligence in the Age of Sophisticated Cyber Attacks},
  author = {Tounsi, Wiem and Rais, Helmi},
  date = {2018-01},
  journaltitle = {Computers \& Security},
  volume = {72},
  pages = {212--233},
  publisher = {Elsevier Ltd},
  issn = {01674048},
  doi = {10.1016/j.cose.2017.09.001},
  url = {https://doi.org/10.1016/j.cose.2017.09.001},
  abstract = {Today's cyber attacks require a new line of security defenses. The static approach of traditional security based on heuristic and signature does not match the dynamic nature of new generation of threats that are known to be evasive, resilient and complex. Organizations need to gather and share real-time cyber threat information and to transform it to threat intelligence in order to prevent attacks or at least execute timely disaster recovery. Threat Intelligence (TI) means evidence-based knowledge representing threats that can inform decisions. There is a general awareness for the need of threat intelligence while vendors today are rushing to provide a diverse array of threat intelligence products, specifically focusing on Technical Threat Intelligence (TTI). Although threat intelligence is being increasingly adopted, there is little consensus on what it actually is, or how to use it. Without any real understanding of this need, organizations risk investing large amounts of time and money without solving existing security problems. Our paper aims to classify and make distinction among existing threat intelligence types. We focus particularly on the TTI issues, emerging researches, trends and standards. Our paper also explains why there is a reluctance among organizations to share threat intelligence. We provide sharing strategies based on trust and anonymity, so participating organizations can do away with the risks of business leak. We also show in this paper why having a standardized representation of threat information can improve the quality of TTI, thus providing better automated analytics solutions on large volumes of TTI which are often non-uniform and redundant. Finally, we evaluate most popular open source/free threat intelligence tools, and compare their features with those of a new AlliaCERT TI tool.}
}

@article{tran_EfficientPrivacyEnhancingCrossSilo_2023,
  title = {An {{Efficient Privacy-Enhancing Cross-Silo Federated Learning}} and {{Applications}} for {{False Data Injection Attack Detection}} in {{Smart Grids}}},
  author = {Tran, Hong-Yen and Hu, Jiankun and Yin, Xuefei and Pota, Hemanshu R.},
  date = {2023},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  volume = {18},
  pages = {2538--2552},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2023.3267892},
  url = {https://ieeexplore.ieee.org/document/10103703},
  urldate = {2024-04-12},
  abstract = {Federated Learning is a prominent machine learning paradigm which helps tackle data privacy issues by allowing clients to store their raw data locally and transfer only their local model parameters to an aggregator server to collaboratively train a shared global model. However, federated learning is vulnerable to inference attacks from dishonest aggregators who can infer information about clients' training data from their model parameters. To deal with this issue, most of the proposed schemes in literature either require a non-colluded server setting, a trusted third-party to compute master secret keys or a secure multiparty computation protocol which is still inefficient over multiple iterations of computing an aggregation model. In this work, we propose an efficient cross-silo federated learning scheme with strong privacy preservation. By designing a double-layer encryption scheme which has no requirement to compute discrete logarithm, utilizing secret sharing only at the establishment phase and in the iterations when parties rejoin, and accelerating the computation performance via parallel computing, we achieve an efficient privacy-preserving federated learning protocol, which also allows clients to dropout and rejoin during the training process. The proposed scheme is demonstrated theoretically and empirically to provide provable privacy against an honest-but-curious aggregator server and simultaneously achieve desirable model utilities. The scheme is applied to false data injection attack detection (FDIA) in smart grids. This is a more secure cross-silo FDIA federated learning resilient to the local private data inference attacks than the existing works.},
  eventtitle = {{{IEEE Transactions}} on {{Information Forensics}} and {{Security}}},
  keywords = {Computational modeling,Cryptography,Data models,encryption,false data injection attack detection,federated learning,Federated learning,Privacy,Privacy-preserving,secret sharing,Servers,Training}
}

@article{trifonov_Artificialintelligencecyber_2019,
  title = {Artificial Intelligence in Cyber Threats Intelligence},
  author = {Trifonov, Roumen and Nakov, Ognyan and Mladenov, Valeri},
  date = {2019},
  journaltitle = {2018 International Conference on Intelligent and Innovative Computing Applications, ICONIC 2018},
  pages = {2018--2021},
  publisher = {IEEE},
  doi = {10.1109/ICONIC.2018.8601235},
  abstract = {In the field of Cyber Security there has been a transition from the stage of Cyber Criminality to the stage of Cyber War over the last few years. According to the new challenges, the expert community has two main approaches: to adopt the philosophy and methods of Military Intelligence, and to use Artificial Intelligence methods for counteraction of Cyber Attacks. This paper describes some of the results obtained at Technical University of Sofia in the implementation of project related to the application of intelligent methods for increasing the security in computer networks. The analysis of the feasibility of various Artificial Intelligence methods has shown that a method that is equally effective for all stages of the Cyber Intelligence cannot be identified. While for Tactical Cyber Threats Intelligence has been selected and experimented a Multi-Agent System, the Recurrent Neural Networks are offered for the needs of Operational Cyber Threats Intelligence.},
  isbn = {9781538664773}
}

@online{trocoso-pastoriza_OrchestratingCollaborativeCybersecurity_2022,
  title = {Orchestrating {{Collaborative Cybersecurity}}: {{A Secure Framework}} for {{Distributed Privacy-Preserving Threat Intelligence Sharing}}},
  shorttitle = {Orchestrating {{Collaborative Cybersecurity}}},
  author = {Trocoso-Pastoriza, Juan R. and Mermoud, Alain and Bouy\'e, Romain and Marino, Francesco and Bossuat, Jean-Philippe and Lenders, Vincent and Hubaux, Jean-Pierre},
  date = {2022-09-06},
  eprint = {2209.02676},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2209.02676},
  urldate = {2022-09-12},
  abstract = {Cyber Threat Intelligence (CTI) sharing is an important activity to reduce information asymmetries between attackers and defenders. However, this activity presents challenges due to the tension between data sharing and confidentiality, that result in information retention often leading to a free-rider problem. Therefore, the information that is shared represents only the tip of the iceberg. Current literature assumes access to centralized databases containing all the information, but this is not always feasible, due to the aforementioned tension. This results in unbalanced or incomplete datasets, requiring the use of techniques to expand them; we show how these techniques lead to biased results and misleading performance expectations. We propose a novel framework for extracting CTI from distributed data on incidents, vulnerabilities and indicators of compromise, and demonstrate its use in several practical scenarios, in conjunction with the Malware Information Sharing Platforms (MISP). Policy implications for CTI sharing are presented and discussed. The proposed system relies on an efficient combination of privacy enhancing technologies and federated processing. This lets organizations stay in control of their CTI and minimize the risks of exposure or leakage, while enabling the benefits of sharing, more accurate and representative results, and more effective predictive and preventive defenses.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Databases}
}

@article{truong_Lightweightfederatedlearningbased_2022,
  title = {Light-Weight Federated Learning-Based Anomaly Detection for Time-Series Data in Industrial Control Systems},
  author = {Truong, Huong Thu and Ta, Bac Phuong and Le, Quang Anh and Nguyen, Dan Minh and Le, Cong Thanh and Nguyen, Hoang Xuan and Do, Ha Thu and Nguyen, Hung Tai and Tran, Kim Phuc},
  date = {2022-09},
  journaltitle = {Computers in Industry},
  shortjournal = {Computers in Industry},
  volume = {140},
  pages = {103692},
  issn = {01663615},
  doi = {10.1016/j.compind.2022.103692},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0166361522000896},
  urldate = {2022-06-30},
  abstract = {With the emergence of the Industrial Internet of Things (IIoT), potential threats to smart manufacturing systems are increasingly becoming challenging, causing severe damage to production operations and vital industrial assets, even sensitive information. Hence, detecting irregularities for timeseries data in industrial control systems that should operate continually is critical, ensuring security and minimizing maintenance costs. In this study, with the hybrid design of Federated learning, Autoencoder, Transformer, and Fourier mixing sublayer, we propose a robust distributed anomaly detection architecture that works more accurately than several most recent anomaly detection solutions within the ICS contexts, whilst being fast learning in minute time scale. This distributed architecture is also proven to achieve lightweight, consume little CPU and memory usage, have low communication costs in terms of bandwidth consumption, which makes it feasible to be deployed on top of edge devices with limited computing capacity.},
  langid = {english}
}

@article{truong_Lightweightfederatedlearningbased_2022a,
  title = {Light-Weight Federated Learning-Based Anomaly Detection for Time-Series Data in Industrial Control Systems},
  author = {Truong, Huong Thu and Ta, Bac Phuong and Le, Quang Anh and Nguyen, Dan Minh and Le, Cong Thanh and Nguyen, Hoang Xuan and Do, Ha Thu and Nguyen, Hung Tai and Tran, Kim Phuc},
  date = {2022-09-01},
  journaltitle = {Computers in Industry},
  shortjournal = {Computers in Industry},
  volume = {140},
  pages = {103692},
  issn = {0166-3615},
  doi = {10.1016/j.compind.2022.103692},
  url = {https://www.sciencedirect.com/science/article/pii/S0166361522000896},
  urldate = {2024-04-12},
  abstract = {With the emergence of the Industrial Internet of Things (IIoT), potential threats to smart manufacturing systems are increasingly becoming challenging, causing severe damage to production operations and vital industrial assets, even sensitive information. Hence, detecting irregularities for time-series data in industrial control systems that should operate continually is critical, ensuring security and minimizing maintenance costs. In this study, with the hybrid design of Federated learning, Autoencoder, Transformer, and Fourier mixing sublayer, we propose a robust distributed anomaly detection architecture that works more accurately than several most recent anomaly detection solutions within the ICS contexts, whilst being fast learning in minute time scale. This distributed architecture is also proven to achieve lightweight, consume little CPU and memory usage, have low communication costs in terms of bandwidth consumption, which makes it feasible to be deployed on top of edge devices with limited computing capacity.},
  keywords = {\_read\_urgently,Anomaly detection,Autoencoder,Federated learning,Fourier,ICS,Transformer}
}

@article{tsukada_NeuralNetworkBasedOndevice_2020,
  title = {A {{Neural Network-Based On-device Learning Anomaly Detector}} for {{Edge Devices}}},
  author = {Tsukada, Mineto and Kondo, Masaaki and Matsutani, Hiroki},
  date = {2020},
  journaltitle = {IEEE Transactions on Computers},
  shortjournal = {IEEE Trans. Comput.},
  pages = {1--1},
  issn = {0018-9340, 1557-9956, 2326-3814},
  doi = {10.1109/TC.2020.2973631},
  url = {https://ieeexplore.ieee.org/document/9000710/},
  urldate = {2021-10-23},
  abstract = {Semi-supervised anomaly detection is an approach to identify anomalies by learning the distribution of normal data. Backpropagation neural networks (i.e., BP-NNs) based approaches have recently drawn attention because of their good generalization capability. In a typical situation, BP-NN-based models are iteratively optimized in server machines with input data gathered from the edge devices. However, (1) the iterative optimization often requires significant efforts to follow changes in the distribution of normal data (i.e., concept drift), and (2) data transfers between edge and server impose additional latency and energy consumption. To address these issues, we propose ONLAD and its IP core, named ONLAD Core. ONLAD is highly optimized to perform fast sequential learning to follow concept drift in less than one millisecond. ONLAD Core realizes on-device learning for edge devices at low power consumption, which realizes standalone execution where data transfers between edge and server are not required. Experiments show that ONLAD has favorable anomaly detection capability in an environment that simulates concept drift. Evaluations of ONLAD Core confirm that the training latency is 1.95x\$6.58x faster than the other software implementations. Also, the runtime power consumption of ONLAD Core implemented on PYNQ-Z1 board, a small FPGA/CPU SoC platform, is 5.0x\$25.4x lower than them.},
  langid = {english}
}

@inproceedings{tu_FedDLFederatedLearning_2021,
  title = {{{FedDL}}: {{Federated Learning}} via {{Dynamic Layer Sharing}} for {{Human Activity Recognition}}},
  shorttitle = {{{FedDL}}},
  booktitle = {Proceedings of the 19th {{ACM Conference}} on {{Embedded Networked Sensor Systems}}},
  author = {Tu, Linlin and Ouyang, Xiaomin and Zhou, Jiayu and He, Yuze and Xing, Guoliang},
  date = {2021-11-15},
  series = {{{SenSys}} '21},
  pages = {15--28},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3485730.3485946},
  url = {https://doi.org/10.1145/3485730.3485946},
  urldate = {2023-12-05},
  abstract = {Deep learning has been increasingly applied to improve human activity recognition (HAR) accuracy and reduce the human efforts of handcrafted feature extractions. Federated Learning (FL) is an emerging learning paradigm that enables the collaborative learning of a global model without exposing users' raw data. However, existing FL approaches yield unsatisfactory HAR performance as they fail to dynamically aggregate models according to the statistical diversity of users' data. In this paper, we propose FedDL, a novel federated learning system for HAR that can capture the underlying user relationships and apply them to learn personalized models for different users dynamically. Specifically, we design a dynamic layer sharing scheme that learns the similarity among users' model weights to form the sharing structure and merges models accordingly in an iterative, bottom-up layer-wise manner. FedDL merges local models based on the dynamic sharing scheme, significantly speeding up the convergence while maintaining high accuracy. We have implemented FedDL and evaluated using a new data set we collected using LiDAR and four public real-world datasets involving 178 users in total. The results show that FedDL outperforms several state-of-the-art FL paradigms in terms of model accuracy (by more than 15\%), converging rate (by more than 70\%), and communication overhead (about 30\% reduction). Moreover, the testing results on the datasets of different scales show that FedDL has high scalability and hence can be deployed for large-scale real-world applications.},
  isbn = {978-1-4503-9097-2},
  keywords = {Federated learning,Federated Learning Personalization,Human activity recognition,Multi-task learning,obsidian}
}

@online{tuli_DRAGONDecentralizedFault_2022,
  title = {{{DRAGON}}: {{Decentralized Fault Tolerance}} in {{Edge Federations}}},
  shorttitle = {{{DRAGON}}},
  author = {Tuli, Shreshth and Casale, Giuliano and Jennings, Nicholas R.},
  date = {2022-08-16},
  eprint = {2208.07658},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2208.07658},
  urldate = {2022-08-22},
  abstract = {Edge Federation is a new computing paradigm that seamlessly interconnects the resources of multiple edge service providers. A key challenge in such systems is the deployment of latency-critical and AI based resource-intensive applications in constrained devices. To address this challenge, we propose a novel memory-efficient deep learning based model, namely generative optimization networks (GON). Unlike GANs, GONs use a single network to both discriminate input and generate samples, significantly reducing their memory footprint. Leveraging the low memory footprint of GONs, we propose a decentralized faulttolerance method called DRAGON that runs simulations (as per a digital modeling twin) to quickly predict and optimize the performance of the edge federation. Extensive experiments with real-world edge computing benchmarks on multiple RaspberryPi based federated edge configurations show that DRAGON can outperform the baseline methods in fault-detection and Quality of Service (QoS) metrics. Specifically, the proposed method gives higher F1 scores for fault-detection than the best deep learning (DL) method, while consuming lower memory than the heuristic methods. This allows for improvement in energy consumption, response time and service level agreement violations by up to 74, 63 and 82 percent, respectively.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Artificial Intelligence,Computer Science - Performance}
}

@inproceedings{uetz_ReproducibleAdaptableLog_2021,
  title = {Reproducible and {{Adaptable Log Data Generation}} for {{Sound Cybersecurity Experiments}}},
  booktitle = {Annual {{Computer Security Applications Conference}}},
  author = {Uetz, Rafael and Hemminghaus, Christian and Hackl\"ander, Louis and Schlipper, Philipp and Henze, Martin},
  date = {2021-12-06},
  pages = {690--705},
  publisher = {ACM},
  location = {Virtual Event USA},
  doi = {10.1145/3485832.3488020},
  url = {https://dl.acm.org/doi/10.1145/3485832.3488020},
  urldate = {2022-08-08},
  abstract = {Artifacts such as log data and network traffic are fundamental for cybersecurity research, e.g., in the area of intrusion detection. Yet, most research is based on artifacts that are not available to others or cannot be adapted to own purposes, thus making it difficult to reproduce and build on existing work. In this paper, we identify the challenges of artifact generation with the goal of conducting sound experiments that are valid, controlled, and reproducible. We argue that testbeds for artifact generation have to be designed specifically with reproducibility and adaptability in mind. To achieve this goal, we present SOCBED, our proof-of-concept implementation and the first testbed with a focus on generating realistic log data for cybersecurity experiments in a reproducible and adaptable manner. SOCBED enables researchers to reproduce testbed instances on commodity computers, adapt them according to own requirements, and verify their correct functionality. We evaluate SOCBED with an exemplary, practical experiment on detecting a multi-step intrusion of an enterprise network and show that the resulting experiment is indeed valid, controlled, and reproducible. Both SOCBED and the log dataset underlying our evaluation are freely available.},
  eventtitle = {{{ACSAC}} '21: {{Annual Computer Security Applications Conference}}},
  isbn = {978-1-4503-8579-4},
  langid = {english}
}

@article{ulltveit-moe_SecureInformationSharing_2016,
  title = {Secure {{Information Sharing}} in an {{Industrial Internet}} of {{Things}}},
  author = {Ulltveit-Moe, Nils and Nergaard, Henrik and Erd\"odi, L\'aszl\'o and Gj\o s\ae ter, Terje and Kolstad, Erland and Berg, P\aa l},
  date = {2016-01-17},
  pages = {1--12},
  url = {http://arxiv.org/abs/1601.04301},
  abstract = {This paper investigates how secure information sharing with external vendors can be achieved in an Industrial Internet of Things (IIoT). It also identifies necessary security requirements for secure information sharing based on identified security challenges stated by the industry. The paper then proposes a roadmap for improving security in IIoT which investigates both short-term and long-term solutions for protecting IIoT devices. The short-term solution is mainly based on integrating existing good practices. The paper also outlines a long term solution for protecting IIoT devices with fine-grained access control for sharing data between external entities that would support cloud-based data storage.}
}

@online{UNSW-NB15_url,
  title = {The {{UNSW-NB15 Dataset}}},
  url = {https://research.unsw.edu.au/projects/unsw-nb15-dataset},
  urldate = {2023-03-22}
}

@inproceedings{uprety_MitigatingPoisoningAttack_2021,
  title = {Mitigating {{Poisoning Attack}} in {{Federated Learning}}},
  booktitle = {2021 {{IEEE Symposium Series}} on {{Computational Intelligence}} ({{SSCI}})},
  author = {Uprety, Aashma and Rawat, Danda B.},
  date = {2021-12},
  pages = {01--07},
  doi = {10.1109/SSCI50451.2021.9659839},
  abstract = {Adversarial machine learning (AML) has emerged as one of the significant research areas in machine learning (ML) because models we train lack robustness and trustworthiness. Federated learning (FL) trains models over distributed devices and model parameters are shared instead of actual data in a privacy-preserving manner. Unfortunately, FL is also vulnerable to attacks including parameter/data poisoning attacks. In this paper, we first analyze the impact of the data poisoning attack on this training method with a label-flipping attack. We propose a poisoning attack mitigation technique based on the reputation of nodes' involved in the training process. The reputation score for each client is calculated using the beta probability distribution method. This is the first work to show the removal of malicious nodes with the poisoned dataset from the training environment based on the calculated reputation score. The improvement in model performance after filtering malicious nodes is validated using the benchmark MNIST dataset. At the same time, our work contributes to preventing denial of service attacks by considering a blockchain-based server network. Our results hold for two different attack settings with different proportions of poisoned data samples.},
  eventtitle = {2021 {{IEEE Symposium Series}} on {{Computational Intelligence}} ({{SSCI}})},
  keywords = {Collaborative work,Computational modeling,Data models,Data poisoning attack,Data privacy,Distance learning,Filtering,reputation model,secure federated learning,Training}
}

@inproceedings{urrehman_BlockchainBasedReputationAwareFederated_2020,
  title = {Towards {{Blockchain-Based Reputation-Aware Federated Learning}}},
  booktitle = {{{IEEE INFOCOM}} 2020 - {{IEEE Conference}} on {{Computer Communications Workshops}} ({{INFOCOM WKSHPS}})},
  author = {family=Rehman, given=Muhammad Habib, prefix=ur, useprefix=true and Salah, Khaled and Damiani, Ernesto and Svetinovic, Davor},
  date = {2020-07},
  pages = {183--188},
  publisher = {IEEE},
  location = {Toronto, ON, Canada},
  doi = {10.1109/INFOCOMWKSHPS50562.2020.9163027},
  url = {https://ieeexplore.ieee.org/document/9163027/},
  urldate = {2021-10-29},
  abstract = {Federated learning (FL) is the collaborative machine learning (ML) technique whereby the devices collectively train and update a shared ML model while preserving their personal datasets. FL systems solve the problems of communicationefficiency, bandwidth-optimization, and privacy-preservation. Despite the potential benefits of FL, one centralized shared ML model across all the devices produce coarse-grained predictions which, in essence, are not required in many application areas involving personalized prediction services. In this paper, we present a novel concept of fine-grained FL to decentralize the shared ML models on the edge servers. We then present a formal extended definition of fine-grained FL process in mobile edge computing systems. In addition, we define the core requirements of finegrained FL systems including personalization, decentralization, fine-grained FL, incentive mechanisms, trust, activity monitoring, heterogeneity and context-awareness, model synchronization, and communication and bandwidth-efficiency. Moreover, we present the concept of blockchain-based reputation-aware fine-grained FL in order to ensure trustworthy collaborative training in mobile edge computing systems. Finally, we perform the qualitative comparison of proposed approach with state-of-the-art related work and found some promising initial results.},
  eventtitle = {{{IEEE INFOCOM}} 2020 - {{IEEE Conference}} on {{Computer Communications Workshops}} ({{INFOCOM WKSHPS}})},
  isbn = {978-1-72818-695-5},
  langid = {english},
  keywords = {\_read}
}

@inproceedings{urrehman_BlockchainBasedReputationAwareFederated_2020a,
  title = {Towards {{Blockchain-Based Reputation-Aware Federated Learning}}},
  booktitle = {{{IEEE INFOCOM}} 2020 - {{IEEE Conference}} on {{Computer Communications Workshops}} ({{INFOCOM WKSHPS}})},
  author = {family=Rehman, given=Muhammad Habib, prefix=ur, useprefix=true and Salah, Khaled and Damiani, Ernesto and Svetinovic, Davor},
  date = {2020-07},
  pages = {183--188},
  publisher = {IEEE},
  location = {Toronto, ON, Canada},
  doi = {10.1109/INFOCOMWKSHPS50562.2020.9163027},
  url = {https://ieeexplore.ieee.org/document/9163027/},
  urldate = {2021-10-29},
  abstract = {Federated learning (FL) is the collaborative machine learning (ML) technique whereby the devices collectively train and update a shared ML model while preserving their personal datasets. FL systems solve the problems of communicationefficiency, bandwidth-optimization, and privacy-preservation. Despite the potential benefits of FL, one centralized shared ML model across all the devices produce coarse-grained predictions which, in essence, are not required in many application areas involving personalized prediction services. In this paper, we present a novel concept of fine-grained FL to decentralize the shared ML models on the edge servers. We then present a formal extended definition of fine-grained FL process in mobile edge computing systems. In addition, we define the core requirements of finegrained FL systems including personalization, decentralization, fine-grained FL, incentive mechanisms, trust, activity monitoring, heterogeneity and context-awareness, model synchronization, and communication and bandwidth-efficiency. Moreover, we present the concept of blockchain-based reputation-aware fine-grained FL in order to ensure trustworthy collaborative training in mobile edge computing systems. Finally, we perform the qualitative comparison of proposed approach with state-of-the-art related work and found some promising initial results.},
  eventtitle = {{{IEEE INFOCOM}} 2020 - {{IEEE Conference}} on {{Computer Communications Workshops}} ({{INFOCOM WKSHPS}})},
  isbn = {978-1-72818-695-5},
  langid = {english},
  keywords = {\_read}
}

@article{vadigi_Federatedreinforcementlearning_2023,
  title = {Federated Reinforcement Learning Based Intrusion Detection System Using Dynamic Attention Mechanism},
  author = {Vadigi, Sreekanth and Sethi, Kamalakanta and Mohanty, Dinesh and Das, Shom Prasad and Bera, Padmalochan},
  date = {2023-11-01},
  journaltitle = {Journal of Information Security and Applications},
  shortjournal = {Journal of Information Security and Applications},
  volume = {78},
  pages = {103608},
  issn = {2214-2126},
  doi = {10.1016/j.jisa.2023.103608},
  url = {https://www.sciencedirect.com/science/article/pii/S2214212623001928},
  urldate = {2024-04-12},
  abstract = {Due to the recent advancements in the Internet of Things (IoT) and cloud computing technologies, the detection and prevention of intrusions in enterprise networks have become a crucial and challenging task. Real-time monitoring of network traffic and resources is required to protect those networks from intrusions. An Intrusion Detection System (IDS) analyses the data packets from the network and the system-level applications to detect any malicious activity. However, existing IDSs require all the data, collected at different network nodes, to be collated at one central location to perform the analysis for any model development. This approach hampers the data privacy at the network nodes as the data needs to be shared with other nodes. Furthermore, many of the existing IDSs are unable to adapt to evolving attack patterns, which may result in poor network vulnerability detection and significant degradation in the performance of the systems. To address these limitations, we present a Federated Deep Reinforcement Learning-based IDS in which multiple agents are deployed on the network in a distributed fashion, and each of these agents runs a Deep Q-Network logic. We considered the data privacy concerns of each agent while designing the system. In our system, the data at each agent node is not shared with any other nodes. At the same time, however, all the agents in the system benefit, via the attention weighted model aggregation process, from the distribution and pattern of the data available at all the other agents. We have also developed an attention mechanism that dynamically determines attention value of an agent, which is used in the model aggregation process. Our model can be scaled to large networks and is resistant to hardware or network failures at any agent node. We have tested and evaluated our proposed system on the cloud-based ISOT-CID dataset and the standard benchmark NSL-KDD dataset. The experimental findings demonstrate the performance and robustness of our proposed model in terms of metrics like accuracy, precision, false-positive rate, and area under the ROC curve.},
  keywords = {Deep Q-networks,Dynamic attention mechanism,Federated learning,Intrusion detection systems (IDS),Reinforcement learning}
}

@article{vaiyapuri_Metaheuristicsfederatedlearning_2023,
  title = {Metaheuristics with Federated Learning Enabled Intrusion Detection System in {{Internet}} of {{Things}} Environment},
  author = {Vaiyapuri, Thavavel and Algamdi, Shabbab and John, Rajan and Sbai, Zohra and Al-Helal, Munira and Alkhayyat, Ahmed and Gupta, Deepak},
  date = {2023},
  journaltitle = {Expert Systems},
  volume = {40},
  number = {5},
  pages = {e13138},
  issn = {1468-0394},
  doi = {10.1111/exsy.13138},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13138},
  urldate = {2024-04-12},
  abstract = {Because of increased applications of Internet of Things (IoT) environment in real-time environment, confidential data gathered by the IoT devices are being communicated to the cloud environment to train the machine learning (ML) models in understanding the patterns that exist in the data. At the same time, the sensitive nature of the IoT data attracts malicious users into hacking efforts. An intrusion detection system (IDS) can be applied to ensure security in the IoT environment. In order to improve security, the ML models can be executed at the data source instead of centralized cloud server. Federated learning (FL) is a recent progression of ML model which enables the ML models to move into the data source rather than moving the data to centralized cloud and thereby resolves cybersecurity problems in the IoT environment. In this view, this study introduces an FL based IDS using bird swarm algorithm based feature selection with classification (FLIDS-BSAFSC) model in IoT environment. The presented FLIDS-BSAFSC model undergoes training on multiple aspects of IoT dataset in a decentralized format to classify, detect, and defend against attacks. The proposed FLIDS-BSAFSC model initially applies min--max normalization technique to pre-process the IoT data. Besides, BSA based feature selection (BSA-FS) technique is designed to elect feature subsets. Finally, social group optimization algorithm with kernel extreme learning machine model is employed for identifying various kinds of classes. In the view of FL where the IoT dataset is not distributed to the server carries out profile aggregation competently with the advantage of peer learning. The experimental validation of the FLIDS-BSAFSC model is tested using benchmark datasets and the results are inspected under several aspects. The experimental values highlighted the better performance of the FLIDS-BSAFSC model over recent approaches.},
  langid = {english},
  keywords = {attack detection,cybersecurity,federated learning,Internet of Things,intrusion detection,machine learning}
}

@inproceedings{vakilinia_Attributebasedsharing_2017,
  title = {Attribute Based Sharing in Cybersecurity Information Exchange Framework},
  booktitle = {2017 {{International Symposium}} on {{Performance Evaluation}} of {{Computer}} and {{Telecommunication Systems}} ({{SPECTS}})},
  author = {Vakilinia, Iman and Tosh, Deepak K. and Sengupta, Shamik},
  date = {2017-07},
  volume = {49},
  number = {10},
  pages = {1--6},
  publisher = {IEEE},
  issn = {07359276},
  doi = {10.23919/SPECTS.2017.8046770},
  url = {http://ieeexplore.ieee.org/document/8046770/},
  abstract = {As the complexity of the cyber attacks are increasing, there is a growing demand for proactive defense against them. CYBersecurity information EXchange (CYBEX) is playing a crucial role to implement proactive defense. CYBEX conveys organizations' sensitive information which demands proper access control management. However, previous works in this area do not consider access control for CYBEX. In this work, we tackle the access control problem in CYBEX. We model the attribute based access control in CYBEX with a semi-trusted sharing server. To achieve attribute based access control in CYBEX, our mechanism is developed based on the concepts of ciphertext policy attribute based encryption (CP-ABE) [1] and STIX [2]. The mechanism's workflow is as follows, at the beginning users claim their attributes from attribute authorities, then a key generation center generates decryption keys for users based on their attributes. For the sharing, organizations embed access control to their shared data. This is conducted by encrypting sensitive information such that only users with appropriate attributes can decrypt them. Security analysis, implementation and performance evaluation indicate the effectiveness and efficiency of the mechanism.}
}

@inproceedings{vakilinia_coalitionalgametheory_2017,
  title = {A Coalitional Game Theory Approach for Cybersecurity Information Sharing},
  booktitle = {{{MILCOM}} 2017 - 2017 {{IEEE Military Communications Conference}} ({{MILCOM}})},
  author = {Vakilinia, Iman and Sengupta, Shamik},
  date = {2017-10},
  volume = {2017-Octob},
  pages = {237--242},
  publisher = {IEEE},
  doi = {10.1109/MILCOM.2017.8170845},
  url = {http://ieeexplore.ieee.org/document/8170845/},
  abstract = {As the complexity and number of cybersecurity incidents are growing, the traditional security measures are not sufficient to defend against attackers. In this situation, cyber threat intelligence capability substantially improves the detection and prevention of the sophisticated attacks. Cybersecurity information sharing is a key factor of threat intelligence, allowing organizations to detect and prevent malicious behaviors proactively. However, stimulating organizations to participate and deterring free-riding in such sharing is a big challenge. To this end, the sharing system should be equipped with a rewarding and participation-fee allocation mechanisms to encourage sharing behavior. In this paper, we investigate a rewarding and participation-fee calculation based on profit sharing in coalitional game theory. In particular, we formulate a coalitional game between organizations and analyze the well-known Shapley value and Nucleolus solution concepts in cybersecurity information sharing system.},
  isbn = {978-1-5386-0595-0}
}

@thesis{vakilinia_CollaborativeAnalysisCybersecurity_2019,
  title = {Collaborative {{Analysis}} of {{Cybersecurity Information Sharing}}},
  author = {Vakilinia, Iman},
  date = {2019},
  url = {http://hdl.handle.net/11714/5773},
  issue = {May}
}

@inproceedings{vakilinia_Privacypreservingcybersecurityinformation_2017,
  title = {Privacy-Preserving Cybersecurity Information Exchange Mechanism},
  booktitle = {2017 {{International Symposium}} on {{Performance Evaluation}} of {{Computer}} and {{Telecommunication Systems}} ({{SPECTS}})},
  author = {Vakilinia, Iman and Tosh, Deepak K. and Sengupta, Shamik},
  date = {2017-07},
  volume = {49},
  number = {10},
  pages = {1--7},
  publisher = {IEEE},
  issn = {07359276},
  doi = {10.23919/SPECTS.2017.8046783},
  url = {http://ieeexplore.ieee.org/document/8046783/},
  abstract = {Cybersecurity information sharing is improving cyber incident detection and prevention by reducing the loss caused by attacks and eliminating the costs of duplication efforts for cyber-defense. However, privacy is one of the major concerns of organizations, while they are gathering security information to share externally. In order to preserve the privacy of organizations in the cybersecurity information sharing framework, we propose a novel mechanism which consists of four components: (i) Registration, (ii) Sharing, (iii) Dispute, (iv) Rewarding. Our mechanism enables the organizations to share their cybersecurity information without revealing their identities. Besides, in order to encourage collaboration and prevent free-riding, rewards are issued anonymously in return for contributions. For this purpose, we are proposing a new aggregatable blind signature based on BBS+ signature scheme. Security analysis and performance evaluation are conducted showing the effectiveness and efficiency of the proposed mechanism.}
}

@article{vasilomanolakis_TaxonomySurveyCollaborative_2015,
  title = {Taxonomy and {{Survey}} of {{Collaborative Intrusion Detection}}},
  author = {Vasilomanolakis, Emmanouil and Karuppayah, Shankar and Fischer, Mathias},
  date = {2015-05},
  journaltitle = {ACM Computing Surveys},
  volume = {47},
  number = {4},
  pages = {33},
  doi = {10.1145/2716260},
  langid = {english},
  keywords = {\_processed,+survey}
}

@inproceedings{vasilomanolakis_TrustAwareCollaborativeIntrusion_2017,
  title = {Towards {{Trust-Aware Collaborative Intrusion Detection}}: {{Challenges}} and {{Solutions}}},
  shorttitle = {Towards {{Trust-Aware Collaborative Intrusion Detection}}},
  booktitle = {Trust {{Management XI}}},
  author = {Vasilomanolakis, Emmanouil and Habib, Sheikh Mahbub and Milaszewicz, Pavlos and Malik, Rabee Sohail and M\"uhlh\"auser, Max},
  editor = {Stegh\"ofer, Jan-Philipp and Esfandiari, Babak},
  date = {2017},
  series = {{{IFIP Advances}} in {{Information}} and {{Communication Technology}}},
  pages = {94--109},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-59171-1_8},
  abstract = {Collaborative Intrusion Detection Systems (CIDSs) are an emerging field in cyber-security. In such an approach, multiple sensors collaborate by exchanging alert data with the goal of generating a complete picture of the monitored network. This can provide significant improvements in intrusion detection and especially in the identification of sophisticated attacks. However, the challenge of deciding to which extend a sensor can trust others, has not yet been holistically addressed in related work. In this paper, we firstly propose a set of requirements for reliable trust management in CIDSs. Afterwards, we carefully investigate the most dominant CIDS trust schemes. The main contribution of the paper is mapping the results of the analysis to the aforementioned requirements, along with a comparison of the state of the art. Furthermore, this paper identifies and discusses the research gaps and challenges with regard to trust and CIDSs.},
  isbn = {978-3-319-59171-1},
  langid = {english},
  keywords = {Computational Trust,decay,Initial Trust,Intrusion Detection System,Trust Level,Trust Management}
}

@inproceedings{verma_DataQualitySecurity_2019,
  title = {Data {{Quality}} for {{Security Challenges}}: {{Case Studies}} of {{Phishing}}, {{Malware}} and {{Intrusion Detection Datasets}}},
  shorttitle = {Data {{Quality}} for {{Security Challenges}}},
  booktitle = {Proceedings of the 2019 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Verma, Rakesh M. and Zeng, Victor and Faridi, Houtan},
  date = {2019-11-06},
  pages = {2605--2607},
  publisher = {ACM},
  location = {London United Kingdom},
  doi = {10.1145/3319535.3363267},
  url = {https://dl.acm.org/doi/10.1145/3319535.3363267},
  urldate = {2022-08-12},
  abstract = {Techniques from data science are increasingly being applied by researchers to security challenges. However, challenges unique to the security domain necessitate painstaking care for the models to be valid and robust. In this paper, we explain key dimensions of data quality relevant for security, illustrate them with several popular datasets for phishing, intrusion detection and malware, indicate operational methods for assuring data quality and seek to inspire the audience to generate high quality datasets for security challenges.},
  eventtitle = {{{CCS}} '19: 2019 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  isbn = {978-1-4503-6747-9},
  langid = {english}
}

@article{verma_FLDIDFederatedLearning_2022,
  title = {{{FLDID}}: {{Federated Learning Enabled Deep Intrusion Detection}} in {{Smart Manufacturing Industries}}},
  shorttitle = {{{FLDID}}},
  author = {Verma, Priyanka and Breslin, John G. and O'Shea, Donna},
  date = {2022-11-19},
  journaltitle = {Sensors},
  shortjournal = {Sensors},
  volume = {22},
  number = {22},
  pages = {8974},
  issn = {1424-8220},
  doi = {10.3390/s22228974},
  url = {https://www.mdpi.com/1424-8220/22/22/8974},
  urldate = {2022-12-14},
  abstract = {The rapid development in manufacturing industries due to the introduction of IIoT devices has led to the emergence of Industry 4.0 which results in an industry with intelligence, increased efficiency and reduction in the cost of manufacturing. However, the introduction of IIoT devices opens up the door for a variety of cyber threats in smart industries. The detection of cyber threats against such extensive, complex, and heterogeneous smart manufacturing industries is very challenging due to the lack of sufficient attack traces. Therefore, in this work, a Federated Learning enabled Deep Intrusion Detection framework is proposed to detect cyber threats in smart manufacturing industries. The proposed FLDID framework allows multiple smart manufacturing industries to build a collaborative model to detect threats and overcome the limited attack example problem with individual industries. Moreover, to ensure the privacy of model gradients, Paillier-based encryption is used in communication between edge devices (representative of smart industries) and the server. The deep learning-based hybrid model, which consists of a Convolutional Neural Network, Long Short Term Memory, and Multi-Layer Perceptron is used in the intrusion detection model. An exhaustive set of experiments on the publically available dataset proves the effectiveness of the proposed framework for detecting cyber threats in smart industries over the state-of-the-art approaches.},
  langid = {english}
}

@article{verma_FLDIDFederatedLearning_2022a,
  title = {{{FLDID}}: {{Federated Learning Enabled Deep Intrusion Detection}} in {{Smart Manufacturing Industries}}},
  shorttitle = {{{FLDID}}},
  author = {Verma, Priyanka and Breslin, John G. and O'Shea, Donna},
  date = {2022-11-19},
  journaltitle = {Sensors},
  shortjournal = {Sensors},
  volume = {22},
  number = {22},
  pages = {8974},
  issn = {1424-8220},
  doi = {10.3390/s22228974},
  url = {https://www.mdpi.com/1424-8220/22/22/8974},
  urldate = {2024-04-12},
  abstract = {The rapid development in manufacturing industries due to the introduction of IIoT devices has led to the emergence of Industry 4.0 which results in an industry with intelligence, increased efficiency and reduction in the cost of manufacturing. However, the introduction of IIoT devices opens up the door for a variety of cyber threats in smart industries. The detection of cyber threats against such extensive, complex, and heterogeneous smart manufacturing industries is very challenging due to the lack of sufficient attack traces. Therefore, in this work, a Federated Learning enabled Deep Intrusion Detection framework is proposed to detect cyber threats in smart manufacturing industries. The proposed FLDID framework allows multiple smart manufacturing industries to build a collaborative model to detect threats and overcome the limited attack example problem with individual industries. Moreover, to ensure the privacy of model gradients, Paillier-based encryption is used in communication between edge devices (representative of smart industries) and the server. The deep learning-based hybrid model, which consists of a Convolutional Neural Network, Long Short Term Memory, and Multi-Layer Perceptron is used in the intrusion detection model. An exhaustive set of experiments on the publically available dataset proves the effectiveness of the proposed framework for detecting cyber threats in smart industries over the state-of-the-art approaches.},
  langid = {english}
}

@article{vu_Networkattacksdetection_InReview,
  title = {Network Attacks Detection across Infrastructures Using an Auto-Labeling Method and Network-Based {{Deep Inductive Transfer Learning}} Approach},
  author = {Vu, Dinh-Minh and Nguyen, Gia Bach and Tran, Hoang Hai},
  year = {In Review},
  doi = {10.21203/rs.3.rs-2554201/v1},
  url = {https://www.researchsquare.com/article/rs-2554201/v1},
  urldate = {2023-04-17},
  abstract = {An alarming number of cyber attacks have been witnessed in recent years, especially during COVID-19 epidemic. Many prevention measures have been proposed as a defense line for a network infrastructure, including Intrusion Detection System (IDS). A variance of IDS using Machine Learning and Deep Learning to detect network anomalies is gaining promising results. However, this approach also poses limitations regarding the indigenous dataset acquisition or the ability to apply a model learned from a benchmark dataset to different network infrastructures. Therefore, this paper proposes a reliable automatic labeling method for a new network dataset, and a Deep Transfer Learning model to detect both known and unknown attacks across different network infrastructures, then compares with other approaches.},
  langid = {english},
  keywords = {\_done,\_unpublished}
}

@online{vucovich_AnomalyDetectionFederated_2022,
  title = {Anomaly {{Detection}} via {{Federated Learning}}},
  author = {Vucovich, Marc and Tarcar, Amogh and Rebelo, Penjo and Gade, Narendra and Porwal, Ruchi and Rahman, Abdul and Redino, Christopher and Choi, Kevin and Nandakumar, Dhruv and Schiller, Robert and Bowen, Edward and West, Alex and Bhattacharya, Sanmitra and Veeramani, Balaji},
  date = {2022-10-12},
  eprint = {2210.06614},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2210.06614},
  urldate = {2022-10-18},
  abstract = {Machine learning has helped advance the field of anomaly detection by incorporating classifiers and autoencoders to decipher between normal and anomalous behavior. Additionally, federated learning has provided a way for a global model to be trained with multiple clients' data without requiring the client to directly share their data. This paper proposes a novel anomaly detector via federated learning to detect malicious network activity on a client's server. In our experiments, we use an autoencoder with a classifier in a federated learning framework to determine if the network activity is benign or malicious. By using our novel min-max scalar and sampling technique, called FedSam, we determined federated learning allows the global model to learn from each client's data and, in turn, provide a means for each client to improve their intrusion detection system's defense against cyber-attacks.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {\_read,Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@incollection{vy_FederatedLearningBasedIntrusion_2021,
  title = {Federated {{Learning-Based Intrusion Detection}} in the {{Context}} of {{IIoT Networks}}: {{Poisoning Attack}} and {{Defense}}},
  shorttitle = {Federated {{Learning-Based Intrusion Detection}} in the {{Context}} of {{IIoT Networks}}},
  booktitle = {Network and {{System Security}}},
  author = {Vy, Nguyen Chi and Quyen, Nguyen Huu and Duy, Phan The and Pham, Van-Hau},
  editor = {Yang, Min and Chen, Chao and Liu, Yang},
  date = {2021},
  volume = {13041},
  pages = {131--147},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-92708-0_8},
  url = {https://link.springer.com/10.1007/978-3-030-92708-0_8},
  urldate = {2024-03-05},
  abstract = {The emerging of Federated Learning (FL) paradigm in training has been drawn much attention from research community because of the demand of privacy preservation in widespread machine learning adoption. This is more serious in the context of industrial Internet of Things (IIoT) with the distributed data resources and the sensitive local data in each data owner. FL in IIoT context can help to ensure the sensitive data from being exploited by adversaries while facilitating the acceptable performance by aggregating additional knowledge from distributed collaborators. Sharing the similar trend, Intrusion detection system (IDS) leveraging the FL approach can encourage the cooperation in building an efficient privacy-preserving solution among multiple participants owning the sensitive network data. But a rogue collaborator can manipulate the local dataset and send malicious updates to the model aggregation, aiming to reduce the global model's prediction accuracy rate. The reason for this case is that the collaborator is a compromised participant, or due to the weak defenses of the local training device. This paper introduces a FL-based IDS, named Fed-IDS which facilitates collaborative training between many organizations to enhance their robustness against diverse and unknown attacks in the context of IIoT. Next, we perform the poisoning attack against such an IDS, including label-flipping strategy and Generative Adversarial Networks (GANs). Then, a validation approach is utilized as a countermeasure of rejecting the malicious updates to protect the global model from poisoning attacks. The experiments conducted on Kitsune, a real-world attack dataset, demonstrate the high effectiveness of the validation function in Fed-IDS framework against data poisoning.},
  isbn = {978-3-030-92707-3 978-3-030-92708-0},
  langid = {english}
}

@inproceedings{wagner_CyberThreatIntelligence_2019,
  title = {Cyber {{Threat Intelligence}} for ``{{Things}}''},
  booktitle = {2019 {{International Conference}} on {{Cyber Situational Awareness}}, {{Data Analytics And Assessment}} ({{Cyber SA}})},
  author = {Wagner, Thomas D},
  date = {2019-06},
  pages = {1--2},
  publisher = {IEEE},
  doi = {10.1109/CyberSA.2019.8899384},
  url = {https://ieeexplore.ieee.org/document/8899384/},
  abstract = {Cyber Threat Intelligence (CTI) programs have gained momentum across the cybersecurity community. Whether they are vendor based or open source solutions, practitioners should be able to find an appropriate solution to enhance security for their IT infrastructure. The tangible world, i.e. (Industrial) Internet of Things (I)IoT products and embedded components have not been considered yet in the CTI world with few exceptions from industry-specific vendors and Information Sharing Analysis Centres (ISACs). This extended abstract presents a work in progress to establish a CTI program for ``things'', especially the generation, consumption and distribution of product-specific CTI.},
  isbn = {978-1-72810-232-0}
}

@article{wagner_Cyberthreatintelligence_2019a,
  title = {Cyber Threat Intelligence Sharing: {{Survey}} and Research Directions},
  author = {Wagner, Thomas D. and Mahbub, Khaled and Palomar, Esther and Abdallah, Ali E.},
  date = {2019},
  journaltitle = {Computers \& Security},
  volume = {87},
  pages = {101589},
  issn = {01674048},
  doi = {10.1016/j.cose.2019.101589},
  abstract = {Cyber Threat Intelligence (CTI) sharing has become a novel weapon in the arsenal of cyber defenders to proactively mitigate increasing cyber attacks. Automating the process of CTI sharing, and even the basic consumption, has raised new challenges for researchers and practitioners. This extensive literature survey explores the current state-of-the-art and approaches different problem areas of interest pertaining to the larger field of sharing cyber threat intelligence. The motivation for this research stems from the recent emergence of sharing cyber threat intelligence and the involved challenges of automating its processes. This work comprises a considerable amount of articles from academic and gray literature, and focuses on technical and non-technical challenges. Moreover, the findings reveal which topics were widely discussed, and hence considered relevant by the authors and cyber threat intelligence sharing communities.}
}

@inproceedings{wagner_MISPdesignimplementation_2016,
  title = {{{MISP}} - {{The}} Design and Implementation of a Collaborative Threat Intelligence Sharing Platform},
  booktitle = {Proceedings of the 2016 {{ACM}} on {{Workshop}} on {{Information Sharing}} and {{Collaborative Security}} - {{WISCS}}'16},
  author = {Wagner, Cynthia and Dulaunoy, Alexandre and Wagener, G\'erard and Iklody, Andras},
  date = {2016},
  pages = {49--56},
  publisher = {ACM Press},
  location = {New York, New York, USA},
  doi = {10.1145/2994539.2994542},
  url = {http://dl.acm.org/citation.cfm?doid=2994539.2994542},
  abstract = {The IT community is confronted with incidents of all kinds and nature, new threats appear on a daily basis. Fighting these security incidents individually is almost impossible. Sharing information about threats among the community has become a key element in incident response to stay on top of the attackers. Reliable information resources, pro- viding credible information, are therefore essential to the IT community, or even at broader scale, to intelligence commu- nities or fraud detection groups. This paper presents the Malware Information Sharing Plat- form (MISP) and threat sharing project, a trusted platform, that allows the collection and sharing of important indica- tors of compromise (IoC) of targeted attacks, but also threat information like vulnerabilities or financial indicators used in fraud cases. The aim of MISP is to help in setting up preven- tive actions and counter-measures used against targeted at- tacks. Enable detection via collaborative-knowledge-sharing about existing malware and other threats.},
  isbn = {978-1-4503-4565-1}
}

@article{wagner_NovelTrustTaxonomy_2018,
  title = {A {{Novel Trust Taxonomy}} for {{Shared Cyber Threat Intelligence}}},
  author = {Wagner, Thomas D. and Palomar, Esther and Mahbub, Khaled and Abdallah, Ali E.},
  date = {2018-06-05},
  journaltitle = {Security and Communication Networks},
  shortjournal = {Security and Communication Networks},
  volume = {2018},
  pages = {1--11},
  issn = {1939-0114, 1939-0122},
  doi = {10.1155/2018/9634507},
  url = {https://www.hindawi.com/journals/scn/2018/9634507/},
  urldate = {2021-06-01},
  abstract = {Cyber threat intelligence sharing has become a focal point for many organizations to improve resilience against cyberattacks. The objective lies in sharing relevant information achieved through automating as many processes as possible without losing control or compromising security. The intelligence may be crowdsourced from decentralized stakeholders to collect and enrich existing information. Trust is an attribute of actionable cyber threat intelligence that has to be established between stakeholders. Sharing information about vulnerabilities requires a high level of trust because of the sensitive information. Some threat intelligence platforms/providers support trust establishment through internal vetting processes; others rely on stakeholders to manually build up trust. The latter may reduce the amount of intelligence sources. This work presents a novel trust taxonomy to establish a trusted threat sharing environment. 30 popular threat intelligence platforms/providers were analyzed and compared regarding trust functionalities. Trust taxonomies were analyzed and compared. Illustrative case studies were developed and analyzed applying our trust taxonomy.},
  langid = {english}
}

@article{wan_BlockchainBasedSolutionEnhancing_2019,
  title = {A {{Blockchain-Based Solution}} for {{Enhancing Security}} and {{Privacy}} in {{Smart Factory}}},
  author = {Wan, Jiafu and Li, Jiapeng and Imran, Muhammad and Li, Di and {Fazal-e-Amin}},
  date = {2019-06},
  journaltitle = {IEEE Transactions on Industrial Informatics},
  volume = {15},
  number = {6},
  pages = {3652--3660},
  issn = {1551-3203},
  doi = {10.1109/TII.2019.2894573},
  url = {https://ieeexplore.ieee.org/document/8621042/},
  abstract = {Through the Industrial Internet of Things (IIoT), a smart factory has entered the booming period. However, as the number of nodes and network size become larger, the traditional IIoT architecture can no longer provide effective support for such enormous system. Therefore, we introduce the Blockchain architecture, which is an emerging scheme for constructing the distributed networks, to reshape the traditional IIoT architecture. First, the major problems of the traditional IIoT architecture are analyzed, and the existing improvements are summarized. Second, we introduce a security and privacy model to help design the Blockchain-based architecture. On this basis, we decompose and reorganize the original IIoT architecture to form a new multicenter partially decentralized architecture. Then, we introduce some relative security technologies to improve and optimize the new architecture. After that we design the data interaction process and the algorithms of the architecture. Finally, we use an automatic production platform to discuss the specific implementation. The experimental results show that the proposed architecture provides better security and privacy protection than the traditional architecture. Thus, the proposed architecture represents a significant improvement of the original architecture, which provides a new direction for the IIoT development.}
}

@article{wang_AIEmpoweredTrajectoryAnomaly_2023,
  title = {{{AI-Empowered Trajectory Anomaly Detection}} for {{Intelligent Transportation Systems}}: {{A Hierarchical Federated Learning Approach}}},
  shorttitle = {{{AI-Empowered Trajectory Anomaly Detection}} for {{Intelligent Transportation Systems}}},
  author = {Wang, Xiaoding and Liu, Wenxin and Lin, Hui and Hu, Jia and Kaur, Kuljeet and Hossain, M. Shamim},
  date = {2023-04},
  journaltitle = {IEEE Transactions on Intelligent Transportation Systems},
  volume = {24},
  number = {4},
  pages = {4631--4640},
  issn = {1558-0016},
  doi = {10.1109/TITS.2022.3209903},
  url = {https://ieeexplore.ieee.org/abstract/document/9929438},
  urldate = {2024-04-12},
  abstract = {The vigorous development of positioning technology and ubiquitous computing has spawned trajectory big data. By analyzing and processing the trajectory big data in the form of data streams in a timely and effective manner, anomalies hidden in the trajectory data can be found, thus serving urban planning, traffic management, safety control and other applications. Limited by the inherent uncertainty, infinity, time-varying evolution, sparsity and skewed distribution of trajectory big data, traditional anomaly detection techniques cannot be directly applied to anomaly detection in trajectory big data. To solve this problem, we propose a hierarchical trajectory anomaly detection scheme for Intelligent Transportation Systems (ITS) using both machine learning and blockchain technologies. To be specific, a hierarchical federated learning strategy is proposed to improve the generalization ability of the global trajectory anomaly detection model by secondary fusion of the multi-area trajectory anomaly detection model. Then, by integrating blockchain and federated learning, the iterative exchange and fusion of the global trajectory anomaly detection model can be realized by means of on-chain and off-chain coordinated data access. Experiments show that the proposed scheme can improve the generalization ability of the trajectory anomaly detection model in different areas, while ensuring its reliability.},
  eventtitle = {{{IEEE Transactions}} on {{Intelligent Transportation Systems}}},
  keywords = {Anomaly detection,Big Data,blockchain,Data models,federated learning,intelligent transportation systems,Machine learning algorithms,Roads,Trajectory,Uncertainty}
}

@article{wang_BlockchainIoTindustrial_2020,
  title = {Blockchain for the {{IoT}} and Industrial {{IoT}}: {{A}} Review},
  author = {Wang, Qin and Zhu, Xinqi and Ni, Yiyang and Gu, Li and Zhu, Hongbo},
  date = {2020-06},
  journaltitle = {Internet of Things},
  volume = {10},
  number = {66},
  pages = {100081},
  issn = {25426605},
  doi = {10.1016/j.iot.2019.100081},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S254266051930085X},
  abstract = {The Internet of Things (IoT), especially the industrial IoT (IIoT), has rapidly developed and is receiving a lot of attention in academic areas and industry, but IoT privacy risks and security vulnerabilities are emerging from lack of fundamental security technology. The blockchain technique, due to its decentralization and information disclosure, was proposed as a decentralized and distributed approach to guarantee security requirements and motivate the development of the IoT and IIoT. In this paper, we first introduce the basic structure and main features of blockchain and summarize the security requirements to develop IoT and Industry 4.0. Then, we explore how blockchain can be applied to the IoT for Industry 4.0 using its security tools and technology. We describe the most relevant blockchain-based IoT applications to promote the functions and advantages of the blockchain technique on IoT and IIoT platforms. Finally, some recommendations are proposed to guide future blockchain researchers and developers.}
}

@inproceedings{wang_CMFLMitigatingCommunication_2019,
  title = {{{CMFL}}: {{Mitigating Communication Overhead}} for {{Federated Learning}}},
  shorttitle = {{{CMFL}}},
  booktitle = {2019 {{IEEE}} 39th {{International Conference}} on {{Distributed Computing Systems}} ({{ICDCS}})},
  author = {Wang, Luping and Wang, Wei and Li, Bo},
  date = {2019-07},
  pages = {954--964},
  publisher = {IEEE},
  location = {Dallas, TX, USA},
  doi = {10/ggv8zc},
  url = {https://ieeexplore.ieee.org/document/8885054/},
  urldate = {2022-02-08},
  abstract = {Federated Learning enables mobile users to collaboratively learn a global prediction model by aggregating their individual updates without sharing the privacy-sensitive data. As mobile devices usually have limited data plan and slow network connections to the central server where the global model is maintained, mitigating the communication overhead is of paramount importance. While existing works mainly focus on reducing the total bits transferred in each update via data compression, we study an orthogonal approach that identifies irrelevant updates made by clients and precludes them from being uploaded for reduced network footprint. Following this idea, we propose Communication-Mitigated Federated Learning (CMFL) in this paper. CMFL provides clients with the feedback information regarding the global tendency of model updating. Each client checks if its update aligns with this global tendency and is relevant enough to model improvement. By avoiding uploading those irrelevant updates to the server, CMFL can substantially reduce the communication overhead while still guaranteeing the learning convergence. CMFL is shown to achieve general improvement in communication efficiency for almost all of the existing federated learning schemes. We evaluate CMFL through extensive simulations and EC2 emulations. Compared with vanilla Federated Learning, CMFL yields 13.97x communication efficiency in terms of the reduction of network footprint. When applied to Federated Multi-Task Learning, CMFL improves the communication efficiency by 5.7x with 4\% higher prediction accuracy.},
  eventtitle = {2019 {{IEEE}} 39th {{International Conference}} on {{Distributed Computing Systems}} ({{ICDCS}})},
  isbn = {978-1-72812-519-0},
  langid = {english}
}

@article{wang_DimensionReductionTechnique_2022,
  title = {Dimension {{Reduction Technique Based}} on {{Supervised Autoencoder}} for {{Intrusion Detection}} of {{Industrial Control Systems}}},
  author = {Wang, Chao and Liu, Hongri and Sun, Yunxiao and Wei, Yuliang and Wang, Kai and Wang, Bailing},
  editor = {Zhaoquan, Gu},
  date = {2022-06-10},
  journaltitle = {Security and Communication Networks},
  shortjournal = {Security and Communication Networks},
  volume = {2022},
  pages = {1--12},
  issn = {1939-0122, 1939-0114},
  doi = {10.1155/2022/5713074},
  url = {https://www.hindawi.com/journals/scn/2022/5713074/},
  urldate = {2022-07-05},
  abstract = {Industrial control systems (ICSs) are closely related to human life. In recent years, many ICSs have been connected to the Internet rather than being physically isolated, which has improved business efficiency while also increasing the risks of being attacked. The security issues of ICSs have gotten a lot of interest in the research community because attack events that aim at ICSs can cause catastrophic damage. An intrusion detection system (IDS) serves as an important tool for providing protection. Many IDS studies using machine learning and deep learning have been proposed. However, high-dimensional data may cause overfitting, resulting in inferior performance. To improve the classification performance, we suggest a dimension reduction technique based on the supervised autoencoder (SupervisedAE) and principal components analysis (PCA) in this study. To obtain more discriminative latent representations, compared with the conventional autoencoder, the SupervisedAE absorbs the label information during the training process. In this way, the improved autoencoder model is trained with reconstruction error and classification error simultaneously. Based on the latent representations extracted from the SupervisedAE, we add the PCA algorithm. The additional PCA algorithm reduces the dimension of features further. We conduct a series of experiments utilizing the suggested technique on a public power system data set to evaluate the performance. Compared with various dimension reduction methods, including autoencoder variants, the technique proposed in this study shows higher performance. In the meanwhile, it outperforms some existing detection methods in terms of accuracy and F1 score.},
  langid = {english}
}

@article{wang_EfficientIntrusionDetection_2022,
  title = {An {{Efficient Intrusion Detection Method Based}} on {{Federated Transfer Learning}} and an {{Extreme Learning Machine}} with {{Privacy Preservation}}},
  author = {Wang, Kunpeng and Li, Jingmei and Wu, Weifei},
  editor = {Nazir, Shah},
  date = {2022-10-11},
  journaltitle = {Security and Communication Networks},
  shortjournal = {Security and Communication Networks},
  volume = {2022},
  pages = {1--13},
  issn = {1939-0122, 1939-0114},
  doi = {10.1155/2022/2913293},
  url = {https://www.hindawi.com/journals/scn/2022/2913293/},
  urldate = {2024-04-12},
  abstract = {Current network security is becoming increasingly important, and intrusion detection is an effective method to protect the network from malicious attacks. This study proposes an intrusion detection algorithm FLTrELM based on federated transfer learning and an extreme learning machine to improve the effect of intrusion detection, which implements data aggregation through federated learning and facilitates the construction of personalized transfer learning for all organizations. FLTrELM first builds a transfer extreme learning machine model to solve the problem of insufficient samples and probability adaptation, then uses the model to learn to protect data privacy without sharing training data under the federated learning mechanism, and finally obtains an intrusion detection model. Experiments on the NSL-KDD, KDD99, and ISCX2012 datasets verify that the proposed method can achieve better detection results and robust performance, especially for small samples and new intrusions, and protects data privacy.},
  langid = {english}
}

@inproceedings{wang_ENIDriftFastAdaptive_2022,
  title = {{{ENIDrift}}: {{A Fast}} and {{Adaptive Ensemble System}} for {{Network Intrusion Detection}} under {{Real-world Drift}}},
  shorttitle = {{{ENIDrift}}},
  booktitle = {Proceedings of the 38th {{Annual Computer Security Applications Conference}}},
  author = {Wang, Xian},
  date = {2022-12-05},
  series = {{{ACSAC}} '22},
  pages = {785--798},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3564625.3567992},
  url = {https://doi.org/10.1145/3564625.3567992},
  urldate = {2022-12-14},
  abstract = {Machine Learning (ML) techniques have been widely applied for network intrusion detection. However, existing ML-based network intrusion detection systems (NIDSs) suffer from fundamental limitations that hinder them from being deployed in the real world. They consider a narrow scope rather than real-world drift that involves dynamically distributed network packets and well-crafted ML attacks. Besides, they pose high runtime overhead and have low processing speed. In this paper, we solve the limitations and design ENIDrift, a fast and adaptive ensemble system for real-world network intrusion detection. ENIDrift employs iP2V, a novel incremental feature extraction method based on network packet fields, which adopts a simple three-layer neural network with relatively lightweight computation and achieves high efficiency. ENIDrift uses a stable sub-classifier generation module that constructs new sub-classifiers based on the stability and accuracy of incoming data chunks, and its training time is reduced from to . We extend the threat model and place experiments in real-world settings. We make the first real-world drift dataset, RWDIDS, which contains intense and different drifts for NIDS. Our extensive evaluation under real-world drift demonstrates that ENIDrift significantly outperforms the state-of-the-art solutions by up to 69.78\% of F1 and reduces running time by 87.6\%. ENIDrift achieves a 100\% F1 against our adversarial attack and is adaptive to various real-world drifts. Our field test also shows ENIDrift functions well even with delayed, inadequate training data, which is practical for real-world usage.},
  isbn = {978-1-4503-9759-9},
  keywords = {Anomaly Detection,Concept Drift,Ensemble Learning,Network Intrusion Detection,Network Security}
}

@inproceedings{wang_FeCoBoostingIntrusion_2022,
  title = {{{FeCo}}: {{Boosting Intrusion Detection Capability}} in {{IoT Networks}} via {{Contrastive Learning}}},
  shorttitle = {{{FeCo}}},
  booktitle = {{{IEEE INFOCOM}} 2022 - {{IEEE Conference}} on {{Computer Communications}}},
  author = {Wang, Ning and Chen, Yimin and Hu, Yang and Lou, Wenjing and Hou, Y. Thomas},
  date = {2022-05},
  pages = {1409--1418},
  issn = {2641-9874},
  doi = {10.1109/INFOCOM48880.2022.9796926},
  abstract = {Over the last decade, Internet of Things (IoT) has permeated our daily life with a broad range of applications. However, a lack of sufficient security features in IoT devices renders IoT ecosystems vulnerable to various network intrusion attacks, potentially causing severe damage. Previous works have explored using machine learning to build anomaly detection models for defending against such attacks. In this paper, we propose FeCo, a federated-contrastive-learning framework that coordinates in-network IoT devices to jointly learn intrusion detection models. FeCo utilizes federated learning to alleviate users' privacy concerns as participating devices only submit their model parameters rather than local data. Compared to previous works, we develop a novel representation learning method based on contrastive learning that is able to learn a more accurate model for the benign class. FeCo significantly improves the intrusion detection accuracy compared to previous works. Besides, we implement a two-step feature selection scheme to avoid overfitting and reduce computation time. Through extensive experiments on the NSL-KDD dataset, we demonstrate that FeCo achieves as high as 8\% accuracy improvement compared to the state-of-the-art and is robust to non-IID data. Evaluations on convergence, computation overhead, and scalability further confirm the suitability of FeCo for IoT intrusion detection.},
  eventtitle = {{{IEEE INFOCOM}} 2022 - {{IEEE Conference}} on {{Computer Communications}}},
  keywords = {Biological system modeling,Data privacy,Feature extraction,Intrusion detection,Representation learning,Scalability,Telecommunication traffic}
}

@article{wang_Federateddeeplearning_2023,
  title = {Federated Deep Learning for Anomaly Detection in the Internet of Things},
  author = {Wang, Xiaofeng and Wang, Yonghong and Javaheri, Zahra and Almutairi, Laila and Moghadamnejad, Navid and Younes, Osama S.},
  date = {2023-05-01},
  journaltitle = {Computers and Electrical Engineering},
  shortjournal = {Computers and Electrical Engineering},
  volume = {108},
  pages = {108651},
  issn = {0045-7906},
  doi = {10.1016/j.compeleceng.2023.108651},
  url = {https://www.sciencedirect.com/science/article/pii/S0045790623000769},
  urldate = {2024-04-12},
  abstract = {Privacy has emerged as a top worry as a result of the development of zero-day hacks because IoT devices produce and transmit sensitive information through the regular internet. This study suggests a deep neural network (DNN) and federated learning (FL) for an IoT network as well as mutual information (MI) for an effective anomaly detection method. The suggested method is different from the conventional model by use of decentralized on-device data to spot IoT network incursions. The information is kept on localized IoT devices for model training and only modified weights are shared in the centralized FL server is an advantage of integrating FL with Deep learning (DL). It uses the IoT-Botnet 2020 dataset for evaluation. Results demonstrate the efficiency of the DNN-based network intrusion detection system (NIDS) in comparison to the deep learning models with improvement in the accuracy of the model and a reduction in the False Alarm rate (FAR).},
  keywords = {Anomaly detection,Cyber-physical system,Deep learning,DNN,Federated learning,IoT environment,Network-based intrusion detection system,Security}
}

@inproceedings{wang_FederatedFewshotLearning_2023,
  title = {Federated {{Few-shot Learning}}},
  booktitle = {Proceedings of the 29th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Wang, Song and Fu, Xingbo and Ding, Kaize and Chen, Chen and Chen, Huiyuan and Li, Jundong},
  date = {2023-08-04},
  series = {{{KDD}} '23},
  pages = {2374--2385},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3580305.3599347},
  url = {https://dl.acm.org/doi/10.1145/3580305.3599347},
  urldate = {2024-06-17},
  abstract = {Federated Learning (FL) enables multiple clients to collaboratively learn a machine learning model without exchanging their own local data. In this way, the server can exploit the computational power of all clients and train the model on a larger set of data samples among all clients. Although such a mechanism is proven to be effective in various fields, existing works generally assume that each client preserves sufficient data for training. In practice, however, certain clients can only contain a limited number of samples (i.e., few-shot samples). For example, the available photo data taken by a specific user with a new mobile device is relatively rare. In this scenario, existing FL efforts typically encounter a significant performance drop on these clients. Therefore, it is urgent to develop a few-shot model that can generalize to clients with limited data under the FL scenario. In this paper, we refer to this novel problem as federated few-shot learning. Nevertheless, the problem remains challenging due to two major reasons: the global data variance among clients (i.e., the difference in data distributions among clients) and the local data insufficiency in each client (i.e., the lack of adequate local data for training). To overcome these two challenges, we propose a novel federated few-shot learning framework with two separately updated models and dedicated training strategies to reduce the adverse impact of global data variance and local data insufficiency. Extensive experiments on four prevalent datasets that cover news articles and images validate the effectiveness of our framework compared with the state-of-the-art baselines.},
  isbn = {9798400701030},
  keywords = {federated learning,few-shot learning,knowledge distillation}
}

@online{wang_FederatedMultiDiscriminatorBiWGANGP_2022,
  title = {Federated {{Multi-Discriminator BiWGAN-GP}} Based {{Collaborative Anomaly Detection}} for {{Virtualized Network Slicing}}},
  author = {Wang, Weili and Liang, Chengchao and Tang, Lun and Yanikomeroglu, Halim and Chen, Qianbin},
  date = {2022-08-16},
  eprint = {2208.07985},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2208.07985},
  urldate = {2022-09-09},
  abstract = {Virtualized network slicing allows a multitude of logical networks to be created on a common substrate infrastructure to support diverse services. A virtualized network slice is a logical combination of multiple virtual network functions, which run on virtual machines (VMs) as software applications by virtualization techniques. As the performance of network slices hinges on the normal running of VMs, detecting and analyzing anomalies in VMs are critical. Based on the three-tier management framework of virtualized network slicing, we first develop a federated learning (FL) based three-tier distributed VM anomaly detection framework, which enables distributed network slice managers to collaboratively train a global VM anomaly detection model while keeping metrics data locally. The high-dimensional, imbalanced, and distributed data features in virtualized network slicing scenarios invalidate the existing anomaly detection models. Considering the powerful ability of generative adversarial network (GAN) in capturing the distribution from complex data, we design a new multi-discriminator Bidirectional Wasserstein GAN with Gradient Penalty (BiWGAN-GP) model to learn the normal data distribution from high-dimensional resource metrics datasets that are spread on multiple VM monitors. The multi-discriminator BiWGAN-GP model can be trained over distributed data sources, which avoids high communication and computation overhead caused by the centralized collection and processing of local data. We define an anomaly score as the discriminant criterion to quantify the deviation of new metrics data from the learned normal distribution to detect abnormal behaviors arising in VMs. The efficiency and effectiveness of the proposed collaborative anomaly detection algorithm are validated through extensive experimental evaluation on a real-world dataset.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Networking and Internet Architecture}
}

@inproceedings{wang_FLAREDefendingFederated_2022,
  title = {{{FLARE}}: {{Defending Federated Learning}} against {{Model Poisoning Attacks}} via {{Latent Space Representations}}},
  shorttitle = {{{FLARE}}},
  booktitle = {Proceedings of the 2022 {{ACM}} on {{Asia Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Wang, Ning and Xiao, Yang and Chen, Yimin and Hu, Yang and Lou, Wenjing and Hou, Y. Thomas},
  date = {2022-05-30},
  pages = {946--958},
  publisher = {ACM},
  location = {Nagasaki Japan},
  doi = {10.1145/3488932.3517395},
  url = {https://dl.acm.org/doi/10.1145/3488932.3517395},
  urldate = {2022-07-05},
  abstract = {Federated learning (FL) has been shown vulnerable to a new class of adversarial attacks, known as model poisoning attacks (MPA), where one or more malicious clients try to poison the global model by sending carefully crafted local model updates to the central parameter server. Existing defenses that have been fixated on analyzing model parameters show limited effectiveness in detecting such carefully crafted poisonous models. In this work, we propose FLARE, a robust model aggregation mechanism for FL, which is resilient against state-of-the-art MPAs. Instead of solely depending on model parameters, FLARE leverages the penultimate layer representations (PLRs) of the model for characterizing the adversarial influence on each local model update. PLRs demonstrate a better capability to differentiate malicious models from benign ones than model parameter-based solutions. We further propose a trust evaluation method that estimates a trust score for each model update based on pairwise PLR discrepancies among all model updates. Under the assumption that honest clients make up the majority, FLARE assigns a trust score to each model update in a way that those far from the benign cluster are assigned low scores. FLARE then aggregates the model updates weighted by their trust scores and finally updates the global model. Extensive experimental results demonstrate the effectiveness of FLARE in defending FL against various MPAs, including semantic backdoor attacks, trojan backdoor attacks, and untargeted attacks, and safeguarding the accuracy of FL.},
  eventtitle = {{{ASIA CCS}} '22: {{ACM Asia Conference}} on {{Computer}} and {{Communications Security}}},
  isbn = {978-1-4503-9140-5},
  langid = {english}
}

@inproceedings{wang_FLAREDefendingFederated_2022a,
  title = {{{FLARE}}: {{Defending Federated Learning}} against {{Model Poisoning Attacks}} via {{Latent Space Representations}}},
  shorttitle = {{{FLARE}}},
  booktitle = {Proceedings of the 2022 {{ACM}} on {{Asia Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Wang, Ning and Xiao, Yang and Chen, Yimin and Hu, Yang and Lou, Wenjing and Hou, Y. Thomas},
  date = {2022-05-30},
  pages = {946--958},
  publisher = {ACM},
  location = {Nagasaki Japan},
  doi = {10.1145/3488932.3517395},
  url = {https://dl.acm.org/doi/10.1145/3488932.3517395},
  urldate = {2022-07-05},
  abstract = {Federated learning (FL) has been shown vulnerable to a new class of adversarial attacks, known as model poisoning attacks (MPA), where one or more malicious clients try to poison the global model by sending carefully crafted local model updates to the central parameter server. Existing defenses that have been fixated on analyzing model parameters show limited effectiveness in detecting such carefully crafted poisonous models. In this work, we propose FLARE, a robust model aggregation mechanism for FL, which is resilient against state-of-the-art MPAs. Instead of solely depending on model parameters, FLARE leverages the penultimate layer representations (PLRs) of the model for characterizing the adversarial influence on each local model update. PLRs demonstrate a better capability to differentiate malicious models from benign ones than model parameter-based solutions. We further propose a trust evaluation method that estimates a trust score for each model update based on pairwise PLR discrepancies among all model updates. Under the assumption that honest clients make up the majority, FLARE assigns a trust score to each model update in a way that those far from the benign cluster are assigned low scores. FLARE then aggregates the model updates weighted by their trust scores and finally updates the global model. Extensive experimental results demonstrate the effectiveness of FLARE in defending FL against various MPAs, including semantic backdoor attacks, trojan backdoor attacks, and untargeted attacks, and safeguarding the accuracy of FL.},
  eventtitle = {{{ASIA CCS}} '22: {{ACM Asia Conference}} on {{Computer}} and {{Communications Security}}},
  isbn = {978-1-4503-9140-5},
  langid = {english}
}

@article{wang_NetConfEvalCanLLMs_2024,
  title = {{{NetConfEval}}: {{Can LLMs Facilitate Network Configuration}}?},
  shorttitle = {{{NetConfEval}}},
  author = {Wang, Changjie and Scazzariello, Mariano and Farshin, Alireza and Ferlin, Simone and Kosti\'c, Dejan and Chiesa, Marco},
  date = {2024-06-13},
  journaltitle = {Proc. ACM Netw.},
  volume = {2},
  pages = {7:1--7:25},
  doi = {10.1145/3656296},
  url = {https://doi.org/10.1145/3656296},
  urldate = {2024-07-07},
  abstract = {This paper explores opportunities to utilize Large Language Models (LLMs) to make network configuration human-friendly, simplifying the configuration of network devices \&amp; development of routing algorithms and minimizing errors. We design a set of benchmarks (NetConfEval) to examine the effectiveness of different models in facilitating and automating network configuration. More specifically, we focus on the scenarios where LLMs translate high-level policies, requirements, and descriptions (i.e., specified in natural language) into low-level network configurations \&amp; Python code. NetConfEval considers four tasks that could potentially facilitate network configuration, such as (i) generating high-level requirements into a formal specification format, (ii) generating API/function calls from high-level requirements, (iii) developing routing algorithms based on high-level descriptions, and (iv) generating low-level configuration for existing and new protocols based on input documentation. Learning from the results of our study, we propose a set of principles to design LLM-based systems to configure networks. Finally, we present two GPT-4-based prototypes to (i) automatically configure P4-enabled devices from a set of high-level requirements and (ii) integrate LLMs into existing network synthesizers.},
  issue = {CoNEXT2}
}

@inproceedings{wang_NovelReputationawareClient_2020,
  title = {A {{Novel Reputation-aware Client Selection Scheme}} for {{Federated Learning}} within {{Mobile Environments}}},
  booktitle = {2020 {{IEEE}} 25th {{International Workshop}} on {{Computer Aided Modeling}} and {{Design}} of {{Communication Links}} and {{Networks}} ({{CAMAD}})},
  author = {Wang, Yuwei and Kantarci, Burak},
  date = {2020-09},
  pages = {1--6},
  issn = {2378-4873},
  doi = {10.1109/CAMAD50429.2020.9209263},
  abstract = {This paper studies the problem of training federated deep learning models over a mobile environment. Stemming from the federated learning (FL) concept, deep learning models on mobile devices can be trained for various use cases including but not limited to image sorting and prediction of upcoming words. Mobile devices have access to rich data sets through embedded sensors and as well as installed software, and these feature rich data can facilitate solid training models, including personal images and other behaviometric features. However, utilizing the data through conventional approaches can potentially lead to privacy leakages. In this paper, we propose an alternate strategy that builds on the Federated Learning (FL) concept, to keep the training data on distributed mobile devices, and train a shared model by aggregating updated local models. The contribution of this study is an optimal user selection method for the federated learning environment based on reputation scores. Through extensive validation experiments considering two different model architectures and three datasets, our experiments show that the proposed approach is stable over data that is not independent nor identically distributed (i.e., non-IID) and under imbalanced distribution. Experimental results show that the proposed reputation-aware FL scheme can achieve improvements in the test accuracy up to 9.30\% under different data sets.},
  eventtitle = {2020 {{IEEE}} 25th {{International Workshop}} on {{Computer Aided Modeling}} and {{Design}} of {{Communication Links}} and {{Networks}} ({{CAMAD}})},
  keywords = {client selection,Computational modeling,Data models,Data privacy,data sharing,deep learning models,Federated learning,Machine learning,Mobile handsets,mobile networks,Servers,Training}
}

@inproceedings{wang_ReputationenabledFederatedLearning_2021,
  title = {Reputation-Enabled {{Federated Learning Model Aggregation}} in {{Mobile Platforms}}},
  booktitle = {{{ICC}} 2021 - {{IEEE International Conference}} on {{Communications}}},
  author = {Wang, Yuwei and Kantarci, Burak},
  date = {2021-06},
  pages = {1--6},
  issn = {1938-1883},
  doi = {10.1109/ICC42927.2021.9500928},
  abstract = {Federated Learning (FL) builds on a mobile network of participating nodes that train local models and contribute to the learning model parameters at a central server without being obliged to share their raw data. The server aggregates the uploaded model parameters to generate a global model. Common practice for the uploaded local models is an evenly weighted aggregation, assuming that each node of the network contributes to advancing the global model equally. Due to the heterogeneous nature of the devices and collected data, it is inevitable to have variations between the contributions of the users to the global model. Therefore, users (i.e., devices) with higher contributions should be weighted higher during aggregation. With this in mind, this paper proposes a reputation-enabled aggregation methodology that scales the aggregation weights of users by their reputation scores. Reputation score of a user is computed according to the performance metrics of their trained local models during each training round, therefore it can be a metric to evaluate the direct contributions of their trained local model. Numerical comparison of the proposed aggregation methodology to a baseline that utilizes standard averaging as well as a second baseline that is scoped to a reputation-based client selection shows an improvement of 17.175\% over the standard baseline for not independent and identically distributed (non-IID) scenarios for an FL network of 100 participants. Consistent improvements over the first and second baselines under smaller FL networks with users ranging from 20 to 100 are also shown.},
  eventtitle = {{{ICC}} 2021 - {{IEEE International Conference}} on {{Communications}}},
  keywords = {Collaborative work,Computational modeling,Data aggregation,Data models,Deep Learning,Deep Neural Networks,Distance measurement,Distributed Learning,Federated Learning,Mobile Networks,Neural networks,Reputation systems,Training}
}

@article{wang_RFLBATRobustFederated_2022,
  title = {{{RFLBAT}}: {{A Robust Federated Learning Algorithm}} against {{Backdoor Attack}}},
  shorttitle = {{{RFLBAT}}},
  author = {Wang, Yongkang and Zhai, Dihua and Zhan, Yufeng and Xia, Yuanqing},
  date = {2022-01-11},
  journaltitle = {ArXiv},
  url = {https://www.semanticscholar.org/paper/e2b38f5d7218b00690201fc608d8f20b283d902f},
  urldate = {2024-04-02},
  abstract = {Federated learning (FL) is a distributed machine learning paradigm where enormous scattered clients (e.g. mobile devices or IoT devices) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized. Unfortunately, FL is susceptible to a variety of attacks, including backdoor attack, which is made substantially worse in the presence of malicious attackers. Most of algorithms usually assume that the malicious at tackers no more than benign clients or the data distribution is independent identically distribution (IID). However, no one knows the number of malicious attackers and the data distribution is usually non identically distribution (Non-IID). In this paper, we propose RFLBAT which utilizes principal component analysis (PCA) technique and Kmeans clustering algorithm to defend against backdoor attack. Our algorithm RFLBAT does not bound the number of backdoored attackers and the data distribution, and requires no auxiliary information outside of the learning process. We conduct extensive experiments including a variety of backdoor attack types. Experimental results demonstrate that RFLBAT outperforms the existing state-of-the-art algorithms and is able to resist various backdoor attack scenarios including different number of attackers (DNA), different Non-IID scenarios (DNS), different number of clients (DNC) and distributed backdoor attack (DBA).}
}

@article{wang_Safeguardingcrosssilofederated_2021,
  title = {Safeguarding Cross-Silo Federated Learning with Local Differential Privacy},
  author = {Wang, Chen and Wu, Xinkui and Liu, Gaoyang and Deng, Tianping and Peng, Kai and Wan, Shaohua},
  date = {2021-11},
  journaltitle = {Digital Communications and Networks},
  shortjournal = {Digital Communications and Networks},
  pages = {S2352864821000961},
  issn = {23528648},
  doi = {10/gpbg2m},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2352864821000961},
  urldate = {2022-01-31},
  abstract = {Federated Learning (FL) is a new computing paradigm in privacy-preserving Machine Learning (ML), where the ML model is trained in a decentralized manner by the clients, preventing the server from directly accessing privacy-sensitive data from the clients. Unfortunately, recent advances have shown potential risks for user-level privacy breaches under the cross-silo FL framework. In this paper, we propose addressing the issue by using a three-plane framework to secure the cross-silo FL, taking advantage of the Local Differential Privacy (LDP) mechanism. The key insight here is that LDP can provide strong data privacy protection, while still retaining user data statistics to preserve its high utility. Experimental results on three real-world datasets demonstrate the effectiveness of our framework.},
  langid = {english}
}

@inproceedings{wang_SDNtrafficanomaly_2022,
  title = {{{SDN}} Traffic Anomaly Detection Method Based on Convolutional Autoencoder and Federated Learning},
  booktitle = {{{GLOBECOM}} 2022 - 2022 {{IEEE Global Communications Conference}}},
  author = {Wang, ZiXuan and Wang, Pan and Sun, ZhiXin},
  date = {2022-12},
  pages = {4154--4160},
  doi = {10.1109/GLOBECOM48099.2022.10001438},
  url = {https://ieeexplore.ieee.org/abstract/document/10001438},
  urldate = {2024-04-12},
  abstract = {With the rapid development of the Internet, people pay more and more attention to network security and data privacy. Using the characteristics of SDN data and control separation, it is easy to embed a traffic detection model in edge devices to achieve abnormal traffic detection. However, although the traditional intrusion detection model can provide good recognition accuracy, it requires many labeled samples for model training. Not only is it challenging to obtain labeled samples, but it also brings privacy issues. This paper combines federated learning and anomaly-based CAE model in the SDN network and realizes intrusion detection on encrypted traffic under the premise of effectively protecting data privacy and reducing the workload of data labeling. Furthermore, we design an aggregation model selection algorithm based on loss and data volume evaluation, which reduces the overall training time of the federation and improves the model's accuracy.},
  eventtitle = {{{GLOBECOM}} 2022 - 2022 {{IEEE Global Communications Conference}}},
  keywords = {Convolutional autoencoder,Data privacy,Deep learning,Encrypted traffic identification,Federated learning,Intrusion detection,Network intrusion detection,Privacy,Solid modeling,Telecommunication traffic,Training}
}

@article{wang_ThreatsTrainingSurvey_2022,
  title = {Threats to {{Training}}: {{A Survey}} of {{Poisoning Attacks}} and {{Defenses}} on {{Machine Learning Systems}}},
  shorttitle = {Threats to {{Training}}},
  author = {Wang, Zhibo and Ma, Jingjing and Wang, Xue and Hu, Jiahui and Qin, Zhan and Ren, Kui},
  date = {2022-05-25},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  pages = {3538707},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3538707},
  url = {https://dl.acm.org/doi/10.1145/3538707},
  urldate = {2022-09-01},
  abstract = {Machine learning (ML) has been universally adopted for automated decisions in a variety of ields, including recognition and classiication applications, recommendation systems, natural language processing, etc. However, in the light of high expenses on training data and computing resources, recent years have witnessed a rapid increase in outsourced ML training, either partially or completely, which provides vulnerabilities for adversaries to exploit. A prime threat in training phase is called poisoning attack, where adversaries strive to subvert the behavior of machine learning systems by poisoning training data or other means of interference. Although a growing number of relevant studies have been proposed, the research among poisoning attack is still overly scattered, with each paper focusing on a particular task in a speciic domain. In this survey, we summarize and categorize existing attack methods and corresponding defenses, as well as demonstrate compelling application scenarios, thus providing a uniied framework to analyze poisoning attacks. Besides, we also discuss the main limitations of current works, along with the corresponding future directions to facilitate further researches. Our ultimate motivation is to provide a comprehensive and self-contained survey of this growing ield of research and lay the foundation for a more standardized approach to reproducible studies. CCS Concepts: {$\cdot$} Theory of computation {$\rightarrow$} Adversarial learning; {$\cdot$} Security and privacy {$\rightarrow$} Systems security.},
  langid = {english}
}

@article{wasielewska_EvaluationLimitDetection_2022,
  title = {Evaluation of the {{Limit}} of {{Detection}} in {{Network Dataset Quality Assessment}} with {{PerQoDA}}},
  author = {Wasielewska, Katarzyna and Soukup, Dominik and Cejka, Tomas and Camacho P\'aez, Jos\'e},
  date = {2022},
  publisher = {{European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML-PKDD 2022, 4th Workshop on Machine Learning for Cybersecurity (MLCS)}},
  url = {https://digibug.ugr.es/handle/10481/81204},
  urldate = {2023-05-15},
  abstract = {Machine learning is recognised as a relevant approach to detect  attacks and other anomalies in network traffic. However, there are  still no suitable network datasets that would enable effective detection.  On the other hand, the preparation of a network dataset is not easy due  to privacy reasons but also due to the lack of tools for assessing their  quality. In a previous paper, we proposed a new method for data quality  assessment based on permutation testing. This paper presents a parallel  study on the limits of detection of such an approach. We focus on the  problem of network flow classification and use well-known machine learning  techniques. The experiments were performed using publicly available  network datasets.},
  langid = {english},
  keywords = {â›” No DOI found},
  annotation = {Accepted: 2023-04-24T07:50:11Z}
}

@incollection{wasielewska_EvaluationLimitDetection_2023,
  title = {Evaluation of the {{Limit}} of {{Detection}} in {{Network Dataset Quality Assessment}} with {{PerQoDA}}},
  booktitle = {Machine {{Learning}} and {{Principles}} and {{Practice}} of {{Knowledge Discovery}} in {{Databases}}},
  author = {Wasielewska, Katarzyna and Soukup, Dominik and \v Cejka, Tom\'a\v s and Camacho, Jos\'e},
  editor = {Koprinska, Irena and Mignone, Paolo and Guidotti, Riccardo and Jaroszewicz, Szymon and Fr\"oning, Holger and Gullo, Francesco and Ferreira, Pedro M. and Roqueiro, Damian and Ceddia, Gaia and Nowaczyk, Slawomir and Gama, Jo\~ao and Ribeiro, Rita and Gavald\`a, Ricard and Masciari, Elio and Ras, Zbigniew and Ritacco, Ettore and Naretto, Francesca and Theissler, Andreas and Biecek, Przemyslaw and Verbeke, Wouter and Schiele, Gregor and Pernkopf, Franz and Blott, Michaela and Bordino, Ilaria and Danesi, Ivan Luciano and Ponti, Giovanni and Severini, Lorenzo and Appice, Annalisa and Andresini, Giuseppina and Medeiros, Ib\'eria and Gra\c ca, Guilherme and Cooper, Lee and Ghazaleh, Naghmeh and Richiardi, Jonas and Saldana, Diego and Sechidis, Konstantinos and Canakoglu, Arif and Pido, Sara and Pinoli, Pietro and Bifet, Albert and Pashami, Sepideh},
  date = {2023},
  volume = {1753},
  pages = {170--185},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-23633-4_13},
  url = {https://link.springer.com/10.1007/978-3-031-23633-4_13},
  urldate = {2023-08-03},
  abstract = {Machine learning is recognised as a relevant approach to detect attacks and other anomalies in network traffic. However, there are still no suitable network datasets that would enable effective detection. On the other hand, the preparation of a network dataset is not easy due to privacy reasons but also due to the lack of tools for assessing their quality. In a previous paper, we proposed a new method for data quality assessment based on permutation testing. This paper presents a parallel study on the limits of detection of such an approach. We focus on the problem of network flow classification and use well-known machine learning techniques. The experiments were performed using publicly available network datasets.},
  isbn = {978-3-031-23632-7 978-3-031-23633-4},
  langid = {english}
}

@article{webber_bisymmetriclogtransformation_2012,
  title = {A Bi-Symmetric Log Transformation for Wide-Range Data},
  author = {Webber, J. Beau W.},
  date = {2012-12},
  journaltitle = {Measurement Science and Technology},
  shortjournal = {Meas. Sci. Technol.},
  volume = {24},
  number = {2},
  pages = {027001},
  publisher = {IOP Publishing},
  issn = {0957-0233},
  doi = {10.1088/0957-0233/24/2/027001},
  url = {https://dx.doi.org/10.1088/0957-0233/24/2/027001},
  urldate = {2024-03-13},
  abstract = {The logarithmic transformation has long been used to present data that have both large and small components that are significant, such as neutron scattering data, or to present data that perhaps cover a wide range of time-scales, such as NMR relaxation data. A more general transformation, which is applicable to many different disciplines, is offered here, and is particularly suitable for representing wide-range data that have both positive and negative (or zero) components. The proposed transform smoothly modifies the gradient of the transformation so that in the region near zero it remains finite. A single constant is provided to tune this behavior, so as to adjust the meaning of `region near zero'. This modified logarithmic transformation can be one-sided or symmetric, and thus can transform negative data to scaled negative data. It can be applied to both the X and Y data, when it becomes a bi-symmetric log transform.},
  langid = {english}
}

@article{wei_RedactableBlockchainFramework_2022,
  title = {A {{Redactable Blockchain Framework}} for {{Secure Federated Learning}} in {{Industrial Internet-of-Things}}},
  author = {Wei, Jiannan and Zhu, Qinchuan and Li, Qianmu and Nie, Laisen and Shen, Zhangyi and Choo, Kim-Kwang Raymond and Yu, Keping},
  date = {2022},
  journaltitle = {IEEE Internet of Things Journal},
  shortjournal = {IEEE Internet Things J.},
  pages = {1--1},
  issn = {2327-4662, 2372-2541},
  doi = {10.1109/JIOT.2022.3162499},
  url = {https://ieeexplore.ieee.org/document/9743331/},
  urldate = {2022-07-05},
  abstract = {Industrial Internet-of-Things (IIoT) facilitate private data collecting via(a broad range of) sensors, and the analysis of such data can inform decision-making at different levels. Federated learning can be used to analyze the collected data, in privacy preserving manner by transmitting model updates instead of private data in IIoT networks. The federated learning framework is, however, vulnerable because model updates are easily tampered with by malicious agents. Motivated by this observation, we propose a novel chameleon hash scheme with changeable trapdoor (CHCT) for secure federated learning in IIoT settings. Our scheme imposes various constraints on the use of trapdoor. We give a rigorous security analysis on our CHCT scheme. We also instantiate the CHCT scheme as a redactable medical blockchain. Experimental evaluations demonstrate the practical utility of CHCT in terms of accuracy and efficiency.},
  langid = {english}
}

@article{wijethilaka_FederatedLearningApproach_2022,
  title = {A {{Federated Learning Approach}} for {{Improving Security}} in {{Network Slicing}}},
  author = {Wijethilaka, Shalitha and Liyanage, Madhusanka},
  date = {2022-12},
  pages = {7},
  abstract = {Network Slicing (NS) is a predominant technology in future telecommunication networks, including Fifth Generation (5G), which supports the realization of heterogeneous applications and services. It allows the allocation of a dedicated logical network slice of the physical network to each application. Security is one of the paramount challenges in an NS ecosystem. Several technologies, including Machine Learning (ML), have been proposed to mitigate security challenges in 5G networks. However, the use of ML for NS security is not properly implemented. Especially, the scarcity of coordination and the difficulties of privacy-protected information sharing between slices cause failures and performance degradation of these ML based NS security solutions. To address this issue, this paper proposes a novel Federated Learning (FL) based coordinated security orchestration architecture named Federated Learning enabled Security Orchestrator (FLeSO) to centrally perform security operations in a slicing ecosystem while preserving the privacy of the data. In addition, the proposed FLeSO architecture enables features such as proactive security deployment and steady security level maintenance independent of the slicing strategy. The proposed architecture is implemented in a realworld slicing testbed, and a comprehensive set of experiments are performed to evaluate the effectiveness of the proposed FLeSO architecture. The test results illustrate the significant advantage of the proposed approach over the legacy system in terms of improving the security of an NS ecosystem.},
  langid = {english},
  keywords = {â›” No DOI found}
}

@inproceedings{wijethilaka_FederatedLearningApproach_2022a,
  title = {A {{Federated Learning Approach}} for {{Improving Security}} in {{Network Slicing}}},
  booktitle = {{{GLOBECOM}} 2022 - 2022 {{IEEE Global Communications Conference}}},
  author = {Wijethilaka, Shalitha and Liyanage, Madhusanka},
  date = {2022-12},
  pages = {915--920},
  doi = {10.1109/GLOBECOM48099.2022.10001190},
  url = {https://ieeexplore.ieee.org/document/10001190},
  urldate = {2024-04-12},
  abstract = {Network Slicing (NS) is a predominant technology in future telecommunication networks, including Fifth Generation (5G), which supports the realization of heterogeneous applications and services. It allows the allocation of a dedicated logical network slice of the physical network to each application. Security is one of the paramount challenges in an NS ecosystem. Several technologies, including Machine Learning (ML), have been proposed to mitigate security challenges in 5G networks. However, the use of ML for NS security is not properly implemented. Especially, the scarcity of coordination and the difficulties of privacy-protected information sharing between slices cause failures and performance degradation of these ML based NS security solutions. To address this issue, this paper proposes a novel Federated Learning (FL) based coordinated security orchestration architecture named Federated Learning enabled Security Orchestrator (FLeSO) to centrally perform security operations in a slicing ecosystem while preserving the privacy of the data. In addition, the proposed FLeSO architecture enables features such as proactive security deployment and steady security level maintenance independent of the slicing strategy. The proposed architecture is implemented in a real-world slicing testbed, and a comprehensive set of experiments are performed to evaluate the effectiveness of the proposed FLeSO architecture. The test results illustrate the significant advantage of the proposed approach over the legacy system in terms of improving the security of an NS ecosystem.},
  eventtitle = {{{GLOBECOM}} 2022 - 2022 {{IEEE Global Communications Conference}}},
  keywords = {5G mobile communication,Deep Learning,Degradation,Ecosystems,Federated learning,Federated Learning,Information sharing,Maintenance engineering,Network slicing,Network Slicing,Security}
}

@article{winick_Inet3InternetTopology_,
  title = {Inet-3.0: {{Internet Topology Generator}}},
  author = {Winick, Jared and Jamin, Sugih},
  abstract = {In this report we present version 3.0 of Inet, an Autonomous System (AS) level Internet topology generator. Our understanding of the Internet topology is quickly evolving, and thus, our understanding of how synthetic topologies should be generated is changing too. We document our analysis of Inet2.2, which highlighted two shortcommings in its topologies. Inet-3.0 improves upon Inet-2.2's two main weaknesses by creating topologies with more accurate degree distributions and minimum vertex covers as compared to Internet topologies. We also examine numerous other metrics to show that Inet3.0 better approximates the actual Internet AS topology than does Inet-2.2. Inet-3.0's topologies still do not well represent the Internet in terms of maximum clique size and clustering coefficient. These related problems stress a need for a better understanding of Internet connectivity and will be addressed in future work.},
  langid = {english}
}

@online{woisetschlager_FederatedLearningPriorities_2024,
  title = {Federated {{Learning Priorities Under}} the {{European Union Artificial Intelligence Act}}},
  author = {Woisetschl\"ager, Herbert and Erben, Alexander and Marino, Bill and Wang, Shiqiang and Lane, Nicholas D. and Mayer, Ruben and Jacobsen, Hans-Arno},
  date = {2024-02-05},
  eprint = {2402.05968},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2402.05968},
  urldate = {2024-07-10},
  abstract = {The age of AI regulation is upon us, with the European Union Artificial Intelligence Act (AI Act) leading the way. Our key inquiry is how this will affect Federated Learning (FL), whose starting point of prioritizing data privacy while performing ML fundamentally differs from that of centralized learning. We believe the AI Act and future regulations could be the missing catalyst that pushes FL toward mainstream adoption. However, this can only occur if the FL community reprioritizes its research focus. In our position paper, we perform a first-of-its-kind interdisciplinary analysis (legal and ML) of the impact the AI Act may have on FL and make a series of observations supporting our primary position through quantitative and qualitative analysis. We explore data governance issues and the concern for privacy. We establish new challenges regarding performance and energy efficiency within lifecycle monitoring. Taken together, our analysis suggests there is a sizable opportunity for FL to become a crucial component of AI Act-compliant ML systems and for the new regulation to drive the adoption of FL techniques in general. Most noteworthy are the opportunities to defend against data bias and enhance private and secure computation.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning,I.2,I.2.11,K.5}
}

@article{wood_Ethereumsecuredecentralised_2014,
  title = {Ethereum: A Secure Decentralised Generalised Transaction Ledger},
  author = {Wood, Gavin},
  date = {2014-11},
  journaltitle = {Ethereum Project Yellow Paper},
  volume = {151},
  pages = {1--32},
  abstract = {The blockchain paradigm when coupled with cryptographically-secured transactions has demonstrated its utility through a number of projects, not least Bitcoin. Each such project can be seen as a simple application on a decentralised, but singleton, compute resource. We can call this paradigm a transactional singleton machine with shared-state. Ethereum implements this paradigm in a generalised manner. Furthermore it provides a plurality of such resources, each with a distinct state and operating code but able to interact through a message-passing framework with others. We discuss its design, implementation issues, the opportunities it provides and the future hurdles we envisage.},
  keywords = {â›” No DOI found}
}

@inproceedings{wu_ImprovedTrustThreat_2019,
  title = {Towards {{Improved Trust}} in {{Threat Intelligence Sharing}} Using {{Blockchain}} and {{Trusted Computing}}},
  booktitle = {2019 {{Sixth International Conference}} on {{Internet}} of {{Things}}: {{Systems}}, {{Management}} and {{Security}} ({{IOTSMS}})},
  author = {Wu, Yichang and Qiao, Yuansong and Ye, Yuhang and Lee, Brian},
  date = {2019-10},
  pages = {474--481},
  publisher = {IEEE},
  doi = {10.1109/IOTSMS48152.2019.8939192},
  url = {https://ieeexplore.ieee.org/document/8939192/},
  abstract = {Threat intelligence sharing is posited as an important aid to help counter cybersecurity attacks and a number of threat intelligence sharing communities exist. There is a general consensus that many challenges remain to be overcome to achieve fully effective sharing, including concerns about privacy, negative publicity, policy/legal issues and expense of sharing, amongst others. One recent trend undertaken to address this is the use of decentralized blockchain based sharing architectures. However while these platforms can help increase sharing effectiveness they do not fully address all of the above challenges. In particular, issues around trust are not satisfactorily solved by current approaches. In this paper, we describe a novel trust enhancement framework -TITAN- for decentralized sharing based on the use of P2P reputation systems to address open trust issues. Our design uses blockchain and Trusted Execution Environment technologies to ensure security, integrity and privacy in the operation of the threat intelligence sharing reputation system.},
  isbn = {978-1-72812-949-5}
}

@article{wu_MarSFLEnablingCompetitors_2022,
  title = {{{MarS-FL}}: {{Enabling Competitors}} to {{Collaborate}} in {{Federated Learning}}},
  shorttitle = {{{MarS-FL}}},
  author = {Wu, Xiaohu and Yu, Han},
  date = {2022},
  journaltitle = {IEEE Transactions on Big Data},
  pages = {1--11},
  issn = {2332-7790},
  doi = {10.1109/TBDATA.2022.3186991},
  abstract = {Federated learning (FL) is rapidly gaining popularity and enables multiple data owners (a.k.a. FL participants) to collaboratively train machine learning models in a privacy-preserving way. A key unaddressed scenario is that these FL participants are in a competitive market, where market shares represent their competitiveness. Although they are interested to enhance the performance of their respective models through FL, market leaders (who are often data owners who can contribute significantly to building high performance FL models) want to avoid losing their market shares by enhancing their competitors' models. Currently, there is no modeling tool to analyze such scenarios and support informed decision-making. In this paper, we bridge this gap by proposing the market share-based decision support framework for participation in FL (MarS-FL). We introduce two notions of {$\delta$}-stable market and friendliness to measure the viability of FL and the market acceptability of FL. The FL participants' behaviours can then be predicted using game theoretic tools (i.e., their optimal strategies concerning participation in FL). If the market {$\delta$}-stability is achievable, the final model performance improvement of each FL-PT shall be bounded, which relates to the market conditions of FL applications. We provide tight bounds and quantify the friendliness, {$\kappa$}, of given market conditions to FL. Experimental results show the viability of FL in a wide range of market conditions. Our results are useful for identifying the market conditions under which collaborative FL model training is viable among competitors, and the requirements that have to be imposed while applying FL under these conditions.},
  eventtitle = {{{IEEE Transactions}} on {{Big Data}}},
  keywords = {Biological system modeling,competitive market,Computational modeling,Data models,Federated learning,game theory,Load modeling,performance allocation,Predictive models,Servers,Training}
}

@inproceedings{wu_QoSAwareCostEfficientDynamic_2023,
  title = {{{QoS-Aware}} and {{Cost-Efficient Dynamic Resource Allocation}} for {{Serverless ML Workflows}}},
  booktitle = {2023 {{IEEE International Parallel}} and {{Distributed Processing Symposium}} ({{IPDPS}})},
  author = {Wu, Hao and Deng, Junxiao and Fan, Hao and Ibrahim, Shadi and Wu, Song and Jin, Hai},
  date = {2023-05},
  pages = {886--896},
  issn = {1530-2075},
  doi = {10.1109/IPDPS54959.2023.00093},
  abstract = {Machine Learning (ML) workflows are increasingly deployed on serverless computing platforms to benefit from their elasticity and fine-grain pricing. Proper resource allocation is crucial to achieve fast and cost-efficient execution of serverless ML workflows (specially for hyperparameter tuning and model training). Unfortunately, existing resource allocation methods are static, treat functions equally, and rely on offline prediction, which limit their efficiency. In this paper, we introduce CE-scaling -- a Cost-Efficient autoscaling framework for serverless ML work-flows. During the hyperparameter tuning, CE-scaling partitions resources across stages according to their exact usage to minimize resource waste. Moreover, it incorporates an online prediction method to dynamically adjust resources during model training. We implement and evaluate CE-scaling on AWS Lambda using various ML models. Evaluation results show that compared to state-of-the-art static resource allocation methods, CE-scaling can reduce the job completion time and the monetary cost by up to 63\% and 41\% for hyperparameter tuning, respectively; and by up to 58\% and 38\% for model training.},
  eventtitle = {2023 {{IEEE International Parallel}} and {{Distributed Processing Symposium}} ({{IPDPS}})},
  keywords = {Computational modeling,Costs,distributed machine learning,Predictive models,Pricing,Quality of service,resource provisioning,serverless computing,Serverless computing,Training}
}

@article{wu_RTIDSRobustTransformerBased_2022,
  title = {{{RTIDS}}: {{A Robust Transformer-Based Approach}} for {{Intrusion Detection System}}},
  shorttitle = {{{RTIDS}}},
  author = {Wu, Zihan and Zhang, Hong and Wang, Penghai and Sun, Zhibo},
  date = {2022},
  journaltitle = {IEEE Access},
  volume = {10},
  pages = {64375--64387},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3182333},
  abstract = {Due to the rapid growth in network traffic and increasing security threats, Intrusion Detection Systems (IDS) have become increasingly critical in the field of cyber security for providing secure communications against cyber adversaries. However, there exist many challenges for designing a robust, efficient and accurate IDS, especially when dealing with high-dimensional anomaly data with unforeseen and unpredictable attacks. In this paper, we propose a Robust Transformer-based Intrusion Detection System (RTIDS) reconstructing feature representations to make a trade-off between dimensionality reduction and feature retention in imbalanced datasets. The proposed method utilizes positional embedding technique to associate sequential information between features, then a variant stacked encoder-decoder neural network is used to learn low-dimensional feature representations from high-dimensional raw data. Furthermore, we apply self-attention mechanism to facilitate network traffic type classifications. Extensive experiments reveal the effectiveness of the proposed RTIDS on two publicly available real traffic intrusion detection datasets named CICIDS2017 and CIC-DDoS2019 with F1-Score of 99.17\% and 98.48\% respectively. A comparative study with classical machine learning algorithm support vector machine (SVM) and deep learning algorithms that include recurrent neural network (RNN), fuzzy neural network (FNN), and long short-term memory network (LSTM) is conducted to demonstrate the validity of the proposed method.},
  eventtitle = {{{IEEE Access}}},
  keywords = {\_read\_urgently,Data models,Decoding,Feature extraction,feature representation,Hidden Markov models,Intrusion detection,self-attention mechanism,Telecommunication traffic,transformer,Transformers}
}

@unpublished{wu_TransferLearningApproach_2019,
  title = {A {{Transfer Learning Approach}} for {{Network Intrusion Detection}}},
  author = {Wu, Peilun and Guo, Hui and Buckland, Richard},
  date = {2019-12-18},
  eprint = {1909.02352},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.1109/ICBDA.2019.8713213},
  url = {http://arxiv.org/abs/1909.02352},
  urldate = {2021-10-04},
  abstract = {Convolution Neural Network (ConvNet) offers a high potential to generalize input data. It has been widely used in many application areas, such as visual imagery, where comprehensive learning datasets are available and a ConvNet model can be well trained and perform the required function effectively. ConvNet can also be applied to network intrusion detection. However, the currently available datasets related to the network intrusion are often inadequate, which makes the ConvNet learning deficient, hence the trained model is not competent in detecting unknown intrusions. In this paper, we propose a ConvNet model using transfer learning for the network intrusion detection. The model consists of two concatenated ConvNets and is built on a two-stage learning process: learning a base dataset and transferring the learned knowledge to the learning of the target dataset. Our experiments on the NSLKDD dataset show that the proposed model can improve the detection accuracy not only on the test dataset containing mostly known attacks (KDDTest+) but also on the test dataset featuring many novel attacks (KDDTest-21) -- about 2.68\% improvement on KDDTest+ and 22.02\% on KDDTest-21 can be achieved, as compared to the traditional ConvNet model.},
  langid = {english},
  keywords = {\_read,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Computer Science - Networking and Internet Architecture}
}

@inproceedings{wustrich_ExtensibleIoTSecurity_2020,
  title = {Towards an {{Extensible IoT Security Taxonomy}}},
  booktitle = {2020 {{IEEE Symposium}} on {{Computers}} and {{Communications}} ({{ISCC}})},
  author = {Wustrich, Lars and Pahl, Marc-Oliver and Liebald, Stefan},
  date = {2020-07},
  volume = {2020-July},
  pages = {1--6},
  publisher = {IEEE},
  issn = {15301346},
  doi = {10.1109/ISCC50000.2020.9219584},
  url = {https://ieeexplore.ieee.org/document/9219584/},
  abstract = {Security is essential in the Internet of Things (IoT). IoT threat classifications are often non-intuitive to use. Identifying relevant properties of an attack is difficult and requires reading details of the attack. We therefore propose a simple-to-use naming scheme for IoT threat classification. It is based on the affected layers and the affected security goals. We evaluate the usefulness of the chosen approach by applying it to common IoT threats.},
  isbn = {978-1-72818-086-1}
}

@inproceedings{xia_AbnormalTrafficDetection_2022,
  title = {An {{Abnormal Traffic Detection Method}} for {{IoT Devices Based}} on {{Federated Learning}} and {{Depthwise Separable Convolutional Neural Networks}}},
  booktitle = {2022 {{IEEE International Performance}}, {{Computing}}, and {{Communications Conference}} ({{IPCCC}})},
  author = {Xia, Qinyu and Dong, Shi and Peng, Tao},
  date = {2022-11},
  pages = {352--359},
  issn = {2374-9628},
  doi = {10.1109/IPCCC55026.2022.9894354},
  url = {https://ieeexplore.ieee.org/abstract/document/9894354},
  urldate = {2024-04-12},
  abstract = {As a bridge for information interaction between people and things, and things and things, IoT devices bring security issues and data privacy protection issues that have always been the main challenges in the IoT environment. In terms of abnormal traffic detection of IoT devices, data sharing between device data is usually not possible. This makes the deep learning method for model training based on a large amount of data unable to fully exert its strength due to the lack of IoT device attack instances, resulting in the problem of low detection accuracy. To this end, we propose an abnormal traffic detection model for IoT devices, FL-DSCNN (Federated Learning and Depthwise separable convolutional neural networks). First, the mayfly optimization algorithm is used to select the traffic features, and the model training time is reduced by reducing the feature dimension. Then, by introducing the FL framework, the depthwise separable convolutional neural network is used as a local model for collaborative training without sharing private data, avoiding the problem of lack of labeled data due to the ``data silos'' phenomenon while protecting data privacy. In addition, we experimentally verify the proposed method on the existing public dataset Aposemat IoT-23 dataset and compare and evaluate it with existing methods. The experimental results show that the method can achieve two-class and multi-class detection respectively. The detection accuracy rates of 98.52\% and 97.73\% prove the progress and superiority of the proposed FL-DSCNN model in the detection of abnormal traffic of IoT devices.},
  eventtitle = {2022 {{IEEE International Performance}}, {{Computing}}, and {{Communications Conference}} ({{IPCCC}})},
  keywords = {Data models,Data privacy,Deep learning,Depthwise separable convolutional neural networks,Feature selection,Federated learning,Internet of Things,IoT device attack detection,Performance evaluation,Training}
}

@inproceedings{xia_ToFiAlgorithmDefend_2021,
  title = {{{ToFi}}: {{An Algorithm}} to {{Defend Against Byzantine Attacks}} in {{Federated Learning}}},
  shorttitle = {{{ToFi}}},
  booktitle = {Security and {{Privacy}} in {{Communication Networks}}},
  author = {Xia, Qi and Tao, Zeyi and Li, Qun},
  editor = {Garcia-Alfaro, Joaquin and Li, Shujun and Poovendran, Radha and Debar, Herv\'e and Yung, Moti},
  date = {2021},
  series = {Lecture {{Notes}} of the {{Institute}} for {{Computer Sciences}}, {{Social Informatics}} and {{Telecommunications Engineering}}},
  pages = {229--248},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-90019-9_12},
  abstract = {In distributed gradient descent based machine learning model training, workers periodically upload locally computed gradients or weights to the parameter server (PS). Byzantine attacks take place when some workers upload wrong gradients or weights, i.e., the information received by the PS is not always the true values computed by workers. Approaches such as score-based, median-based, and distance-based defense algorithms were proposed previously, but all of them made the asumptions: (1) the dataset on each worker is independent and identically distributed (i.i.d.), and (2) the majority of all participating workers are honest. These assumptions are not realistic in federated learning where each worker may keep its non-i.i.d. private dataset and malicious workers may take over the majority in some iterations. In this paper, we propose a novel reference dataset based algorithm along with a practical Two-Filter algorithm (ToFi) to defend against Byzantine attacks in federated learning. Our experiments highlight the effectiveness of our algorithm compared with previous algorithms in different settings.},
  isbn = {978-3-030-90019-9},
  langid = {english},
  keywords = {Byzantine attacks,Federated learning}
}

@article{xiao_SCASybilbasedCollusion_2022,
  title = {{{SCA}}: {{Sybil-based Collusion Attacks}} of {{IIoT Data Poisoning}} in {{Federated Learning}}},
  shorttitle = {{{SCA}}},
  author = {Xiao, Xiong and Tang, Zhuo and Li, Chuanying and Xiao, Bin and Li, Kenli},
  date = {2022},
  journaltitle = {IEEE Transactions on Industrial Informatics},
  pages = {1--1},
  issn = {1941-0050},
  doi = {10.1109/TII.2022.3172310},
  abstract = {With the massive amounts of data generated by Industrial Internet of Things (IIoT) devices at all moments, federated learning (FL) enables these distributed distrusted devices to collaborate to build machine learning model while maintaining data privacy. However, malicious participants still launch malicious attacks against the security vulnerabilities during model aggregation. This paper is the first to propose sybil-based collusion attacks (SCA) in the IIoT-FL system for the vulnerabilities mentioned above. The malicious participants use label flipping attacks to complete local poisoning training. Meanwhile, they can virtualize multiple sybil nodes to make the local poisoning models aggregated with the greatest possibility during aggregation. They focus on making the joint model misclassify the selected attack class samples during the testing phase, while other non-attack classes kept the main task accuracy similar to the non-poisoned state. Exhaustive experimental analysis demonstrates that our SCA has superior performance on multiple aspects than the state-of-the-art.},
  eventtitle = {{{IEEE Transactions}} on {{Industrial Informatics}}},
  keywords = {Collaborative work,Collusion attacks,Data models,Distributed databases,Federated learning,IIoT,Industrial Internet of Things,Label flipping attacks,Performance evaluation,Servers,Sybil,Training}
}

@article{xiao_TimesensitiveLearningHeterogeneous_2023,
  title = {Time-Sensitive {{Learning}} for {{Heterogeneous Federated Edge Intelligence}}},
  author = {Xiao, Yong and Zhang, Xiaohan and Li, Yingyu and Shi, Guangming and Krunz, Marwan and Nguyen, Diep N. and Hoang, Dinh Thai},
  date = {2023},
  journaltitle = {IEEE Transactions on Mobile Computing},
  pages = {1--18},
  issn = {1558-0660},
  doi = {10.1109/TMC.2023.3237374},
  abstract = {Real-time machine learning (ML) has recently attracted significant interest due to its potential to support instantaneous learning, adaptation, and decision making in a wide range of application domains, including self-driving vehicles, intelligent transportation, and industry automation. In this paper, we investigate real-time ML in a federated edge intelligence (FEI) system, an edge computing system that implements federated learning (FL) solutions based on data samples collected and uploaded from decentralized data networks, e.g., Internet-of-Things (IoT) and/or wireless sensor networks. FEI systems often exhibit heterogenous communication and computational resource distribution, as well as non-i.i.d. data samples arrived at different edge servers, resulting in long model training time and inefficient resource utilization. Motivated by this fact, we propose a time-sensitive federated learning (TS-FL) framework to minimize the overall run-time for collaboratively training a shared ML model with desirable accuracy. Training acceleration solutions for both TS-FL with synchronous coordination (TS-FL-SC) and asynchronous coordination (TS-FL-ASC) are investigated. To address the straggler effect in TS-FL-SC, we develop an analytical solution to characterize the impact of selecting different subsets of edge servers on the overall model training time. A server dropping-based solution is proposed to allow some slow-performance edge servers to be removed from participating in the model training if their impact on the resulting model accuracy is limited. A joint optimization algorithm is proposed to minimize the overall time consumption of model training by selecting participating edge servers, the local epoch number (the number of model training iterations per coordination), and the data batch size (the number of data samples for each model training iteration). Motivated by the fact that data samples at the slowest edge server may exhibit special characteristics that cannot be removed from model training, we develop an analytical expression to characterize the impact of both staleness effect of asynchronous coordination and straggler effect of FL on the time consumption of TS-FL-ASC. We propose a load forwarding-based solution that allows a slow edge server to offload part of its training samples to trusted edge servers with higher processing capability. We develop a hardware prototype to evaluate the model training time of a heterogeneous FEI system. Experimental results show that our proposed TS-FL-SC and TS-FL-ASC can provide up to 63\% and 28\% of reduction, in the overall model training time, respectively, compared with traditional FL solutions.},
  eventtitle = {{{IEEE Transactions}} on {{Mobile Computing}}},
  keywords = {Analytical models,asynchronous coordination,Computational modeling,Data models,edge intelligence,federated learning,Predictive models,Runtime,Servers,Time-sensitive machine learning,Training}
}

@article{xing_FLMAAEIntrusionDetection_2023,
  title = {{{FL-MAAE}}: {{An Intrusion Detection Method}} for the {{Internet}} of {{Vehicles Based}} on {{Federated Learning}} and {{Memory-Augmented Autoencoder}}},
  shorttitle = {{{FL-MAAE}}},
  author = {Xing, Ling and Wang, Kun and Wu, Honghai and Ma, Huahong and Zhang, Xiaohui},
  date = {2023-01},
  journaltitle = {Electronics},
  volume = {12},
  number = {10},
  pages = {2284},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics12102284},
  url = {https://www.mdpi.com/2079-9292/12/10/2284},
  urldate = {2024-04-12},
  abstract = {The Internet of Vehicles (IoV) is a network system that enables wireless communication and information exchange between vehicles and other traffic participants. Intrusion detection plays a very important role in the IoV. However, with the development of the IoV, unknown attack behaviors may appear. The lack of analysis and collection of these attack behavior has led to an imbalance in the sample data categories of the IoV intrusion detection, which causes the problem of low detection accuracy. At the same time, the intrusion detection model usually needs to upload data to the cloud for training, which will introduce the privacy risk due to of the leakage of vehicle users' information. In this paper, we propose an intrusion detection method for the IoV based on federated learning and memory-augmented autoencoder (FL-MAAE). We add a memory module to the autoencoder model to enhance its ability to store the behavior feature patterns of the IoV, make it robust to imbalanced samples, and use the reconstruction error as the evaluation index, so as to detect unknown attacks in the IoV. We propose a federated learning based training method for the IoV intrusion detection model. Local training of intrusion detection models in roadside units can effectively protect the privacy of data resources. We also designed an aggregation method based on the performance contribution of participants to improve the reliability of model aggregation. We conducted experiments on the NSL-KDD intrusion detection dataset to evaluate the performance of the proposed method. Experimental results show that our method has the best intrusion detection performance. In the case of contaminated samples, the accuracy and F1 score of the proposed method are 9.6\% and 7.39\% higher than those of the comparison methods on average.},
  issue = {10},
  langid = {english},
  keywords = {autoencoder,federated learning,Internet of Vehicles,intrusion detection,network security}
}

@online{xiong_FedDMIterativeDistribution_2022,
  title = {{{FedDM}}: {{Iterative Distribution Matching}} for {{Communication-Efficient Federated Learning}}},
  shorttitle = {{{FedDM}}},
  author = {Xiong, Yuanhao and Wang, Ruochen and Cheng, Minhao and Yu, Felix and Hsieh, Cho-Jui},
  date = {2022-07-20},
  eprint = {2207.09653},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2207.09653},
  urldate = {2022-08-12},
  abstract = {Federated learning (FL) has recently attracted increasing attention from academia and industry, with the ultimate goal of achieving collaborative training under privacy and communication constraints. Existing iterative model averaging based FL algorithms require a large number of communication rounds to obtain a wellperformed model due to extremely unbalanced and non-i.i.d data partitioning among different clients. Thus, we propose FedDM to build the global training objective from multiple local surrogate functions, which enables the server to gain a more global view of the loss landscape. In detail, we construct synthetic sets of data on each client to locally match the loss landscape from original data through distribution matching. FedDM reduces communication rounds and improves model quality by transmitting more informative and smaller synthesized data compared with unwieldy model weights. We conduct extensive experiments on three image classification datasets, and results show that our method can outperform other FL counterparts in terms of efficiency and model performance. Moreover, we demonstrate that FedDM can be adapted to preserve differential privacy with Gaussian mechanism and train a better model under the same privacy budget.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@article{xiong_PeerTrustsupportingreputationbased_2004,
  title = {{{PeerTrust}}: Supporting Reputation-Based Trust for Peer-to-Peer Electronic Communities},
  shorttitle = {{{PeerTrust}}},
  author = {Xiong, Li and Liu, Ling},
  date = {2004-07},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {16},
  number = {7},
  pages = {843--857},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2004.1318566},
  url = {https://ieeexplore.ieee.org/document/1318566},
  urldate = {2024-01-08},
  abstract = {Peer-to-peer (P2P) online communities are commonly perceived as an environment offering both opportunities and threats. One way to minimize threats in such communities is to use community-based reputations to help estimate the trustworthiness of peers. We present PeerTrust - a reputation-based trust supporting framework, which includes a coherent adaptive trust model for quantifying and comparing the trustworthiness of peers based on a transaction-based feedback system, and a decentralized implementation of such a model over a structured P2P network. PeerTrust model has two main features. First, we introduce three basic trust parameters and two adaptive factors in computing trustworthiness of peers, namely, feedback a peer receives from other peers, the total number of transactions a peer performs, the credibility of the feedback sources, transaction context factor, and the community context factor. Second, we define a general trust metric to combine these parameters. Other contributions of the paper include strategies used for implementing the trust model in a decentralized P2P environment, evaluation mechanisms to validate the effectiveness and cost of PeerTrust model, and a set of experiments that show the feasibility and benefit of our approach.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}}
}

@inproceedings{xu_Efficient2DMethod_2023,
  title = {An {{Efficient 2D Method}} for {{Training Super-Large Deep Learning Models}}},
  booktitle = {2023 {{IEEE International Parallel}} and {{Distributed Processing Symposium}} ({{IPDPS}})},
  author = {Xu, Qifan and You, Yang},
  date = {2023-05},
  pages = {222--232},
  issn = {1530-2075},
  doi = {10.1109/IPDPS54959.2023.00031},
  abstract = {Since the rise of Transformer [22] and BERT [6], large language models [7], [12] have been proposed and shown unprecedented performance in tasks like translation, classification, and text generation. However, due to the memory constraint, model parallelism must be used to split the model across multiple processors. Inter-layer partition, intra-layer partition, and sparse activation are the major approaches to achieve model parallelism. Among them, inter-layer partition [10], [11] often requires the model to be explicitly expressed as a stack of sub-modules, the number of which equals to the number of processors, and would introduce either gradient staleness or bubble overhead; while the sparse activation [12] is primarily designed for Google TPU cluster and hard to deploy on GPU servers, intra-layer partition [17], especially Megatron-LM [18], can be easily deployed on GPU servers and has been adopted in subsequent works like Turing-NLG and M6. Though as pioneers of intra-layer parallelism, they still show memory redundancy and sub-optimal communication efficiency, which reveals the space for further improvements. In this work, we leverage SUMMA [21] and propose Optimus, a highly efficient and scalable paradigm for training super-large language models. In Optimus, activations and gradients are partitioned and distributed along processors all the way through forward and backward propagations, with hardly any memory redundancy. The isoefficiency of communication in pure model parallelism improves from W p3 for Megatron-LM, to W\textbackslash sim (\textbackslash sqrt p \textbackslash log p)\textasciicircum 3 for our Optimus. This framework is implemented with open-source deep learning framework, PyTorch, and consolidates existing techniques such as mixed precision training [13], activation checkpointing [5], and data parallelism. In experiments on TACC Frontera supercomputers, Optimus shows 1.48\texttimes{} the speed for training, 1.78\texttimes{} speed for inference, and 8\texttimes{} the maximum batch size over Megatron-LM on 64 GPUs in pure model parallelism; and 1.73\texttimes{} speed for training, 2.32\texttimes{} speed for inference with data parallelism size equaling 2 on 128 GPUs. In pure model parallelism, Optimus surpasses Megatron-LM in weak scaling efficiency by a great margin, and shows an extraordinary increasing strong scaling efficiency. Optimus would facilitate the scaling of language models and serve as a strong thrust in the space exploration of artificial intelligence.},
  eventtitle = {2023 {{IEEE International Parallel}} and {{Distributed Processing Symposium}} ({{IPDPS}})},
  keywords = {Deep learning,distributed training,Graphics processing units,matrix-matrix multiplication,Memory management,natural language processing,neural networks,Parallel processing,Redundancy,Training,Transformers}
}

@online{xu_EfficientReliableAsynchronous_2022,
  title = {An {{Efficient}} and {{Reliable Asynchronous Federated Learning Scheme}} for {{Smart Public Transportation}}},
  author = {Xu, Chenhao and Qu, Youyang and Luan, Tom H. and Eklund, Peter W. and Xiang, Yong and Gao, Longxiang},
  date = {2022-08-15},
  eprint = {2208.07194},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2208.07194},
  urldate = {2022-08-23},
  abstract = {Machine Learning (ML) is a distributed approach for training predictive models on the Internet of Vehicles (IoV) to enable smart public transportation. Since the traffic conditions change over time, the ML model that predicts traffic flows and the time passengers wait at stops must be updated continuously and efficiently. Federated learning (FL) is a distributed machine learning scheme that allows vehicles to receive continuous model updates without having to upload raw data to the cloud and wait for models to be trained. However, FL in smart public transportation is vulnerable to poisoning or DDoS attacks since vehicles travel in public. Besides, due to device heterogeneity and imbalanced data distributions, the synchronized aggregation strategy that collects local models from specific vehicles before aggregation is inefficient. Although Asynchronous Federated Learning (AFL) schemes are developed to improve efficiency by aggregating local models as soon as they are received, the stale local models remain unreasonably weighted, resulting in poor learning performance. To enable smarter public transportation, this paper offers a blockchainbased asynchronous federated learning scheme with a dynamic scaling factor (DBAFL). Specifically, the novel committee-based consensus algorithm for blockchain improves reliability at the lowest possible cost of time. Meanwhile, the devised dynamic scaling factor allows AFL to assign reasonable weight to stale local models. Extensive experiments conducted on heterogeneous devices validate outperformed learning performance, efficiency, and reliability of DBAFL.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Machine Learning}
}

@online{xu_FederatedMultiorganSegmentation_2022,
  title = {Federated {{Multi-organ Segmentation}} with {{Partially Labeled Data}}},
  author = {Xu, Xuanang and Yan, Pingkun},
  date = {2022-06-14},
  eprint = {2206.07156},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2206.07156},
  urldate = {2022-08-11},
  abstract = {Federated learning is an emerging paradigm allowing large-scale decentralized learning without sharing data across different data owners, which helps address the concern of data privacy in medical image analysis. However, the requirement for label consistency across clients by the existing methods largely narrows its application scope. In practice, each clinical site may only annotate certain organs of interest with partial or no overlap with other sites. Incorporating such partially labeled data into a unified federation is an unexplored problem with clinical significance and urgency. This work tackles the challenge by using a novel federated multi-encoding U-Net (Fed-MENU) method for multi-organ segmentation. In our method, a multi-encoding UNet (MENU-Net) is proposed to extract organ-specific features through different encoding sub-networks. Each sub-network can be seen as an expert of a specific organ and trained for that client. Moreover, to encourage the organ-specific features extracted by different sub-networks to be informative and distinctive, we regularize the training of the MENU-Net by designing an auxiliary generic decoder (AGD). Extensive experiments on four public datasets show that our Fed-MENU method can effectively obtain a federated learning model using the partially labeled datasets with superior performance to other models trained by either localized or centralized learning methods. Source code will be made publicly available at the time of paper publication.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing}
}

@article{xu_RethinkingLabelFlipping_2023,
  title = {Rethinking {{Label Flipping Attack}}: {{From Sample Masking}} to {{Sample Thresholding}}},
  shorttitle = {Rethinking {{Label Flipping Attack}}},
  author = {Xu, Qianqian and Yang, Zhiyong and Zhao, Yunrui and Cao, Xiaochun and Huang, Qingming},
  date = {2023-06},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {45},
  number = {6},
  pages = {7668--7685},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2022.3220849},
  url = {https://ieeexplore.ieee.org/abstract/document/9944159},
  urldate = {2024-03-28},
  abstract = {Nowadays, machine learning (ML) and deep learning (DL) methods have become fundamental building blocks for a wide range of AI applications. The popularity of these methods also makes them widely exposed to malicious attacks, which may cause severe security concerns. To understand the security properties of the ML/DL methods, researchers have recently started to turn their focus to adversarial attack algorithms that could successfully corrupt the model or clean data owned by the victim with imperceptible perturbations. In this paper, we study the Label Flipping Attack (LFA) problem, where the attacker expects to corrupt an ML/DL model's performance by flipping a small fraction of the labels in the training data. Prior art along this direction adopts combinatorial optimization problems, leading to limited scalability toward deep learning models. To this end, we propose a novel minimax problem which provides an efficient reformulation of the sample selection process in LFA. In the new optimization problem, the sample selection operation could be implemented with a single thresholding parameter. This leads to a novel training algorithm called Sample Thresholding. Since the objective function is differentiable and the model complexity does not depend on the sample size, we can apply Sample Thresholding to attack deep learning models. Moreover, since the victim's behavior is not predictable in a poisonous attack setting, we have to employ surrogate models to simulate the true model employed by the victim model. Seeing the problem, we provide a theoretical analysis of such a surrogate paradigm. Specifically, we show that the performance gap between the true model employed by the victim and the surrogate model is small under mild conditions. On top of this paradigm, we extend Sample Thresholding to the crowdsourced ranking task, where labels collected from the annotators are vulnerable to adversarial attacks. Finally, experimental analyses on three real-world datasets speak to the efficacy of our method.},
  eventtitle = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}},
  keywords = {Data models,Deep learning,Label flipping attack,machine learning,Optimization,Predictive models,Testing,Training,Training data}
}

@inproceedings{xu_RobustModelAggregation_2021,
  title = {Robust {{Model Aggregation}} for {{Federated Learning}} with {{Heterogeneous Clients}}},
  booktitle = {2021 7th {{International Conference}} on {{Computer}} and {{Communications}} ({{ICCC}})},
  author = {Xu, Ruiting and Feng, Xinxin and Zheng, Haifeng},
  date = {2021-12-10},
  pages = {1606--1610},
  publisher = {IEEE},
  location = {Chengdu, China},
  doi = {10/gpbg4q},
  url = {https://ieeexplore.ieee.org/document/9674541/},
  urldate = {2022-01-31},
  abstract = {This Federated learning has received extensive attention in recent years due to its potential in mitigating risks of intruding privacy. However, most of existing methods don't provide adequate consideration to the heterogeneity of client. Therefore these parameters are treated equally and aggregated with the same weight. As a result, the overall performance may be degraded because of straggling clients. In this paper, we propose an aggregation algorithm considering the accuracy of local model of heterogeneous clients. The server evaluates the accuracy of the uploaded local model with a benchmark dataset, and then updates model parameters according to the accuracy ratio. Experimental results show the model accuracy of our proposed method performs better than existing methods. At the same time, in the presence of noisy users, it can eliminate their effect by assigning lower aggregation weights to them.},
  eventtitle = {2021 7th {{International Conference}} on {{Computer}} and {{Communications}} ({{ICCC}})},
  isbn = {978-1-66540-950-6},
  langid = {english}
}

@inproceedings{xue_DeepTransferLearning_2022,
  title = {Deep {{Transfer Learning}} for {{IoT Intrusion Detection}}},
  booktitle = {2022 3rd {{International Conference}} on {{Computing}}, {{Networks}} and {{Internet}} of {{Things}} ({{CNIOT}})},
  author = {Xue, Bing and Zhao, Hai and Yao, Wei},
  date = {2022-05},
  pages = {88--94},
  doi = {10.1109/CNIOT55862.2022.00023},
  abstract = {Intrusion detection system (IDS) is crucial to security architecture of Internet of Things (IoT). In recent researches, the traditional machine learning and deep learning methods have been applied to the field of intrusion detection and achieved satisfactory performance. However, due to diverse IoT and dynamic network environment, it is difficult to use a single model for heterogeneous IoT networks and collect enough labeled data to train the new model. To solve these issues, we propose an intrusion detection approach based on heterogeneous transfer learning (HTL) for building an intrusion detection model with strong adaptability. Specifically, the approach consists of an Autoencoder architecture for aligning the heterogeneous features and lightweight Convolutional Neural Network (CNN) for unsupervised domain adaptation. Extensive experimental results on three public datasets reveal that the effectiveness of our proposed approach in the IoT environment with unlabeled and limited data.},
  eventtitle = {2022 3rd {{International Conference}} on {{Computing}}, {{Networks}} and {{Internet}} of {{Things}} ({{CNIOT}})},
  keywords = {\_read\_urgently,Adaptation models,Buildings,Computer architecture,Data models,Deep learning,domain adaptation,intrusion detection,Intrusion detection,IoT,transfer learning,Transfer learning}
}

@incollection{yadav_TechnicalAspectsCyber_2015,
  title = {Technical {{Aspects}} of {{Cyber Kill Chain}}},
  booktitle = {Communications in {{Computer}} and {{Information Science}}},
  author = {Yadav, Tarun and Rao, Arvind Mallari},
  date = {2015},
  volume = {536},
  pages = {438--452},
  issn = {18650929},
  doi = {10.1007/978-3-319-22915-7_40},
  url = {http://link.springer.com/10.1007/978-3-319-22915-7_40},
  abstract = {Recent trends in targeted cyber-attacks has increased the interest of research in the field of cyber security. Such attacks have massive disruptive effects on organizations, enterprises and governments. Cyber kill chain is a model to describe cyber-attacks so as to develop incident response and analysis capabilities. Cyber kill chain in simple terms is an attack chain, the path that an intruder takes to penetrate information systems over time to execute an attack on the target. This paper broadly categories the methodologies, techniques and tools involved in cyber-attacks. This paper intends to help a cyber security researcher to realize the options available to an attacker at every stage of a cyberattack.}
}

@inproceedings{yadav_UnsupervisedFederatedLearning_2021,
  title = {Unsupervised {{Federated Learning}} Based {{IoT Intrusion Detection}}},
  booktitle = {2021 {{IEEE}} 10th {{Global Conference}} on {{Consumer Electronics}} ({{GCCE}})},
  author = {Yadav, Krishna and Gupta, B.B and Hsu, Ching-Hsein and Chui, Kwok Tai},
  date = {2021-10-12},
  pages = {298--301},
  publisher = {IEEE},
  location = {Kyoto, Japan},
  doi = {10.1109/GCCE53005.2021.9621784},
  url = {https://ieeexplore.ieee.org/document/9621784/},
  urldate = {2022-01-31},
  abstract = {Machine learning has been widely used these days to detect novel intrusions across IoT devices. Supervised-based machine learning techniques need labelled datasets to train a model. Due to privacy reasons, these days, people don't share the dataset generated across their devices with external authority. When datasets are not aggregated centrally, it becomes very difficult to process the unlabelled data and train a model across edge devices. Considering these drawbacks, we have brought an unsupervised deep learning approach that uses autoencoders to learn from unlabeled data. Our approach uses federated machine learning and can be trained across the unlabeled dataset of edge devices without compromising people's privacy. We have tested our approach against CICIDS 2017 dataset in a federated environment and have got an accuracy of 97.75\% in detecting intrusions.},
  eventtitle = {2021 {{IEEE}} 10th {{Global Conference}} on {{Consumer Electronics}} ({{GCCE}})},
  isbn = {978-1-66543-676-2},
  langid = {english}
}

@article{yang_BlockchainBasedFederatedLearning_2024,
  title = {Blockchain-{{Based Federated Learning With Enhanced Privacy}} and {{Security Using Homomorphic Encryption}} and {{Reputation}}},
  author = {Yang, Ruizhe and Zhao, Tonghui and Yu, F. Richard and Li, Meng and Zhang, Dajun and Zhao, Xuehui},
  date = {2024},
  journaltitle = {IEEE Internet of Things Journal},
  pages = {1--1},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2024.3379395},
  url = {https://ieeexplore.ieee.org/abstract/document/10475694},
  urldate = {2024-04-12},
  abstract = {Federated learning, leveraging distributed data from multiple nodes to train a common model, allows for the use of more data to improve the model while also protecting the privacy of original data. However, challenges still exist in ensuring privacy and security within the interactions. To address these issues, this paper proposes a federated learning approach that incorporates blockchain, homomorphic encryption, and reputation. Using homomorphic encryption, edge nodes possessing local data can complete the training of ciphertext models, with their contributions to the aggregation being evaluated by a reputation mechanism. Both models and reputations are documented and verified on the blockchain through consensus process, which then determines the rewards based on the incentive mechanism. This approach not only incentivizes participation in training, but also ensures the privacy of data and models through encryption. Additionally, it addresses security risks associated with both data and network attacks, ultimately leading to a highly accurate trained model. To enhance the efficiency of learning and the performance of the model, a joint adaptive aggregation and resource optimization algorithm is introduced. Finally, simulations and analyses demonstrate that the proposed scheme enhances learning accuracy while maintaining privacy and security.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {blockchain,Data models,Data privacy,Federated learning,Industrial Internet of Things,Industrial Internet of Things (IIoT),privacy,Privacy,security,Security,Training}
}

@article{yang_Cloudbaseddata_2016,
  title = {Cloud Based Data Sharing with Fine-Grained Proxy Re-Encryption},
  author = {Yang, Yanjiang and Zhu, Haiyan and Lu, Haibing and Weng, Jian and Zhang, Youcheng and Choo, Kim-Kwang Raymond},
  date = {2016-06},
  journaltitle = {Pervasive and Mobile Computing},
  volume = {28},
  pages = {122--134},
  publisher = {Elsevier B.V.},
  issn = {15741192},
  doi = {10.1016/j.pmcj.2015.06.017},
  url = {http://dx.doi.org/10.1016/j.pmcj.2015.06.017},
  abstract = {Conditional proxy re-encryption (CPRE) enables fine-grained delegation of decryption rights, and has many real-world applications. In this paper, we present a ciphertext-policy attribute based CPRE scheme, together with a formalization of the primitive and its security analysis. We demonstrate the utility of the scheme in a cloud deployment, which achieves fine-grained data sharing. This application implements cloud server-enabled user revocation, offering an alternative yet more efficient solution to the user revocation problem in the context of fine-grained encryption of cloud data. High user-side efficiency is another prominent feature of the application, which makes it possible for users to use resource constrained devices, e.g., mobile phones, to access cloud data. Our evaluations show promising results on the performance of the proposed scheme.}
}

@article{yang_Dependablefederatedlearning_2023,
  title = {Dependable Federated Learning for {{IoT}} Intrusion Detection against Poisoning Attacks},
  author = {Yang, Run and He, Hui and Wang, Yulong and Qu, Yue and Zhang, Weizhe},
  date = {2023-09-01},
  journaltitle = {Computers \& Security},
  shortjournal = {Computers \& Security},
  volume = {132},
  pages = {103381},
  issn = {0167-4048},
  doi = {10.1016/j.cose.2023.103381},
  url = {https://www.sciencedirect.com/science/article/pii/S0167404823002912},
  urldate = {2024-03-04},
  abstract = {Network intrusion detection methods based on federated learning (FL) and edge computing have great potential for protecting the cybersecurity of the Internet of Things. It overcomes the disadvantages of the traditional centralized method, such as high latency, overloaded network, and privacy leakage. At the same time, it can combine private data from multiple participants to train models, and the rich data can train more effective models. However, the inherent security vulnerabilities of the FL framework do not ensure the robustness of the global models trained collaboratively. Towards FL, each participant has access to model parameters and training data, and malicious participants can affect the global model by tampering with data or weights. This paper studies label-flipping attacks in FL-based IoT intrusion detection. We propose a lightweight detection mechanism to mitigate the impact of poisoning attacks on FL-based intrusion detection methods in IoT networks. The detection mechanism on a central server filters anomalous participants and excludes their uploaded models from the global model aggregation. Specifically, we propose a scoring mechanism for evaluating participants based on the loss of the local model and the training dataset size. Afterwards, the Manhattan similarity between each participant will be calculated according to the scores. Finally, the anomalous participants will be found by clustering algorithm for similarity cluster analysis. The experimental results show that our proposed detection method can defend against label-flipping attacks in FL. On the CIC-IDS-2017 dataset, our method can improve the accuracy of the intrusion detection model trained based on FL from 84.3\% to 97.1\%, while enhancing the protection of IoT network security.},
  keywords = {Cyber-physical systems,Federated learning,Internet of thing,Label-flipping attacks,Network intrusion detection,obsidian}
}

@article{yang_Dependablefederatedlearning_2023a,
  title = {Dependable Federated Learning for {{IoT}} Intrusion Detection against Poisoning Attacks},
  author = {Yang, Run and He, Hui and Wang, Yulong and Qu, Yue and Zhang, Weizhe},
  date = {2023-09-01},
  journaltitle = {Computers \& Security},
  shortjournal = {Computers \& Security},
  volume = {132},
  pages = {103381},
  issn = {0167-4048},
  doi = {10.1016/j.cose.2023.103381},
  url = {https://www.sciencedirect.com/science/article/pii/S0167404823002912},
  urldate = {2024-04-12},
  abstract = {Network intrusion detection methods based on federated learning (FL) and edge computing have great potential for protecting the cybersecurity of the Internet of Things. It overcomes the disadvantages of the traditional centralized method, such as high latency, overloaded network, and privacy leakage. At the same time, it can combine private data from multiple participants to train models, and the rich data can train more effective models. However, the inherent security vulnerabilities of the FL framework do not ensure the robustness of the global models trained collaboratively. Towards FL, each participant has access to model parameters and training data, and malicious participants can affect the global model by tampering with data or weights. This paper studies label-flipping attacks in FL-based IoT intrusion detection. We propose a lightweight detection mechanism to mitigate the impact of poisoning attacks on FL-based intrusion detection methods in IoT networks. The detection mechanism on a central server filters anomalous participants and excludes their uploaded models from the global model aggregation. Specifically, we propose a scoring mechanism for evaluating participants based on the loss of the local model and the training dataset size. Afterwards, the Manhattan similarity between each participant will be calculated according to the scores. Finally, the anomalous participants will be found by clustering algorithm for similarity cluster analysis. The experimental results show that our proposed detection method can defend against label-flipping attacks in FL. On the CIC-IDS-2017 dataset, our method can improve the accuracy of the intrusion detection model trained based on FL from 84.3\% to 97.1\%, while enhancing the protection of IoT network security.},
  keywords = {Cyber-physical systems,Federated learning,Internet of thing,Label-flipping attacks,Network intrusion detection}
}

@article{yang_dynamicglobalbackbone_2022,
  title = {A Dynamic Global Backbone Updating for Communication-Efficient Personalised Federated Learning},
  author = {Yang, Zhao and Sun, Qingshuang},
  date = {2022-12-31},
  journaltitle = {Connection Science},
  shortjournal = {Connection Science},
  volume = {34},
  number = {1},
  pages = {2240--2264},
  issn = {0954-0091, 1360-0494},
  doi = {10.1080/09540091.2022.2114428},
  url = {https://www.tandfonline.com/doi/full/10.1080/09540091.2022.2114428},
  urldate = {2022-09-01},
  abstract = {Federated learning (FL) is an emerging distributed machine learning technique. However, when dealing with heterogeneous data, a shared global model cannot generalise all devices' local data. Furthermore, the FL training process necessitates frequent parameter communication, which interferes with the limited bandwidth and unstable connections of participating devices. These two issues have a significant impact on FL's effectiveness and efficiency. In this paper, an enhanced communication-efficient personalised FL technique, FedGB, is proposed. Different from existing approaches, FedGB believes that only interacting common information from training results on different devices can improve local personalised training results more effectively. FedGB dynamically selects the backbone structures in the local models to represent the dynamically determined backbone information (common features) in the global model for aggregation. Only interacting common features between different nodes reduce the impact of heterogeneous data to a certain extent. The dynamic adaptive sub-model selection avoids the impact of manually setting the scale of sub-model. FedGB can thus reduce communication overheads while maintaining inference accuracy. The results obtained in a variety of experimental settings show that FedGB can effectively improve communication efficiency and inference accuracy.},
  langid = {english}
}

@article{yang_FederatedMachineLearning_2019,
  title = {Federated {{Machine Learning}}: {{Concept}} and {{Applications}}},
  author = {Yang, Qiang and Liu, Yang and Chen, Tianjian and Tong, Yongxin},
  date = {2019-02-28},
  journaltitle = {ACM Transactions on Intelligent Systems and Technology},
  volume = {10},
  number = {2},
  pages = {1--19},
  issn = {2157-6904},
  doi = {10.1145/3298981},
  url = {https://dl.acm.org/doi/10.1145/3298981},
  abstract = {Today's artificial intelligence still faces two major challenges. One is that, in most industries, data exists in the form of isolated islands. The other is the strengthening of data privacy and security.We propose a possible solution to these challenges: Secure federated learning. Beyond the federated-learning framework first proposed by Google in 2016, we introduce a comprehensive secure federated-learning framework, which includes horizontal federated learning, vertical federated learning, and federated transfer learning.We provide definitions, architectures, and applications for the federated-learning framework, and provide a comprehensive survey of existing works on this subject. In addition, we propose building data networks among organizations based on federated mechanisms as an effective solution to allowing knowledge to be shared without compromising user privacy.},
  keywords = {\_processed,+survey}
}

@inproceedings{yang_HFLHierarchicalCommunicationEfficient_2021,
  title = {H-{{FL}}: {{A Hierarchical Communication-Efficient}} and {{Privacy-Protected Architecture}} for {{Federated Learning}}},
  shorttitle = {H-{{FL}}},
  booktitle = {Proceedings of the {{Thirtieth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Yang, He},
  date = {2021-08},
  pages = {479--485},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  location = {Montreal, Canada},
  doi = {10/gngc3r},
  url = {https://www.ijcai.org/proceedings/2021/67},
  urldate = {2022-01-31},
  abstract = {The longstanding goals of federated learning (FL) require rigorous privacy guarantees and low communication overhead while holding a relatively high model accuracy. However, simultaneously achieving all the goals is extremely challenging. In this paper, we propose a novel framework called hierarchical federated learning (H-FL) to tackle this challenge. Considering the degradation of the model performance due to the statistic heterogeneity of the training data, we devise a runtime distribution reconstruction strategy, which reallocates the clients appropriately and utilizes mediators to rearrange the local training of the clients. In addition, we design a compression-correction mechanism incorporated into H-FL to reduce the communication overhead while not sacrificing the model performance. To further provide privacy guarantees, we introduce differential privacy while performing local training, which injects moderate amount of noise into only part of the complete model. Experimental results show that our H-FL framework achieves the state-of-art performance on different datasets for the real-world image recognition tasks.},
  eventtitle = {Thirtieth {{International Joint Conference}} on {{Artificial Intelligence}} \{\vphantom\}{{IJCAI-21}}\vphantom\{\}},
  isbn = {978-0-9992411-9-6},
  langid = {english},
  keywords = {\_read\_urgently}
}

@article{yang_PersonalizedFederatedLearning_2022,
  title = {Personalized {{Federated Learning}} on {{Non-IID Data}} via {{Group-Based Meta-Learning}}},
  author = {Yang, Lei and Huang, Jiaming and Lin, Wanyu and Cao, Jiannong},
  date = {2022-08-15},
  journaltitle = {ACM Transactions on Knowledge Discovery from Data},
  shortjournal = {ACM Trans. Knowl. Discov. Data},
  issn = {1556-4681},
  doi = {10.1145/3558005},
  url = {https://doi.org/10.1145/3558005},
  urldate = {2022-08-29},
  abstract = {Personalized federated learning (PFL) has emerged as a paradigm to provide a personalized model that can fit the local data distribution of each client. One natural choice for PFL is to leverage the fast adaptation capability of meta-learning, where it first obtains a single global model, and each client achieves a personalized model by fine-tuning the global one with its local data. However, existing meta-learning-based approaches implicitly assume that the data distribution among different clients is similar, which may not be applicable due to the property of data heterogeneity in federated learning. In this work, we propose a Group-based Federated Meta-Learning framework, called G-FML, which adaptively divides the clients into groups based on the similarity of their data distribution, and the personalized models are obtained with meta-learning within each group. In particular, we develop a simple yet effective grouping mechanism to adaptively partition the clients into multiple groups. Our mechanism ensures that each group is formed by the clients with similar data distribution such that the group-wise meta-model can achieve ``personalization'' at large. By doing so, our framework can be generalized to a highly heterogeneous environment. We evaluate the effectiveness of our proposed G-FML framework on three heterogeneous benchmarking datasets. The experimental results show that our framework improves the model accuracy by up to 13.15\% relative to the state-of-the-art federated meta-learning.},
  keywords = {clustering methods,Federated learning,meta learning,neural networks},
  annotation = {Just Accepted}
}

@article{yang_Reviewapplicationprogress_2023,
  title = {Review on Application Progress of Federated Learning Model and Security Hazard Protection},
  author = {Yang, Aimin and Ma, Zezhong and Zhang, Chunying and Han, Yang and Hu, Zhibin and Zhang, Wei and Huang, Xiangdong and Wu, Yafeng},
  date = {2023-02-01},
  journaltitle = {Digital Communications and Networks},
  shortjournal = {Digital Communications and Networks},
  volume = {9},
  number = {1},
  pages = {146--158},
  issn = {2352-8648},
  doi = {10.1016/j.dcan.2022.11.006},
  url = {https://www.sciencedirect.com/science/article/pii/S2352864822002474},
  urldate = {2024-04-12},
  abstract = {Federated learning is a new type of distributed learning framework that allows multiple participants to share training results without revealing their data privacy. As data privacy becomes more important, it becomes difficult to collect data from multiple data owners to make machine learning predictions due to the lack of data security. Data is forced to be stored independently between companies, creating ``data silos''. With the goal of safeguarding data privacy and security, the federated learning framework greatly expands the amount of training data, effectively improving the shortcomings of traditional machine learning and deep learning, and bringing AI algorithms closer to our reality. In the context of the current international data security issues, federated learning is developing rapidly and has gradually moved from the theoretical to the applied level. The paper first introduces the federated learning framework, analyzes its advantages, reviews the results of federated learning applications in industries such as communication and healthcare, then analyzes the pitfalls of federated learning and discusses the security issues that should be considered in applications, and finally looks into the future of federated learning and the application layer.},
  keywords = {Data silos,Federated learning,Learning framework,Machine learning,Privacy protection}
}

@inproceedings{ye_PFedSAPersonalizedFederated_2023,
  title = {{{PFedSA}}: {{Personalized Federated Multi-Task Learning}} via {{Similarity Awareness}}},
  shorttitle = {{{PFedSA}}},
  booktitle = {2023 {{IEEE International Parallel}} and {{Distributed Processing Symposium}} ({{IPDPS}})},
  author = {Ye, Chuyao and Zheng, Hao and Hu, Zhigang and Zheng, Meiguang},
  date = {2023-05},
  pages = {480--488},
  issn = {1530-2075},
  doi = {10.1109/IPDPS54959.2023.00055},
  url = {https://ieeexplore.ieee.org/document/10177489},
  urldate = {2023-12-05},
  abstract = {Federated Learning (FL) constructs a distributed machine learning framework that involves multiple remote clients collaboratively training models. However in real-world situations, the emergence of non-Independent and Identically Distributed (non-IID) data makes the global model generated by traditional FL algorithms no longer meet the needs of all clients, and the accuracy is greatly reduced. In this paper, we propose a personalized federated multi-task learning method via similarity awareness (PFedSA), which captures the similarity between client data through model parameters uploaded by clients, thus facilitating collaborative training of similar clients and providing personalized models based on each client's data distribution. Specifically, it generates the intrinsic cluster structure among clients and introduces personalized patch layers into the cluster to personalize the cluster model. PFedSA also maintains the generalization ability of models, which allows each client to benefit from nodes with similar data distributions when training data, and the greater the similarity, the more benefit. We evaluate the performance of the PFedSA method using MNIST, EMNIST and CIFAR10 datasets, and investigate the impact of different data setting schemes on the performance of PFedSA. The results show that in all data setting scenarios, the PFedSA method proposed in this paper can achieve the best personalization performance, having more clients with higher accuracy, and it is especially effective when the client's data is non-IID.},
  eventtitle = {2023 {{IEEE International Parallel}} and {{Distributed Processing Symposium}} ({{IPDPS}})},
  keywords = {clustering,Collaboration,Distributed databases,federated learning,Federated learning,Learning systems,Machine learning algorithms,multi-task learning,similarity awareness,Training,Training data}
}

@inproceedings{yin_ByzantineRobustDistributedLearning_2018,
  title = {Byzantine-{{Robust Distributed Learning}}: {{Towards Optimal Statistical Rates}}},
  shorttitle = {Byzantine-{{Robust Distributed Learning}}},
  booktitle = {Proceedings of the 35th {{International Conference}} on {{Machine Learning}}},
  author = {Yin, Dong and Chen, Yudong and Kannan, Ramchandran and Bartlett, Peter},
  date = {2018-07-03},
  pages = {5650--5659},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v80/yin18a.html},
  urldate = {2023-03-07},
  abstract = {In this paper, we develop distributed optimization algorithms that are provably robust against Byzantine failures---arbitrary and potentially adversarial behavior, in distributed computing systems, with a focus on achieving optimal statistical performance. A main result of this work is a sharp analysis of two robust distributed gradient descent algorithms based on median and trimmed mean operations, respectively. We prove statistical error rates for all of strongly convex, non-strongly convex, and smooth non-convex population loss functions. In particular, these algorithms are shown to achieve order-optimal statistical error rates for strongly convex losses. To achieve better communication efficiency, we further propose a median-based distributed algorithm that is provably robust, and uses only one communication round. For strongly convex quadratic loss, we show that this algorithm achieves the same optimal error rate as the robust distributed gradient descent algorithms.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@inproceedings{yosinski_Howtransferableare_2014,
  title = {How Transferable Are Features in Deep Neural Networks?},
  booktitle = {Proceedings of the 27th {{International Conference}} on {{Neural Information Processing Systems}} - {{Volume}} 2},
  author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  date = {2014-12-08},
  pages = {9},
  abstract = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.},
  eventtitle = {Neural {{Information Processing Systems}} ({{NIPS}})},
  langid = {english}
}

@inproceedings{you_Poisoningattackdetection_2022,
  title = {Poisoning Attack Detection Using Client Historical Similarity in Non-Iid Environments},
  booktitle = {2022 12th {{International Conference}} on {{Cloud Computing}}, {{Data Science}} \& {{Engineering}} ({{Confluence}})},
  author = {You, XinTong and Liu, Zhengqi and Yang, Xu and Ding, Xuyang},
  date = {2022-01},
  pages = {439--447},
  doi = {10.1109/Confluence52989.2022.9734158},
  abstract = {Federated learning has drawn widespread attention as privacy-preserving solution, which has a protective effect on data security and privacy. It has unique distributed machine learning mechanism, namely model sharing instead of data sharing. However, the mechanism also leads to the fact that malicious clients can easily train local model based on poisoned data and upload it to the server for contaminating the global model, thus severely hampering the development of federated learning. In this paper, we build a federated learning system and simulate heterogeneous data on each client for training. Although we cannot directly differentiate malicious customers by the uploaded model in a heterogeneous data environment, by experiments we found some features that are used to distinguish malicious customers from benign customers during training. Given above, we propose a federated learning poisoning attack detection method for detecting malicious clients and ensuring aggregation quality. The method can filter out anomaly models by comparing the similarity of the historical changes of clients and gradually identifying attacker clients through reputation mechanism. We experimentally demonstrate that the method significantly improves the performance of the global model even when the proportion of malicious clients is as high as one-third.},
  eventtitle = {2022 12th {{International Conference}} on {{Cloud Computing}}, {{Data Science}} \& {{Engineering}} ({{Confluence}})},
  keywords = {Collaborative work,Distributed databases,Distributed Machine Learning,Euclidean distance,Federated Learning,Heterogeneous Data,Machine learning,Market research,Poisoning Attack Detection,Resists,Training}
}

@unpublished{yu_FedUnifiedApproach_2021,
  title = {Fed+: {{A Unified Approach}} to {{Robust Personalized Federated Learning}}},
  shorttitle = {Fed+},
  author = {Yu, Pengqian and Kundu, Achintya and Wynter, Laura and Lim, Shiau Hong},
  date = {2021-06-06},
  eprint = {2009.06303},
  eprinttype = {arXiv},
  eprintclass = {cs, math, stat},
  url = {http://arxiv.org/abs/2009.06303},
  urldate = {2022-01-31},
  abstract = {We present a class of methods for robust, personalized federated learning, called Fed+, that unifies many federated learning algorithms. The principal advantage of this class of methods is to better accommodate the real-world characteristics found in federated training, such as the lack of IID data across parties, the need for robustness to outliers or stragglers, and the requirement to perform well on party-specific datasets. We achieve this through a problem formulation that allows the central server to employ robust ways of aggregating the local models while keeping the structure of local computation intact. Without making any statistical assumption on the degree of heterogeneity of local data across parties, we provide convergence guarantees for Fed+ for convex and non-convex loss functions and robust aggregation. The Fed+ theory is also equipped to handle heterogeneous computing environments including stragglers without additional assumptions; specifically, the convergence results cover the general setting where the number of local update steps across parties can vary. We demonstrate the benefits of Fed+ through extensive experiments across standard benchmark datasets as well as on a challenging real-world problem in financial portfolio management where the heterogeneity of party-level data can lead to training failure in standard federated learning approaches.},
  langid = {english},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},\_read\_urgently,â›” No DOI found,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning}
}

@article{yu_IntrusionDetectionMethod_2020,
  title = {An {{Intrusion Detection Method Using Few-Shot Learning}}},
  author = {Yu, Yingwei and Bian, Naizheng},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {49730--49740},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2980136},
  abstract = {Network intrusion detection is an essential means to ensure the security of the network information system. In the real network, abnormal behaviors occur much less frequently than normal behaviors, resulting in scarcity of abnormal samples. We proposed an intrusion detection method based on Few-Shot Learning (FSL), which only used less than 1\% of NSL-KDD KDDTrain+ dataset for training, and achieved high accuracy of 92.34\% for KDD-Test+ and 85.75\% for KDD-Test-21, while other methods, such as J48, Naive Bayes(NB), Random Forest(RF), Support Vector Machine(SVM), recurrent neural network(RNN) and Channel boosted and residual learning based deep convolutional neural network (CBR-CNN), used 20\% of KDDTrain+ dataset for training, and achieved relatively low accuracy (less than 89.41\% for KDD-Test+ and less than 80.36\% for KDD-Test-21). The experiment on dataset of UNSW- NB15 showed a similar result. The detection rates for Dos, U2R, R2L and U2R are improved by our method too, especially for U2R and R2L, which only take up a small proportion of the dataset, the detection rates are increased from 13\% to 81.50\% and 44.41\% to 75.93\%, respectively.},
  eventtitle = {{{IEEE Access}}},
  keywords = {data scarcity,deep learning,Feature extraction,Few-shot learning,intrusion detection,Intrusion detection,Machine learning,Measurement,Neural networks,Testing,Training}
}

@inproceedings{yu_PrivacyPreservingModelsIntrusion_2022,
  title = {Privacy-{{Preserving}} and {{Models Intrusion Detection Federated Deep Learning Challenges}}, {{Schemas}} and {{Future Trajectories}}},
  booktitle = {2022 19th {{International Computer Conference}} on {{Wavelet Active Media Technology}} and {{Information Processing}} ({{ICCWAMTIP}})},
  author = {Yu, Yang and Jianping, Li and Weiwei, Duan},
  date = {2022-12},
  pages = {1--10},
  issn = {2576-8964},
  doi = {10.1109/ICCWAMTIP56608.2022.10016548},
  url = {https://ieeexplore.ieee.org/abstract/document/10016548},
  urldate = {2024-04-12},
  abstract = {Deep learning has made remarkable research advancements and wide-ranging applications in the domains of computer vision, multimodal, natural language processing, additionally, other areas. This has caused the academic community to pay increasingly close attention to the attack and defense technology in its training and testing phases, among which the federal deep learning has produced positive results. Federated deep learning models are prone to memorizing private and sensitive terminal participants' data, model parameters, when combined with the model's inherent vulnerability, they will result in privacy leakage, poisoning attack, model inference attack, adversarial attack. We briefly discuss the conception of federated deep learning as well as security challenges and open questions in this paper. In order to facilitate the understanding of these challenges and problems, we further propose a security system model. We also provide an overview and deduce the attack and mitigation approaches to the most sophisticated privacy-preserving and intrusion detection models. in the last two years. To tackle these challenges and enlighten further encryption techniques researches, finally, we discuss and describe current prospects and future trajectories of federated deep learning.},
  eventtitle = {2022 19th {{International Computer Conference}} on {{Wavelet Active Media Technology}} and {{Information Processing}} ({{ICCWAMTIP}})},
  keywords = {Adversarial attack,Computational modeling,Data models,Deep learning,Encryption techniques,Federated deep learning,Inference attack,Intrusion detection,Models intrusion detection,Poisoning attack,Privacy-preserving,Training,Training data,Trajectory}
}

@inproceedings{yuan_LightweightEfficientDistributed_2021,
  title = {Towards {{Lightweight}} and {{Efficient Distributed Intrusion Detection Framework}}},
  booktitle = {2021 {{IEEE Global Communications Conference}} ({{GLOBECOM}})},
  author = {Yuan, Shuai and Li, Hongwei and Zhang, Rui and Hao, Meng and Li, Yiran and Lu, Rongxing},
  date = {2021-12},
  pages = {1--6},
  publisher = {IEEE},
  location = {Madrid, Spain},
  doi = {10.1109/GLOBECOM46510.2021.9685953},
  url = {https://ieeexplore.ieee.org/document/9685953/},
  urldate = {2022-02-15},
  abstract = {Federated learning (FL), as a promising distributed learning paradigm, has put many efforts into distributed intrusion detection systems (IDS), for defending against various malicious attacks, such as SQL injection and DDoS attacks. Compared with traditional IDS based on centralized deep learning (DL), FL-based solutions require not to share users' raw data while yielding better detection performance. However, state-ofthe-art FL-based methods still suffer from two key limitations: 1) insufficient detection performance on non-independent and identically distributed (non-IID) data, and 2) high communication and computational overheads due to the utilization of large-scale neural network models. In this paper, we propose a lightweight collaborative intrusion detection framework, called CoLGBM, the first of its kind in the regime of decentralized IDS, where decision tree and light gradient boosting machine (LGBM) are combined for constructing the detection scheme. The main insight is that through combining user-trained decision trees (each user's decision tree is derived from its own data with unique distribution), our framework can perform effectively on non-IID data while working efficiently for handling enormous samples. Compared with the current FL-based methods, our CoLGBM achieves higher accuracy and lower overhead on both IID and non-IID data. Extensive experiment results demonstrate our scheme with high-level performance.},
  eventtitle = {{{GLOBECOM}} 2021 - 2021 {{IEEE Global Communications Conference}}},
  isbn = {978-1-72818-104-2},
  langid = {english}
}

@inproceedings{yutao_InternetThingsIntrusion_2022,
  title = {Internet of {{Things Intrusion Detection System}} Based on {{Transfer Learning}}},
  booktitle = {2022 {{IEEE}} 2nd {{International Conference}} on {{Electronic Technology}}, {{Communication}} and {{Information}} ({{ICETCI}})},
  author = {Yutao, Wang and Zhongtian, Li and Yi, Bu and Jie, Li and Fangzheng, Xu and Yu, Bao},
  date = {2022-05},
  pages = {25--30},
  doi = {10.1109/ICETCI55101.2022.9832387},
  abstract = {Because of the many types of Internet of Things (IoT) attacks, as well as the lack of computing resources for some devices, the small number of anomalous datasets and the lack of updated data, resulting in insufficient training data and computational power for supervised learning-based intrusion detection models and the Internet datasets still dominate the research on IoT intrusion detection. Therefore, this paper proposes a VGG-RED approach to IoT intrusion detection based on Transfer Learning (TL), which migrates the feature weights from the training of two Internet intrusion detection datasets to the training of three IoT intrusion detection datasets respectively, and inter-migrates the three IoT datasets. The classification models are trained by model parameter migration and neural network fine-tuning. Unlike previous work on extracting manually designed features, this method retains the end-to-end learning performance of Deep Learning (DL), reduces the risk of concept migration occurring, and reduces human intervention. Experimental results demonstrate the feasibility of the VGG-RED model to migrate Internet attack classification to the IoT. The model can effectively improve the accuracy of malicious attack detection in IoT environments while reducing computational resources, and has a strong generalization capability, with an accuracy improvement of about 2\% and a time reduction of 7-13\%.},
  eventtitle = {2022 {{IEEE}} 2nd {{International Conference}} on {{Electronic Technology}}, {{Communication}} and {{Information}} ({{ICETCI}})},
  keywords = {anomaly detection,Computational modeling,convolutional neural networks,deep learning,Deep learning,Intrusion detection,IoT intrusion detection,Neural networks,Training,Training data,transfer learning,Transfer learning}
}

@inproceedings{zaabar_IntrusionDetectionSystem_2022,
  title = {Intrusion {{Detection System}} for {{IoMT}} through {{Blockchain-based Federated Learning}}},
  booktitle = {2022 15th {{International Conference}} on {{Security}} of {{Information}} and {{Networks}} ({{SIN}})},
  author = {Zaabar, Bessem and Cheikhrouhou, Omar and Abid, Mohamed},
  date = {2022-11},
  pages = {01--08},
  doi = {10.1109/SIN56466.2022.9970536},
  abstract = {Federated Learning (FL) is a feasible technology to collaboratively train a model without sharing private data. This approach differs from traditional machine learning techniques, which aggregate local datasets in a single server. Thus, FL is adopted in the Healthcare sector to preserve the privacy of collected sensitive medical data from heterogenous and resource-constrained Internet of Medical Things (IoMT). However, FL requires aggregating all trained local models in a central server that presents a single point of failure. To address this issue, we propose a novel Blockchain-based Federated Learning architecture, which is applied to detect malicious network traffic in IoMT environments. In this paper, the proposed architecture takes advantage of a Hyperledger Fabric channel coupled with FL to manage efficiently and securely the learning process of an Intrusion Detection System (IDS). The Blockchain channel replaces the commonly used central server with the traditional FL approach. Moreover, the proposed approach benefits from the inherent features of Blockchain and FL. Besides, it secures patient data collection from the IoMT by examining the network traffic for unauthorised behaviour or policy breaches.},
  eventtitle = {2022 15th {{International Conference}} on {{Security}} of {{Information}} and {{Networks}} ({{SIN}})},
  keywords = {Blockchain,Data privacy,Distributed ledger,Fabrics,Fed-erated Learning (FL),Federated learning,Internet of Medical Things,Internet of Medical Things (IoMT),Intrusion detection,Intrusion Detection System (IDS),Security and Privacy,Telecommunication traffic}
}

@inproceedings{zaabar_IntrusionDetectionSystem_2022a,
  title = {Intrusion {{Detection System}} for {{IoMT}} through {{Blockchain-based Federated Learning}}},
  booktitle = {2022 15th {{International Conference}} on {{Security}} of {{Information}} and {{Networks}} ({{SIN}})},
  author = {Zaabar, Bessem and Cheikhrouhou, Omar and Abid, Mohamed},
  date = {2022-11},
  pages = {01--08},
  doi = {10.1109/SIN56466.2022.9970536},
  url = {https://ieeexplore.ieee.org/abstract/document/9970536},
  urldate = {2024-04-12},
  abstract = {Federated Learning (FL) is a feasible technology to collaboratively train a model without sharing private data. This approach differs from traditional machine learning techniques, which aggregate local datasets in a single server. Thus, FL is adopted in the Healthcare sector to preserve the privacy of collected sensitive medical data from heterogenous and resource-constrained Internet of Medical Things (IoMT). However, FL requires aggregating all trained local models in a central server that presents a single point of failure. To address this issue, we propose a novel Blockchain-based Federated Learning architecture, which is applied to detect malicious network traffic in IoMT environments. In this paper, the proposed architecture takes advantage of a Hyperledger Fabric channel coupled with FL to manage efficiently and securely the learning process of an Intrusion Detection System (IDS). The Blockchain channel replaces the commonly used central server with the traditional FL approach. Moreover, the proposed approach benefits from the inherent features of Blockchain and FL. Besides, it secures patient data collection from the IoMT by examining the network traffic for unauthorised behaviour or policy breaches.},
  eventtitle = {2022 15th {{International Conference}} on {{Security}} of {{Information}} and {{Networks}} ({{SIN}})},
  keywords = {Blockchain,Data privacy,Distributed ledger,Fabrics,Fed-erated Learning (FL),Federated learning,Internet of Medical Things,Internet of Medical Things (IoMT),Intrusion detection,Intrusion Detection System (IDS),Security and Privacy,Telecommunication traffic}
}

@inproceedings{zainudin_FedDDoSEfficientFederated_2022,
  title = {{{FedDDoS}}: {{An Efficient Federated Learning-based DDoS Attacks Classification}} in {{SDN-Enabled IIoT Networks}}},
  shorttitle = {{{FedDDoS}}},
  booktitle = {2022 13th {{International Conference}} on {{Information}} and {{Communication Technology Convergence}} ({{ICTC}})},
  author = {Zainudin, Ahmad and Akter, Rubina and Kim, Dong-Seong and Lee, Jae-Min},
  date = {2022-10},
  pages = {1279--1283},
  issn = {2162-1241},
  doi = {10.1109/ICTC55196.2022.9952610},
  abstract = {Independent distribution systems are made possible by Industry 4.0, and these systems produce heterogeneous data that is vulnerable to cyberattacks. The Distributed Denial of Service (DDoS) attack is a typical contemporary cyber threat that disables a target server by flooding it with malicious traffic. In this research, a deep-federated learning-based decentralized DDoS classification method enables independent clients to train local data while maintaining each industrial agent's data privacy. This framework applies a filter-based Pearson correlation coefficient (PCC) feature selection technique for selecting potential features to reduce complexity and improve the model performance. The proposed model has been evaluated with the recent DDoS attacks dataset, CICDDoS2019, and achieves great accuracy of 98.37\% with a computational time of 3.917 ms.},
  eventtitle = {2022 13th {{International Conference}} on {{Information}} and {{Communication Technology Convergence}} ({{ICTC}})},
  keywords = {Computational modeling,Data privacy,DDoS classification,Denial-of-service attack,Feature extraction,federated learning,Fourth Industrial Revolution,IIoT,Information and communication technology,SDN,Servers}
}

@inproceedings{zakariyya_ResourceEfficientFederated_2022,
  title = {Resource {{Efficient Federated Deep Learning}} for~{{IoT Security Monitoring}}},
  booktitle = {Attacks and {{Defenses}} for the {{Internet-of-Things}}},
  author = {Zakariyya, Idris and Kalutarage, Harsha and Al-Kadri, M. Omar},
  editor = {Li, Wenjuan and Furnell, Steven and Meng, Weizhi},
  date = {2022},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {122--142},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-21311-3_6},
  abstract = {Federated Learning (FL) uses a distributed Machine Learning (ML) concept to build a global model using multiple local models trained on distributed edge devices. A disadvantage of the FL paradigm is the requirement of many communication rounds before model convergence. As a result, there is a challenge for running on-device FL with resource-hungry algorithms such as Deep Neural Network (DNN), especially in the resource-constrained Internet of Things (IoT) environments for security monitoring. To address this issue, this paper proposes Resource Efficient Federated Deep Learning (REFDL) method. Our method exploits and optimizes Federated Averaging (Fed-Avg) DNN based technique to reduce computational resources consumption for IoT security monitoring. It utilizes pruning and simulated micro-batching in optimizing the Fed-Avg DNN for effective and efficient IoT attacks detection at distributed edge nodes. The performance was evaluated using various realistic IoT and non-IoT benchmark datasets on virtual and testbed environments build with GB-BXBT-2807 edge-computing-like devices. The experimental results show that the proposed method can reduce memory usage by 81\% in the simulated environment of virtual workers compared to its benchmark counterpart. In the realistic testbed scenario, it saves 6\% memory while reducing execution time by 15\% without degrading accuracy.},
  isbn = {978-3-031-21311-3},
  langid = {english},
  keywords = {Deep Neural Network (DNN),Distributed machine learning,Edge devices,Federated learning (FL),Internet of Things (IoT),Security monitoring}
}

@inproceedings{zakariyya_ResourceEfficientFederated_2022a,
  title = {Resource {{Efficient Federated Deep Learning}} for~{{IoT Security Monitoring}}},
  booktitle = {Attacks and {{Defenses}} for the {{Internet-of-Things}}},
  author = {Zakariyya, Idris and Kalutarage, Harsha and Al-Kadri, M. Omar},
  editor = {Li, Wenjuan and Furnell, Steven and Meng, Weizhi},
  date = {2022},
  pages = {122--142},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-21311-3_6},
  abstract = {Federated Learning (FL) uses a distributed Machine Learning (ML) concept to build a global model using multiple local models trained on distributed edge devices. A disadvantage of the FL paradigm is the requirement of many communication rounds before model convergence. As a result, there is a challenge for running on-device FL with resource-hungry algorithms such as Deep Neural Network (DNN), especially in the resource-constrained Internet of Things (IoT) environments for security monitoring. To address this issue, this paper proposes Resource Efficient Federated Deep Learning (REFDL) method. Our method exploits and optimizes Federated Averaging (Fed-Avg) DNN based technique to reduce computational resources consumption for IoT security monitoring. It utilizes pruning and simulated micro-batching in optimizing the Fed-Avg DNN for effective and efficient IoT attacks detection at distributed edge nodes. The performance was evaluated using various realistic IoT and non-IoT benchmark datasets on virtual and testbed environments build with GB-BXBT-2807 edge-computing-like devices. The experimental results show that the proposed method can reduce memory usage by 81\% in the simulated environment of virtual workers compared to its benchmark counterpart. In the realistic testbed scenario, it saves 6\% memory while reducing execution time by 15\% without degrading accuracy.},
  isbn = {978-3-031-21311-3},
  langid = {english}
}

@online{zakerinia_QuAFLFederatedAveraging_2022,
  title = {{{QuAFL}}: {{Federated Averaging Can Be Both Asynchronous}} and {{Communication-Efficient}}},
  shorttitle = {{{QuAFL}}},
  author = {Zakerinia, Hossein and Talaei, Shayan and Nadiradze, Giorgi and Alistarh, Dan},
  date = {2022-06-22},
  eprint = {2206.10032},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2206.10032},
  urldate = {2022-07-25},
  abstract = {Federated Learning (FL) is an emerging paradigm to enable the largescale distributed training of machine learning models, while still providing privacy guarantees. In this work, we jointly address two of the main practical challenges when scaling federated optimization to large node counts: the need for tight synchronization between the central authority and individual computing nodes, and the large communication cost of transmissions between the central server and clients. Specifically, we present a new variant of the classic federated averaging (FedAvg) algorithm, which supports both asynchronous communication and communication compression. We provide a new analysis technique showing that, in spite of these system relaxations, our algorithm essentially matches the best known bounds for FedAvg, under reasonable parameter settings. On the experimental side, we show that our algorithm ensures fast practical convergence for standard federated tasks.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning}
}

@article{zang_TrafficFlowPrediction_2022,
  title = {Traffic {{Flow Prediction Based}} on {{Federated Learning}} with {{Joint PCA Compression}} and {{Bayesian Optimization}}},
  author = {Zang, Lu and Qin, Yang and Li, Ruonan},
  date = {2022-10-09},
  journaltitle = {2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  pages = {3330--3335},
  publisher = {IEEE},
  location = {Prague, Czech Republic},
  doi = {10.1109/SMC53654.2022.9945217},
  url = {https://ieeexplore.ieee.org/document/9945217/},
  urldate = {2024-04-02},
  abstract = {Traffic flow prediction (TFP) is of great significance in the field of traffic congestion mitigation on the Internet of Vehicle(Iov). To be capable of a trade-off between data privacy protection and accurate prediction, we introduce a training paradigm based on Federated Learning (FL). However, the implementation of federal learning in practice is confronted with high communication and data heterogeneity. In this paper, Principal component analysis (PCA) is introduced to minimize the scale of data transmission on both the client and server. Due to the errors arising from the compression and reversion of the transmission model, we add an additional error term in the local objective function. To address the imbalanced data distribution and to accelerate the federal learning convergence, we then propose a mechanism that incorporates Bayesian optimization to dynamically determine the weights of clients during aggregation. With extensive experiments on real data, it can be demonstrated that communication costs can be minimized by 60-70\% while ensuring fewer errors.},
  eventtitle = {2022 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  isbn = {9781665452588}
}

@inproceedings{zang_TrafficFlowPrediction_2022a,
  title = {Traffic {{Flow Prediction Based}} on {{Federated Learning}} with {{Joint PCA Compression}} and {{Bayesian Optimization}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  author = {Zang, Lu and Qin, Yang and Li, Ruonan},
  date = {2022-10},
  pages = {3330--3335},
  issn = {2577-1655},
  doi = {10.1109/SMC53654.2022.9945217},
  url = {https://ieeexplore.ieee.org/document/9945217},
  urldate = {2024-04-02},
  abstract = {Traffic flow prediction (TFP) is of great significance in the field of traffic congestion mitigation on the Internet of Vehicle(Iov). To be capable of a trade-off between data privacy protection and accurate prediction, we introduce a training paradigm based on Federated Learning (FL). However, the implementation of federal learning in practice is confronted with high communication and data heterogeneity. In this paper, Principal component analysis (PCA) is introduced to minimize the scale of data transmission on both the client and server. Due to the errors arising from the compression and reversion of the transmission model, we add an additional error term in the local objective function. To address the imbalanced data distribution and to accelerate the federal learning convergence, we then propose a mechanism that incorporates Bayesian optimization to dynamically determine the weights of clients during aggregation. With extensive experiments on real data, it can be demonstrated that communication costs can be minimized by 60-70\% while ensuring fewer errors.},
  eventtitle = {2022 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  keywords = {Bayes methods,bayesian optimization,Federated learning,Linear programming,Prediction algorithms,principal component analysis,Privacy,Servers,traffic flow prediction,Training}
}

@inproceedings{zang_TrafficFlowPrediction_2022b,
  title = {Traffic {{Flow Prediction Based}} on {{Federated Learning}} with {{Joint PCA Compression}} and {{Bayesian Optimization}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  author = {Zang, Lu and Qin, Yang and Li, Ruonan},
  date = {2022-10},
  pages = {3330--3335},
  issn = {2577-1655},
  doi = {10.1109/SMC53654.2022.9945217},
  url = {https://ieeexplore.ieee.org/document/9945217},
  urldate = {2024-04-02},
  abstract = {Traffic flow prediction (TFP) is of great significance in the field of traffic congestion mitigation on the Internet of Vehicle(Iov). To be capable of a trade-off between data privacy protection and accurate prediction, we introduce a training paradigm based on Federated Learning (FL). However, the implementation of federal learning in practice is confronted with high communication and data heterogeneity. In this paper, Principal component analysis (PCA) is introduced to minimize the scale of data transmission on both the client and server. Due to the errors arising from the compression and reversion of the transmission model, we add an additional error term in the local objective function. To address the imbalanced data distribution and to accelerate the federal learning convergence, we then propose a mechanism that incorporates Bayesian optimization to dynamically determine the weights of clients during aggregation. With extensive experiments on real data, it can be demonstrated that communication costs can be minimized by 60-70\% while ensuring fewer errors.},
  eventtitle = {2022 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  keywords = {Bayes methods,bayesian optimization,Federated learning,Linear programming,Prediction algorithms,principal component analysis,Privacy,Servers,traffic flow prediction,Training}
}

@article{zangrandi_SteppingoutMUD_2020,
  title = {Stepping out of the {{MUD}}: {{Contextual}} Threat Information for {{IoT}} Devices with Manufacturer-Provided Behaviour Profiles},
  author = {Zangrandi, Luca Morgese and family=Ede, given=Thijs, prefix=van, useprefix=true and Booij, Tim and Sciancalepore, Savio and Allodi, Luca and Continella, Andrea},
  date = {2020},
  pages = {15},
  abstract = {Besides coming with unprecedented benefits, the Internet of Things (IoT) suffers deficits in security measures, leading to attacks increasing every year. In particular, network environments such as smart homes lack managed security capabilities to detect IoT-related attacks; IoT devices hosted therein are thus more easily infiltrated by threats. As such, context awareness on IoT infections is hard to achieve, preventing prompt response. In this work, we propose MUDscope, an approach to monitor malicious network activities affecting IoT in real-world consumer environments. We leverage the recent Manufacturer Usage Description (MUD) specification, which defines networking whitelists for IoT devices in MUD profiles, to reflect consistent and necessarily-anomalous activities from smart things. Our approach characterizes this traffic and extracts signatures for given attacks. By analyzing attack signatures for multiple devices, we gather insights into emerging attack patterns. We evaluate our approach on both an existing dataset, and a new openly available dataset created for this research. We show that MUDscope detects several attacks targeting IoT devices with an F1-score of 95.77\% and correctly identifies signatures for specific attacks with an F1-score of 87.72\%.},
  langid = {english},
  keywords = {\_read\_urgently,â›” No DOI found}
}

@unpublished{zhang_AdaptiveMemoryNetworks_2022,
  title = {Adaptive {{Memory Networks}} with {{Self-supervised Learning}} for {{Unsupervised Anomaly Detection}}},
  author = {Zhang, Yuxin and Wang, Jindong and Chen, Yiqiang and Yu, Han and Qin, Tao},
  date = {2022-01-02},
  eprint = {2201.00464},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2201.00464},
  urldate = {2022-01-31},
  abstract = {Unsupervised anomaly detection aims to build models to effectively detect unseen anomalies by only training on the normal data. Although previous reconstruction-based methods have made fruitful progress, their generalization ability is limited due to two critical challenges. First, the training dataset only contains normal patterns, which limits the model generalization ability. Second, the feature representations learned by existing models often lack representativeness which hampers the ability to preserve the diversity of normal patterns. In this paper, we propose a novel approach called Adaptive Memory Network with Self-supervised Learning (AMSL) to address these challenges and enhance the generalization ability in unsupervised anomaly detection. Based on the convolutional autoencoder structure, AMSL incorporates a self-supervised learning module to learn general normal patterns and an adaptive memory fusion module to learn rich feature representations. Experiments on four public multivariate time series datasets demonstrate that AMSL significantly improves the performance compared to other state-of-the-art methods. Specifically, on the largest CAP sleep stage detection dataset with 900 million samples, AMSL outperforms the second-best baseline by 4\%+ in both accuracy and F1 score. Apart from the enhanced generalization ability, AMSL is also more robust against input noise.},
  langid = {english},
  keywords = {â›” No DOI found,Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
}

@article{zhang_BlockchainbasedFederatedLearning_2020,
  title = {Blockchain-Based {{Federated Learning}} for {{Device Failure Detection}} in {{Industrial IoT}}},
  author = {Zhang, Weishan and Lu, Qinghua and Yu, Qiuyu and Li, Zhaotong and Liu, Yue and Lo, Sin Kit and Chen, Shiping and Xu, Xiwei and Zhu, Liming},
  date = {2020-09-06},
  journaltitle = {IEEE Internet of Things Journal},
  pages = {1--1},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2020.3032544},
  url = {https://ieeexplore.ieee.org/document/9233457/},
  abstract = {Device failure detection is one of most essential problems in industrial internet of things (IIoT). However, in conventional IIoT device failure detection, client devices need to upload raw data to the central server for model training, which might lead to disclosure of sensitive business data. Therefore, in this paper, to ensure client data privacy, we propose a blockchain-based federated learning approach for device failure detection in IIoT. First, we present a platform architecture of blockchain-based federated learning systems for failure detection in IIoT, which enables verifiable integrity of client data. In the architecture, each client periodically creates a Merkle tree in which each leaf node represents a client data record, and stores the tree root on a blockchain. Further, to address the data heterogeneity issue in IIoT failure detection, we propose a novel centroid distance weighted federated averaging (CDW\textbackslash\_FedAvg) algorithm taking into account the distance between positive class and negative class of each client dataset. In addition, to motivate clients to participate in federated learning, a smart contact based incentive mechanism is designed depending on the size and the centroid distance of client data used in local model training. A prototype of the proposed architecture is implemented with our industry partner, and evaluated in terms of feasibility, accuracy and performance. The results show that the approach is feasible, and has satisfactory accuracy and performance.},
  keywords = {survey-fids}
}

@inproceedings{zhang_BlockchainEmpoweredReliable_2021,
  title = {Blockchain {{Empowered Reliable Federated Learning}} by {{Worker Selection}}: {{A Trustworthy Reputation Evaluation Method}}},
  shorttitle = {Blockchain {{Empowered Reliable Federated Learning}} by {{Worker Selection}}},
  booktitle = {2021 {{IEEE Wireless Communications}} and {{Networking Conference Workshops}} ({{WCNCW}})},
  author = {Zhang, Qinnan and Ding, Qingyang and Zhu, Jianming and Li, Dandan},
  date = {2021-03},
  pages = {1--6},
  doi = {10.1109/WCNCW49093.2021.9420026},
  abstract = {Federated learning is a distributed machine learning framework that enables distributed model training with local datasets, which can effectively protect the data privacy of workers (i.e., intelligent edge nodes). The majority of federated learning algorithms assume that the workers are trusted and voluntarily participate in the cooperative model training process. However, the situation in practical application is not consistent with this. There are many challenges such as worker selection schemes for participating workers, which hamper the widespread adoption of federated learning. The existing research about worker selection scheme focused on multi-weight subjective logic model to calculate reputation value and adopted contract theory to motivate workers, which may exist subjective judgmental factors and unfair profit distribution. To address above challenges, we calculate the reputation value by model quality parameters to evaluate the reliability of workers. Blockchain is designed to store historical reputation value that realized tamperresistance and non-repudiation. Numerical results indicate that the worker selection scheme can improve the accuracy of the model and accelerate the model convergence.},
  eventtitle = {2021 {{IEEE Wireless Communications}} and {{Networking Conference Workshops}} ({{WCNCW}})},
  keywords = {Analytical models,blockchain,Blockchain,Conferences,consensus algorithm,Data privacy,federated learning,Machine learning,Predictive models,reputation evaluation,Training}
}

@online{zhang_DimKrumBackdoorResistantFederated_2022,
  title = {Dim-{{Krum}}: {{Backdoor-Resistant Federated Learning}} for {{NLP}} with {{Dimension-wise Krum-Based Aggregation}}},
  shorttitle = {Dim-{{Krum}}},
  author = {Zhang, Zhiyuan and Su, Qi and Sun, Xu},
  date = {2022-10-13},
  eprint = {2210.06894},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2210.06894},
  urldate = {2022-10-18},
  abstract = {Despite the potential of federated learning, it is known to be vulnerable to backdoor attacks. Many robust federated aggregation methods are proposed to reduce the potential backdoor risk. However, they are mainly validated in the CV field. In this paper, we find that NLP backdoors are hard to defend against than CV, and we provide a theoretical analysis that the malicious update detection error probabilities are determined by the relative backdoor strengths. NLP attacks tend to have small relative backdoor strengths, which may result in the failure of robust federated aggregation methods for NLP attacks. Inspired by the theoretical results, we can choose some dimensions with higher backdoor strengths to settle this issue. We propose a novel federated aggregation algorithm, Dim-Krum, for NLP tasks, and experimental results validate its effectiveness.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@inproceedings{zhang_DualAdversarialFederated_2022,
  title = {Dual {{Adversarial Federated Learning}} on~{{Non-IID Data}}},
  booktitle = {Knowledge {{Science}}, {{Engineering}} and {{Management}}},
  author = {Zhang, Tao and Yang, Shaojing and Song, Anxiao and Li, Guangxia and Dong, Xuewen},
  editor = {Memmi, Gerard and Yang, Baijian and Kong, Linghe and Zhang, Tianwei and Qiu, Meikang},
  date = {2022},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {233--246},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-10989-8_19},
  abstract = {Federated Learning (FL) enables multiple distributed local clients to coordinate with a central server to train a global model without sharing their private data. However, the data owned by different clients, even with the same label, may induce conflicts in the latent feature maps, especially under the non-IID FL scenarios. This would fatally impair the performance of the global model. To this end, we propose a novel approach, DAFL, for Dual Adversarial Federated Learning, to mitigate the divergence on latent feature maps among different clients on non-IID data. In particular, a local dual adversarial training is designed to identify the origins of latent feature maps, and then transforms the conflicting latent feature maps to reach a consensus between global and local models in each client. Besides, the latent feature maps of the two models become closer to each other adaptively by reducing their Kullback Leibler divergence. Extensive experiments on benchmark datasets validate the effectiveness of DAFL and also demonstrate that DAFL outperforms the state-of-the-art approaches in terms of test accuracy under different non-IID settings.},
  isbn = {978-3-031-10989-8},
  langid = {english},
  keywords = {Dual adversarial training,Federated learning,Kullback Leibler divergence,Latent feature map,Non-IID data}
}

@article{zhang_DynamicFusionbased_2020,
  title = {Dynamic {{Fusion}} Based {{Federated Learning}} for {{COVID-19 Detection}}},
  author = {Zhang, Weishan and Zhou, Tao and Lu, Qinghua and Wang, Xiao and Zhu, Chunsheng and Sun, Haoyun and Wang, Zhipeng and Lo, Sin Kit and Wang, Fei-Yue},
  date = {2020-09-22},
  journaltitle = {arXiv},
  volume = {14},
  number = {8},
  pages = {1--9},
  issn = {23318422},
  url = {http://arxiv.org/abs/2009.10401},
  abstract = {Medical diagnostic image analysis (e.g., CT scan or X-Ray) using machine learning is an efficient and accurate way to detect COVID-19 infections. However, sharing diagnostic images across medical institutions is usually not allowed due to the concern of patients' privacy. This causes the issue of insufficient datasets for training the image classification model. Federated learning is an emerging privacy-preserving machine learning paradigm that produces an unbiased global model based on the received updates of local models trained by clients without exchanging clients' local data. Nevertheless, the default setting of federated learning introduces huge communication cost of transferring model updates and can hardly ensure model performance when data heterogeneity of clients heavily exists. To improve communication efficiency and model performance, in this paper, we propose a novel dynamic fusion-based federated learning approach for medical diagnostic image analysis to detect COVID-19 infections. First, we design an architecture for dynamic fusion-based federated learning systems to analyse medical diagnostic images. Further, we present a dynamic fusion method to dynamically decide the participating clients according to their local model performance and schedule the model fusion-based on participating clients' training time. In addition, we summarise a category of medical diagnostic image datasets for COVID-19 detection, which can be used by the machine learning community for image analysis. The evaluation results show that the proposed approach is feasible and performs better than the default setting of federated learning in terms of model performance, communication efficiency and fault tolerance.},
  keywords = {â›” No DOI found}
}

@inproceedings{zhang_DynasparseAcceleratingGNN_2023,
  title = {Dynasparse: {{Accelerating GNN Inference}} through {{Dynamic Sparsity Exploitation}}},
  shorttitle = {Dynasparse},
  booktitle = {2023 {{IEEE International Parallel}} and {{Distributed Processing Symposium}} ({{IPDPS}})},
  author = {Zhang, Bingyi and Prasanna, Viktor},
  date = {2023-05},
  pages = {233--244},
  issn = {1530-2075},
  doi = {10.1109/IPDPS54959.2023.00032},
  abstract = {Graph Neural Network (GNN) inference is used in many real-world applications. Data sparsity in GNN inference, including sparsity in the input graph and the GNN model, offer opportunities to further speed up inference. Also, many pruning techniques have been proposed for model compression that increase the data sparsity of GNNs.We propose Dynasparse, a comprehensive hardware-software codesign on FPGA to accelerate GNN inference through dynamic sparsity exploitation. For this, we decouple the GNN computation kernels from the basic computation primitives, and explore hardware-software codesign as follows: 1) Hardware design: We propose a novel unified accelerator design on FPGA to efficiently execute various computation primitives. We develop a customized soft processor that is tightly coupled with the accelerator to execute a runtime system. Moreover, we develop efficient hardware mechanisms to profile the data sparsity and perform on-the-fly data format transformation to prepare the input data for various computation primitives; 2) Software design: We develop a runtime system that works synergistically with the accelerator to perform dynamic kernel-to-primitive mapping based on data sparsity. We implement Dynasparse on a state-of-the-art FPGA platform, Xilinx Alveo U250, and evaluate the design using widely used GNN models (GCN, GraphSAGE, GIN and SGC). For the above GNN models and various input graphs, the proposed accelerator and dynamic kernel-to-primitive mapping reduces the inference latency by 3.73\texttimes{} on the average compared with the static mapping strategies employed in the state-of-the-art GNN accelerators. Compared with state-of-the-art CPU (GPU) implementations, Dynasparse achieves up to 56.9\texttimes{} (2.37\texttimes ) speedup in end-to-end latency. Compared with state-of-the-art FPGA implementations, Dynasparse achieves 2.7\texttimes{} speedup in accelerator execution latency.},
  eventtitle = {2023 {{IEEE International Parallel}} and {{Distributed Processing Symposium}} ({{IPDPS}})},
  keywords = {Computational modeling,Data models,Graph neural network,Graph neural networks,Graphics processing units,Hardware,hardware architecture,hardware-software code-sign,Runtime,runtime system,Software design}
}

@inproceedings{zhang_Evaluationdatapoisoning_2022,
  title = {Evaluation of Data Poisoning Attacks on Federated Learning-Based Network Intrusion Detection System},
  booktitle = {2022 {{IEEE}} 24th {{Int Conf}} on {{High Performance Computing}} \& {{Communications}}; 8th {{Int Conf}} on {{Data Science}} \& {{Systems}}; 20th {{Int Conf}} on {{Smart City}}; 8th {{Int Conf}} on {{Dependability}} in {{Sensor}}, {{Cloud}} \& {{Big Data Systems}} \& {{Application}} ({{HPCC}}/{{DSS}}/{{SmartCity}}/{{DependSys}})},
  author = {Zhang, Yuemeng and Zhang, Yong and Zhang, Zhao and Bai, Haonan and Zhong, Tianyi and Song, Mei},
  date = {2022-12},
  pages = {2235--2242},
  doi = {10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00330},
  url = {https://ieeexplore.ieee.org/document/10074658},
  urldate = {2023-10-31},
  abstract = {Recently, federated learning-based network intrusion detection system (FL-based NIDS) has been considered as an essential tool to protect network security. It enables learning an effective intrusion detection model collaboratively without data privacy leakage. However, FL- based NIDS has exhibited inherent vulnerabilities on the data poisoning attacks launched by malicious clients. In this paper, we conduct the first systematic robustness evaluations of FL-based NIDS under data poisoning attack. Firstly, in consideration of the traffic domain constraints, we design the clean-label data poisoning attack against FL-based NIDS. Specifically, we propose an improved poisoned sample generation model based on Generative Adversarial Network, called PT-GAN, which optimizes with a new loss function that incorporates the feedback of the target intrusion detection model. The minimally-perturbed and correctly-labeled traffic samples generated by PT-GAN are then injected in the local training dataset to corrupt the intrusion detection model. Then, we explore the potential defense mechanism for these data poisoning attacks against FL- based NIDS and propose a novel defense method based on poisoned sample detection. Concretely, we propose the important neuron activations extraction method based on the layerwise relevance propagation method and then apply Oneclass-SVM to detect the poisoned sample. Experiments show that the proposed PT-GAN can degrade the performance of FL-based NIDS up to 28\% on UNSW-NB15 dataset. We also demonstrate the robustness of our proposed defense methods against data poisoning attacks.},
  eventtitle = {2022 {{IEEE}} 24th {{Int Conf}} on {{High Performance Computing}} \& {{Communications}}; 8th {{Int Conf}} on {{Data Science}} \& {{Systems}}; 20th {{Int Conf}} on {{Smart City}}; 8th {{Int Conf}} on {{Dependability}} in {{Sensor}}, {{Cloud}} \& {{Big Data Systems}} \& {{Application}} ({{HPCC}}/{{DSS}}/{{SmartCity}}/{{DependSys}})}
}

@article{zhang_FedDQAnovelregularizationbased_2024,
  title = {{{FedDQA}}: {{A}} Novel Regularization-Based Deep Learning Method for Data Quality Assessment in Federated Learning},
  shorttitle = {{{FedDQA}}},
  author = {Zhang, Zongxiang and Chen, Gang and Xu, Yunjie and Huang, Lihua and Zhang, Chenghong and Xiao, Shuaiyong},
  date = {2024-05-01},
  journaltitle = {Decision Support Systems},
  shortjournal = {Decision Support Systems},
  volume = {180},
  pages = {114183},
  issn = {0167-9236},
  doi = {10.1016/j.dss.2024.114183},
  url = {https://www.sciencedirect.com/science/article/pii/S0167923624000162},
  urldate = {2024-03-27},
  abstract = {Researchers strive to design artificial intelligence (AI) models that can fully utilize the potentials of data while protecting privacy. Federated learning is a promising solution because it utilizes data but shields them from those who do not own them. However, assessing data quality becomes a challenge in federated learning. We propose a data quality assessment method, Federated Data Quality Assessment (FedDQA), and compare it with traditional federated learning methods. FedDQA identifies low-quality data from participants and reduces their influence on the global model. We integrate data quality regularization strategies at the instance, feature, and participant levels into federate learning model. In various data poisoning settings, FedDQA outperforms existing federated learning methods in prediction performance and the accuracy in detecting low-quality data.},
  keywords = {Data heterogeneity,Data quality,Federated learning,Regularization-based strategies}
}

@article{zhang_FederatedMarkovLogic_2022,
  title = {Federated {{Markov Logic Network}} for Indoor Activity Recognition in {{Internet}} of {{Things}}},
  author = {Zhang, Chang and Ren, Xiaorui and Zhu, Tao and Zhou, Fang and Liu, Hong and Lu, Qinghua and Ning, Huansheng},
  date = {2022-10-11},
  journaltitle = {Knowledge-Based Systems},
  shortjournal = {Knowledge-Based Systems},
  volume = {253},
  pages = {109553},
  issn = {0950-7051},
  doi = {10.1016/j.knosys.2022.109553},
  url = {https://www.sciencedirect.com/science/article/pii/S095070512200781X},
  urldate = {2022-08-11},
  abstract = {Indoor activity recognition is essential in numerous Internet of Things (IoT) applications. As one of the widely used methods in this domain, Markov Logic Network (MLN) can simultaneously use activity knowledge and data by unifying probability and logic. The ``cloud computing'' model has recently been adopted to concentrate the activity data and activity knowledge in a central node for processing in indoor activity recognition by using MLN, which may lead to the data leakage of the clients. Therefore, to further alleviate client data privacy issues when building an indoor activity recognition model by training MLN, this paper proposes a Federated Markov Logic Network (FMLN) framework for indoor activity recognition. We designed different scenarios to investigate the FMLN framework, including statistical heterogeneity, the number ofvarious clients, and various network environments. The experimental results show that the FMLN framework effectively detects indoor activity.},
  langid = {english},
  keywords = {Federated learning,Indoor activity recognition,Internet of Things,Markov Logic Network}
}

@online{zhang_FLDetectorDefendingFederated_2022,
  title = {{{FLDetector}}: {{Defending Federated Learning Against Model Poisoning Attacks}} via {{Detecting Malicious Clients}}},
  shorttitle = {{{FLDetector}}},
  author = {Zhang, Zaixi and Cao, Xiaoyu and Jia, Jinyuan and Gong, Neil Zhenqiang},
  date = {2022-07-26},
  eprint = {2207.09209},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2207.09209},
  urldate = {2022-08-12},
  abstract = {Federated learning (FL) is vulnerable to model poisoning attacks, in which malicious clients corrupt the global model via sending manipulated model updates to the server. Existing defenses mainly rely on Byzantine-robust or provably robust FL methods, which aim to learn an accurate global model even if some clients are malicious. However, they can only resist a small number of malicious clients. It is still an open challenge how to defend against model poisoning attacks with a large number of malicious clients. Our FLDetector addresses this challenge via detecting malicious clients. FLDetector aims to detect and remove majority of the malicious clients such that a Byzantine-robust or provably robust FL method can learn an accurate global model using the remaining clients. Our key observation is that, in model poisoning attacks, the model updates from a client in multiple iterations are inconsistent. Therefore, FLDetector detects malicious clients via checking their model-updates consistency. Roughly speaking, the server predicts a client's model update in each iteration based on historical model updates, and flags a client as malicious if the received model update from the client and the predicted model update are inconsistent in multiple iterations. Our extensive experiments on three benchmark datasets show that FLDetector can accurately detect malicious clients in multiple stateof-the-art model poisoning attacks and adaptive attacks tailored to FLDetector. After removing the detected malicious clients, existing Byzantine-robust FL methods can learn accurate global models. Our code is available at https://github.com/zaixizhang/FLDetector.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security}
}

@article{zhang_iFlipperLabelFlipping_2023,
  title = {{{iFlipper}}: {{Label Flipping}} for {{Individual Fairness}}},
  shorttitle = {{{iFlipper}}},
  author = {Zhang, Hantian and Tae, Ki Hyun and Park, Jaeyoung and Chu, Xu and Whang, Steven Euijong},
  date = {2023-05-30},
  journaltitle = {Proceedings of the ACM on Management of Data},
  shortjournal = {Proc. ACM Manag. Data},
  volume = {1},
  number = {1},
  pages = {8:1--8:26},
  doi = {10.1145/3588688},
  url = {https://dl.acm.org/doi/10.1145/3588688},
  urldate = {2024-03-28},
  abstract = {As machine learning becomes prevalent, mitigating any unfairness present in the training data becomes critical. Among the various notions of fairness, this paper focuses on the well-known individual fairness, which states that similar individuals should be treated similarly. While individual fairness can be improved when training a model (in-processing), we contend that fixing the data before model training (pre-processing) is a more fundamental solution. In particular, we show that label flipping is an effective pre-processing technique for improving individual fairness. Our system iFlipper solves the optimization problem of minimally flipping labels given a limit to the individual fairness violations, where a violation occurs when two similar examples in the training data have different labels. We first prove that the problem is NP-hard. We then propose an approximate linear programming algorithm and provide theoretical guarantees on how close its result is to the optimal solution in terms of the number of label flips. We also propose techniques for making the linear programming solution more optimal without exceeding the violations limit. Experiments on real datasets show that iFlipper significantly outperforms other pre-processing baselines in terms of individual fairness and accuracy on unseen test sets. In addition, iFlipper can be combined with in-processing techniques for even better results.},
  keywords = {data labeling,data pre-processing,individual fairness}
}

@inproceedings{zhang_IoTIntrusionDetection_2023,
  title = {{{IoT Intrusion Detection Based}} on {{Personalized Federated Learning}}},
  booktitle = {2023 24st {{Asia-Pacific Network Operations}} and {{Management Symposium}} ({{APNOMS}})},
  author = {Zhang, Qianqian and Wang, Ying and Wei, Tongyan and Wen, Jiachen and Chen, Jingjing and Qiu, Xuesong},
  date = {2023-09},
  pages = {326--329},
  issn = {2576-8565},
  url = {https://ieeexplore.ieee.org/abstract/document/10258223},
  urldate = {2024-04-12},
  abstract = {The failure of edge devices in the IoT will affect the use of IoT applications. The introduction of the federated learning can train efficient models for devices under the premise of protecting privacy. However, current solutions rarely focus on the problem of data heterogeneity on IoT devices. In this paper, we introduce two personalized federated learning algorithms to implement intrusion detection models, which aim to solve data heterogeneity. We perform diverse partitions on the IoT dataset to simulate data heterogeneity on devices. Our experiments show that the proposed models have high performance in detecting attacks under various data distributions. Under the Non-IID setting, the test accuracies of our models are 95.5\% and 93.4\%, which are 8.4\% and 6.3\% higher than the model using traditional federated learning (FedAvg), respectively.},
  eventtitle = {2023 24st {{Asia-Pacific Network Operations}} and {{Management Symposium}} ({{APNOMS}})},
  isbn = {978-89-950043-9-5},
  keywords = {Data models,Federated learning,Internet of Things,Intrusion detection,Intrusion Detection,IoT,Partitioning algorithms,Performance evaluation,Personalized Federated Learning,Privacy}
}

@article{zhang_Networkattackprediction_2019,
  title = {Network Attack Prediction Method Based on Threat Intelligence for {{IoT}}},
  author = {Zhang, Hongbin and Yi, Yuzi and Wang, Junshe and Cao, Ning and Duan, Qiang},
  date = {2019-11-20},
  journaltitle = {Multimedia Tools and Applications},
  volume = {78},
  number = {21},
  pages = {30257--30270},
  publisher = {{Multimedia Tools and Applications}},
  issn = {1380-7501},
  doi = {10.1007/s11042-018-7005-2},
  url = {http://link.springer.com/10.1007/s11042-018-7005-2},
  abstract = {The Social Internet of Things (SIoT) is a combination of the Internet of Things (IoT) and social networks, which enables better service discovery and improves the user experience. The threat posed by the malicious behavior of social network accounts also affects the SIoT, this paper studies the analysis and prediction of malicious behavior for SIoT accounts, proposed a method for predicting malicious behavior of SIoT accounts based on threat intelligence. The method uses support vector machine (SVM) to obtain threat intelligence related to malicious behavior of target accounts, analyze contextual data in threat intelligence to predict the behavior of malicious accounts. By collecting and analyzing the data in a SIoT environment, verifies the malicious behavior prediction method of SIoT account proposed in this paper.}
}

@article{zhang_PhysicalSafetyCyber_2021,
  title = {Physical {{Safety}} and {{Cyber Security Analysis}} of {{Multi-Agent Systems}}: {{A Survey}} of {{Recent Advances}}},
  author = {Zhang, Dan and Feng, Gang and Shi, Yang and Srinivasan, Dipti},
  date = {2021-02},
  journaltitle = {IEEE/CAA Journal of Automatica Sinica},
  volume = {8},
  number = {2},
  pages = {319--333},
  issn = {2329-9266},
  doi = {10.1109/JAS.2021.1003820},
  url = {https://ieeexplore.ieee.org/document/9317716/},
  abstract = {Multi-agent systems (MASs) are typically composed of multiple smart entities with independent sensing, communication, computing, and decision-making capabilities. Nowadays, MASs have a wide range of applications in smart grids, smart manufacturing, sensor networks, and intelligent transportation systems. Control of the MASs are often coordinated through information interaction among agents, which is one of the most important factors affecting coordination and cooperation performance. However, unexpected physical faults and cyber attacks on a single agent may spread to other agents via information interaction very quickly, and thus could lead to severe degradation of the whole system performance and even destruction of MASs. This paper is concerned with the safety/security analysis and synthesis of MASs arising from physical faults and cyber attacks, and our goal is to present a comprehensive survey on recent results on fault estimation, detection, diagnosis and fault-tolerant control of MASs, and cyber attack detection and secure control of MASs subject to two typical cyber attacks. Finally, the paper concludes with some potential future research topics on the security issues of MASs.}
}

@article{zhang_SecFedNIDSRobustdefense_2022,
  title = {{{SecFedNIDS}}: {{Robust}} Defense for Poisoning Attack against Federated Learning-Based Network Intrusion Detection System},
  shorttitle = {{{SecFedNIDS}}},
  author = {Zhang, Zhao and Zhang, Yong and Guo, Da and Yao, Lei and Li, Zhao},
  date = {2022-09},
  journaltitle = {Future Generation Computer Systems},
  shortjournal = {Future Generation Computer Systems},
  volume = {134},
  pages = {154--169},
  issn = {0167739X},
  doi = {10.1016/j.future.2022.04.010},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X22001339},
  urldate = {2022-07-05},
  abstract = {Federated learning-based network intrusion detection system (FL-based NIDS) has demonstrated tremendous potential in protecting the security of IoT network. It enables learning an effective intrusion detection model from massive traffic data collaboratively without data privacy leakage. However, FL-based NIDS has exhibited inherent vulnerabilities on the poisoning attacks launched by malicious clients. The poisoning attacks aim to corrupt the intrusion detection model and impair its protection capability, by injecting the poisoned traffic data into the local training dataset. We build a secure FL-based NIDS that is robust for the poisoning attacks, namely SecFedNIDS. Firstly, we propose the model-level defensive mechanism based on poisoned model detection. Specifically, we propose the gradient-based important model parameter selection method to provide the effective low-dimensional representations of the uploaded local model parameters, and then we propose the online unsupervised poisoned model detection method to identify the poisoned models and reject them to join in the global intrusion detection model. Subsequently, we design the data-level defensive mechanism based on poisoned data detection. Notably, we propose a novel poisoned data detection method based on class path similarity, to filter out the poisoned traffic data and avoid them participating in subsequent local training. We adopt layer-wise relevance propagation to extract the class path of clean traffic data, and transmit the class paths to the poisoned clients to help distinguish the poisoned traffic data. Results show that SecFedNIDS with the proposed model-level defense boosts the accuracy by up to 48\% under the poisoning attacks on UNSW-NB15 dataset and 36\% on CICIDS2018 dataset, and the proposed data-level defense further improves its accuracy by up to 13\% on CICIDS2018 dataset.},
  langid = {english}
}

@article{zhang_SecFedNIDSRobustdefense_2022a,
  title = {{{SecFedNIDS}}: {{Robust}} Defense for Poisoning Attack against Federated Learning-Based Network Intrusion Detection System},
  shorttitle = {{{SecFedNIDS}}},
  author = {Zhang, Zhao and Zhang, Yong and Guo, Da and Yao, Lei and Li, Zhao},
  date = {2022-09-01},
  journaltitle = {Future Generation Computer Systems},
  shortjournal = {Future Generation Computer Systems},
  volume = {134},
  pages = {154--169},
  issn = {0167-739X},
  doi = {10.1016/j.future.2022.04.010},
  url = {https://www.sciencedirect.com/science/article/pii/S0167739X22001339},
  urldate = {2024-04-12},
  abstract = {Federated learning-based network intrusion detection system (FL-based NIDS) has demonstrated tremendous potential in protecting the security of IoT network. It enables learning an effective intrusion detection model from massive traffic data collaboratively without data privacy leakage. However, FL-based NIDS has exhibited inherent vulnerabilities on the poisoning attacks launched by malicious clients. The poisoning attacks aim to corrupt the intrusion detection model and impair its protection capability, by injecting the poisoned traffic data into the local training dataset. We build a secure FL-based NIDS that is robust for the poisoning attacks, namely SecFedNIDS. Firstly, we propose the model-level defensive mechanism based on poisoned model detection. Specifically, we propose the gradient-based important model parameter selection method to provide the effective low-dimensional representations of the uploaded local model parameters, and then we propose the online unsupervised poisoned model detection method to identify the poisoned models and reject them to join in the global intrusion detection model. Subsequently, we design the data-level defensive mechanism based on poisoned data detection. Notably, we propose a novel poisoned data detection method based on class path similarity, to filter out the poisoned traffic data and avoid them participating in subsequent local training. We adopt layer-wise relevance propagation to extract the class path of clean traffic data, and transmit the class paths to the poisoned clients to help distinguish the poisoned traffic data. Results show that SecFedNIDS with the proposed model-level defense boosts the accuracy by up to 48\% under the poisoning attacks on UNSW-NB15 dataset and 36\% on CICIDS2018 dataset, and the proposed data-level defense further improves its accuracy by up to 13\% on CICIDS2018 dataset.},
  keywords = {Defensive mechanism,Federated learning,Network intrusion detection,Poisoned data detection,Poisoned model detection,Poisoning attacks}
}

@inproceedings{zhang_ShuffleFLgradientpreservingfederated_2021,
  title = {{{ShuffleFL}}: Gradient-Preserving Federated Learning Using Trusted Execution Environment},
  shorttitle = {{{ShuffleFL}}},
  booktitle = {Proceedings of the 18th {{ACM International Conference}} on {{Computing Frontiers}}},
  author = {Zhang, Yuhui and Wang, Zhiwei and Cao, Jiangfeng and Hou, Rui and Meng, Dan},
  date = {2021-05-11},
  pages = {161--168},
  publisher = {ACM},
  location = {Virtual Event Italy},
  doi = {10.1145/3457388.3458665},
  url = {https://dl.acm.org/doi/10.1145/3457388.3458665},
  urldate = {2023-04-03},
  abstract = {Federated Learning (FL) is a promising approach to privacy-preserving machine learning. However, recent works reveal that gradients can leak private data. Using trusted SGX-processors for this task yields gradient-preserving but requires to prevent exploitation of any side-channel attacks.},
  eventtitle = {{{CF}} '21: {{Computing Frontiers Conference}}},
  isbn = {978-1-4503-8404-9},
  langid = {english}
}

@inproceedings{zhang_surveysecurityprivacy_2021,
  title = {A Survey on Security and Privacy Threats to Federated Learning},
  booktitle = {2021 {{International Conference}} on {{Networking}} and {{Network Applications}} ({{NaNA}})},
  author = {Zhang, Junpeng and Li, Mengqian and Zeng, Shuiguang and Xie, Bin and Zhao, Dongmei},
  date = {2021-10},
  pages = {319--326},
  doi = {10.1109/NaNA53684.2021.00062},
  url = {https://ieeexplore.ieee.org/abstract/document/9634881},
  urldate = {2024-04-12},
  abstract = {Federated learning (FL) has nourished a promising scheme to solve the data silo, which enables multiple clients to construct a joint model without centralizing data. The critical concerns for flourishing FL applications are that build a security and privacy-preserving learning environment. It is thus highly necessary to comprehensively identify and classify potential threats to utilize FL under security guarantees. This paper starts from the perspective of launched attacks with different computing participants to construct the unique threats classification, highlighting the significant attacks, e.g., poisoning attacks, inference attacks, and generative adversarial networks (GAN) attacks. Our study shows that existing FL protocols do not always provide sufficient security, containing various attacks from both clients and servers. GAN attacks lead to larger significant threats among the kinds of threats given the invisible of the attack process. Moreover, we summarize a detailed review of several defense mechanisms and approaches to resist privacy risks and security breaches. Then advantages and weaknesses are generalized, respectively. Finally, we conclude the paper to prospect the challenges and some potential research directions.},
  eventtitle = {2021 {{International Conference}} on {{Networking}} and {{Network Applications}} ({{NaNA}})},
  keywords = {Collaborative work,Computational modeling,Federated learning,GAN attacks.,Generative adversarial networks,IEEE Standards,inference attacks,poisoning attacks,Privacy,privacy-preserving,Protocols,Resists,security threat}
}

@unpublished{zhang_TrainingFederatedGANs_2021,
  title = {Training {{Federated GANs}} with {{Theoretical Guarantees}}: {{A Universal Aggregation Approach}}},
  shorttitle = {Training {{Federated GANs}} with {{Theoretical Guarantees}}},
  author = {Zhang, Yikai and Qu, Hui and Chang, Qi and Liu, Huidong and Metaxas, Dimitris and Chen, Chao},
  date = {2021-02-09},
  eprint = {2102.04655},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2102.04655},
  urldate = {2021-10-06},
  abstract = {Recently, Generative Adversarial Networks (GANs) have demonstrated their potential in federated learning, i.e., learning a centralized model from data privately hosted by multiple sites. A federatedGAN jointly trains a centralized generator and multiple private discriminators hosted at different sites. A major theoretical challenge for the federated GAN is the heterogeneity of the local data distributions. Traditional approaches cannot guarantee to learn the target distribution, which isa mixture of the highly different local distributions. This paper tackles this theoretical challenge, and for the first time, provides a provably correct framework for federated GAN. We propose a new approach called Universal Aggregation, which simulates a centralized discriminator via carefully aggregating the mixture of all private discriminators. We prove that a generator trained with this simulated centralized discriminator can learn the desired target distribution. Through synthetic and real datasets, we show that our method can learn the mixture of largely different distributions where existing federated GAN methods fail.},
  langid = {english},
  keywords = {\_read,â›” No DOI found,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,I.2.11,I.2.6}
}

@online{zhao_MultiAgentLearningResilient_2022,
  title = {Multi-{{Agent Learning}} for {{Resilient Distributed Control Systems}}},
  author = {Zhao, Yuhan and Rieger, Craig and Zhu, Quanyan},
  date = {2022-08-09},
  eprint = {2208.05060},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2208.05060},
  urldate = {2022-08-16},
  abstract = {Resilience describes a system's ability to function under disturbances and threats. Many critical infrastructures, including smart grids and transportation networks, are large-scale complex systems consisting of many interdependent subsystems. Decentralized architecture becomes a key resilience design paradigm for large-scale systems. In this book chapter, we present a multi-agent system (MAS) framework for distributed large-scale control systems and discuss the role of MAS learning in resiliency. This chapter introduces the creation of an artificial intelligence (AI) stack in the MAS to provide computational intelligence for subsystems to detect, respond, and recover. We discuss the application of learning methods at the cyber and physical layers of the system. The discussions focus on distributed learning algorithms for subsystems to respond to each other, and game-theoretic learning for them to respond to disturbances and adversarial behaviors. The book chapter presents a case study of distributed renewable energy systems to elaborate on the MAS architecture and its interface with the AI stack.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Electrical Engineering and Systems Science - Systems and Control}
}

@inproceedings{zhao_MultiTaskNetworkAnomaly_2019,
  title = {Multi-{{Task Network Anomaly Detection}} Using {{Federated Learning}}},
  booktitle = {Proceedings of the {{Tenth International Symposium}} on {{Information}} and {{Communication Technology}}  - {{SoICT}} 2019},
  author = {Zhao, Ying and Chen, Junjun and Wu, Di and Teng, Jian and Yu, Shui},
  date = {2019},
  pages = {273--279},
  publisher = {ACM Press},
  location = {Hanoi, Ha Long Bay, Viet Nam},
  doi = {10.1145/3368926.3369705},
  url = {http://dl.acm.org/citation.cfm?doid=3368926.3369705},
  urldate = {2021-06-07},
  abstract = {Because of the complexity of network traffic, there are various significant challenges in the network anomaly detection fields. One of the major challenges is the lack of labeled training data. In this paper, we use federated learning to tackle data scarcity problem and to preserve data privacy, where multiple participants collaboratively train a global model. Unlike the centralized training architecture, participants do not need to share their training to the server in federated learning, which can prevent the training data from being exploited by attackers. Moreover, most of the previous works focus on one specific task of anomaly detection, which restricts the application areas and can not provide more valuable information to network administrators. Therefore, we propose a multi-task deep neural network in federated learning (MT-DNN-FL) to perform network anomaly detection task, VPN (Tor) traffic recognition task, and traffic classification task, simultaneously. Compared with multiple single-task models, the multi-task method can reduce training time overhead. Experiments conducted on well-known CICIDS2017, ISCXVPN2016, and ISCXTor2016 datasets, show that the detection and classification performance achieved by the proposed method is better than the baseline methods in centralized training architecture.},
  eventtitle = {The {{Tenth International Symposium}}},
  isbn = {978-1-4503-7245-9},
  langid = {english},
  keywords = {survey-fids}
}

@article{zhao_PersonalizedFederatedFewShot_2022,
  title = {Personalized {{Federated Few-Shot Learning}}},
  author = {Zhao, Yunfeng and Yu, Guoxian and Wang, Jun and Domeniconi, Carlotta and Guo, Maozu and Zhang, Xiangliang and Cui, Lizhen},
  date = {2022},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  pages = {1--11},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2022.3190359},
  abstract = {Personalized federated learning (PFL) learns a personalized model for each client in a decentralized manner, where each client owns private data that are not shared and data among clients are non-independent and identically distributed (i.i.d.) However, existing PFL solutions assume that clients have sufficient training samples to jointly induce personalized models. Thus, existing PFL solutions cannot perform well in a few-shot scenario, where most or all clients only have a handful of samples for training. Furthermore, existing few-shot learning (FSL) approaches typically need centralized training data; as such, these FSL methods are not applicable in decentralized scenarios. How to enable PFL with limited training samples per client is a practical but understudied problem. In this article, we propose a solution called personalized federated few-shot learning (pFedFSL) to tackle this problem. Specifically, pFedFSL learns a personalized and discriminative feature space for each client by identifying which models perform well on which clients, without exposing local data of clients to the server and other clients, and which clients should be selected for collaboration with the target client. In the learned feature spaces, each sample is made closer to samples of the same category and farther away from samples of different categories. Experimental results on four benchmark datasets demonstrate that pFedFSL outperforms competitive baselines across different settings.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Networks}} and {{Learning Systems}}},
  keywords = {\_read\_urgently,Collaboration,Collaborative work,Computational modeling,Data models,Distributed databases,feature space learning,few-shot learning (FSL),non-independent and identically distributed (i.i.d.) data,personalized federated learning (PFL),Servers,Training,Training data}
}

@article{zhao_Reviewerassignmentalgorithms_2022,
  title = {Reviewer Assignment Algorithms for Peer Review Automation: {{A}} Survey},
  shorttitle = {Reviewer Assignment Algorithms for Peer Review Automation},
  author = {Zhao, Xiquan and Zhang, Yangsen},
  date = {2022-09-01},
  journaltitle = {Information Processing \& Management},
  shortjournal = {Information Processing \& Management},
  volume = {59},
  number = {5},
  pages = {103028},
  issn = {0306-4573},
  doi = {10.1016/j.ipm.2022.103028},
  url = {https://www.sciencedirect.com/science/article/pii/S0306457322001388},
  urldate = {2024-02-12},
  abstract = {Assigning paper to suitable reviewers is of great significance to ensure the accuracy and fairness of peer review results. In the past three decades, many researchers have made a wealth of achievements on the reviewer assignment problem (RAP). In this survey, we provide a comprehensive review of the primary research achievements on reviewer assignment algorithm from 1992 to 2022. Specially, this survey first discusses the background and necessity of automatic reviewer assignment, and then systematically summarize the existing research work from three aspects, i.e., construction of candidate reviewer database, computation of matching degree between reviewers and papers, and reviewer assignment optimization algorithm, with objective comments on the advantages and disadvantages of the current algorithms. Afterwards, the evaluation metrics and datasets of reviewer assignment algorithm are summarized. To conclude, we prospect the potential research directions of RAP. Since there are few comprehensive survey papers on reviewer assignment algorithm in the past ten years, this survey can serve as a valuable reference for the related researchers and peer review organizers.},
  keywords = {Information retrieval,Matching degree,Natural language processing,Optimization algorithm,Peer review,Reviewer assignment problem}
}

@article{zhao_SemisupervisedFederatedLearningBasedIntrusion_2023,
  title = {Semisupervised {{Federated-Learning-Based Intrusion Detection Method}} for {{Internet}} of {{Things}}},
  author = {Zhao, Ruijie and Wang, Yijun and Xue, Zhi and Ohtsuki, Tomoaki and Adebisi, Bamidele and Gui, Guan},
  date = {2023-05},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {10},
  number = {10},
  pages = {8645--8657},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2022.3175918},
  url = {https://ieeexplore.ieee.org/abstract/document/9777753},
  urldate = {2024-04-12},
  abstract = {Federated learning (FL) has become an increasingly popular solution for intrusion detection to avoid data privacy leakage in Internet of Things (IoT) edge devices. Existing FL-based intrusion detection methods, however, suffer from three limitations: 1) model parameters transmitted in each round may be used to recover private data, which leads to security risks; 2) not independent and identically distributed (non-IID) private data seriously adversely affect the training of FL (especially distillation-based FL); and 3) high communication overhead caused by the large model size greatly hinders the actual deployment of the solution. To address these problems, this article develops an intrusion detection method based on a semisupervised FL scheme via knowledge distillation. First, our proposed method leverages unlabeled data via distillation method to enhance the classifier performance. Second, we build a model based on convolutional neural networks (CNNs) for extracting deep features of the traffic packets, and take this model as both the classifier network and discriminator network. Third, the discriminator is designed to improve the quality of each client's predicted labels, and to avoid the failure of distillation training caused by a large number of incorrect predictions under private non-IID data. Moreover, the combination of the hard-label strategy and voting mechanism further reduces communication overhead. The experiments on the real-world traffic data set with three non-IID scenarios show that our proposed method can achieve better detection performance as well as lower communication overhead than state-of-the-art methods.},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {Data models,Distributed databases,Feature extraction,Federated learning (FL),Internet of Things,intrusion detection,Intrusion detection,knowledge distillation,semisupervised learning,Servers,Training}
}

@online{zhao_ShieldingCollaborativeLearning_2020,
  title = {Shielding {{Collaborative Learning}}: {{Mitigating Poisoning Attacks}} through {{Client-Side Detection}}},
  shorttitle = {Shielding {{Collaborative Learning}}},
  author = {Zhao, Lingchen and Hu, Shengshan and Wang, Qian and Jiang, Jianlin and Shen, Chao and Luo, Xiangyang and Hu, Pengfei},
  date = {2020-03-09},
  eprint = {1910.13111},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1910.13111},
  urldate = {2022-08-28},
  abstract = {Collaborative learning allows multiple clients to train a joint model without sharing their data with each other. Each client performs training locally and then submits the model updates to a central server for aggregation. Since the server has no visibility into the process of generating the updates, collaborative learning is vulnerable to poisoning attacks where a malicious client can generate a poisoned update to introduce backdoor functionality to the joint model. The existing solutions for detecting poisoned updates, however, fail to defend against the recently proposed attacks, especially in the non-IID setting. In this paper, we present a novel defense scheme to detect anomalous updates in both IID and non-IID settings. Our key idea is to realize client-side cross-validation, where each update is evaluated over other clients' local data. The server will adjust the weights of the updates based on the evaluation results when performing aggregation. To adapt to the unbalanced distribution of data in the non-IID setting, a dynamic client allocation mechanism is designed to assign detection tasks to the most suitable clients. During the detection process, we also protect the client-level privacy to prevent malicious clients from stealing the training data of other clients, by integrating differential privacy with our design without degrading the detection performance. Our experimental evaluations on two real-world datasets show that our scheme is significantly robust to two representative poisoning attacks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@dataset{zheng_ResearchDatasetsTaxonomy_2018,
  title = {Research {{Datasets}}: {{Taxonomy}} and {{Empirical Analysis}}},
  shorttitle = {Replication {{Data}} For},
  author = {Zheng, Muwei and Robbins, Hannah and Chai, Zimo and Thapa, Prakash and Moore, Tyler},
  date = {2018},
  doi = {10.7910/DVN/4EPUIA},
  url = {https://dataverse.harvard.edu/citation?persistentId=doi:10.7910/DVN/4EPUIA},
  urldate = {2022-08-08},
  abstract = {We inspect 965 cybersecurity research papers published between 2012 and 2016 in order to understand better how datasets are used, produced and shared. We construct a taxonomy of the types of data created and shared, informed and validated by the examined papers. We then analyze the gathered data on datasets. Three quarters of existing datasets used as input to research are publicly available, but less than one fifth of datasets created by researchers are publicly shared. Using a series of linear regressions, we demonstrate that those researchers who do make public the datasets they create are rewarded with more citations to the associated papers. Hence, we conclude that an under-appreciated incentive exists for researchers to share their created datasets with the broader research community.},
  langid = {english}
}

@article{zhong_Efficientdynamicmultikeyword_2020,
  title = {Efficient Dynamic Multi-Keyword Fuzzy Search over Encrypted Cloud Data},
  author = {Zhong, Hong and Li, Zhanfei and Cui, Jie and Sun, Yue and Liu, Lu},
  date = {2020-01},
  journaltitle = {Journal of Network and Computer Applications},
  volume = {149},
  pages = {102469},
  publisher = {Elsevier Ltd},
  issn = {10848045},
  doi = {10.1016/j.jnca.2019.102469},
  url = {https://doi.org/10.1016/j.jnca.2019.102469},
  abstract = {Multi-keyword search of encrypted cloud data has attracted extensive attention worldwide in the recent years due to the increasing concern for data security and privacy in Cloud Computing. Fault-tolerance is important for multi-keyword fuzzy search which can provide accurate results even with the presence of minor spelling and typographical errors in the search keywords. But, existing fuzzy search schemes lack efficiency due to their high computational overhead and do not support file dynamic updates. This paper proposes an efficient dynamic multi-keyword fuzzy search scheme for encrypted cloud data to support dynamic file updates. Locality sensitive hashing (LSH) and Bloom filters are employed to generate index vectors and query vectors. Based on the generated vectors, a balanced binary tree is constructed as the index for the entire file set, and a Top-k search algorithm is developed to search k files that are most relevant to a given query with the help of the index tree. Extensive experiments conducted on real-world datasets demonstrate that our scheme is more efficient than existing similar schemes.},
  issue = {October 2019}
}

@inproceedings{zhou_AcceleratingDistributedDeep_2023,
  title = {Accelerating {{Distributed Deep Learning Training}} with {{Compression Assisted Allgather}} and {{Reduce-Scatter Communication}}},
  booktitle = {2023 {{IEEE International Parallel}} and {{Distributed Processing Symposium}} ({{IPDPS}})},
  author = {Zhou, Qinghua and Anthony, Quentin and Xu, Lang and Shafi, Aamir and Abduljabbar, Mustafa and Subramoni, Hari and Panda, Dhabaleswar K. DK},
  date = {2023-05},
  pages = {134--144},
  issn = {1530-2075},
  doi = {10.1109/IPDPS54959.2023.00023},
  abstract = {Fully Sharded Data Parallel (FSDP) technology achieves higher performance by scaling out data-parallel training of Deep Learning (DL) models. It shards the model parameters, gradients, and optimizer states of the model among multiple GPUs. Consequently, this requires data-intensive Allgather and Reduce-Scatter communication to share the model parameters, which becomes a bottleneck. Existing schemes that use GPU-aware MPI libraries are highly prone to saturating the interconnect bandwidth. Therefore, integrating GPU-based compression into MPI libraries has proven efficient to achieve faster training time. In this paper, we propose an optimized Ring algorithm of Allgather and Reduce-Scatter collectives that encompass an efficient collective-level online compression scheme. At the microbenchmark level, Allgather achieves benefits of up to 83.6\% and 30.3\% compared to the baseline and existing point-to-point-based compression in a state-of-the-art MPI library on modern GPU clusters. Reduce-Scatter achieves 88.1\% and 40.6\% compared to baseline and point-to-point compression, respectively. For distributed DL training with PyTorch-FSDP, our approach yields 31.7\% faster training than the baseline, and up to 12.5\% compared to the existing point-to-point-based compression while maintaining similar accuracy.},
  eventtitle = {2023 {{IEEE International Parallel}} and {{Distributed Processing Symposium}} ({{IPDPS}})},
  keywords = {Allgather,Bandwidth,Clustering algorithms,Compression,Deep learning,Deep Learning,Distributed databases,Distributed processing,FSDP,GPU-Aware MPI,Graphics processing units,Reduce-Scatter,Training}
}

@unpublished{zhou_DeFTAPlugandPlayDecentralized_2022,
  title = {{{DeFTA}}: {{A Plug-and-Play Decentralized Replacement}} for {{FedAvg}}},
  shorttitle = {{{DeFTA}}},
  author = {Zhou, Yuhao and Shi, Minjia and Tian, Yuxin and Ye, Qing and Lv, Jiancheng},
  date = {2022-04-06},
  eprint = {2204.02632},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2204.02632},
  urldate = {2022-04-13},
  abstract = {Federated learning (FL) is identified as a crucial enabler for large-scale distributed machine learning (ML) without the need for local raw dataset sharing, substantially reducing privacy concerns and alleviating the isolated data problem. In reality, the prosperity of FL is largely due to a centralized framework called FedAvg [1], in which workers are in charge of model training and servers are in control of model aggregation. However, FedAvg's centralized worker-server architecture has raised new concerns, be it the low scalability of the cluster, the risk of data leakage, and the failure or even defection of the central server. To overcome these problems, we propose Decentralized Federated Trusted Averaging (DeFTA), a decentralized FL framework that serves as a plug-and-play replacement for FedAvg, instantly bringing better security, scalability, and fault-tolerance to the federated learning process after installation. In principle, it fundamentally resolves the above-mentioned issues from an architectural perspective without compromises or tradeoffs, primarily consisting of a new model aggregating formula with theoretical performance analysis, and a decentralized trust system (DTS) to greatly improve system robustness. Note that since DeFTA is an alternative to FedAvg at the framework level, prevalent algorithms published for FedAvg can be also utilized in DeFTA with ease. Extensive experiments on six datasets and six basic models suggest that DeFTA not only has comparable performance with FedAvg in a more realistic setting, but also achieves great resilience even when 66\% of workers are malicious. Furthermore, we also present an asynchronous variant of DeFTA to endow it with more powerful usability.},
  langid = {english},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},â›” No DOI found,Computer Science - Artificial Intelligence}
}

@article{zhou_DifferentiallyPrivateFederated_2022,
  title = {A {{Differentially Private Federated Learning Model}} against {{Poisoning Attacks}} in {{Edge Computing}}},
  author = {Zhou, Jun and Wu, Nan and Wang, Yisong and Gu, Shouzhen and Cao, Zhenfu and Dong, Xiaolei and Choo, Kim-Kwang Raymond},
  date = {2022},
  journaltitle = {IEEE Transactions on Dependable and Secure Computing},
  pages = {1--1},
  issn = {1941-0018},
  doi = {10.1109/TDSC.2022.3168556},
  abstract = {Federated learning is increasingly popular, as it allows us to circumvent challenges due to data islands, by training a global model using data from one or more data owners/sources. However, in edge computing, resource-constrained end devices are vulnerable to be compromised and abused to facilitate poisoning attacks. Privacy-preserving is another important property to consider when dealing with sensitive user data on end devices. Most existing approaches only consider either defending against poisoning attacks or supporting privacy, but not both properties simultaneously. In this paper, we propose a differentially private federated learning model against poisoning attacks, designed for edge computing deployment. First, we design a weight-based algorithm to perform anomaly detection on the parameters uploaded by end devices in edge nodes, which improves detection rate using only small-size validation datasets and minimizes the communication cost. Then, differential privacy technology is leveraged to protect the privacy of both data and model in an edge computing setting. We also evaluate and compare the detection performance in the presence of random and customized malicious end devices with the state-of-the-art, in terms of attack resiliency, communication and computation costs. Experimental results demonstrate that our scheme can achieve an optimal tradeoff between security, efficiency and accuracy.},
  eventtitle = {{{IEEE Transactions}} on {{Dependable}} and {{Secure Computing}}},
  keywords = {Collaborative work,Computational modeling,Data models,Differential privacy,Edge computing,Federated learning,High-practicability,Image edge detection,Poisoning attack,Privacy,Training}
}

@inproceedings{zhou_ModelingAdversarialNoise_2022,
  title = {Modeling {{Adversarial Noise}} for {{Adversarial Training}}},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Machine Learning}}},
  author = {Zhou, Dawei and Wang, Nannan and Han, Bo and Liu, Tongliang},
  date = {2022-06-28},
  pages = {27353--27366},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v162/zhou22k.html},
  urldate = {2024-03-28},
  abstract = {Deep neural networks have been demonstrated to be vulnerable to adversarial noise, promoting the development of defense against adversarial attacks. Motivated by the fact that adversarial noise contains well-generalizing features and that the relationship between adversarial data and natural data can help infer natural data and make reliable predictions, in this paper, we study to model adversarial noise by learning the transition relationship between adversarial labels (i.e. the flipped labels used to generate adversarial data) and natural labels (i.e. the ground truth labels of the natural data). Specifically, we introduce an instance-dependent transition matrix to relate adversarial labels and natural labels, which can be seamlessly embedded with the target model (enabling us to model stronger adaptive adversarial noise). Empirical evaluations demonstrate that our method could effectively improve adversarial accuracy.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@article{zhou_PFLFPrivacyPreservingFederated_2022,
  title = {{{PFLF}}: {{Privacy-Preserving Federated Learning Framework}} for {{Edge Computing}}},
  shorttitle = {{{PFLF}}},
  author = {Zhou, Hao and Yang, Geng and Dai, Hua and Liu, Guoxiu},
  date = {2022},
  journaltitle = {IEEE Transactions on Information Forensics and Security},
  volume = {17},
  pages = {1905--1918},
  issn = {1556-6021},
  doi = {10.1109/TIFS.2022.3174394},
  abstract = {Federated learning (FL) can protect clients' privacy from leakage in distributed machine learning. Applying federated learning to edge computing can protect the privacy of edge clients and benefit edge computing. Nevertheless, eavesdroppers can analyze the parameter information to specify clients' private information and model features. And it is difficult to achieve a high privacy level, convergence, and low communication overhead during the entire process in the FL framework. In this paper, we propose a novel privacy-preserving federated learning framework for edge computing (PFLF). In PFLF, each client and the application server add noise before sending the data. To protect the privacy of clients, we design a flexible arrangement mechanism to count the optimal training times for clients. We prove that PFLF guarantees the privacy of clients and servers during the entire training process. Then, we theoretically prove that PFLF has three main properties: 1) For a given privacy level and model aggregation times, there is an optimal number of participating times for clients; 2) There is an upper and lower bound of convergence; 3) PFLF achieves low communication overhead by designing a flexible participation training mechanism. Simulation experiments confirm the correctness of our theoretical analysis. Therefore, PFLF helps design a framework to balance privacy levels and convergence and achieve low communication overhead when there is a part of clients dropping out of training.},
  eventtitle = {{{IEEE Transactions}} on {{Information Forensics}} and {{Security}}},
  keywords = {Collaborative work,Computational modeling,Convergence,convergence performance,differential privacy,edge computing,Edge computing,Federated learning,information leakage,Privacy,Servers,Training}
}

@article{zhou_surveycoordinatedattacks_2010,
  title = {A Survey of Coordinated Attacks and Collaborative Intrusion Detection},
  author = {Zhou, Chenfeng Vincent and Leckie, Christopher and Karunasekera, Shanika},
  date = {2010-02},
  journaltitle = {Computers \& Security},
  shortjournal = {Computers \& Security},
  volume = {29},
  number = {1},
  pages = {124--140},
  issn = {01674048},
  doi = {10.1016/j.cose.2009.06.008},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S016740480900073X},
  urldate = {2021-07-21},
  abstract = {Coordinated attacks, such as large-scale stealthy scans, worm outbreaks and distributed denial-of-service (DDoS) attacks, occur in multiple networks simultaneously. Such attacks are extremely difficult to detect using isolated intrusion detection systems (IDSs) that monitor only a limited portion of the Internet. In this paper, we summarize the current research directions in detecting such attacks using collaborative intrusion detection systems (CIDSs). In particular, we highlight two main challenges in CIDS research: CIDS architectures and alert correlation algorithms. We review the current CIDS approaches in terms of these two challenges. We conclude by highlighting opportunities for an integrated solution to large-scale collaborative intrusion detection.},
  langid = {english},
  keywords = {\_read,+survey}
}

@article{zhu_Attentionbasedfederatedincremental_2022,
  title = {Attention-Based Federated Incremental Learning for Traffic Classification in the {{Internet}} of {{Things}}},
  author = {Zhu, Meng-yuan and Chen, Zhuo and Chen, Ke-fan and Lv, Na and Zhong, Yun},
  date = {2022-03},
  journaltitle = {Computer Communications},
  shortjournal = {Computer Communications},
  volume = {185},
  pages = {168--175},
  issn = {01403664},
  doi = {10.1016/j.comcom.2022.01.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0140366422000123},
  urldate = {2022-01-31},
  abstract = {The Internet of Things (IoT) traffic follows non-independent and identical distribution (non-IID). Traditional machine learning classification methods will cause low classification accuracy, high communication costs, and privacy leakage issues. Federated Learning enables several clients to train a deep learning model collaboratively without requiring any of the clients to share their local data with a centralized server. In this paper, we propose a novel attention-based federated incremental learning algorithm: Fed-SOINN. We introduce the attention mechanism to improve the weight of parameters uploaded by clients which are beneficial to the global model, where instead of the full gradient, only a small subset of important gradients is communicated. Meanwhile, we improve the sparsity of the model by upgrading the online optimization function in Fed-SOINN, it also brings faster convergence speed and higher accuracy in the changeable network environment. Results reveal that Fed-SOINN has improved detection accuracy by 3.1\% compared with benchmark methods and can reduce the number of communications rounds up to 73\%. When facing new traffic categories, the incremental learning mechanism in Fed-SOINN also effectively identify unknown traffic categories.},
  langid = {english}
}

@article{zhu_FederatedlearningnonIID_2021,
  title = {Federated Learning on Non-{{IID}} Data: {{A}} Survey},
  shorttitle = {Federated Learning on Non-{{IID}} Data},
  author = {Zhu, Hangyu and Xu, Jinjin and Liu, Shiqing and Jin, Yaochu},
  date = {2021-11-20},
  journaltitle = {Neurocomputing},
  shortjournal = {Neurocomputing},
  volume = {465},
  pages = {371--390},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2021.07.098},
  url = {https://www.sciencedirect.com/science/article/pii/S0925231221013254},
  urldate = {2024-05-16},
  abstract = {Federated learning is an emerging distributed machine learning framework for privacy preservation. However, models trained in federated learning usually have worse performance than those trained in the standard centralized learning mode, especially when the training data are not independent and identically distributed (Non-IID) on the local devices. In this survey, we provide a detailed analysis of the influence of Non-IID data on both parametric and non-parametric machine learning models in both horizontal and vertical federated learning. In addition, current research work on handling challenges of Non-IID data in federated learning are reviewed, and both advantages and disadvantages of these approaches are discussed. Finally, we suggest several future research directions before concluding the paper.},
  keywords = {Federated learning,Machine learning,Non-IID data,Privacy preservation}
}

@article{zhu_ResilientCommunicationEfficient_2022,
  title = {Resilient and {{Communication Efficient Learning}} for {{Heterogeneous Federated Systems}}},
  author = {Zhu, Zhuangdi and Hong, Junyuan and Drew, Steve and Zhou, Jiayu},
  date = {2022},
  pages = {23},
  abstract = {The rise of Federated Learning (FL) is bringing machine learning to edge computing by utilizing data scattered across edge devices. However, the heterogeneity of edge network topologies and the uncertainty of wireless transmission are two major obstructions of FL's wide application in edge computing, leading to prohibitive convergence time and high communication cost. In this work, we propose an FL scheme to address both challenges simultaneously. Specifically, we enable edge devices to learn self-distilled neural networks that are readily prunable to arbitrary sizes, which capture the knowledge of the learning domain in a nested and progressive manner. Not only does our approach tackle system heterogeneity by serving edge devices with varying model architectures, but it also alleviates the issue of connection uncertainty by allowing transmitting part of the model parameters under faulty network connections, without wasting the contributing knowledge of the transmitted parameters. Extensive empirical studies show that under system heterogeneity and network instability, our approach demonstrates significant resilience and higher communication efficiency compared to the state-of-the-art.},
  langid = {english},
  keywords = {\_read\_urgently,â›” No DOI found}
}

@unpublished{zhuo_FederatedDeepReinforcement_2020,
  title = {Federated {{Deep Reinforcement Learning}}},
  author = {Zhuo, Hankz Hankui and Feng, Wenfeng and Lin, Yufeng and Xu, Qian and Yang, Qiang},
  date = {2020-02-09},
  eprint = {1901.08277},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1901.08277},
  urldate = {2022-01-31},
  abstract = {In deep reinforcement learning, building policies of high-quality is challenging when the feature space of states is small and the training data is limited. Despite the success of previous transfer learning approaches in deep reinforcement learning, directly transferring data or models from an agent to another agent is often not allowed due to the privacy of data and/or models in many privacy-aware applications. In this paper, we propose a novel deep reinforcement learning framework to federatively build models of high-quality for agents with consideration of their privacies, namely Federated deep Reinforcement Learning (FedRL). To protect the privacy of data and models, we exploit Gausian differentials on the information shared with each other when updating their local models. In the experiment, we evaluate our FedRL framework in two diverse domains, Grid-world and Text2Action domains, by comparing to various baselines.},
  langid = {english},
  keywords = {â›” No DOI found,Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
}

@article{zohrafilali_GlobalTrustTrust_2015,
  title = {Global {{Trust}}: {{A Trust Model}} for {{Cloud Service Selection}}},
  shorttitle = {Global {{Trust}}},
  author = {Zohra Filali, Fatima and Yagoubi, Belabbes},
  date = {2015-04-08},
  journaltitle = {International Journal of Computer Network and Information Security},
  shortjournal = {IJCNIS},
  volume = {7},
  number = {5},
  pages = {41--50},
  issn = {20749090, 20749104},
  doi = {10.5815/ijcnis.2015.05.06},
  url = {http://www.mecs-press.org/ijcnis/ijcnis-v7-n5/v7n5-6.html},
  urldate = {2024-07-03},
  abstract = {Cloud Computing refers to network-based service provided by a large number of computers, sharing computing and storage resources. Combined with ondemand provisioning mechanisms and relied on a payper-use business model.},
  langid = {english}
}

@article{zuo_OverviewRecentAdvances_2018,
  title = {An {{Overview}} of {{Recent Advances}} in {{Fixed-Time Cooperative Control}} of {{Multiagent Systems}}},
  author = {Zuo, Zongyu and Han, Qing-Long and Ning, Boda and Ge, Xiaohua and Zhang, Xian-Ming},
  date = {2018-06},
  journaltitle = {IEEE Transactions on Industrial Informatics},
  volume = {14},
  number = {6},
  pages = {2322--2334},
  publisher = {IEEE},
  issn = {1551-3203},
  doi = {10.1109/TII.2018.2817248},
  url = {https://ieeexplore.ieee.org/document/8322314/},
  abstract = {Fixed-time cooperative control is currently a hot research topic in multiagent systems since it can provide a guaranteed settling time, which does not depend on initial conditions. Compared with asymptotic cooperative control algorithms, fixed-time cooperative control algorithms can achieve better closed-loop performance and disturbance rejection properties. Different from finite-time control, fixed-time cooperative control produces the faster rate of convergence and provides an explicit estimation of the settling time independent of initial conditions, which is desirable for multiagent systems. This paper aims at presenting an overview of recent advances in fixed-time cooperative control of multiagent systems. Some fundamental concepts about finite- and fixed-time stability and stabilization are first recalled with insight understanding. Then, recent results in finite- and fixed-time cooperative control are reviewed in detail and categorized according to different agent dynamics. Finally, this paper raises several challenging issues that need to be addressed in the near future.}
}
